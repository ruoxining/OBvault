{"config":{"lang":["ja"],"separator":"[\\s\\-\uff0c\u3002]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"Home","text":"<p>Hi there \ud83d\udc4b</p> <p>\u6211\u7684\u7b14\u8bb0\u4e0d\u591a\uff01\uff08\u4ee5\u540e\u4e5f\u4e0d\u4f1a\u591a\u7684\ud83d\ude24\uff09 \u6b22\u8fce\u6765\u770b\u6211\u7684\u7b14\u8bb0\uff01</p> <p>\u5927\u90e8\u5206\u5185\u5bb9\u8fd8\u5728\u4e00\u70b9\u4e00\u70b9\u65bd\u5de5\u4e2d\uff0c\u8bf7\u7a0d\u7b49\uff01</p>"},{"location":"#_1","title":"\u63a8\u8350\u9605\u8bfb","text":""},{"location":"#_2","title":"\u7533\u8bf7\u5fc3\u5f97","text":"<p>\u4ece\u82f1\u4e13\u8f6cCS\u548cNLP\u7684\u5efa\u8bae\u5e16\uff01</p>"},{"location":"#computer-science-notes","title":"Computer Science Notes","text":"<p>C\u5927\u7a0blibgraphics\u8e29\u5751\u6587\u6863 \uff08\u4f46\u5176\u5b9e\u9047\u5230\u7684\u5751\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u8fd9\u91cc\u5217\u51fa\u6765\u7684 \u6b22\u8fceissue\u6216\u90ae\u4ef6\u50ac\u66f4\uff01\uff09</p> <p>C++\u542c\u8bfe\u7b14\u8bb0</p> <p>OS\u64cd\u4f5c\u7cfb\u7edf\u7b14\u8bb0</p>"},{"location":"#deep-learning-notes","title":"Deep Learning Notes","text":"<p>\u62b1\u6b49\uff0c\u8fd9\u680f\u5168\u662fTODO\uff0c\uff0c</p>"},{"location":"#linguistics-notes","title":"Linguistics Notes","text":"<p>ZJU Semantics Notes \uff08\u867d\u7136\u6392\u7248\u4ecd\u4e0d\u662f\u5f88\u597d\u770b\u4f46\u53ef\u80fd\u662f\u5168\u7f51\u9996\u4e2a\ud83d\ude2d\uff09</p>"},{"location":"#_3","title":"\u5176\u5b83\u8bfe\u7a0b","text":"<p>ZJU\u6253\u5f00\u827a\u672f\u4e4b\u95e8-\u94a2\u7434\u671f\u672b\u590d\u4e60\u7b14\u8bb0</p>"},{"location":"#_4","title":"\u5de5\u5177\u63a8\u8350","text":"<p>\u5173\u4e8e\u6211\u600e\u6837\u5728\u7b14\u8bb0\u5de5\u5177Notion\u548cObsidian\u4e4b\u95f4\u505a\u9009\u62e9</p>"},{"location":"#_5","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<p>\u301019/11/2023\u3011Update\u4e86\u4e00\u4e9b\u6691\u671f\u7684\u8bba\u6587\u9605\u8bfb\u7b14\u8bb0\u548c\u4e24\u4e09\u95e8ling/CS\u8bfe\u3002\u5f00\u4e86\u4e00\u4e2a24fall\u7533\u8bf7\u5386\u7a0b\u7684\u5751\u300212\u6708ddl\u6708\u8fc7\u53bb\u5c31\u5f00\u59cb\u586b\uff01</p> <p>\u301028/07/2023\u3011\u6362\u7ad9\u4e86\uff01\u5c45\u7136\u505a\u5230\u4e86\u628aOb\u548cMkdocs\u5408\u5e76\u5728\u4e86\u540c\u4e00\u4e2a\u6587\u4ef6\u5939\u3002\u628aNotion\u7684\u4e1c\u897f\u4e5f\u642c\u4e0a\u6765\u4e86\uff01</p>"},{"location":"#_6","title":"\u8054\u7cfb\u4f5c\u8005","text":"<p>\ud83d\udceb RuoxiNing@outlook.com \ud83e\uddd1\u200d\ud83d\udcbb https://ruoxining.github.io</p>"},{"location":"Application/","title":"\u7d22\u5f15","text":"<p>\u672c\u7ae0\u8282\u5305\u542b\u5347\u5b66\u7ecf\u9a8c\u548c\u5fc3\u5f97\uff0c\u5df2\u7ecf\u5b8c\u6210 - ZJU\u82f1\u4e13\u8f6cCS/NLP\u7684\u5fc3\u5f97</p>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/","title":"\u642c\u8fd0NLP\u7533\u8bf7PhD\u7ecf\u9a8c","text":"<p>\u7ffb\u8bd1\u81eahttps://github.com/zhijing-jin/nlp-phd-global-equality</p>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_1","title":"\u9996\u63a8\u8d44\u6e90","text":"<ol> <li>ACL \u5e74\u5ea6\u5bfc\u5e08\u5236\u9879\u76ee\uff08https://acl-mentorship.github.io\uff09</li> <li>NLP with Friends \uff08Welcome! - NLP with Friends\uff09</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#phd","title":"\u7b2c\u4e00\u9636\u6bb5\uff1a\u600e\u6837\u7533\u8bf7PhD\uff1f","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_2","title":"\u7533\u8bf7\u5efa\u8bae","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#phd_1","title":"\u6211\u5e94\u8be5\u8bfbPhD\u5417\uff1f","text":"<ol> <li> <p>(John Hewitt, PhD@Stanford)\u00a0Undergrad to PhD, or not - advice for undergrads interested in research\u00a0(2018). [Suggestions]</p> </li> <li> <p>\u7a77\u548c\u4e0d\u806a\u660e\u4e0d\u662f\u7406\u7531</p> </li> <li>\u591a\u4e0e\u4eba\u4ea4\u6d41\uff0c\u542c\u7684\u5efa\u8bae\u8d8a\u591a\u8d8a\u597d</li> <li>\u89c2\u5bdf\u4e86\u89e3phd\u7684\u65e5\u5e38\u751f\u6d3b</li> <li>\u770b\u770b\u81ea\u5df1\u662f\u5426\u6709\u70ed\u60c5</li> <li> <p>\u7533\u8bf7\u524d\u76848\u6708\u52309\u6708\u8981\u5199\u597d\u81ea\u5df1\u7684SOP\uff0c\u601d\u8003\u81ea\u5df1\u8981\u505a\u600e\u6837\u7684\u7814\u7a76\uff0c\u600e\u6837\u8ba9\u81ea\u5df1\u7684\u7814\u7a76\u6709\u5f71\u54cd\u529b\u3002\u57288\u6708\u8981\u8054\u7cfb\u597d\u63a8\u8350\u4fe1</p> </li> <li> <p>(Prof Jason Eisner@JHU)\u00a0Advice for Research Students\u00a0(last updated: 2021). [List of suggestions]</p> </li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_3","title":"\u7533\u8bf7\u8fc7\u7a0b\u662f\u4ec0\u4e48\u6837\u5b50\u7684\uff1f","text":"<ol> <li>(Nelson Liu, PhD@Stanfard)\u00a0Student Perspectives on Applying to NLP PhD Programs\u00a0(2019). [Suggestions Based on Surveys]</li> <li>\u4e3a\u4ec0\u4e48\u73b0\u5728\u5c31\u8981\u7533\u8bf7\uff1a\uff081\uff09AI\u754c\u8d8a\u6765\u8d8a\u5377\uff0c\u66f4\u65b0\u975e\u5e38\u5feb\uff0c\u6240\u4ee5\u53d1\u66f4\u591apaper\u4e0d\u4e00\u5b9a\u8868\u793a\u7533\u8bf7\u66f4\u5360\u4f18\u52bf \uff082\uff09\u7855\u58eb\u7533\u8bf7phd\u6bd4\u672c\u79d1\u7533\u8bf7phd\u9700\u8981\u66f4\u591a\u6587\u7ae0 \uff083\uff09\u4e0d\u786e\u5b9a\u6027\u5f88\u5927\uff0c\u8ba1\u5212\u5f88\u53ef\u80fd\u6ca1\u6709\u53d8\u5316\u5feb \uff084\uff09\u9664\u975e\u4f60\u8ba4\u4e3a\u8bfb\u5b8c\u7855\u58eb\u540e\u81ea\u5df1\u80fd\u53d8\u5f97\u66f4\u5f3a</li> <li>\u7533\u8bf7\u54ea\u91cc\uff1a\uff081\uff09\u9996\u5148\u8981\u8003\u8651\u5b66\u6821\u548c\u5bfc\u5e08\uff0c\u6709\u5efa\u8bae\u79f0\u6700\u597d\u9009\u62e9\u67092\u4f4d\u4ee5\u4e0a\u76f8\u5173\u5bfc\u5e08\u7684\u5b66\u6821\u3002\uff082\uff09\u5730\u5740\u4e5f\u5f88\u91cd\u8981\uff0c\u8fd9\u662f\u672a\u67655\u5e74\u91cc\u4f60\u7684\u5de5\u4f5c\u73af\u5883\u3002\uff083\uff09\u9009\u62e9\u4e0e\u5de5\u4e1a\u754c\u5173\u7cfb\u7d27\u5bc6\u7684\u5730\u65b9</li> <li>\u51c6\u5907SOP\u548c\u63a8\u8350\u4fe1\uff1a\u89c1\u4e0b\u65b9\u5c0f\u6807\u9898</li> <li>\u51c6\u5907\u4e09\u7ef4\u6210\u7ee9\uff1a\u5360\u5c0f\u5206\u91cf\u3002\u5176\u4e2d\u6258\u798f\u5fc5\u987b\u8fc7\u7ebf</li> <li>\u9762\u8bd5\uff1a\u7ed3\u6784\u662f\u201c\u4ecb\u7ecd\u4e00\u4e2a\u4f60\u6700\u60f3\u8bb2\u7684\u7814\u7a76\u9879\u76ee\u201d+\u201c\u4f60\u7684\u7814\u7a76\u5174\u8da3\u662f\u4ec0\u4e48\u201d+\u201c\u8fd8\u6709\u4ec0\u4e48\u95ee\u9898\u201d\u3002\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\u662f\u770b\u4f60\u7684\u89e3\u51b3\u95ee\u9898\u80fd\u529b\u600e\u4e48\u6837\uff0c\u7814\u7a76\u5174\u8da3\u5339\u914d\u4e0d\u5339\u914d\uff0c\u5c11\u90e8\u5206\u60c5\u51b5\u4e5f\u4f1a\u95ee\u5230\u6280\u672f\u7ec6\u8282\u3002\u5728QA\u73af\u8282\uff0c\u53ef\u4ee5\u95ee\u5bf9\u65b9\u4e4b\u524d\u7684\u5de5\u4f5c\uff0c\u53ef\u4ee5\u95ee\u672a\u6765\u4f60\u80fd\u505a\u7684\u5de5\u4f5c\uff0c\u53ef\u4ee5\u95ee\u9879\u76ee\uff0c\u95ee\u5b66\u6821\u3002\u4e0d\u77e5\u9053\u7684\u5c31\u8bf4\u4e0d\u77e5\u9053\u3002</li> <li>(Prof Dragomir Radev@Yale)\u00a0Advice for PhD Applications, Faculty Applications, etc\u00a0(2023). [List of Suggestions]</li> </ol> <ol> <li>[(Roma Patel PhD@Brown, Prof Nathan Schneider@Georgetown University)\u00a0PhD Application Series of the NLP Highlights Podcast)\u00a0(2021). [Podcast] (A new series they launched that addresses all aspects of PhD application. Besides, it is just a great podcast in general that talks about recent NLP advances)</li> <li>(Albert Webson et al., PhDs@Brown University)\u00a0Resources for Underrepresented Groups, including Brown's Own Applicant Mentorship Program\u00a0(2020, but we will keep updating it throughout the 2021 application season.) [List of Resources]</li> <li>A Princeton CS Major's Guide to Applying to Graduate School. [List of suggestions]</li> <li>(Tim Dettmers, PhD@UW)\u00a0Machine Learning PhD Applications \u2014 Everything You Need to Know\u00a0(2018). [Guide]</li> </ol> <ol> <li>(Kalpesh Krishna, PhD@UMass Amherst)\u00a0Grad School Resources\u00a0(2018). [Article] (This list lots of useful pointers!)</li> <li>(Prof\u00a0Mor Harchol-Balter@CMU)\u00a0Applying to Ph.D. Programs in Computer Science\u00a0(2014). [Guide]</li> </ol> <ol> <li>(CS Rankings)\u00a0Advice on Applying to Grad School in Computer Science. [Pointers]</li> <li>(Prof Scott E. Fahlman@CMU)\u00a0Quora answers on the LTI program at CMU\u00a0(2017). [Article]     ---------------------------------------------------------------------------------------</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_4","title":"\u600e\u6837\u9009\u62e9\u5b66\u6821/\u9879\u76ee\uff1f","text":"<ol> <li>(Nelson Liu, PhD@Stanfard)\u00a0Student Perspectives on Applying to NLP PhD Programs\u00a0(2019). [Suggestions Based on Surveys]</li> <li>\u6295\u591a\u5c11\u6240\u5b66\u6821\uff1a8\uff5e13\u6240      </li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#sop","title":"\u600e\u6837\u51c6\u5907SOP\uff1f","text":"<ol> <li>(Nelson Liu, PhD@Stanfard)\u00a0Student Perspectives on Applying to NLP PhD Programs\u00a0(2019). [Suggestions Based on Surveys]</li> <li>\u516b\u6708\u4efd\u5f00\u59cb\u5199\u7684\u6700\u591a</li> <li>SOP\u5e94\u5f53\u63cf\u8ff0\u4f60\u7684\u7814\u7a76\u7ecf\u5386\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u505a\u8fc7\u7684\u7814\u7a76\u7684\u5177\u4f53\u8fc7\u7a0b\u3001\u7814\u7a76\u6bcf\u4e00\u6b65\u7684\u7ec6\u8282\uff0c\u8fd9\u6837\u6bd4\u8f83\u65b9\u4fbf\u8bc4\u59d4\u4f30\u8ba1\u4f60\u7814\u7a76\u7684\u4ef7\u503c\uff0c\u8ba9\u4ed6\u4eec\u77e5\u9053\u4f60\u660e\u767d\u81ea\u5df1\u7684\u7814\u7a76\u6bcf\u4e00\u6b65\u90fd\u5728\u505a\u4ec0\u4e48\u3002\u4e4b\u540e\uff0c\u4f60\u5e94\u5f53\u4ece\u6574\u4e2a\u7814\u7a76\u751f\u6daf\u7684\u89c6\u89d2\u6765\u4ecb\u7ecd\u4f60\u4e4b\u524d\u7684\u5de5\u4f5c\uff0c\u5e76\u5206\u522b\u4ece\u5177\u4f53\u7684\u7814\u7a76\u5de5\u4f5c\u3001\u4f60\u7684\u7814\u7a76\u5fc3\u5f97\u4e24\u4e2a\u65b9\u9762\u4ecb\u7ecd\u4f60\u7684\u672a\u6765\u5c55\u671b\uff0c\u4ecb\u7ecd\u4f60\u5728phd\u9636\u6bb5\u8981\u505a\u600e\u6837\u7684\u7814\u7a76\u3002</li> <li>\u6bcf\u6240\u5b66\u6821\u5e94\u8be5\u6295\u4e0d\u4e00\u6837\u7684SOP\uff0c\u53ea\u6539\u6700\u540e\u4e00\u4e24\u6bb5\u4e5f\u6709\u70b9\u5c11\uff0c\u6700\u597d\u6539\u52a8\u5927\u4e00\u4e9b\uff0c\u6295\u5176\u6240\u597d\u3002</li> <li>\u53ef\u4ee5\u628aSOP\u7ed9recommender\u770b\u4e00\u4e0b</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_5","title":"\u600e\u6837\u51c6\u5907\u63a8\u8350\u4fe1\uff1f","text":"<ol> <li>(Nelson Liu, PhD@Stanfard)\u00a0Student Perspectives on Applying to NLP PhD Programs\u00a0(2019). [Suggestions Based on Surveys]</li> <li>\u9009\u62e9\u63a8\u8350\u4eba\uff081\uff09\u4f60\u5bf9\u63a8\u8350\u4eba\u7684\u719f\u77e5\u7a0b\u5ea6\uff082\uff09\u4f60\u4e0e\u8fd9\u4f4d\u63a8\u8350\u4eba\u5408\u4f5c\u7684\u5de5\u4f5c\u597d\u4e0d\u597d\uff083\uff09\u63a8\u8350\u4eba\u7684\u77e5\u540d\u5ea6\u3002\u56e0\u6b64\u8bfe\u7a0b\u63a8\u6216TA\u63a8\u662f\u4e0d\u597d\u7528\u7684\u3002\u5de5\u4e1a\u754c\u63a8\u662f\u597d\u7528\u7684\uff0c\u5bf9\u4e8e\u8fd9\u79cd\u63a8\u8350\u4fe1\u4f60\u540c\u6837\u9700\u8981\u8bc4\u4f30\u63a8\u8350\u4eba\u7684\u77e5\u540d\u5ea6\u3002</li> <li>\u9700\u8981\u6ce8\u610f\u77e5\u540d\u7684\u63a8\u8350\u4eba\uff0c\u7ade\u4e89\u7684\u5b66\u751f\u4e5f\u591a\uff0c\u53ea\u4f1a\u63a8\u8350\u6700\u4f18\u79c0\u7684\u5b66\u751f\u3002</li> <li>\u63d0\u9192\u63a8\u8350\u4eba\u4f60\u7684\u4f18\u70b9\u548c\u5de5\u4f5c\uff0c\u63a8\u8350\u4eba\u5f88\u5fd9\uff0c\u53ef\u80fd\u60f3\u4e0d\u8d77\u6765\u3002\u6ce8\u610f\u5728\u63a8\u8350\u4fe1\u63d0\u4ea4\u622a\u6b62\u524d1\u661f\u671f\u548c2\u661f\u671f\u5206\u522b\u90ae\u4ef6\u63d0\u9192\u63a8\u8350\u4eba\u63d0\u4ea4\u63a8\u8350\u4fe1\u3002</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_6","title":"\u524d\u63d0\u6761\u4ef6\uff1a\u6691\u7814","text":"<ol> <li>(Andrew Kuznetsov, PhD@CMU)\u00a0CS/HCI PhD Opportunity Tracker from Twitter\u00a0(Developed in 2021).\u00a0http://www.andrewkuz.net/hci-opportunities-2022.html</li> <li>(Eugene Vinitsky, PhD@UC Berkeley)\u00a0A Guide to Cold Emailing\u00a0(2020). [Article]</li> <li>(Prof Shomir Wilson@Penn State University)\u00a0Guide for Interacting With Faculty\u00a0(2018). [Suggestions]</li> <li>(Prof Shomir Wilson@Penn State University)\u00a0Reference Letter Procedure. [Suggestions]</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_7","title":"\u524d\u63d0\u6761\u4ef6\uff1a\u5de5\u6b32\u5584\u5176\u4e8b\uff0c\u5fc5\u5148\u5229\u5176\u5668","text":"<ul> <li>Google Colab</li> <li>AWS\uff08credits for research\uff09</li> <li>Digitalocean</li> <li>\u8ba1\u7b97\u673a\u6559\u80b2\u4e2d\u7f3a\u5931\u7684\u4e00\u8bfe</li> </ul>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_8","title":"\u53e6\u4e00\u79cd\u9009\u62e9\uff1a\u8f6f\u4ef6\u5f00\u53d1\u5de5\u7a0b\u5e08","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#phd_2","title":"\u7b2c\u4e8c\u9636\u6bb5\uff1a\u600e\u6837\u505a\u4e00\u4e2a\u597dPHD\uff1f","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_9","title":"\u7efc\u5408\u6307\u5bfc","text":"<ol> <li>(Prof Isabelle Augenstein@UCopenhagen)\u00a0Increasing Well-Being in Academia\u00a0(2020). [Suggestions]</li> <li>(Sebastian Ruder@DeepMind)\u00a010 Tips for Research and a PhD\u00a0(2020) . [Suggestions]</li> <li>(Maxwell Forbes, PhD@UW)\u00a0Every PhD Is Different. [Suggestions]</li> <li>(Prof Mark Dredze@JHU, Prof Hanna M. Wallach@UMass Amherst)\u00a0How to be a successful PhD student (in computer science (in NLP/ML)). [Suggestions]</li> <li>(Andrej Karpathy)\u00a0A Survival Guide to a PhD\u00a0(2016). [Suggestions]</li> <li>be \u201cshe\u2019s the person who did X\u201d</li> <li>\u4e0d\u8981\u628aphd\u5f53\u4f5c\u5199paper\uff0c\u4f60\u8981\u628a\u81ea\u5df1\u5f53\u6210\u8be5\u9886\u57df\u7684\u4e00\u5458\uff0c\u8981\u63a8\u52a8\u9886\u57df\u7684\u8fdb\u5c55\u3002</li> <li>(Prof Kevin Gimpel@TTIC)\u00a0Kevin Gimpel's Advice to PhD Students. [Suggestions]</li> <li>(Prof Marie desJardins@Simmons University)\u00a0How to Succeed in Graduate School: A Guide for Students and Advisors\u00a0(1994). [Article] [Part II]</li> <li>(Prof Eric Gilbert@UMich)\u00a0Syllabus for Eric\u2019s PhD students\u00a0(incl. Prof's expectation for PhD students). [syllabus]</li> <li>(Marek Rei, Lecturer@Imperial College London)\u00a0Advice for students doing research projects in ML/NLP\u00a0(2022). [Suggestions]</li> <li>(Prof H.T. Kung@Harvard)\u00a0Useful Thoughts about Research\u00a0(1987). [Suggestions]</li> <li>(Prof Phil Agre@UCLA)\u00a0Networking on the Network: A Guide to Professional Skills for PhD Students\u00a0(last updated: 2015). [Suggestions]     --------------------------------------------------------------------------------------------------------------------------------------</li> <li>(Prof Stephen C. Stearns@Yale)\u00a0Some Modest Advice for Graduate Students. [Article]</li> <li>(Prof Tao Xie@UIUC)\u00a0Graduate Student Survival/Success Guide. [Slides]</li> <li>(Mu Li@Amazon)\u00a0\u535a\u58eb\u8fd9\u4e94\u5e74\u00a0(A Chinese article about five years in PhD at CMU). [Article]</li> <li>(Karl Stratos)\u00a0A Note to a Prospective Student. [Suggestions]</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#llmnlp","title":"\u70ed\u70b9\u8bdd\u9898\uff1aLLM\u65f6\u4ee3\u7684NLP\u7814\u7a76","text":"<ol> <li>(UMich; led by Prof Rada Mihalcea)\u00a0A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models\u00a0(2023). [Paper]</li> <li>Multilinguality and Low-resource Languages      ------------------------------------------</li> <li>Reasoning      ---------</li> <li>Knowledge Bases      ---------------</li> <li>Language Grounding      ------------------</li> <li>Computational Social Science</li> <li>Child Language Acquisition</li> <li>Non-verbal Communication</li> <li>Synthetic Datasets</li> <li>Interpretability</li> <li>Efficient NLP</li> <li>NLP in education</li> <li>NLP in healthcare</li> <li>NLP and ethics</li> <li>(Prof Julian Togelius@NYU, Prof Georgios Yannakakis@UMalta)\u00a0Choose Your Weapon: Survival Strategies for Depressed AI Academics Julian Togelius, Georgios N. Yannakakis\u00a0(2023). [Tweet] [Paper]</li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#idea","title":"\u627e\u5230\u597d\u7684\u7814\u7a76Idea","text":"<ol> <li>(Prof Jia-Bin Huang@UMaryland)\u00a0How to come up with research ideas?\u00a0(2021). [Suggestions]</li> </ol> <ol> <li>(John Schulman, co-founder of OpenAI)\u00a0An Opinionated Guide to ML Research (e.g., horning your taste)\u00a0(2020). [Suggestions]</li> </ol> <p>Interesting snippets: \"Goal-driven. Develop a vision of some new AI capabilities you\u2019d like to achieve, and solve problems that bring you closer to that goal.\", \"If you are working on incremental ideas, be aware that their usefulness depends on their complexity.\", \"Consider how the biggests bursts of impactful work tend to be tightly clustered in a small number of research groups and institutions. That\u2019s not because these people are dramatically smarter than everyone else, it\u2019s because they have a higher density of expertise and perspective, which puts them a little ahead of the rest of the community, and thus they dominate in generating new results.\", \"Early on in your career, I recommend splitting your time about evenly between textbooks and papers. You should choose a small set of relevant textbooks and theses to gradually work through, and you should also reimplement the models and algorithms from your favorite papers.\" 3. (Prof Fei-Fei Li@Stanford)\u00a0De-Mystifying Good Research and Good Papers\u00a0(2014). [Suggestions]</p> <p>Interesting snippets: \"This means publishing papers is NOT about \u201cthis has not been published or written before, let me do it\u201d, nor is it about \u201clet me find an arcane little problem that can get me an easy poster\u201d. It\u2019s about \u201cif I do this, I could offer a better solution to this important problem,\u201d or \u201cif I do this, I could add a genuinely new and important piece of knowledge to the field.\u201d You should always conduct research with the goal that it could be directly used by many people (or industry). In other words, your research topic should have many \u2018customers\u2019, and your solution would be the one they want to use. A good research project is not about the past (i.e. obtaining a higher performance than the previous N papers). It\u2019s\u00a0about the future (i.e. inspiring N future papers to follow and cite you, N-&gt;\\inf).\"</p>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_10","title":"\u8bfb\u6587\u7ae0\u7684\u5de5\u5177","text":"<ul> <li>Connected Papers\uff08https://www.connectedpapers.com/\uff09</li> <li>Glactica\uff08https://galactica.org/mission/\uff09\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u7ae0\u8bc4\u8bba</li> </ul>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_11","title":"\u8bfb\u6587\u7ae0","text":"<ol> <li>(Prof Srinivasan Keshav@Cambridge)\u00a0How to Read a Paper\u00a0(2007). [Suggestions]</li> </ol> <ol> <li>(Prof Jason Eisner@JHU)\u00a0How to Read a Technical Paper\u00a0(2009). [Suggestions]</li> </ol> <ol> <li>(Prof Emily M. Bender@UW)\u00a0Critical Reading\u00a0(2003). [Suggestions]</li> <li>\u6279\u5224\u6027\u9605\u8bfb\u662f\u5728\u9605\u8bfb\u4e2d\u79ef\u6781\u6295\u5165\u6587\u7ae0\u7684\u8fc7\u7a0b\u3002\u4f60\u53ef\u4ee5\u5728\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u95ee\u4ee5\u4e0b\u95ee\u9898\uff1a</li> <li>\u5b9e\u9a8c\u6587\u7ae0\uff1a<ul> <li>\u6587\u7ae0\u7684\u7814\u7a76\u95ee\u9898\u662f\u4ec0\u4e48\uff1f</li> <li>\u4e3a\u5efa\u7acb\u7814\u7a76\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u54ea\u4e9b\u5047\u8bbe\uff1f</li> <li>\u6570\u636e\u600e\u6837\u6536\u96c6\u7684\uff1f</li> <li>\u6536\u96c6\u6570\u636e\u7684\u65b9\u6cd5\u6709\u6ca1\u6709\u53ef\u80fd\u5bfc\u81f4\u504f\u89c1\u6216\u504f\u5dee\uff1f</li> <li>\u4f5c\u8005\u5bf9\u4ed6\u4eec\u6536\u96c6\u6570\u636e\u65b9\u6cd5\u7684\u5047\u8bbe\u662f\u4ec0\u4e48</li> <li>\u6587\u7ae0\u7684\u7ed3\u8bba\u662f\u4ec0\u4e48\uff1f</li> <li>\u4ece\u7ed3\u679c\u5230\u7ed3\u8bba\u5efa\u7acb\u7684\u8fc7\u7a0b\uff0c\u7528\u4e86\u54ea\u4e9b\u5047\u8bbe\uff1f</li> </ul> </li> <li>\u6559\u79d1\u4e66\u6587\u7ae0\uff0c\u6982\u5ff5\u8bf4\u660e\u6587\u7ae0<ul> <li>\u8fd9\u4e2a\u6982\u5ff5\u5c5e\u4e8e\u4ec0\u4e48\u66f4\u5e7f\u7684\u6982\u5ff5/\u9886\u57df</li> <li>\u8fd9\u4e2a\u6982\u5ff5\u4e0e\u5176\u5b83\u6982\u5ff5\u51b2\u7a81\u5417\uff1f\u4e0e\u4e4b\u51b2\u7a81\u7684\u6982\u5ff5\u6709\u4ec0\u4e48\uff1f</li> <li>\u5982\u679c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u7ec4\u8fd1\u4e49\u6982\u5ff5\uff08taxomony\uff09\uff0c\u8fd9\u4e9b\u6982\u5ff5\u90fd\u8986\u76d6\u4e86\u54ea\u4e9b\u8303\u56f4</li> <li>\u5982\u679c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u7ec4\u6982\u5ff5\uff0c\u8fd9\u4e9b\u6982\u5ff5\u76f8\u4e92\u5305\u542b\u3001\u91cd\u53e0\u6216\u4e92\u4e0d\u76f8\u4ea4\uff1f</li> <li>\u8fd9\u4e9b\u6982\u5ff5\u7684\u4f5c\u7528/\u610f\u4e49\u662f\u4ec0\u4e48\uff1f\uff08\u80fd\u591f\u63d0\u51fa\u600e\u6837\u7684\u7814\u7a76\u95ee\u9898\uff09</li> <li>\u63d0\u51fa\u8fd9\u4e9b\u6982\u5ff5\u7275\u626f\u5230\u600e\u6837\u7684\u5047\u8bbe/\u524d\u63d0\uff1f</li> </ul> </li> <li>\u671f\u520a\u6742\u5fd7\u4e2d\u7684\u8bf4\u7406\u6027\u6587\u7ae0<ul> <li>\u6587\u7ae0\u7684\u8bba\u70b9\u662f\u4ec0\u4e48\uff1f</li> <li>\u6587\u7ae0\u7684\u8bba\u70b9\u548c\u5b83\u7684\u53cd\u8c03\u5171\u540c\u5efa\u7acb\u5728\u54ea\u4e9b\u5047\u8bbe\u7684\u57fa\u7840\u4e0a</li> <li>\u6587\u7ae0\u7528\u54ea\u4e9b\u8bc1\u636e\u5efa\u7acb\u8bba\u70b9\uff1f</li> <li>\u6587\u7ae0\u7684\u8bc1\u636e\u5efa\u7acb\u5728\u54ea\u4e9b\u5047\u8bbe\u4e0a\uff1f</li> <li>\u6587\u7ae0\u4ece\u8bc1\u636e\u5230\u5efa\u7acb\u8bba\u70b9\uff0c\u7528\u4e86\u54ea\u4e9b\u5047\u8bbe\uff1f</li> </ul> </li> </ol>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_12","title":"\u5199\u6587\u7ae0","text":"<ol> <li>(Prof Jason Eisner@JHU)\u00a0How to write a paper?\u00a0(2010). [Suggestions]</li> <li>(Simon Peyton Jones@Microsoft)\u00a0How to write a great research paper: Seven simple suggestions\u00a0(2014). [Slides] [Talk]</li> <li>\u5199\u6587\u7ae0\u662f\u5e2e\u52a9\u5efa\u7acb\u7814\u7a76\u7684\u7b2c\u4e00\u6b65\uff0c\u800c\u4e0d\u662f\u4e00\u79cd\u6c47\u62a5\u7814\u7a76\u7684\u673a\u5236      </li> <li>\u4e0d\u662f\u53ea\u6709\u597d\u7684idea\u80fd\u5199\uff0c\u968f\u4fbf\u4ec0\u4e48idea\u90fd\u53ef\u4ee5\u5199\u4e0b\u6765\uff0c\u7136\u540e\u8ddf\u522b\u4eba\u8c08\u4e00\u8c08</li> <li>\u4e00\u7bc7paper\u4e00\u4e2aidea\uff0c\u80fd\u591f\u6e05\u6670\u8868\u8fbe\u3002\u6bd4\u5982\u6709\u8fd9\u79cd\u53e5\u5f0f\u201cThe main idea of this paper is\u2026\u201d \u201cIn this section we present the main contributions of this paper.\u201d</li> <li>\u8981\u5f3a\u8c03\u4f60\u7684contribution\uff0c\u5728introduction\u91cc\u5f3a\u8c03\u3002introduction\u5c31\u662f\u7528\u6765\u63cf\u8ff0\u95ee\u9898+\u4ecb\u7ecd\u8d21\u732e\u7684\u3002</li> <li>\u53ef\u4ee5\u5148\u5217\u4e3e\u51fa\u6240\u6709\u7684contribution\uff0c\u7136\u540e\u7528contribution\u9a71\u52a8\u6574\u7bc7\u6587\u7ae0</li> <li>introduction\u91cc\u7684\u201c\u540e\u6587\u7ed3\u6784\u5982\u4e0b\u2026.\u201d\u5e94\u5f53\u7528\u5c06\u6765\u65f6\uff08\u5b58\u7591\uff09</li> <li>\u600e\u6837\u5199\u76f8\u5173\u7814\u7a76\uff1a<ul> <li>\u5982\u679c\u76ee\u524d\u4f60\u7684\u7814\u7a76\u6ca1\u6709\u76f8\u5173\u7814\u7a76\uff0c\u5728\u4f60\u7684\u65b9\u6cd5\u4e4b\u524d\u4ecb\u7ecd\u4e00\u5927\u5806\u522b\u4eba\u7684\u65b9\u6cd5\u4f1a\u8ba9\u8bfb\u8005get lost\uff0c\u6240\u4ee5\u6700\u597d\u5728\u4f60\u7684result\u548cconclusion\u4e4b\u95f4\u653e\u76f8\u5173\u7814\u7a76\uff0c\u5373\u653e\u5230\u540e\u9762\u53bb</li> <li>\u4e0d\u662f\u5fc5\u987b\u5f3a\u8c03\u522b\u4eba\u7684\u5de5\u4f5c\u574f\uff0c\u8981\u8ba4\u53ef\u522b\u4eba\u7684\u597d\u5de5\u4f5c\uff0c\u627f\u8ba4\u81ea\u5df1\u7684\u7f3a\u70b9</li> </ul> </li> <li>\u600e\u6837\u5199\u7ed3\u679c\uff1a\u628a\u8bfb\u8005\u653e\u5728\u7b2c\u4e00\u4f4d<ul> <li>\u4e00\u5b9a\u8981\u4f20\u8fbe\u597dintuition\uff0c\u4e0d\u8981\u5199\u5f97\u5197\u957f\u6a21\u7cca\uff0c\u5f53\u8bfb\u8005\u80fdfollow\u4f60\u7684intuition\uff0c\u4ed6\u4eec\u5c31\u80fd\u9010\u6b65\u7406\u89e3\u4f60\u4e4b\u540e\u7684\u4e1c\u897f</li> <li>\u7528\u4f8b\u5b50\u89e3\u91ca\u95ee\u9898\uff0c\u53ea\u7528general example</li> <li>\u4e0d\u7528\u8bb2\u4f60\u8bd5\u9519\u7684\u8fc7\u7a0b\uff0c\u53ea\u8bb2\u6700\u540e\u5b8c\u6210idea\u7684\u90a3\u4e9b\u5b9e\u9a8c\u6b65\u9aa4</li> </ul> </li> <li>\u8bb2\u7ed9\u522b\u4eba\u542c\uff0c\u95ee\u8bfb\u8005\u7684\u610f\u89c1\uff0c\u95ee\u8bc4\u59d4\u7684\u610f\u89c1\uff08\u975e\u5e38\u96be\u4f46\u975e\u5e38\uff0c\u975e\u5e38\uff0c\u975e\u5e38\u91cd\u8981\uff09</li> <li>\u7528\u4e3b\u52a8\u8bed\u6c14\uff08we can see\uff09\u4e0d\u8981\u7528\u88ab\u52a8\u8bed\u6c14\uff08it can be seen that\uff09\uff0c\u4f1a\u4f7f\u6587\u7ae0\u8bfb\u8d77\u6765\u5f88\u6b7b</li> <li>\u7528\u7b80\u5355\u8bcd\uff0c\u7b80\u5355\u8868\u8fbe</li> <li>(Prof Jennifer Widom@Stanford)\u00a0Tips for Writing Technical Papers\u00a0(2006). [Suggestions]</li> <li>(Prof Shomir Wilson@Penn State University)\u00a0Guide for Scholarly Writing. [Suggestions]</li> <li>(Prof Jia-Bin Huang@U Maryland)\u00a0How to write the introduction (and also the What-Why-How figures). [Tweet]</li> <li>(Prof Jia-Bin Huang@U Maryland)\u00a0How to write a rebuttal for a conference?\u00a0[Tweet]</li> <li>(Prof Michael Black@Max Planck Institute)\u00a0Twitter Thread about \"Writing is laying out your logical thoughts\". [Tweet]</li> <li>(Prof Shomir Wilson@Penn State University)\u00a0Guide for Citations and References\u00a0[Suggestions]</li> <li>(Carmine Gallo, a bestselling author)\u00a0The Storytellers Secret\u00a0(2016). [Video]Takeaways: Writing the Introduction section and giving talks can also be like telling a Hollywood story: the setting (what problem we are solving; how important it is), the villian (how difficult this problem is; how previous work cannot solve it well), and the superhero (what we propose). For giving talks, starting with personal stories (e.g., a story of grandma telling the kid not to drink and persist the right thing leading to the person's life pursuit on social justice) is very helpful to get the audience involved.</li> <li>(Maxwell Forbes@UW)\u00a0Figure Creation Tutorial: Making a Figure 1\u00a0(2021). [Suggestions]</li> <li>UI design as a medium of thought: see Michael Nielsen's\u00a0explanation of why UI is important for science,\u00a0Bret Victor's work,\u00a0Miegakure\u00a0that visualizes a 4D environment.</li> <li>(Prof Jia-Bin Huang@U Maryland)\u00a0How to write math in a paper?\u00a0(2023). [Tweet]</li> </ol> <p>\u672a\u5b8c\u5f85\u7eed\uff1a</p>"},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_13","title":"\u7b2c\u4e09\u9636\u6bb5\uff1a\u5de5\u4e1a\u754c\u7814\u7a76\u8005\u7684\u751f\u6d3b","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_14","title":"\u7b2c\u56db\u9636\u6bb5\uff1a\u5982\u4f55\u83b7\u5f97\u6559\u804c\uff1f\u5982\u4f55\u505a\u4e00\u4e2a\u597d\u5bfc\u5e08\uff1f","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#nlp","title":"\u7b2c\u4e94\u9636\u6bb5\uff1a\u89c4\u5212NLP\u7684\u7814\u7a76\u751f\u6daf","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_15","title":"\u4e86\u89e3\u66f4\u591a","text":""},{"location":"Application/NLP%20Global%20PHD%20Equality%20Digest/#_16","title":"\u5f15\u7528","text":"<pre><code>@misc{resources2021jin,\n  author = {Zhijing Jin},\n  title = {Resources to Help Global Equality for PhDs in NLP},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/zhijing-jin/nlp-phd-global-equality}}\n}\n</code></pre>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/","title":"\u672c\u6587\u6863\u662f\u4ec0\u4e48\uff1f","text":"<p>\u7b14\u8005\u8f6c\u4e13\u4e1a\u8e29\u8fc7\u7684\u5751\u548c\u5bf9\u540e\u8f88\u7684\u5efa\u8bae\uff0c\u771f\u5fc3\u60f3\u5efa\u7acb\u8d77ZJU\u5185\u90e8\u826f\u597d\u7684\u4f20\u5e2e\u5e26\u6c1b\u56f4\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_2","title":"\u89c2\u5ff5&amp;\u4e60\u60ef\u95ee\u9898","text":"<p>\u5728\u5177\u4f53\u5efa\u8bae\u524d\u9996\u5148\u56de\u7b54\u4e00\u4e9b\u5e38\u6709\u7684\u62c5\u5fe7+\u505a\u4e00\u4e9b\u4e60\u60ef\u65b9\u9762\u7684\u63d0\u9192</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#cs","title":"\u6211\u80fd\u8f6c\u5230CS\u5417\uff1f","text":"<p>\u80fd\u3002\u6709\u5982\u4e0b\u6848\u4f8b\uff08\u4e0d\u4ee3\u8868\u6240\u6709\u4eba\u613f\u610f\u88ab\u8054\u7cfb\u5230\uff0c\u4e0d\u4fdd\u8bc1\u63d0\u4f9b\u8054\u7cfb\u65b9\u5f0f\uff09 - 16\u7ea7 +CS\u53cc\u5b66\u4f4d\u2192\u6e05\u534e\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u6240CV\u65b9\u5411 \u7855\u58eb\u751f\u6216PhD - 16\u7ea7 +\u672c\u6821CS\u65b9\u5411\u79d1\u7814\u2192\u5317\u7f8e\u4e00\u6240top20\u6821\uff08\u5177\u4f53\u4e0d\u77e5\uff09 PhD - 16\u7ea7 +CS\u53cc\u5b66\u4f4d\u2192ZJU\u672c\u6821CV\u65b9\u5411PhD\u2192\u5728UCSD\u4ea4\u6362 - 16\u7ea7 +CS\u8f85\u4fee\u2192CMU LTI ms\u2192UCSD NLP\u65b9\u5411PhD - 17\u7ea7 +\u66fc\u5927\u8bed\u8a00\u5b66\u53cc\u5b66\u4f4d\u2192NWU CompLing\u65b9\u5411PhD - 17\u7ea7 +CS\u53cc\u5b66\u4f4d\u2192\u672c\u79d1\u6bd5\u4e1a\u627e\u5230\u5de5\u4f5c \u4f60\u7684\u524d\u8f88\u5f88\u591a\u4e5f\u5f88\u6210\u529f\uff0c\u6240\u4ee5\u4f60\u4e5f\u80fd\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#nlp","title":"NLP\u4e0d\u662f\u4e0d\u8981\u8bed\u8a00\u5b66\u540c\u5b66\u5417\uff1f","text":"<ul> <li>\u9996\u5148\uff0c\u4ece\u4f60\u51b3\u5b9a\u8f6c\u4e13\u4e1a\u7684\u4e00\u523b\u8d77\u5c31\u8981\u628a\u81ea\u5df1\u770b\u6210CS\u4eba\u3002</li> <li>\u5176\u6b21\uff0cNLP\u4e2d\u6709\u6570\u4e2a\u9886\u57df\u4ecd\u9700\u8981\u624e\u5b9e\u7684\u8bed\u8a00\u5b66\u529f\u5e95\uff08\u5728\u4e0b\u65b9\u79d1\u7814\u7ae0\u8282\u8be6\u7ec6\u4ecb\u7ecd\uff09\u3002\u5728ChatGPT\u95ee\u4e16\u540eNLP\u7684\u7814\u7a76\u65b9\u5f0f\u5927\u8f6c\u53d8\uff0c\u6211\u76f8\u4fe1\u591a\u4e13\u4e1a\u80cc\u666f\u5728\u8fd9\u79cd\u65f6\u5019\u662f\u4e00\u79cd\u4f18\u52bf\uff0c\u603b\u80fd\u4e3a\u9886\u57df\u5e26\u6765\u65b0\u7684idea\u3002\u53ea\u662f\u8bfb\u8005\u5e94\u5f53\u628a\u672c\u4e13\u4e1a\u7684\u77e5\u8bc6\u4e5f\u5b66\u597d\uff0c\u5728\u9762\u5bf9CS\u4e13\u4e1a\u7684NLP\u7814\u7a76\u8005\u65f6\u4f60\u5bf9\u4ed6\u4eec\u800c\u8a00\u7684\u89d2\u8272\u5e94\u81f3\u5c11\u662f\u4e00\u4e2a\u8bed\u8a00\u5b66\u4e13\u5bb6\u3002</li> <li>\u8ddf\u56fd\u5916\uff08\u4e3b\u8981\u662f\u5317\u7f8e\uff09\u7684\u8bed\u8a00\u5b66\u4eba\u6807\u9f50\uff0c\u5317\u7f8e\u7684\u8bed\u8a00\u5b66\u5b66\u751f\u90fd\u8981\u505a\u5927\u91cf\u5b9e\u9a8c\u5199\u5927\u91cf\u4ee3\u7801\u7684\uff0c\u8bed\u8a00\u5b66\u662f\u7406\u79d1\u3002Stanford\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u672c\u79d1\u8bfe\u7a0b\u540c\u65f6\u5f00\u5728CS\u548cLing\u7684\u8bfe\u53f7\u4e0b\u3002\u5317\u7f8eNLP\u7814\u7a76\u8005\u6709\u5f88\u591a\u90fd\u6709CS\u548cLing\u53cc\u5b66\u58eb\u5b66\u4f4d\u3002</li> </ul>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_3","title":"\u660e\u786e\u4e00\u4e2a\u5341\u5e74\u5230\u4e09\u5341\u5e74\u7684\u957f\u8fdc\u89c4\u5212\uff0c\u4e3b\u8981\u662f\u4ee5\u4e0b\u51e0\u4e2a\u95ee\u9898","text":"\u95ee\u9898 \u6211\u7684\u56de\u7b54 \u6211\u8981\u5728\u54ea\u91cc\u751f\u6d3b\uff0c\u56fd\u5185\u8fd8\u662f\u56fd\u5916\uff1f \u6211\u8f6cCS\u662f\u66f4\u591a\u56e0\u4e3a\u559c\u6b22\u7406\u5de5\u79d1\uff0c\u8fd8\u662f\u56e0\u4e3a\u559c\u6b22\u5de5\u8d44\uff1f \u6211\u8981\u8fdb\u5de5\u4e1a\u754c\uff0c\u53bb\u79d1\u6280\u4e92\u8054\u7f51\u516c\u53f8\u5de5\u4f5c\uff1b\u8fd8\u662f\u7559\u5728\u5b66\u672f\u754c\uff0c\u5728\u9ad8\u6821\u6216\u7814\u7a76\u6240\u5de5\u4f5c\uff1f \u6211\u8981\u505aCS\u9664NLP\u5176\u5b83\u7684\u65b9\u5411\uff0c\u5982\u7cfb\u7edf\u3001\u7f51\u7edc\u3001\u5b89\u5168\u3001CV\u6216\u7eaf\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u65b9\u5411\uff1b\u8fd8\u662f\u505a\u504f\u6df1\u5ea6\u5b66\u4e60\u7684NLP\u65b9\u5411\uff1b\u8fd8\u662f\u505a\u504f\u8bed\u8a00\u5b66\u7684NLP\u65b9\u5411\uff1f \u6211\u6709\u591a\u5c11\u7ecf\u8d39\uff1f \u6211\u591a\u5c11\u5e74\u5185\u9700\u8981\u8f6c\u597d\u4e13\u4e1a\uff1f"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_4","title":"\u89c4\u5212\u4eba\u751f\u4e2d\u8be5\u505a/\u4e0d\u8be5\u505a\u7684\u4e8b\u7684\u4e24\u4e2a\u51c6\u5219","text":"<ul> <li> <p>\u60f3\u8c61\u4e00\u4e2a\u7b80\u5386     \u80fd\u5728\u7b80\u5386\u4e0a\u5f88\u663e\u773c\u548c\u4e00\u4e2a\u77ed\u8bed\u4ee5\u5185\u80fd\u8868\u8ff0\u7684\u7ecf\u5386\uff0c\u624d\u8981\u52aa\u529b\u53bb\u5237\u3002     \u6bd4\u5982\u76f8\u6bd4\u4e8e\u201c\u53cc\u4e13\u4e1a\uff0c\u662f\u4e00\u4e2azju\u7279\u6709\u7684\u8f85\u4fee\uff0c\u4e0d\u6c34\u7684\uff0c\u5b83\u8981\u6c42\u7684\u8bfe\u6bd4\u8f85\u4fee\u591a\uff0c\u4f8b\u5982\u6211\u4fee\u4e86xxx\uff0c\u6211\u53ea\u662f\u6ca1\u4feexxx\u201d\u548c\u201c\u4fee\u4e86\u4e00\u534aCS\u8bfe\u4e00\u534aAI\u8bfe\u201d\uff0c\u201cCS\u53cc\u5b66\u4f4d\u201d\u5c31\u66f4\u9002\u5408\u51fa\u73b0\u5728\u7b80\u5386\u4e0a\u3002</p> </li> <li> <p>\u505a\u91cd\u5927\u51b3\u5b9a\u65f6\uff0c\u81f3\u5c11\u54a8\u8be220\u4e2a\u4eba\u7684\u5efa\u8bae\uff0c\u8981\u4e48\u54a8\u8be2\u4e86\u89e3n\u4e2a\u4eba\u5efa\u8bae\u7684\u4eba\uff08\u6bd4\u5982\u76f8\u5e94\u884c\u4e1a\u7684\u4eb2\u4eba\u670b\u53cb\u3001\u5b66\u751f\u5f88\u591a\u7684\u8001\u5e08\uff09\u6765\u62b5n\u4e2a\u4eba\uff0c\u603b\u4e4b\u603b\u548c\u8981\u62ff\u523020\u4e2a\u4eba\u5de6\u53f3\u7684\u5efa\u8bae\u3002</p> </li> </ul>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#cs_1","title":"\u628a\u81ea\u5df1\u770b\u6210CS\u4eba","text":"<ul> <li>\u4e0d\u8981\u628a\u81ea\u5df1\u770b\u4f5c\u4f4e\u4eba\u4e00\u7b49\uff0c\u6240\u4ee5CS\u540c\u5b66\u8be5\u6709\u7684\u673a\u4f1a\u548c\u540d\u989d\u4f60\u90fd\u8981\u4e89\u53d6\u3002\u4e00\u6b21\u6b21\u7ed9\u8001\u5e08\u53d1\u90ae\u4ef6\u3001\u8dd1\u529e\u516c\u5ba4\u662f\u5e38\u6709\u4e14\u5408\u7406\u7684\u4e8b\uff0c\u4e0d\u5fc5\u60f3\u201c\u8001\u5e08\u89c9\u5f97\u6211\u4e0d\u591f\u683c\u600e\u4e48\u529e\uff1f\u201c\uff0c\u8981\u60f3\u60f3\u201d\u5982\u679c\u8fd9\u6b21\u673a\u4f1a\u803d\u8bef\u4e86\u6211\u81ea\u5df1\uff0c\u4ee5\u540e\u6709\u522b\u7684\u673a\u4f1a\u4f1a\u66f4\u4e0d\u591f\u683c\u201c\u5440</li> <li>\u4e0d\u8981\u6709\u201c\u5b66\u4e0d\u61c2\u3001\u8fdb\u5ea6\u843d\u540e\u4e00\u70b9\u6ca1\u4e8b\u201d\u8fd9\u79cd\u89c2\u5ff5\uff0c\u4f60\u5e94\u5f53\u65f6\u523b\u4e0e\u540c\u7ea7\u7684CS\u540c\u5b66\u6bd4\u8f83\u8fdb\u5ea6\uff0c\u4e89\u53d6\u4e0d\u8981\u843d\u540e\u3002</li> </ul>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#cs_2","title":"CS\u6709\u8001\u5e08\u540c\u5b66\u770b\u4e0d\u8d77\u6211\u600e\u4e48\u529e\uff1f","text":"<ul> <li>\u65e0\u9700\u4ee5\u504f\u6982\u5168\uff0c\u5927\u90e8\u5206CS\u8001\u5e08\u540c\u5b66\u662f\u5f88nice\u7684\uff0c\u5982\u679c\u6709\u4e0d\u652f\u6301\u4f60\u7684\u4eba\u4e5f\u65e0\u9700\u8ba1\u8f83\uff0c\u65f6\u523b\u60f3\u60f3\u652f\u6301\u4f60\u9f13\u52b1\u4f60\u7684\u90a3\u4e9b\u4eba\u3002</li> <li>\u505a\u4e8b\u524d\u63d0\u524d\u8ddf\u8001\u5e08\u540c\u5b66\u63a8\u9500\u4e00\u4e0b\u81ea\u5df1\uff0c\u6839\u636e\u9a6c\u592a\u6548\u5e94\uff0c\u4f60\u4f1a\u5f97\u5230\u8d8a\u6765\u8d8a\u591a\u6b63\u53cd\u9988\u3002\u6bd4\u5982\u9009\u8bfe\u524d\u53ef\u80fd\u6709\u8001\u5e08\u8d28\u7591\u4f60\u7684\u4e13\u4e1a\uff0c\u95ee\u4f60\u4f1a\u4e0d\u4f1a\u5b66\u4e0d\u61c2\u8fd9\u95e8\u8bfe\uff0c\u4f60\u53ef\u4ee5\u5728\u6c9f\u901a\u65f6\u6709\u610f\u65e0\u610f\u5411\u8001\u5e08\u63d0\u4e00\u4e0b\u4e4b\u524d\u4f60\u5df2\u7ecf\u6709\u54ea\u4e9b\u6210\u7ee9\u548c\u6280\u80fd\uff0c\u8ba9\u8001\u5e08\u660e\u767d\u54ea\u4e9b\u5730\u65b9\u5e94\u8be5\u5173\u7167\u4f60\uff0c\u54ea\u4e9b\u5730\u65b9\u53ef\u4ee5\u653e\u5fc3\uff0c\u8fd9\u6837\u5728\u8001\u5e08\u6709\u610f\u65e0\u610f\u7684\u652f\u6301\u4e0b\u5b66\u751f\u4e5f\u5bb9\u6613\u5b66\u5f97\u6bd4\u9884\u671f\u66f4\u597d\u3002</li> </ul>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#cs_3","title":"\u5b66\u4e0d\u597dCS\uff0c\u662f\u4e0d\u662f\u56e0\u4e3a\u5b66\u82f1\u8bed\u8bfe\u4f7f\u6211\u53d8\u4e0d\u806a\u660e\u4e86\uff1f","text":"<p>\u4e0d\u662f\u3002 - \u7406\u8bba\u4e0a\u662f\u5b8c\u5168\u53ef\u4ee5\u5b66\u597d\u7684\u3002NLP\u5708\u6709\u5f88\u591a\u7814\u7a76\u8005\u8bfb\u8fc7\u8bed\u8a00\u5b66\u548cCS\u53cc\u672c\u79d1\uff0c\u4ee3\u8868AP\u6709AllenNLP Noah Smitch, Colimbia University Zhou Yu\uff08ZJU\u7684\u672c\u79d1\uff09. \u8bfb\u8bed\u8a00\u5b66\u6ca1\u6709\u803d\u8bef\u4ed6\u4eec\u7684\u8111\u5b50\uff0c\u53cd\u800c\u662f\u4e00\u4e2a\u5f88\u597d\u7684idea\u6765\u6e90\u3002\u6211\u611f\u89c9\u6709\u5f88\u591a\u5929\u624d\u7684\u6848\u4f8b\u53ef\u4ee5\u8bc1\u660e\u4eba\u7684\u77e5\u8bc6\u5bb9\u91cf\u548c\u5b66\u4e60\u80fd\u529b\u4e0a\u9650\u662f\u8d85\u51fa\u5927\u5bb6\u60f3\u8c61\u7684\uff0c\u5b66\u4e24\u4e2a\u4e13\u4e1a\u8fd9\u4ef6\u5c0f\u4e8b\u8fdc\u8fdc\u5728\u8fd9\u4e2a\u4e0a\u9650\u4e4b\u4e0b\u3002\u6211\u6c38\u8fdc\u8ba4\u4e3a\u6bc5\u529b\u548c\uff08\u5bf9\u81ea\u5df1\u4eba\u751f\u4e0a\u9650\u7684\uff09\u60f3\u8c61\u529b\u6bd4\u5f53\u524d\u80fd\u529b\u66f4\u6709\u51b3\u5b9a\u4f5c\u7528\u3002 - \u5b9e\u9645\u82f1\u8bed\u4e13\u4e1a\u53bbCS\u53cc\u4e13\u4e1a\u5bb9\u6613\u5403\u4f4e\u7ee9\u70b9\u7684\u539f\u56e0\uff0c\u5f80\u5f80\u4e0d\u662f\u80fd\u529b\u667a\u529b\u4e0d\u8db3\uff0c\u800c\u662f\u6709\u4fe1\u606f\u5dee\uff1a\u751f\u6d3b\u5728\u6587\u79d1\u7684\u6563\u6f2b\u73af\u5883\u4e2d\u96be\u4ee5\u77e5\u9053\u5927\u90e8\u5206\u540c\u5b66\u7684\u81ea\u5b66\u8fdb\u5ea6\uff0c\u548c\u5982\u679c\u67d0\u4e9b\u8bfe\u7a0b\u6709\u5b9e\u8df5\u4e0a\u7684\u5751\uff0c\u6ca1\u6709\u4e0e\u5927\u90e8\u961f\u4e00\u8d77\u5b66\u4e60\u7684\u540c\u5b66\u5c31\u96be\u4ee5\u77e5\u9053\u600e\u6837\u7075\u6d3b\u5e94\u5bf9\u3002\u6240\u4ee5\u5efa\u8bae\u4e0e\u540c\u5b66\u4e00\u8d77\u5b66\u4e60\uff0c\u53c2\u89c1\u4e0b\u4e00\u6761\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#cscs","title":"\u8981\u62e5\u6709\u4e00\u4e2a\u6216\u51e0\u4e2a\u540c\u6837\u8de8\u4e13\u4e1a\u5b66CS\u7684\u670b\u53cb\uff0c\u6216\u76f4\u63a5\u878d\u5165\u540c\u4e00\u7ea7\u7684CS\u672c\u79d1\u751f\u5708\u5b50\u91cc\u3002\u5982\u679c\u5b9e\u5728\u6ca1\u6709\uff0c\u4e00\u4e9b\u5176\u5b83\u5de5\u79d1\u7684\u540c\u5b66\u4e5f\u53ef\u4ee5\u3002","text":"<p>\u540c\u5b66\u7684\u7528\u5904\u6709\uff1a - \u5e2e\u52a9\u4f60\u8ddf\u4e0a\u5b66\u4e60\u8282\u594f\u3002CS\u7684\u751f\u6d3b\u8282\u594f\u662f\u82f1\u8bed\u4e13\u4e1a\u76842\u500d\uff0c\u662f\u7406\u79d1\u4e13\u4e1a\u76841.5\u500d\uff0c\u5982\u679c\u51b3\u5b9a\u8f6c\u4e13\u4e1a\u662f\u9700\u8981\u4e3b\u52a8\u63d0\u9ad8\u4e00\u4e0b\u751f\u6d3b\u8282\u594f\u7684\uff0c\u505a\u4e8b\u79ef\u6781\u4e00\u70b9\uff0c\u544a\u522b\u62d6\u5ef6\u3002 - \u4e92\u76f8\u63a8\u8350\u597d\u7684\u81ea\u5b66\u8d44\u6599\uff0c\u4e92\u76f8\u5206\u4eab\u7b14\u8bb0\u548c\u8ba8\u8bba\u9898\u76ee\uff0c\u5206\u5de5\u6574\u7406\u671f\u672b\u590d\u4e60\u8d44\u6599\uff0c\u671f\u672b\u4e92\u76f8\u63d0\u95ee\uff0c\u5f62\u6210\u81ea\u5b66\u6c1b\u56f4\uff0c\u8282\u7701\u4e00\u4e9b\u8e29\u5751\u65f6\u95f4\u3002 - \u5982\u679c\u67d0\u4e9b\u8bfe\u7a0b\u5b89\u6392\u6709\u6559\u5b66\u4e8b\u6545\uff0c\u4f60\u53ef\u4ee5\u53ca\u65f6\u77e5\u9053\u5927\u90e8\u5206\u540c\u5b66\u662f\u600e\u6837\u5e94\u5bf9\u7684\uff0c\u53ca\u65f6\u8c03\u6574\u81ea\u5df1\u7684\u5e94\u5bf9\u63aa\u65bd\uff0c\u9632\u6b62\u5982\u679c\u6210\u7ee9\u5360\u6bd4\u7a81\u7136\u8c03\u6574\uff0c\u81ea\u5df1\u5c06\u52aa\u529b\u82b1\u5728\u4e86\u6700\u540e\u5360\u6210\u7ee9\u6bd4\u91cd\u5f88\u5c0f\u7684\u5730\u65b9\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_5","title":"\u8981\u591a\u8bb0\u7b14\u8bb0","text":"<p>\u8bb0\u7b14\u8bb0\u662f\u8d39\u66fc\u5b66\u4e60\u6cd5\u7684\u6295\u5165\u4ea7\u51fa\u6bd4\u6700\u9ad8\u7684\u5b9e\u8df5\u5f62\u5f0f\uff0c\u5373\u65e2\u5e2e\u52a9\u68c0\u67e5\u7406\u89e3\uff0c\u7b14\u8bb0\u53c8\u9020\u798f\u540e\u4eba\u3002\u4f60\u53ef\u4ee5\u79c9\u627f\u5f00\u6e90\u7cbe\u795e\uff0c\u50cf\u524d\u8f88\u4e00\u6837\u591a\u5c06\u7b14\u8bb0\u516c\u5e03\u9020\u798f\u540e\u4eba\uff08\u4e0d\u8fc7\u8bf7\u9075\u5b88\u8bda\u4fe1\u5b88\u5219\uff09\u3002\u975e\u5e38\u5e0c\u671bZJU\u80fd\u9010\u6e10\u5f62\u6210\u8f83\u597d\u7684\u4f20\u5e2e\u5e26\u6c1b\u56f4\uff0c\u8ba9\u540e\u8f88\u4e5f\u6709\u826f\u597d\u6821\u53cb\u8d44\u6e90\u53ef\u4eab\u7528\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_6","title":"\u6211\u53ef\u4ee5\u4ee5\u600e\u6837\u7684\u8eab\u4efd\u672c\u79d1\u6bd5\u4e1a\uff1f\u6211\u6709\u54ea\u4e9b\u53ef\u884c\u7684\u51fa\u8def\uff1f","text":"<p>\u4ee5\u4e0b\u8fd9\u4e9b\u90fd\u662f\u53ef\u80fd\u505a\u5230\u7684\uff0c\u6211\u4e5f\u5206\u522b\u5217\u51fa\u4e86\u6211\u8ba4\u4e3a\u9700\u8981\u51c6\u5907\u7684\u80cc\u666f\u3002 - \u51fa\u56fdms\uff1a\u7ee9\u70b9\uff0c\u6691\u7814/\u5b9e\u4e60 - \u51fa\u56fd\u76f4\u63a5phd\uff1a\u6691\u7814\uff0cpaper - \u672c\u6821\u76f4\u535a\uff1a\u7ee9\u70b9\uff0c\u8fdb\u672c\u6821\u7ec4\uff0c\u590f\u4ee4\u8425\uff0cpaper - \u8de8\u6821\u76f4\u535a\uff1a\u7ee9\u70b9\uff0c\u5bf9\u65b9\u6821\u590f\u4ee4\u8425\uff0cpaper - \u5de5\u4f5c\uff1a\u5237\u9898\uff0c\u5b9e\u4e60 \u5176\u4e2d\u6211\u8ba4\u4e3a\u503c\u5f97\u6ce8\u610f\u7684\u8fd8\u6709\uff0c\u5177\u4f53\u6700\u597d\u7531\u8bfb\u8005\u518d\u54a8\u8be2\u76f8\u5e94\u8eab\u4efd\u7684\u4eba\u7684\u5efa\u8bae\u3002\u672c\u6761\u9002\u7528\u524d\u9762\u6240\u8ff0\u201c20\u4e2a\u4eba\u5efa\u8bae\u201d\u51c6\u5219\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_7","title":"\u8bfe\u7a0b","text":""},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#cs_4","title":"CS\u5fc5\u4fee\u8bfe","text":"<p>\u9996\u5148\u8981\u660e\u786e\u4e00\u4e2a\u8ba4\u77e5\u95ee\u9898\uff1a\u8bfbCS\u53cc\u5b66\u4f4d\u662f\u4e00\u4e2a\u539f\u5b50\u6027\u7684\u4e8b\u52a1\uff0c\u8981\u4e48\u4e0d\u8bfb\uff0c\u8981\u4e48\u6309\u9700\u6c42\u8bfb\u5b8c\u6216\u8f85\u4fee\u6216\u53cc\u5b66\u4f4d\uff0c\u8fd9\u4e24\u79cd\u9009\u62e9\u90fd\u662f\u6295\u5165\u4ea7\u51fa\u6bd4\u8f83\u9ad8\u7684\uff1b\u6295\u5165\u4ea7\u51fa\u6bd4\u6700\u4f4e\u7684\u662f\u8bfb\u4e00\u534a\uff08\u5fae\u8f85\u4fee\u6216\u53cc\u4e13\u4e1a\uff09\u3002 \u8be5\u56fe\u4e2d\u9664\u6570\u7406\u57fa\u7840\u6a21\u5757\u4e0d\u662f\u53cc\u5b66\u4f4d\u5fc5\u4fee\uff0c\u5176\u5b83\u662f\u5fc5\u4fee\u3002  \uff08\u8fd9\u4e2a\u56fe\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\u6709\u4e2a\u7ea2\u5708\uff0c\u627e\u4e0d\u5230\u539f\u56fe\u4e86\uff0c\u6279\u8bc4cyh\u540c\u5b66\u4e71\u753b\uff09</p> <p>\u9009\u4e0d\u4e0aCS\u7684\u8bfe\u600e\u4e48\u529e\uff1f - \u6700\u6709\u6548\uff1a\u8865\u9009+\u5728\u8865\u9009\u7684\u51e0\u5929\u91cc\u7ebf\u4e0b\u53bb\u9009\u8bfe\u529e\u6216\u7ed9\u9009\u8bfe\u529e\u53d1\u90ae\u4ef6\u3002\u674e\u6653\u8001\u5e08\u548c\u5f20\u4f20\u534e\u8001\u5e08\u90fd\u5f88nice\uff0c\u8868\u793a\u81ea\u5df1\u5f88\u60f3\u9009\u8bfe\uff0c\u8ddf\u8001\u5e08\u8bf4\u660e\u539f\u56e0\u3002 - \u7b2c\u4e8c\u6709\u6548\uff1a\u5982\u679c\u4efb\u8bfe\u8001\u5e08\u5728\u8ba1\u9662\u8bdd\u8bed\u6743\u8f83\u5927\uff0c\u8bf7\u4efb\u8bfe\u8001\u5e08\u5e2e\u5fd9\u8ddf\u9009\u8bfe\u529e\u8bf4\uff0c\u80fd\u4fdd\u8bc1\u4f60\u9009\u4e0a\u8be5\u8001\u5e08\u7684\u8bfe\u3002 - \u7b2c\u4e09\u6709\u6548\uff1a\u9009\u8bfe\u65f6\u4e0eCS\u7684\u540c\u5b66\u5546\u91cf\uff0c\u505a\u51fa\u65f6\u95f4\u6b63\u597d\u7684\u4e00\u4e9b\u8bfe\u8868\u3002\u53ef\u80fd\u6d89\u53ca\u5230\u201c\u7528\u4e00\u4e9b\u8bfe\u5835\u4f4f\u53e6\u4e00\u4e9b\u8bfe\u201d\u8fd9\u79cd\u590d\u6742\u64cd\u4f5c\uff0c\u6240\u4ee5\u5408\u4f5c\u6bd4\u8f83\u5212\u7b97\u3002</p> <p>\u600e\u4e48\u5b66\uff1f - ZJU\u8bfe\u7a0b\u5171\u4eab\u8ba1\u5212 https://github.com/QSCTech/zju-icicles - \u56fe\u7075\u73ed\u8bfe\u7a0b\u901f\u901a\u8ba1\u5212 https://github.com/ZJU-Turing/TuringCourses - \u4e00\u4f4d\u5b66\u957f\u7684\u4f18\u8d28\u7b14\u8bb0 \u54b8\u9c7c\u6684\u7684\u4ee3\u7801\u7a7a\u95f4\uff01 - \u54b8\u9c7c\u6684\u7684\u4ee3\u7801\u7a7a\u95f4 (xuan-insr.github.io) - \u4e00\u4f4d\u5b66\u957f\u7684\u4f18\u8d28\u7b14\u8bb0 https://github.com/Zhang-Each/CourseNoteOfZJUSE</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#ai","title":"AI","text":"<p>AI\u8bfe\u4e00\u822c\u6bd4CS\u8bfe\u597d\u9009\uff0c\u4f46\u662f\u5982\u679c\u9009\u4e0d\u4e0a\u4e5f\u8bf7\u9075\u7167\u4e0a\u6761\u4e2d\u7684\u5efa\u8bae\u3002 \u975e\u5fc5\u8981\u4e0d\u9009AI\u8bfe\uff0cAI\u8bfe\u6700\u5927\u7684\u6536\u83b7\u662f\u5728\u7b80\u5386\u4e0a\u4f5c\u4e3a\u4e00\u4e2a90+\u8bfe\u7a0b\u51fa\u73b0\uff0c\u57fa\u672c\u5b66\u4e0d\u5230\u4e1c\u897f\uff08\u9664\u4e86NLP\u8bfe\u6211\u611f\u89c9\u542c\u8bfe\u6536\u83b7\u633a\u5927\u7684\uff09\uff0c\u4e3b\u8981\u9760\u81ea\u5b66\u540e\u5377\u51fa\u5927\u4f5c\u4e1a\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_8","title":"\u8bed\u8a00\u5b66","text":"<p>\u56e0\u4e3a\u82f1\u4e13\u57f9\u517b\u65b9\u6848\u8fd8\u662f\u8981\u6c42\u4fee\u5927\u91cf\u4e13\u4e1a\u8bfe\u7684\uff0c\u611f\u89c9\u53ef\u4ee5\u5c3d\u91cf\u628a\u8bed\u8a00\u5b66\u6a21\u5757\u591a\u4fee\u4e00\u70b9\uff0c\u6709\u4e9b\u5728\u8fdb\u7ec4\u7684\u65f6\u5019\u53ef\u80fd\u8fd8\u662f\u8ba4\u53ef\u7684\u3002 \u4ee5\u4e0b\u8bfe\u7a0b\u5982\u679c\u62ff\u4e86\u9ad8\u5206\u503c\u5f97\u5728\u7b80\u5386\u4e0a\u4e00\u63d0 - \u5f53\u4ee3\u8bed\u8a00\u5b66 - \u8bed\u97f3\u5b66 - \u53e5\u6cd5\u5b66 - \u5fc3\u7406\u8bed\u8a00\u5b66 - \u8bed\u4e49\u5b66 - \u8bed\u7528\u5b66 - \u8bed\u6599\u5e93\u8bed\u8a00\u5b66</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_9","title":"\u6570\u5b66","text":"<p>\u5bf9\u4e8ePhD\u3001\u627e\u5de5\u548c\u56fd\u5185\u76f4\u535a\uff1a \u53ef\u80fd\u4e0d\u9700\u8981\u6570\u5b66\u3002\u3002\u3002\u8ba4\u4e3a\u6700\u597d\u4e0d\u8981\u989d\u5916\u9009\u6570\u5b66\u8bfe \u6211\u81f3\u4eca\u9047\u5230\u7684\u8001\u5e08\u6ca1\u6709\u56e0\u4e3a\u6211\u7b80\u5386\u4e0a\u4efb\u4f55\u6570\u5b66\u76f8\u5173\u7684\u4e1c\u897f\u800c\u5f55\u6211\u6216\u62d2\u6211\u7684\uff0c\u90fd\u662f\u53ea\u95ee\u7f16\u7a0b\u3002 CS\u4e13\u4e1a\u8bfe\u91cc\u7684\u79bb\u6563\u6570\u5b66\u548c\u8ba1\u7b97\u7406\u8bba\uff08\u548c\u53ef\u80fd\u8fd8\u6709\u6570\u903b\uff09\u5df2\u7ecf\u8db3\u591f\u57f9\u517b\u6570\u5b66\u601d\u7ef4\u3002 \u5982\u679c\u62c5\u5fc3\u6570\u636e\u5206\u6790\u548c\u7edf\u8ba1\u6280\u80fd\uff0c\u6587\u6570\u91cc\u636e\u8bf4\u5e94\u7528\u7edf\u8ba1\u5b66\u8fd9\u95e8\u8bfe\u7a0b\u6bd4\u9ad8\u7b49\u6570\u5b66\u597d\u4f7f\uff0c\u8fd8\u6709\u673a\u4f1a\u7684\u540c\u5b66\u53ef\u4ee5\u8bd5\u4e00\u4e0b\u3002</p> <p>\u5bf9\u4e8ems\uff1a \u786e\u5b9e\u6709\u4e00\u4e9b\u9879\u76ee\u8981\u6c42\u4fee\u8fc7\u4e00\u4e9b\u6570\u5b66\u8bfe\u7a0b\uff0c\u4f8b\u5982\u521a\u770b\u5230SUTD\u7684ISTD ms\u8981\u6c42\u4e24\u5b66\u671f\u5fae\u79ef\u5206\uff0c\u4e00\u5b66\u671f\u7ebf\u4ee3\u548c\u4e00\u5b66\u671f\u6982\u7edf\uff0c\u8fd9\u79cd\u65e0\u7591\u662f\u6bd4\u8f83\u4e0d\u53cb\u597d\u7684\u9879\u76ee\u4e86\u3002 \u4e5f\u6709\u6bd4\u8f83\u53cb\u597d\u7684\u9879\u76ee\uff0c\u5317\u7f8e\u4e00\u4e9b0\u57fa\u7840\u8f6c\u7801\u9879\u76ee\u53ef\u53c2\u7167OpenCSapp\uff0c\u82f1\u56fd\u7684IC\u548cUCL\u5728\u524d\u5e74\u4e5f\u5f00\u4e86\u96f6\u57fa\u7840\u8f6c\u7801\u9879\u76ee\uff0c\u4e0d\u8fc7\u51fa\u8def\u548c\u542b\u91d1\u91cf\u9700\u8981\u81ea\u5df1\u8861\u91cf\uff0c\u8fd8\u662f\u5efa\u8bae\u201c\u54a8\u8be220\u4e2a\u4eba\u201d\u51c6\u5219\u3002\u4ee3\u8868dp\u662f18\u7ea7SJTU\u82f1\u8bed\u4e13\u4e1a\uff0c4\u6bb5\u79d1\u7814\u6216\u4e92\u8054\u7f51\u5382NLP\u4ea7\u54c1\u5b9e\u4e60\uff0c\u5c11\u91cf\u9ad8\u5206\u6570\u5b66\u548c\u7f16\u7a0b\u8bfe\u7a0b\uff0c\u7ee9\u70b990+ \u2192 IC CS ms</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_10","title":"\u7ee9\u70b9","text":"<ul> <li>\u5982\u7533ms\uff1a\u5c11\u9009\u8bfe\uff0c\u4fee\u4e2a\u8f85\u4fee\u5373\u53ef\uff0c\u7ee9\u70b9\u4fdd\u630188\u4ee5\u4e0a</li> <li>\u4fdd\u7814\u76f4\u535a\uff1a\u7ee9\u70b9\u548ctitle\u6743\u8861\u4e00\u4e0b\uff0c\u4e0d\u8fc7\u597d\u50cf\u662f\u590f\u4ee4\u8425\u548c\u63d0\u524d\u8fdb\u7ec4\u66f4\u91cd\u8981</li> <li>\u5982\u7533phd\u6216\u5de5\u4f5c\uff1a\u4e89\u53d6\u53cc\u5b66\u4f4d\u7684title\uff0c\u8fc7\u7a0b\u4e2d\u5c3d\u529b\u800c\u4e3a\uff0c\u7ee9\u70b9\u522b\u592a\u7ea0\u7ed3\uff0c\u6ce8\u91cd\u79d1\u7814/\u5b9e\u4e60</li> </ul>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_11","title":"\u79d1\u7814","text":""},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#nlp_1","title":"\u5982\u4f55\u9009\u9898\uff1fNLP\u6709\u54ea\u4e9b\u65b9\u5411\u53ef\u505a\uff1f","text":"<p>\u53c2\u7167\u8fd9\u4e9b\u9876\u4f1a\u90fd\u6709\u4ec0\u4e48track\uff0c\u4e0b\u9762\u662f\u6700\u8fd1\u4e00\u671f\u6bcf\u4e2atrack\u7684best paper - Best Papers - ACL 2023 (aclweb.org) - Best Paper Awards - emnlp 2022 (balhafni.github.io) - Transactions of the Association for Computational Linguistics (transacl.org) - Announcing the NAACL 2022 Best Paper Awards! - NAACL-HLT 2022</p> <p>\u7279\u522b\u5730\uff0c\u60f3\u5230NLP\u91cc\u6bd4\u8f83\u7eaf\u8bed\u8a00\u5b66\u7684\u4e3b\u9898/\u65b9\u6cd5\u4e5f\u6709\u4e00\u4e9b\uff0c\u6709\u5982\u4e0b\u51e0\u4e2a \u4e3a\u4ec0\u4e48\u8981\u8bb2\u8fd9\u4e00\u5757\u56e0\u4e3a\u62c5\u5fc3\u4f60\u5728\u9762\u8bd5\u7684\u65f6\u5019\u4f1a\u9700\u8981\u5411\u8001\u5e08\u8bc1\u660e\u4f60\u7684\u53e6\u4e00\u90e8\u5206\u4e13\u4e1a\u77e5\u8bc6\u4e5f\u662f\u6709\u7528\u7684 \u4e00\u822c\u6b27\u6d32\u7684NLP\u4f1a\u504f\u8bed\u8a00\u5b66\u4e00\u70b9 - \u5b9e\u9a8c\u8bed\u97f3\u548c\u97f3\u7cfb\u5b66 - \u7528\u8bed\u8a00\u5b66\u77e5\u8bc6\u505a\u6570\u636e\u548c\u6570\u636e\u589e\u5f3a - AI\u4e2d\u7684\u4f26\u7406\u9053\u5fb7\u95ee\u9898 - \u7a00\u6709\u8bed\u8a00\u6316\u6398</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_12","title":"\u5982\u4f55\u9009\u5bfc\uff1f","text":"<p>\u56fd\u5916\u5bfc\u5e08\uff1a\u5e38\u8bfb\u6bcf\u5e74\u7684\u9876\u4f1a\u6709\u610f\u601d\u8bba\u6587\uff0c\u5e76\u53c2\u7167CSRankings: Computer Science Rankings\uff0c\u5173\u6ce8\u5b66\u672f\u5708\u517b\u597d\u53f7\u540e\u5e38\u5237Twitter \u56fd\u5185\u6821\u5185\u5bfc\u5e08\uff1a\u5982\u679c\u6709\u60f3\u8be2\u95ee\u7684\u5bfc\u5e08\u540d\u5355\u53ef\u4ee5\u90ae\u4ef6\u95ee\u6211 \u9009\u5bfc\u6216\u8005\u8054\u7cfbPhD\u7684\u65f6\u5019\u5982\u679c\u63a5\u5230\u7684\u4efb\u52a1\u662f\u4e8c\u4f5c\u4e09\u4f5c\u5f80\u540e\uff0c\u5f88\u53ef\u80fd\u662f\u6253\u767d\u5de5\uff0c\u57fa\u672c\u53ef\u4ee5\u62d2\u7edd\u3002\u9664\u975e\u4f60\u8ba4\u4e3a\u4f60\u627f\u62c5\u7684\u5de5\u4f5c\u8f83\u4e3a\u91cd\u8981\uff0c\u8001\u5e08\u53ef\u4ee5\u7ed9\u4f60\u63a8\u8350\u4fe1\uff0c\u4e8c\u4f5c\u4e09\u4f5c\u7684\u4f5c\u7528\u53ef\u80fd\u6ca1\u6709\u63a8\u8350\u4fe1\u5927\u3002 \u5982\u679c\u7533\u8bf7PhD\uff0c\u63a8\u8350\u4fe1\u7684\u529b\u5ea6\uff1a\u4f60\u4e0e\u63a8\u8350\u4eba\u7684\u4ea7\u51fa\u5f88\u91cd\u8981+\u76ee\u6807PhD\u5bfc\u8ba4\u8bc6\u7684\u4eba &gt; \u4f60\u4e0e\u63a8\u8350\u4eba\u7684\u4ea7\u51fa\u5f88\u91cd\u8981+\u76ee\u6807PhD\u5bfc\u4e0d\u8ba4\u8bc6\u7684\u4eba &gt; \u5176\u5b83</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_13","title":"\u7533\u8bf7","text":"<p>\u56e0\u4e3a\u4fdd\u7814\u548c\u627e\u5de5\u6211\u786e\u5b9e\u4e0d\u61c2\uff0c\u8fd9\u91cc\u6682\u65f6\u53ea\u5199\u7533\u8bf7\u4e86\u3002\u540e\u7eed\u6709\u8bf7\u5171\u540c\u4f5c\u8005\u6269\u5c55\u5185\u5bb9\u7684\u8ba1\u5212\uff0c\u5982\u613f\u610f\u8d21\u732e\u8bf7\u8054\u7cfb\u6211\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#check-point","title":"Check Point","text":"<p>\u5927\u4e00\u6691\u5047\u7ed3\u675f\u65f6\uff1a\u4e13\u5fc3\u5b66\u4e13\u4e1a\u8bfe \u5927\u4e8c\u6691\u5047\u7ed3\u675f\u65f6\uff1a\u8fdb\u7ec4\uff0c\u5b66\u4f1apytorch\uff0c\u8bad\u8fc7\u4e00\u4e9b\u5e38\u7528\u7684\u6a21\u578b \u5927\u4e09\u6691\u5047\u7ed3\u675f\u65f6\uff1a\u4ea7\u51fa\u4e00\u4f5c\u6216\u5171\u4e00\u8bba\u6587</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_14","title":"\u6211\u8981\u4e0d\u8981\u627e\u4e2d\u4ecb\uff1f","text":"<p>\u4e0d\u8981\u3002 \u539f\u56e0\u4e00\uff1aCS\u7684\u5728\u7ebf\u514d\u8d39\u8d44\u6599\u8db3\u591f\u4f7f\u7528 \u539f\u56e0\u4e8c\uff1a\u4e2d\u4ecb\u7684\u4fe1\u606f\u66f4\u65b0\u901f\u5ea6\u8d76\u4e0d\u4e0aCS\u5b66\u79d1\u7684\u53d1\u5c55\u901f\u5ea6</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_15","title":"\u6211\u7533\u8bf7\u53ef\u4ee5\u53c2\u8003\u54ea\u4e9b\u8d44\u6599\uff1f","text":"<p>\u7533\u8bf7MS - \u5317\u7f8e\u7684CS master Home - Open CS Application - \u9664\u5317\u7f8e\u5916\u7684\u5176\u5b83CS master Global CS (global-cs-application.github.io) - \u4e00\u4ea9\u4e09\u5206\u5730/\u5bc4\u6258\u5bb6\u56ed\u7b49\u8bba\u575b - CC98\u4e0a\u6bcf\u4e00\u5e74CS\u7684\u98de\u8dc3\u624b\u518c</p> <p>\u7533\u8bf7PhD - \u6b27\u7f8eNLP\u5708\u5bf9PhD\u7533\u8bf7\u7684\u5efa\u8bae https://github.com/zhijing-jin/nlp-phd-global-equality - \u4e86\u89e3\u5b66\u79d1\u4f18\u52bf\u5b66\u6821\u548c\u5bfc\u5e08 CSRankings: Computer Science Rankings - \u6ce8\u518c\u4e00\u4e2aTwitter\u8d26\u53f7\uff0c\u5f00\u59cb\u5173\u6ce8NLP\u5708\u7684PhD\u548cAP\uff0c\u5404\u79cd\u7533\u8bf7\u673a\u4f1a\u4ed6\u4eec\u90fd\u4f1a\u5c3d\u5feb\u53d1\u5e03\u7684\u3002\u6bd4\u5982\u4f60\u53ef\u4ee5\u5148\u4eceAndrew Ng\u3001Christopher Manning\u3001Geoffrey Hinton\u8fd9\u79cd\u8001\u6559\u6388\u5173\u6ce8\u8d77\uff0c\u7136\u540e\u5173\u6ce8\u4ed6\u4eec\u7684\u5173\u6ce8\u8fd9\u6837\u6765\u641e\u3002 - \u5173\u6ce8\u4e00\u4ea9\u4e09\u5206\u5730/CC98/\u4e00\u4e9b\u5fae\u4fe1\u516c\u4f17\u53f7/\u77e5\u4e4e\u7684\u62db\u751f\u4fe1\u606f</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_16","title":"\u6295\u9012\u6691\u7814\u6ce8\u610f\u4e8b\u9879","text":"<p>\u6d41\u7a0b\u540c\u7533\u8bf7PhD \u5df2\u7ecf\u719f\u8bc6\u7684\u5bfc\u5e08\u63a8\u8350\u662f\u6700\u5feb\u7684\uff1b\u5426\u5219\u5c31\u81ea\u5df1\u6d77\u6295\uff0c\u6295\u53d1\u5e03\u8fc7\u62db\u751f\u5e7f\u544a\u6216\u4e3b\u9875\u8868\u660e\u6b63\u5728\u62db\u751f\u7684\u8001\u5e08\u662f\u6700\u5feb\u7684\u3002\u6709\u7684\u65f6\u5019\u53ef\u4ee5\u5c1d\u8bd5\u6295\u8ba4\u8bc6\u7684PhD\uff0c\u56e0\u4e3a\u6691\u7814\u671f\u95f4\u5927\u90e8\u5206\u60c5\u51b5\u8fd8\u662f\u8ddf\u7740PhD\u6253\u5de5\u3002 \u5982\u679c\u8001\u5e08\u7ed9\u4f60\u7684\u8d23\u4efb\u6bd4\u8f83\u91cd\uff0c\u4e14\u4f60\u6709\u6bd4\u8f83\u597d\u7684\u5de5\u4f5c\u73af\u5883\uff0c\u6211\u8ba4\u4e3a\u7ebf\u4e0a\u7ebf\u4e0b\u533a\u522b\u4e0d\u5927\u3002 \u60f3\u53bb\u5317\u7f8e\u5c31\u5957\u5317\u7f8e\uff0c\u6211\u89c9\u5f97\u6700\u597d\u4e0d\u8981\u627e\u8df3\u677f\uff0c\u6709\u5317\u7f8e\u7684\u7ebf\u4e0a\u6691\u7814\u4e5f\u5f88\u597d\uff0c\u53ea\u8981\u662f\u4f60\u4e00\u4f5c\uff0c\u65f6\u957f6\u4e2a\u6708\u4ee5\u4e0a\uff0c\u6bcf\u5468\u6c47\u62a5\u8fdb\u5ea6\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_17","title":"\u6295\u9012\u5b9e\u4e60\u6ce8\u610f\u4e8b\u9879","text":"<p>\u9700\u8981\u5b9e\u4e60 iff \u4f60\u6253\u7b97\u627e\u5de5or\u8bfb\u5b8c\u7855\u58eb\u627e\u5de5\uff0c\u7533\u8bf7\u5b66\u672f\u7c7bms\u548cPhD\u7684\u8bdd\uff0c\u5b9e\u4e60\u4e0d\u5f3a\u6c42\u3002</p>"},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#-xuan-insrgithubio","title":"- \ud83c\udff3\ufe0f\u200d\ud83c\udf08 \u603b\u89c8 - \u54b8\u9c7c\u6684\u7684\u4ee3\u7801\u7a7a\u95f4 (xuan-insr.github.io) \u627e\u6691\u671f\u5b9e\u4e60\u548c\u79cb\u62db\u7684\u7ecf\u9a8c\u5e16","text":""},{"location":"Application/ZJU%20English%20Major%20to%20CS%26NLP/#_18","title":"\u5173\u4e8e\u7b14\u8005&amp;\u8054\u7cfb\u7b14\u8005","text":"<p>\u7b14\u8005\u4f30\u8ba1\u662f\u4ece\u82f1\u8bed\u4e13\u4e1a\u8f6cNLP\u89c4\u5212\u6700\u4e0d\u987a\u3001\u8fdb\u5ea6\u6700\u66f2\u6298\u7684\u4e00\u4e2a\u3002\u8fd9\u4efd\u6587\u6863\u4e0d\u662f\u4ec0\u4e48\u6210\u529f\u7ecf\u9a8c\u5206\u4eab\uff0c\u6211\u5e76\u4e0d\u6210\u529f\uff0c\u53ea\u662f\u60f3\u628a\u6211\u8e29\u8fc7\u7684\u5751\u544a\u8bc9\u540e\u4eba\uff0c\u5e0c\u671b\u5c11\u6709\u4eba\u91cd\u8e48\u6211\u7684\u8986\u8f99\u3002\u6211\u89c9\u5f97\u6211\u7684\u9ad8\u4e2d\u548c\u672c\u79d1\u8fc7\u5f97\u592a\u574e\u5777\u4e86\uff0c\u771f\u8bda\u5730\u60f3\u5e2e\u52a9\u5b66\u5f1f\u5b66\u59b9\uff0c\u5e0c\u671b\u4f60\u4eec\u4e00\u5207\u987a\u5229\u3002\u8bfb\u8005\u53ef\u4ee5\u4ee5\u6211\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5728\u56db\u5e74\u540e\u4e0d\u80fd\uff08\u5f53\u7136\u5982\u679c\u65e9\u505a\u89c4\u5212\uff0c\u4e00\u76f4\u5728\u52aa\u529b\uff0c\u4e5f\u4e0d\u4f1a\uff09\u6bd4\u6211\u66f4\u5dee\u3002\u6bd5\u7adf\u4e00\u6761\u8def\u8d70\u7684\u4eba\u591a\u4e86\uff0c\u540e\u4eba\u4e00\u5b9a\u662f\u8981\u8d8a\u8d70\u8d8a\u987a\u7684\u3002</p> <p>\u5982\u6709\u5efa\u8bae\u6216\u7591\u95ee\u8bf7\u901a\u8fc7\u90ae\u4ef6\u8054\u7cfb\u6211 RuoxiNing@outlook.com\u3002</p>"},{"location":"Application/%E3%80%90TODO%E3%80%91%E6%88%91%E7%9A%8424fall%E7%94%B3%E8%AF%B7%E8%AE%B0%E5%BD%95/","title":"24fall\u7533\u8bf7\u8bb0\u5f55","text":"<p>\u672c\u9875\u9762\u4f1a\u5728\u621112\u6708\u6295\u9012\u5b8c\u7b2c\u4e00\u6279\u7533\u8bf7\u540e\u66f4\u65b0\u4e00\u4e2a\u7533\u8bf7\u8bb0\u5f55\u3002</p> <p>\u4e3b\u8981\u76ee\u7684\u6709\u5206\u4eab\u6211\u7684\u7ecf\u9a8c\u5fc3\u5f97\u548c\u52aa\u529b\u83b7\u5f97\u7684\u4e00\u4e9b\u4fe1\u606f\uff0c\u81f4\u529b\u4e8e\u7ef4\u62a4CS\u548clinguistics\u7533\u8bf7\u8d44\u6599\u5f00\u6e90\u7684\u751f\u6001\u3002</p> <p>\u9884\u8ba1\u66f4\u65b0\u5c0f\u6807\u9898\u6709\uff1a - \u7533\u8bf7\u683c\u8a00 - ms\u9009\u6821 - phd\u5957\u74f7/\u9009\u6821/\u9009\u5bfc - \u8bed\u8a00\u6210\u7ee9 - \u6587\u4e66</p>"},{"location":"CS_Notes/","title":"\u7d22\u5f15","text":"<p>\u672c\u7ae0\u8282\u5305\u62ec\u8ba1\u7b97\u673a\u79d1\u5b66\u7b14\u8bb0</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/","title":"Lab\u8bb0\u5f55","text":"<p>\u26a0 Lab\u5df2\u7ecf\u5168\u90e8\u6362\u6389\uff0c\u8fd9\u90e8\u5206\u4f5c\u4e1a\u4ecb\u7ecd\u65e0\u6cd5\u53c2\u8003\u4e86\u3002 1. \u4f5c\u4e1a1: \u5b57\u7b26\u4e32\u8f6c\u6362     \u8f93\u5165\u4e00\u4e2a\u5b57\u7b26\u4e32\uff0c\u5c0f\u5199\u5b57\u6bcd\u5168\u90e8\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\uff0c\u5220\u9664\u7a7a\u683c\u540e\u8f93\u51fa\u3002     \u8bb0\u5f97\u4ed6\u6709\u5b57\u7b26\u4e32\u8bfb\u5199\u7684\u6e90\u4ee3\u7801\u3002 2. \u4f5c\u4e1a2: \u6253\u5370ASCII\u7801\u8868     \u8fdb\u5165\u56fe\u5f62\u6a21\u5f0f\uff0c\u8f93\u51fa\u7ea2\u7684ascii\u7801\u548c\u7eff\u7684\u76f8\u5e94\u5341\u516d\u8fdb\u5236\u7f16\u53f7\u3002     \u4e2a\u4eba\u611f\u89c9\u5148\u628a\u4f4d\u79fb\u5199\u51fa\u6765\u518d\u586b\u91cc\u9762\u7684\u8f93\u51fa\u6bd4\u8f83\u597d\u5f04\u3002     \u53ef\u4ee5\u53c2\u7167\u4ed6\u7684\u6570\u5b57\u7528\u5faa\u73af\u5de6\u79fb\u8f93\u51fa\u6210\u5341\u516d\u8fdb\u5236\u4ee3\u7801\u3002 3. \u4f5c\u4e1a3: \u7b80\u6613\u8ba1\u7b97\u5668     \u6574\u4f53\u601d\u8def\uff1a80386\u8bed\u6cd5\u5199\uff0c\u5185\u5bb9\u90fd\u5b58\u5728\u5185\u5b58\u53d8\u91cf\u91cc     \u52a0\u6cd5\u601d\u8def\uff1a\u9ad8\u4f4d\u52a0\u9ad8\u4f4d\uff0c\u4f4e\u4f4d\u52a0\u4f4e\u4f4d     \u4e58\u6cd5\u601d\u8def\uff1a\u5206\u522b\u4e58\u4f4e\u4f4d\u548c\u9ad8\u4f4d\uff0c\u9ad8\u4f4d\u7ed3\u679c\u52a0\u8fdb\u4f4d     \u9664\u6cd5\u601d\u8def\uff1a\u5206\u522b\u9664\u9ad8\u4f4d\u548c\u4f4e\u4f4d\uff0c\u3002\u3002\u540e\u9762\u5fd8\u4e86     \u8f93\u51fa\u5341\u8fdb\u5236\u601d\u8def\uff1a\u9ad8\u4f4d\u4f4e\u4f4d     \u8f93\u51fa\u5341\u516d\u8fdb\u5236\u601d\u8def\uff1a 4. \u4f5c\u4e1a4: C\u4ee3\u7801\u6587\u4ef6\u67e5\u770b\u5668\u7ffb\u8bd1\u6210\u6c47\u7f16     \u4ed6\u4f1a\u7ed9\u4e00\u4e2ac\u6e90\u4ee3\u7801\uff0c\u7528c\u548c\u6c47\u7f16\u5939\u5fc3\u8c03\u8bd5\u628ac\u7ffb\u8bd1\u6210\u6c47\u7f16\u3002     \u903b\u8f91\u7684\u601d\u8def\uff1a     \u5bc4\u5b58\u5668\u72b6\u6001\u4fdd\u5b58+\u521d\u59cb\u72b6\u6001+\u5224\u65ad\u7ec8\u6b62+\u64cd\u4f5c+\u50a8\u5b58+\u5faa\u73af\u6761\u4ef6+\u8df3\u8f6c+\u5bc4\u5b58\u5668\u72b6\u6001\u6062\u590d</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#6","title":"6\u79cd\u5bfb\u5740\u65b9\u5f0f\u4e0e\u5176\u4f5c\u7528","text":"\u8bf4\u660e \u793a\u4f8b \u4f5c\u7528 \u7acb\u5373\u5bfb\u5740 mov eax,56H \u901a\u5e38\u7528\u4e8e\u8d4b\u503c \u76f4\u63a5\u5bfb\u5740 mov eax,[1255887H] \u901a\u5e38\u7528\u4e8e\u5904\u7406\u53d8\u91cf \u5bc4\u5b58\u5668\u5bfb\u5740 mov eax,[edi] \u5730\u5740\u5728\u5bc4\u5b58\u5668\u4e2d \u5bc4\u5b58\u5668\u76f8\u5bf9\u5bfb\u5740 mov eax,[edi+20H] \u5e38\u7528\u4e8e\u8bbf\u95ee\u6570\u7ec4\u548c\u7ed3\u6784 \u57fa\u5740\u52a0\u53d8\u5740\u5bfb\u5740 mov eax,[EBP+ESI] \u5e38\u7528\u4e8e\u8bbf\u95ee\u6570\u7ec4 \u76f8\u5bf9\u57fa\u5740\u52a0\u53d8\u5740\u5bfb\u5740 mov eax,[EBX+EDI-10H] \u5e38\u7528\u4e8e\u8bbf\u95ee\u7ed3\u6784"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#obj-dump","title":"obj dump","text":"<p>\u6e90\u4ee3\u7801\u6587\u4ef6\u540dmytest.c</p> <pre><code>gcc -c -g -o mytest mytest.c\nobjdump -s -d main.o &gt; main.o.txt\n</code></pre> <p>\u76ee\u6807\u6587\u4ef6\u53cd\u6c47\u7f16\uff0c\u540c\u65f6\u663e\u793a\u6e90\u4ee3\u7801</p> <pre><code>gcc -g -c -o main.o main.c\nobjdump -S -d main.o &gt; main.o.txt\n</code></pre> <p>\u663e\u793a\u6e90\u4ee3\u7801\u7684\u540c\u65f6\u663e\u793a\u884c\u53f7</p> <pre><code>objdump -j .text -ld -C -S main.o &gt; main.o.txt\n</code></pre> <p>\u53ef\u6267\u884c\u6587\u4ef6\u53cd\u6c47\u7f16</p> <pre><code>gcc -o main main.c\nobjdump -s -d main &gt; main.txt\n</code></pre> <p>\u540c\u65f6\u663e\u793a\u6e90\u4ee3\u7801</p> <pre><code>gcc -g -o main main.c\nobjdump -S -d main &gt; main.txt\n</code></pre>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_1","title":"\u671f\u672b\u8003\u8bd5","text":"<ol> <li>\u662f\u975e\u9898(10\u4e2a\uff0c\u6bcf\u98981\u5206\uff0c\u517110\u5206)</li> <li>\u586b\u7a7a(15\u4e2a\uff0c\u6bcf\u7a7a2\u5206\uff0c\u517130\u5206)\uff1a</li> <li> <p>\u7a0b\u5e8f\u586b\u7a7a\u9898(3\u9898\uff0c\u6bcf\u989810\u5206\uff0c\u517130\u5206)</p> <p>\u4e00\u822c\u90fd\u4f1a\u7528stack\u538b\u5165\u53c2\u6570 \u4f1a\u7ed9\u51fac\u8bed\u8a00\u7684\u539f\u578b\uff08\uff1f\uff0c\u53c2\u6570\u7684\u538b\u5165\u987a\u5e8f\u4ece\u53f3\u5230\u5de6\uff0ccaller\u6e05\u7406 pascal\uff0c\u4ece\u5de6\u5230\u53f3\uff0ccallee\u6e05\u7406 stdcall\uff0c\u4ece\u53f3\u5230\u5de6\uff0ccaller\u6e05\u7406 \u90fd\u7528ax\u8fd4\u56de\u53c2\u6570 \u4e00\u822c\u4e24\u4e2a\u7a7a\u4e0d\u53ef\u4ee5\u4ea4\u6362\u3002\u3002\u3002 \u5148\u81ea\u5df1\u5199\u4e00\u904d\u518d\u586b \uff08\u4e00\u822c20\u51e0\u884c\u7684\u7a0b\u5e8f\uff09</p> </li> <li> <p>\u7a0b\u5e8f\u9605\u8bfb(2\u9898\uff0c\u6bcf\u98985\u5206\uff0c\u517110\u5206)     \u4f1a\u95ee\u8fd0\u884c\u7ed3\u679c\u548c\u4e2d\u95f4\u7ed3\u679c\uff08#\uff09\uff08\u5982\u679c\u6709\u5faa\u73af\uff0c\u6bcf\u6b21\u5faa\u73af\u5230\u90fd\u8981\u5199\uff0c\u4f46\u662f\u4e0d\u4f1a\u592a\u591a\uff09</p> </li> </ol> <p>\u4e0d\u4f1a\u6709\u76f4\u63a5\u624b\u5199\u4e00\u6574\u4e2a\u7a0b\u5e8f\u7684\u9898</p> <p>\u91cd\u70b9\uff1a \u51fd\u6570\u53c2\u6570\u4f20\u9012\uff0c\u5982\u4f55\u6784\u9020\u4e00\u4e2a\u5806\u6808\u6846\u67b6\uff0cebp\u3002\u3002 \u9700\u8981\u770b\u61c2\u662f\u4e0d\u662f\u9012\u5f52\uff0c \u6709\u4e00\u4e2a\u7a0b\u5e8f\u586b\u7a7a\u4f1a\u51fa\u5355\u6b65\u8c03\u8bd5\uff0c\u8fb9\u89e3\u5bc6\u8fb9\u52a0\u5bc6\u90a3\u4e2a\u3002\u3002 \u4e0d\u4f1a\u8003\u4fdd\u62a4\u6a21\u5f0f\u3002</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_2","title":"\u590d\u4e60","text":""},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#intel-808680386-cpu","title":"Intel 8086/80386 CPU \u529f\u80fd\u7ed3\u6784","text":""},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_3","title":"\u5de5\u4f5c\u65b9\u5f0f","text":"<ol> <li>\u4ece\u5b58\u50a8\u5668\u4e2d\u53d6\u4e00\u6761\u6307\u4ee4</li> <li>\u5206\u6790\u6307\u4ee4\u7684\u64cd\u4f5c\u7801</li> <li>\u4ece\u5b58\u50a8\u5668\u4e2d\u8bfb\u53d6\u64cd\u4f5c\u6570</li> <li>\u6267\u884c\u6307\u4ee4</li> <li>\u5199\u5165\u7ed3\u679c\u96c6</li> <li>\u56de\u52301</li> </ol> <p>\u8fd0\u7b97\u5668\u8fdb\u884c\u4fe1\u606f\u5904\u7406\uff0c\u5bc4\u5b58\u5668\u8fdb\u884c\u4fe1\u606f\u5b58\u50a8\uff0c\u63a7\u5236\u5668\u63a7\u5236\u5404\u79cd\u5668\u4ef6\u5de5\u4f5c\uff0c\u603b\u7ebf\u8fde\u63a5\u5404\u79cd\u5668\u4ef6\u3002</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#163280x86-view","title":"16\u4f4d\u548c32\u4f4d\u768480x86\u7684\u533a\u522b - \u64cd\u4f5c\u7cfb\u7edfview","text":"<ul> <li>16\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684\u4e2d\u65ad\u8c03\u7528\u76f8\u5f53\u4e8e32\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684API\u8c03\u7528\u300216\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684\u6bb5\u5730\u5740\u548c\u4fbf\u5b9c\u5730\u5740\u572832\u4f4d\u4e2d\u6d88\u5931\u4e86\uff0c\u572832\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7edf\u4e00\u91c7\u7528\u5e73\u5766\u7684\u5185\u5b58\u5730\u5740\u6a21\u5f0f\u5bfb\u5740\u3002</li> <li>16\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684\u7a0b\u5e8f\u8fd0\u884c\u5728RING0\u7ea7\uff0c\u4e5f\u5c31\u662f\u8bf4\u666e\u901a\u7a0b\u5e8f\u548c\u64cd\u4f5c\u7cfb\u7edf\u8fd0\u884c\u5728\u540c\u4e00\u4e2a\u7ea7\u522b\u5e76\u62e5\u6709\u6700\u9ad8\u6743\u9650\uff0c\u800c32\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684\u7a0b\u5e8f\u4e00\u822c\u53ea\u62e5\u6709RING3\u7ea7\u8fd0\u884c\u6743\u9650\uff0c\u7a0b\u5e8f\u7684\u6240\u6709\u64cd\u4f5c\u90fd\u53d7\u5230\u64cd\u4f5c\u7cfb\u7edf\u63a7\u5236\uff0c\u82e5\u7a0b\u5e8f\u8981\u83b7\u5f97RING0\u64cd\u4f5c\u7279\u6743\uff0c\u53ea\u80fd\u901a\u8fc7\u9a71\u52a8\u7a0b\u5e8f\u5b9e\u73b0\u3002</li> <li>16\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u7684\u53ef\u6267\u884c\u6587\u4ef6\u683c\u5f0f\u548c32\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u7684\u53ef\u6267\u884c\u6587\u4ef6\u683c\u5f0f\u4e0d\u540c\uff0c\u572832\u4f4d\u7684windows\u64cd\u4f5c\u7cfb\u7edf\u4e2d\uff0c\u53ef\u6267\u884c\u6587\u4ef6\u7684\u683c\u5f0f\u53ebPE\u683c\u5f0f\uff0c32\u4f4d\u7684windows\u64cd\u4f5c\u7cfb\u7edf\u8fd0\u884c\u5728CPU\u7684\u4fdd\u62a4\u6a21\u5f0f\u4e4b\u4e0a\uff0c\u800c16\u4f4d\u7684\u7cfb\u7edf\u5219\u8fd0\u884c\u5728CPU\u7684\u5b9e\u6a21\u5f0f\u4e0a\u3002</li> </ul>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_4","title":"\u903b\u8f91\u5730\u5740\u4e0e\u7269\u7406\u5730\u5740\u8f6c\u6362\uff1a","text":"<p>1234h:0058h \u8f6c\u5316\u6210\u7269\u7406\u5730\u5740=12340h+0058h=12398h \u8865\u7801</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_5","title":"\u6807\u5fd7\u4f4d","text":"<p>\u72b6\u6001\u6807\u5fd7\uff1aCF ZF SF OF AF PF \u63a7\u5236\u6807\u5fd7\uff1aDF(direction flags) TF(trace/trap flag) IF(interrupt flag)</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_6","title":"\u6570\u636e\u5728\u5185\u5b58\u4e2d\u7684\u5b58\u653e\u89c4\u5f8b\uff1a","text":"<p>\u5c0f\u7aef\u683c\u5f0f\u3002\u4f4e\u5b57\u8282\u5728\u524d\uff0c\u9ad8\u5b57\u8282\u5728\u540e\u3002 \u8bbeds=1000h, bx=2000h, ax=1234h Mov ds:[bx], ax \u6267\u884c\u540e1000:2001\u6307\u5411\u7684\u5b57\u8282=12h</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_7","title":"\u5bc4\u5b58\u5668","text":"<p>\u603b\u7ed3</p> \u5bc4\u5b58\u5668 \u7c7b\u522b \u7528\u9014 AX \u6570\u636e\u5bc4\u5b58\u5668 \u7b97\u672f\u8fd0\u7b97\u4e2d\u7684\u4e3b\u8981\u5bc4\u5b58\u5668\uff0c\u5728\u4e58\u9664\u8fd0\u7b97\u4e2d\u7528\u6765\u5236\u5b9a\u88ab\u9664\u6570\uff0c\u4e5f\u662f\u4e58\u9664\u8fd0\u7b97\u540e\u7ed3\u679c\u7684\u9ed8\u8ba4\u5b58\u50a8\u5355\u5143\u3002\u53e6\u5916I/O\u6307\u4ee4\u5747\u4f7f\u7528\u8be5\u5bc4\u5b58\u5668\u4e0eI/O\u8bbe\u5907\u4f20\u9001\u4fe1\u606f\u3002 BX \u6570\u636e\u5bc4\u5b58\u5668 \u6307\u4ee4\u5bfb\u5740\u65f6\u5e38\u7528\u505a\u57fa\u5740\u5bc4\u5b58\u5668\uff0c\u5b58\u5165\u504f\u79fb\u91cf\u6216\u504f\u79fb\u91cf\u7684\u6784\u6210\u6210\u5206 CX \u6570\u636e\u5bc4\u5b58\u5668 \u5728\u5faa\u73af\u6307\u4ee4\u64cd\u4f5c\u6216\u4e32\u5904\u7406\u6307\u4ee4\u4e2d\u9690\u542b\u8ba1\u6570 DX \u6570\u636e\u5bc4\u5b58\u5668 \u5728\u53cc\u5b57\u8282\u957f\u8fd0\u7b97\u4e2d\u4e0eAX\u6784\u621032\u4f4d\u64cd\u4f5c\u6570\uff0cDX\u4e3a\u9ad816\u4f4d\u3002\u5728\u67d0\u4e9bI/O\u6307\u4ee4\u4e2d\uff0cDX\u88ab\u7528\u6765\u5b58\u653e\u7aef\u53e3\u5730\u5740 SP \u6307\u9488\u53ca\u53d8\u5740\u5bc4\u5b58\u5668 \u59cb\u7ec8\u662f\u6808\u9876\u7684\u4f4d\u7f6e\uff0c\u4e0eSS\u5bc4\u5b58\u5668\u4e00\u8d77\u6784\u6210\u6808\u9876\u6570\u636e\u7684\u7269\u7406\u5730\u5740 BP \u6307\u9488\u53ca\u53d8\u5740\u5bc4\u5b58\u5668 \u7cfb\u7edf\u9ed8\u8ba4\u5176\u6307\u5411\u5806\u6808\u4e2d\u67d0\u4e00\u5355\u5143\uff0c\u5373\u63d0\u4f9b\u6808\u4e2d\u8be5\u5355\u5143\u7684\u504f\u79fb\u91cf\u3002\u52a0\u6bb5\u524d\u7f00\u540e\uff0cBP\u53ef\u4f5c\u4e3a\u975e\u5806\u6808\u6bb5\u7684\u5730\u5740\u6307\u9488 SI \u6307\u9488\u53ca\u53d8\u5740\u5bc4\u5b58\u5668 \u4e0eDS\u8054\u7528\uff0c\u6307\u793a\u6570\u636e\u6bb5\u4e2d\u67d0\u64cd\u4f5c\u7684\u504f\u79fb\u91cf\u3002\u5728\u505a\u4e32\u5904\u7406\u65f6\uff0cSI\u6307\u793a\u6e90\u64cd\u4f5c\u6570\u5730\u5740\uff0c\u5e76\u6709\u81ea\u52a8\u589e\u91cf\u548c\u81ea\u52a8\u51cf\u91cf\u7684\u529f\u80fd\u3002\u53d8\u5740\u5bfb\u5740\u65f6\uff0cSI\u4e0e\u67d0\u4e00\u4f4d\u79fb\u91cf\u5171\u540c\u6784\u6210\u64cd\u4f5c\u6570\u7684\u504f\u79fb\u91cf DI \u6307\u9488\u53ca\u53d8\u5740\u5bc4\u5b58\u5668 \u4e0eDS\u8054\u7528\uff0c\u6307\u793a\u6570\u636e\u6bb5\u4e2d\u67d0\u64cd\u4f5c\u6570\u7684\u504f\u79fb\u91cf\uff0c\u6216\u4e0e\u67d0\u4e00\u4f4d\u79fb\u91cf\u5171\u540c\u6784\u6210\u64cd\u4f5c\u6570\u7684\u504f\u79fb\u91cf\uff0c\u4e32\u5904\u7406\u64cd\u4f5c\u65f6\uff0cDI\u6307\u793a\u9644\u52a0\u6bb5\u4e2d\u76ee\u7684\u5730\u5740\uff0c\u5e76\u6709\u81ea\u52a8\u589e\u91cf\u548c\u51cf\u91cf\u7684\u529f\u80fd\u3002 CS \u6bb5\u5bc4\u5b58\u5668 \u5b58\u653e\u5f53\u524d\u7a0b\u5e8f\u7684\u6307\u793a\u4ee3\u7801 DS \u6bb5\u5bc4\u5b58\u5668 \u5b58\u653e\u7a0b\u5e8f\u6240\u8bbe\u8ba1\u7684\u6e90\u6570\u636e\u6216\u7ed3\u679c SS \u6bb5\u5bc4\u5b58\u5668 \u4ee5\u201c\u5148\u5165\u540e\u51fa\u201d\u4e3a\u539f\u5219\u7684\u6570\u636e\u533a ES \u6bb5\u5bc4\u5b58\u5668 \u8f85\u52a9\u6570\u636e\u533a\uff0c\u5b58\u653e\u4e32\u6216\u5176\u5b83\u6570\u636e IP \u63a7\u5236\u5bc4\u5b58\u5668 \u5b83\u59cb\u7ec8\u6307\u5411\u5f53\u524d\u5c06\u8981\u6267\u884c\u6307\u4ee4\u5728\u4ee3\u7801\u6bb5\u4e2d\u7684\u504f\u79fb\u91cf FR \u63a7\u5236\u5bc4\u5b58\u5668 \u63a7\u5236\u6807\u5fd7\u4f4d <p></p> <p></p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_8","title":"\u901a\u7528\u5bc4\u5b58\u5668","text":"<p>IA-32\u67b6\u6784\u4e2d\u4e00\u5171\u67094\u4e2a32\u4f4d\u5bc4\u5b58\u5668\uff0c\u7528\u4e8e\u4fdd\u5b58\u4e34\u65f6\u6570\u636e\uff0c\u8fd94\u4e2a\u901a\u7528\u5bc4\u5b58\u5668\u53ef\u4ee5\u5f53\u4f5c16\u4f4d\u7528\uff0c\u4e5f\u53ef\u4ee5\u4f5c8\u4f4d\u7528\u3002</p> <p>AX BX CX DX\uff1a\u6570\u636e\u5bc4\u5b58\u5668\uff0c\u6bcf\u4e2a\u6570\u636e\u5bc4\u5b58\u5668\u90fd\u53ef\u4ee5\u62c6\u6210\u4e24\u4e2a 8 \u4f4d\u5bc4\u5b58\u5668\u72ec\u7acb\u4f7f\u7528\uff0c\u5982 AX \u53ef\u62c6\u5206\u4e3a AH \u548c AL\uff0cBX \u62c6\u5206\u4e3a BH \u548c BL \u7b49\u3002H \u548c L \u5206\u522b\u8868\u793a\u9ad8 8 \u4f4d\u548c\u4f4e 8 \u4f4d\u3002</p> <p>AX(accumulator)\uff1a\u7d2f\u52a0\u5668\u3002\u5728\u4e58\u9664\u6cd5\u8fd0\u7b97\u3001\u4e32\u8fd0\u7b97\u3001 I/O \u6307\u4ee4\u4e2d\u90fd\u4f5c\u4e3a\u4e13\u7528\u5bc4\u5b58\u5668\uff1b BX (base)\uff1a\u57fa\u5740\u5bc4\u5b58\u5668\uff0c\u5e38\u7528\u4e8e\u5b58\u6863\u5185\u5b58\u5730\u5740\u3002</p> <p>CX (count)\uff1a\u8ba1\u6570\u5bc4\u5b58\u5668\u3002\u5e38\u7528\u4e8e\u5b58\u653e\u5faa\u73af\u8bed\u53e5\u7684\u5faa\u73af\u6b21\u6570\uff0c\u5b57\u7b26\u4e32\u64cd\u4f5c\u4e2d\u4e5f\u5e38\u7528\u3002</p> <p>DX (data)\uff1a\u6570\u636e\u5bc4\u5b58\u5668\u3002\u5e38\u5e38\u548cEAX\u4e00\u8d77\u4f7f\u7528\u3002</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_9","title":"\u53d8\u5740\u5bc4\u5b58\u5668","text":"<p>\u5b58\u653e\u5728\u53d8\u52a8\u7684\u5185\u5b58\u5730\u5740</p> <p>ESI(source index): \u6e90\u53d8\u5740\u5bc4\u5b58\u5668\uff0c\u901a\u5e38\u5b58\u653e\u8981\u5904\u7406\u7684\u6570\u636e\u7684\u5185\u5b58\u5730\u5740\u3002</p> <p>EDI(destination index)\uff1a\u76ee\u7684\u53d8\u5740\u5bc4\u5b58\u5668\uff0c\u901a\u5e38\u5b58\u653e\u5904\u7406\u540e\u7684\u6570\u636e\u7684\u5185\u5b58\u5730\u5740\u3002</p> <p>ESI\u548cEDI\u5e38\u7528\u6765\u914d\u5408\u4f7f\u7528\u5b8c\u6210\u6570\u636e\u7684\u8d4b\u503c\u64cd\u4f5c</p> <pre><code>rep movs dword ptr[edi], dword ptr[esi];\n</code></pre> <p>\u8fd9\u53e5\u7684\u610f\u601d\u662f\u628aESI\u6307\u5411\u7684\u5185\u5b58\u5730\u5740\u4e2d\u7684\u5185\u5bb9\u590d\u5236\u5230EDI\u6240\u6307\u5411\u7684\u5185\u5b58\u4e2d\uff0c\u6570\u636e\u957f\u5ea6\u5728ECX\u4e2d\u6307\u5b9a\u3002</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_10","title":"\u6307\u9488\u5bc4\u5b58\u5668","text":"<p>ESP\uff08stack pointer\uff09\uff1a\u5806\u6808\u6307\u9488\u5bc4\u5b58\u5668\u3002SS\uff1aSP\u6307\u5411\u5806\u6808\u7684\u6808\u9876\uff0c\u56e0\u6b64\u867d\u7136\u662f\u901a\u7528\u5bc4\u5b58\u5668\uff0c\u4f46\u4e0d\u5e94\u968f\u4fbf\u6539\u53d8SP\u7684\u503c\u3002\u4e0d\u53ef\u4ee5\u4f5c\u4e3a\u901a\u7528\u5bc4\u5b58\u5668\u4f7f\u7528\uff0cESP\u5b58\u653e\u5f53\u524d\u5806\u6808\u6808\u9876\u7684\u5730\u5740\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\uff0cESP\u548cEBP\u8054\u5408\u4f7f\u7528\u6765\u8bbf\u95ee\u51fd\u6570\u4e2d\u7684\u53c2\u6570\u548c\u5c40\u90e8\u53d8\u91cf\u3002 EBP\uff08base pointer\uff09\uff1a\u57fa\u5740\u6307\u9488\u5bc4\u5b58\u5668\u3002\u53ef\u4ee5\u4f5c\u4e3a\u901a\u7528\u5bc4\u5b58\u5668\u7528\u4e8e\u5b58\u653e\u64cd\u4f5c\u6570\uff0c\u5e38\u7528\u6765\u4ee3\u66ff\u5806\u6808\u6307\u9488\u8bbf\u95ee\u5806\u6808\u7684\u6570\u636e\u3002 EIP\uff1a\u6307\u4ee4\u6307\u9488\u5bc4\u5b58\u5668\uff0c\u603b\u662f\u6307\u5411\u4e0b\u4e00\u6761\u8981\u6267\u884c\u7684\u6307\u4ee4\u7684\u5730\u5740\u3002 \u5e38\u89c1\u7684\u8bbf\u95ee\u5806\u6808\u6307\u4ee4\uff1a</p> <pre><code>push ebp\nmov ebp, esp\nsub esp, 78\npush esi\npush edi\ncmp dword ptr [ebp+8], 0\n</code></pre> <p>ss\u6808\u6bb5\u5bc4\u5b58\u5668 sp\u6808\u9876\u6307\u9488\u5bc4\u5b58\u5668 bp\u9ed8\u8ba4\u7684\u6808\u5bfb\u5740\u5bc4\u5b58\u5668</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_11","title":"\u6807\u5fd7\u5bc4\u5b58\u5668","text":"<p>\u6807\u5fd7\u5bc4\u5b58\u5668EFLAGS\u4e00\u5171\u670932\u4f4d\uff0c\u5728\u8fd932\u4f4d\u4e2d\u5927\u90e8\u5206\u662f\u4fdd\u7559\u7ed9\u7f16\u5199\u64cd\u4f5c\u7cfb\u7edf\u7684\u4eba\u7528\u7684\u3002</p> <p>IP (instruction pointer)\uff1a\u6307\u4ee4\u6307\u9488\u5bc4\u5b58\u5668\u3002\u4ee3\u7801\u6bb5\u5bc4\u5b58\u5668 CS \u548c\u6307\u4ee4\u6307\u9488\u5bc4\u5b58\u5668 IP \u662f 8086CPU \u4e2d\u6700\u5173\u952e\u7684\u4e24\u4e2a\u5bc4\u5b58\u5668\u3002\u5b83\u4eec\u5206\u522b\u7528\u6765\u63d0\u4f9b\u5f53\u524d\u6307\u4ee4\u7684\u6bb5\u5730\u5740\u548c\u504f\u79fb\u5730\u5740\u3002\u5373\u4efb\u610f\u65f6\u523b\uff0c8086CPU \u5c06 CS:IP \u6307\u5411\u7684\u5185\u5bb9\u5f53\u505a\u547d\u4ee4\u6267\u884c\u3002\u6bcf\u6761\u6307\u4ee4\u8fdb\u5165\u6307\u4ee4\u7f13\u51b2\u5668\u540e\u3001\u6267\u884c\u524d\uff0cIP += \u6240\u8bfb\u53d6\u6307\u4ee4\u7684\u957f\u5ea6\uff0c\u4ece\u800c\u6307\u5411\u4e0b\u4e00\u6761\u6307\u4ee4\u3002\u7528\u6237\u4e0d\u80fd\u76f4\u63a5\u8bbf\u95ee IP \u5bc4\u5b58\u5668\u3002</p> <p>FL (flags)\uff1a\u6807\u5fd7\u5bc4\u5b58\u5668\u3002\u4e0e\u5176\u4ed6\u5bc4\u5b58\u5668\u4e00\u6837\uff0c\u6807\u5fd7\u5bc4\u5b58\u5668\u4e5f\u6709 16 \u4f4d\uff0c\u4f46\u662f\u6807\u5fd7\u5bc4\u5b58\u5668\u53ea\u7528\u5230\u5176\u4e2d\u7684 9 \u4f4d\u3002\u8fd9 9 \u4f4d\u5305\u62ec 6 \u4e2a\u72b6\u6001\u6807\u5fd7\u548c 3 \u4e2a\u63a7\u5236\u6807\u5fd7\uff0c\u53c2\u89c1\u4e0b\u9762\u7684\u201c\u6807\u5fd7\u4f4d\u201d\u3002</p> <p>OF\uff08Overflow Flag\uff09:\u6ea2\u51fa\u6807\u5fd7\uff0c\u6ea2\u51fa\u65f6\u4e3a1\uff0c\u5426\u5219\u7f6e0\u3002\u4e24\u4e2a\u6b63\u6570\u76f8\u52a0\u53d8\u8d1f\uff0c\u6216\u4e24\u4e2a\u8d1f\u6570\u76f8\u52a0\u53d8\u6b63\u4f1a\u6ea2\u51fa\u3002#</p> <p>DF \uff08Direction Flag\uff09:\u65b9\u5411\u6807\u5fd7\uff0c\u5728\u4e32\u5904\u7406\u6307\u4ee4\u4e2d\u63a7\u5236\u4fe1\u606f\u7684\u65b9\u5411\u30020:\u6b63\u65b9\u5411\uff0c1\uff1a\u53cd\u65b9\u5411\u3002cld\uff0cstd\u3002#</p> <p>IF (Interrupt Flag) :\u4e2d\u65ad\u6807\u5fd7\u3002\u7981\u6b62\u4e2d\u65ad0\uff0c\u5141\u8bb8\u4e2d\u65ad1\u3002cli\uff0csti\u3002#</p> <p>AF (Auxiliary carry Flag) :\u8f85\u52a9\u8fdb\u4f4d\u6807\u5fd7\uff0c\u6709\u8fdb\u4f4d\u65f6\u7f6e1\uff0c\u5426\u5219\u7f6e0\u3002</p> <p>ZF (Zero Flag) :\u96f6\u6807\u5fd7\uff0c\u8fd0\u7b97\u7ed3\u6784\u4e3a0\u65f6ZF\u4f4d\u4f4d\u7f6e1\uff0c\u5426\u5219\u7f6e0\u3002</p> <p>SF (Sign Flag):\u7b26\u53f7\u6807\u5fd7\uff0c\u7ed3\u679c\u4e3a\u8d1f\u65f6\u7f6e1\uff0c\u5426\u5219\u7f6e0\u3002#</p> <p>CF (Carry Flag): \u8fdb\u4f4d\u6807\u5fd7\uff0c\u8fdb\u4f4d\u65f6\u7f6e1\uff0c\u5426\u5219\u7f6e0\u3002\u914d\u5957\u7684clc\uff0cstc\u4e24\u6761\u8bbe\u7f6e\u6307\u4ee4\uff1a\u6e05\u9664\u548c\u7f6e1\u3002#</p> <p>PF (Parity Flag): \u5947\u5076\u6807\u5fd7\u3002\u7ed3\u679c\u64cd\u4f5c\u6570\u4e2d1\u7684\u4e2a\u6570\u4e3a\u5076\u6570\u65f6\u7f6e1\uff0c\u5426\u5219\u7f6e0\u3002</p> <p>TF\uff1a\u5355\u6b65\u8c03\u8bd5\u8981\u7528\u3002#</p> <p></p> <p></p> <p>EFLAGS\u662f\u5b9e\u73b0\u6761\u4ef6\u5224\u65ad\u548c\u903b\u8f91\u5224\u65ad\u7684\u4e00\u79cd\u673a\u5236\uff0c\u5728\u6c47\u7f16\u8bed\u8a00\u4e2d\u4e00\u822c\u4e0d\u76f4\u63a5\u8bbf\u95eeEFLAGS\u5bc4\u5b58\u5668\uff0c\u800c\u662f\u901a\u8fc7\u6307\u4ee4\u7684\u64cd\u4f5c\u9690\u542b\u8bbf\u95eeEFLAGS\u5bc4\u5b58\u5668\u3002</p> <pre><code>cmp dword ptr [ebp+8], 0. // \u5f71\u54cd\u6807\u5fd7\u4f4dCF\uff0cZF\uff0cSF\uff0cOF\uff0cAF\u548cPF\nJz 99495898 //\u5982\u679cZF\u7b49\u4e8e1\uff0c\u5219\u8df3\u8f6c\u523000405898 \n</code></pre>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_12","title":"\u6307\u4ee4","text":"<p>\u603b\u7ed3</p> \u6307\u4ee4 \u4f5c\u7528 \u53c2\u6570 \u6539\u53d8\u6807\u5fd7\u4f4d mov \u8d4b\u503c \u88ab\u8d4b\u503c\u5bc4\u5b58\u5668\uff0c\u3010\u5bc4\u5b58\u5668\uff0c\u5185\u5b58\uff0c\u503c\u3011 no xchg \u6570\u636e\u4ea4\u6362 \u3010\u5bc4\u5b58\u5668\uff0c\u5185\u5b58\u3011\uff0c\u3010\u5bc4\u5b58\u5668\uff0c\u5185\u5b58\u3011 no push \u8fdb\u6808 \u6e90\u64cd\u4f5c\u6570\u3010\u5bc4\u5b58\u5668\u3011 pop \u51fa\u6808 \u76ee\u7684\u64cd\u4f5c\u6570\u3010\u5bc4\u5b58\u5668\u3011 pushf \u6807\u5fd7\u4f4d\u8fdb\u6808 \u65e0 popf \u6807\u5fd7\u4f4d\u51fa\u6808 \u65e0 lea Load effect address\uff0c\u5bfb\u5740\uff0c\u53d6\u504f\u79fb\u5730\u5740 lds \u5f53\u6307\u4ee4\u6307\u5b9a\u7684\u662f16\u4f4d\u5bc4\u5b58\u5668\u65f6\uff0c\u628a\u6e90\u64cd\u4f5c\u6570\u5b58\u50a8\u5355\u5143\u4e2d\u5b58\u653e\u7684\u5341\u516d\u4f4d\u504f\u79fb\u5730\u5740\u53d6\u51fa\u5b58\u653e\u5728\u5bc4\u5b58\u5668\u4e2d\uff0c\u7136\u540e\u628a\u6e90\u64cd\u4f5c\u6570+2\u7684\u5341\u516d\u4f4d\u6570\u88c5\u5165\u6307\u4ee4\u6307\u5b9a\u7684\u6bb5\u5bc4\u5b58\u5668\u3002\u5f53\u6307\u4ee4\u6307\u5b9a\u7684\u662f32\u4f4d\u5bc4\u5b58\u5668\u65f6 \u628a\u6e90\u64cd\u4f5c\u6570\u5b58\u50a8\u5355\u5143\u4e2d\u5b58\u653e\u768432\u4f4d\u504f\u79fb\u5730\u5740\u88c5\u5165\u5bc4\u5b58\u5668 \u7136\u540e\u628a \u6e90\u64cd\u4f5c\u6570+4 \u768416\u4f4d\u6570\u88c5\u5165\u6bb5\u5bc4\u5b58\u5668\u3002mem\u6307\u5411\u7684\u5730\u5740,\u9ad8\u4f4d\u5b58\u653e\u5728DS\u4e2d,\u4f4e\u4f4d\u5b58\u653e\u5728reg\u4e2d. LDS reg,mem les \u628a\u5185\u5b58\u4e2d\u6307\u5b9a\u4f4d\u7f6e\u7684\u53cc\u5b57\u64cd\u4f5c\u6570\u7684\u4f4e\u4f4d\u5b57\u88c5\u5165\u6307\u4ee4\u4e2d\u6307\u5b9a\u7684\u5bc4\u5b58\u5668\u3001\u9ad8\u4f4d\u5b57\u88c5\u5165ES\u5bc4\u5b58\u5668\u3002 cbw 8\u4f4d\u6570\u6269\u5c55\u4e3a16\u4f4d\u6570\uff0c\u6709\u7b26\u53f7\u6269\u5145 no cwd \u5b57(16\u4f4d)\u6269\u5c55\u4e3a\u53cc\u5b57(32\u4f4d)\uff0c\u6709\u7b26\u53f7\uff1f no add \u52a0 OPRDS\uff0cOPRDD adc \u5e26\u8fdb\u4f4d\u52a0\uff08\u7ed3\u679c\u542b\u6807\u5fd7\u4f4dCF\u7684\u503c\uff0c=OPRDS\uff0bOPRDD\uff0bCF\uff09 OPRDS\uff0cOPRDD sub \u51cf OPRDD\uff0cOPRDS sbb \u5e26\u8fdb\u4f4d\u51cf\uff08\u7ed3\u679c\u542b\u6807\u5fd7\u4f4dCF\u7684\u503c\uff0c=OPRDD\uff0dOPRDS\uff0dCF\uff09 OPRDD\uff0cOPRDS inc \u81ea\u589e1 \u5bc4\u5b58\u5668 dec \u81ea\u51cf1 \u5bc4\u5b58\u5668 mul 32\u4f4d\uff1a\u88ab\u4e58\u6570\u9ed8\u8ba4\u4e3aEAX\uff0c\u90a3\u4e48\u4e58\u79ef\u5c06\u5b58\u653e\u5728EDX\uff1aEAX\u4e2d 32\u4f4d\u4e58\u6570 16\u4f4d\uff1a\u88ab\u4e58\u6570\u9ed8\u8ba4\u4e3aAX\u90a3\u4e48\u4e58\u79ef\u5c06\u653e\u5728DX\uff1aAX\u4e2di 16\u4f4d\u4e58\u6570 8\u4f4d\uff1a\u88ab\u4e58\u6570\u9ed8\u8ba4\u4e3aAL\uff0c\u90a3\u4e48\u4e58\u79ef\u5c06\u653e\u5728AX 8\u4f4d\u4e58\u6570 div 32\u4f4d\uff1a\u88ab\u9664\u6570\u5c06\u662fEDX\uff1aEAX\uff0c \u6700\u7ec8\u7684\u5546\u5c06\u5b58\u653e\u5728EAX\uff0c \u4f59\u6570\u5c06\u5b58\u653e\u5728EDX\u4e2d 32\u4f4d\u4e58\u6570 16\u4f4d\uff1a\u88ab\u9664\u6570\u4e3aEAX\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u5546\u653e\u5728AX\uff0c\u4f59\u6570\u653e\u5728EAX\u7684\u9ad816\u4f4d 16\u4f4d\u4e58\u6570 8\u4f4d\uff1a\u88ab\u9664\u6570\u662f16\u4f4d\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u5546\u5c06\u653e\u5728AL\u4e2d\uff0c\u4f59\u6570\u653e\u5728AH\u4e2d 8\u4f4d\u4e58\u6570 imul \u65e0\u7b26\u53f7\u4e58 idiv \u65e0\u7b26\u53f7\u9664 xlat \u6362\u7801\u6307\u4ee4\uff0c\u4ee5bx\u4e3a\u9996\u5730\u5740\u7684\uff0c\u504f\u79fb\u5730\u5740\u4e3aal\u7684\u5185\u5bb9\u9001\u7ed9al\u3002 in \u7aef\u53e3\u8bfb\u5199\u6307\u4ee4 IN AL,21H\uff1b\u8868\u793a\u4ece21H\u7aef\u53e3\u8bfb\u53d6\u4e00\u5b57\u8282\u6570\u636e\u5230AL out \u7aef\u53e3\u8bfb\u5199\u6307\u4ee4 and \u6309\u4f4d\u4e0e or \u6309\u4f4d\u6216 xor \u6309\u4f4d\u5f02\u6216 not \u64cd\u4f5c\u6570\u6309\u4f4d\u53d6\u53cd neg \u64cd\u4f5c\u6570\u6309\u4f4d\u53d6\u53cd\u52a0\u4e00 test \u5bf9\u4e24\u4e2a\u64cd\u4f5c\u6570\u8fdb\u884c\u6309\u4f4d\u4e0e\u64cd\u4f5c\u3002\u4e0eand\u4e0d\u540c\uff0c\u4e0d\u5f71\u54cd\u76ee\u6807\u64cd\u4f5c\u6570\u7684\u503c\u3002 shl \u903b\u8f91\u5de6\u79fb\uff0c\u5c06\u4e00\u4e2a\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u6216\u5355\u5143\u4e2d\u7684\u6570\u636e\u5411\u5de6\u79fb\u4f4d\uff0c\u5c06\u6700\u540e\u79fb\u51fa\u7684\u4e00\u4f4d\u5199\u5165cf\u4e2d\u3002\u6700\u4f4e\u4f4d\u75280\u8865\u5145\u3002 shr \u903b\u8f91\u53f3\u79fb\uff0c\u5c06\u4e00\u4e2a\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u6216\u5355\u5143\u4e2d\u7684\u6570\u636e\u5411\u5de6\u79fb\u4f4d\uff0c\u5c06\u6700\u540e\u79fb\u51fa\u7684\u4e00\u4f4d\u5199\u5165cf\u4e2d\u3002\u6700\u9ad8\u4f4d\u75280\u8865\u5145\u3002 sal \u7b97\u672f\u5de6\u79fb\uff0c\u4e0eshl\u4e00\u6837\uff0c\u88650 sar \u7b97\u672f\u53f3\u79fb\uff0c\u4e0eshr\u4e0d\u4e00\u6837\uff0c\u7b97\u672f\u53f3\u79fb\u8865\u6700\u9ad8\u4f4d rol \u5faa\u73af\u5de6\u79fb ror \u5faa\u73af\u53f3\u79fb rcl \u5e26\u8fdb\u4f4d\u5faa\u73af\u5de6\u79fb\uff0c\u5de6\u79fb\u7684\u65f6\u5019\u79fb\u51fa\u53bb\u7684\u4f1a\u653e\u5728cf\uff1f rcr \u5e26\u8fdb\u4f4d\u5faa\u73af\u53f3\u79fb cmp \u6bd4\u8f83 ja jump if above jb Jump if below jae Jump if above or equal jbe Jump if below or equal jg jump if greater\uff0c\u6709\u7b26\u53f7\u5927\u4e8e\u8df3\u8f6c jl jump less\uff0c\u6709\u7b26\u53f7\u5c0f\u4e8e\u8df3\u8f6c jge jump if greater or equal jle Jump if less or equal jc jump if with carry, CF = 1 jnc jump if not with carry, CF = 0 je = jz jump if equal, ZF = 1 jne = jnz jump if not equal, ZF = 0 jz jump if zero, ZF = 1 jnz jump if not zero, ZF = 0 jcxz jump if cx equals zero js SF = 1 jns SF = 0 jo Jump if overflow, OF = 1 jno jump if not overflow, OF = 0 loop \u5faa\u73af \u4ee3\u7801\u6bb5\uff08\uff1f\uff09\u540d clc clear carry flag\uff0c\u5c06cf\u4f4d\u6e05\u96f6 stc set carry flag\uff0cCF\u7f6e1 cli clear interrupt endable flag\uff0cIF\u6e05\u96f6\uff0c\u5173\u95ed\u4e2d\u65ad sti set interrupt endable flag\uff0cIF\u7f6e\u4f4d1\uff0c\u6253\u5f00\u4e2d\u65ad CMC complement carry flag\uff0cCF\u53d6\u53cd CLD clear direction flag\uff0cDF\u6e05\u96f6 STD set interrupt endable flag\uff0cDF\u7f6e1 call \u8fd1\u8c03\u7528 ret \u8fd1\u8fd4\u56de call far ptr \u8fdc\u8c03\u7528\u3002\u4e09\u4e2apush\u4e00\u4e2ajmp\u3002push f\uff0cpush cs\uff0cpush ip\uff0cjump retf \u8fdc\u8fd4\u56de\u3002\u4e09\u4e2apop\u3002\u6307\u4ee4\u2f64\u6808\u4e2d\u7684\u6570\u636e\uff0c\u4fee\u6539CS\u548cIP\u7684\u5185\u5bb9\uff0c\u4ece\u2f7d\u5b9e\u73b0\u8fdc\u8f6c\u79fb int \u4e2d\u65ad\u6307\u4ee4 iret \u4e2d\u65ad\u8fd4\u56de jmp short \u6bb5\u5185\u77ed\u8f6c\u79fb\uff0c\u77ed\u662f\u6307\u8981\u8df3\u2f84\u7684\u2f6c\u6807\u5730\u5740\u4e0e\u5f53\u524d\u5730\u5740\u524d\u540e\u76f8\u5dee\u4e0d\u8d85\u8fc7128\u5b57\u8282 jmp near ptr \u6bb5\u5185\u8fd1\u8f6c\u79fb\u3002\u8fd1\u662f\u6307\u8df3\u8f6c\u7684\u2f6c\u6807\u5730\u5740\u4e0e\u5f53\u524d\u5730\u5740\u5728\u2f64\u2f00\u4e2a\u6bb5\u5185\uff0c\u5373CS\u7684\u503c\u4e0d\u53d8\uff0c\u53ea\u6539\u53d8EIP\u7684\u503c jmp far ptr \u6bb5\u95f4\u8f6c\u79fb\uff0c\u8fdc\u6307\u8df3\u5230\u53e6\u2f00\u4e2a\u4ee3\u7801\u6bb5\u53bb\u6267\u2f8f\uff0cCS/EIP\u90fd\u8981\u6539\u53d8 Jmp dword ptr \u6bb5\u95f4\u8f6c\u79fb\uff0c\u4ee5\u5185\u5b58\u5730\u5740\u5355\u5143\u5904\u7684\u53cc\u5b57\u6765\u4fee\u6539\u6307\u4ee4\uff0c\u2fbc\u5730\u5740\u5185\u5bb9\u4fee\u6539CS\uff0c\u4f4e\u5730\u5740\u5185\u5bb9 \u4fee\u6539IP\uff0c\u5185\u5b58\u5730\u5740\u53ef\u4ee5\u4ee5\u4efb\u4f55\u5408\u6cd5\u7684\u2f45\u5f0f\u7ed9\u51fa repe/renpe scasb \u5b57\u7b26\u4e32\u626b\u63cf\u6307\u4ee4\u3002cmp al, es:[di] di++; \u5f53DF=1\u65f6\uff0c\u4e3adi-- repne:\u5f53ECX!=0\u5e76\u4e14ZF==0\u65f6 \u91cd\u590d repe: cx != 0\u4e14zf != 0\u91cd\u590d repe/renpe cmpsb \u5b57\u7b26\u4e32\u6bd4\u8f83\u6307\u4ee4\u3002\u2f50\u8f83byte ptr ds:[si]\u4e0ebyte ptr es:[di] \u5f53DF=0\u65f6\uff0cSI++\uff0cDI++ \u5f53DF=1\u65f6\uff0cSI--\uff0cDI-- repne:\u5f53ECX!=0\u5e76\u4e14ZF==0\u65f6 \u91cd\u590d repe: cx != 0\u4e14zf != 0\u91cd\u590d rep movsb \u5b57\u7b26\u4e32\u79fb\u52a8\u6307\u4ee4\u3002\u5176\u4e2drep\u8868\u793arepeat\uff0cs\u8868\u793astring\uff0cb\u8868\u793abyte \u5728\u6267\u2f8f\u6b64\u6307\u4ee4\u524d\u8981\u505a\u4ee5\u4e0b\u51c6\u5907\u2f2f\u4f5c\uff1a \u2460ds:si lodsb \u5757\u88c5\u5165\u6307\u4ee4\uff0c\u628aSI\u6307\u5411\u7684\u5b58\u50a8\u5355\u5143\u8bfb\u5165\u7d2f\u52a0\u5668\uff0clodsb\u5c31\u8bfb\u5165ax\uff0clodsw\u5c31\u8bfb\u5165ax\uff0c\u7136\u540esi\u81ea\u52a8\u589e\u52a0\u6216\u51cf\u5c0f1\u62162 stosb/stosw/stosd SI\u6307\u5411\u7684https://baike.baidu.com/item/%E5%AD%98%E5%82%A8%E5%8D%95%E5%85%83\u8bfb\u5165https://baike.baidu.com/item/%E7%B4%AF%E5%8A%A0%E5%99%A8,\u5176\u4e2dLODSB\u662f\u8bfb\u5165AL, LODSW\u662f\u8bfb\u5165AX\u4e2d, \u7136\u540eSI\u81ea\u52a8\u589e\u52a0\u6216\u51cf\u5c0f1\u62162\u4f4d.\u5f53\u65b9\u5411\u6807\u5fd7\u4f4dDF=0\u65f6\uff0c\u5219SI\u81ea\u52a8\u589e\u52a0\uff1bDF=1\u65f6\uff0cSI\u81ea\u52a8\u51cf\u5c0f\u3002 rep stosb lodsb"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_13","title":"\u6570\u636e\u4f20\u9001\u6307\u4ee4","text":"<p>\u6570\u636e\u4f20\u9001\u6307\u4ee4\u662f\u4e3a\u4e86\u5b9e\u73b0CPU\u548c\u5185\u5b58\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u7aef\u53e3\u4e4b\u95f4\u7684\u6570\u636e\u4f20\u9001\u3002</p> <p>mov</p> <pre><code>mov eax, 56 // \u5c0656H\u4f20\u9001\u5230eax\u5bc4\u5b58\u5668\nmov esi, dword ptr [eax * 2 + 1]  // \u5c06\u5185\u5b58\u5730\u5740\u4e3aeax*2+1\u76844\u5b57\u8282\u6570\u636e\u4f20\u9001\u5230esi\u5bc4\u5b58\u5668\nmov ah, byte ptr [esi * 2 + eax]  // \u5c06\u5185\u5b58\u5730\u5740\u4e3aesi*+eax\u5904\u76848\u4f4d\u6570\u636e\u4f20\u9001\u5230AH\u5bc4\u5b58\u5668\n</code></pre> <p>xchg</p> <p>\u5bc4\u5b58\u5668\u548c\u5185\u5b58\u7684\u6570\u636e\u4ea4\u6362\uff0c\u4ea4\u6362\u7684\u6570\u636e\u53ef\u4ee5\u662f8\u5b57\u8282\u300116\u5b57\u8282\u621632\u5b57\u8282\uff0c\u5fc5\u987b\u683c\u5f0f\u76f8\u540c</p> <pre><code>xchg eax, edx; // \u5c06edx\u5bc4\u5b58\u5668\u7684\u503c\u548ceax\u5bc4\u5b58\u5668\u7684\u503c\u4ea4\u6362\nxchg [esp-55], edi; // \u5c06edi\u5bc4\u5b58\u5668\u7684\u503c\u548c\u5806\u6808\u5730\u5740\u4e3a[esp-55]\u5904\u7684\u503c\u4ea4\u6362\n</code></pre> <p>push pop</p> <p>push\u548cpop\uff1a\u79f0\u4e3a\u538b\u5165\u5806\u6808\u6307\u4ee4\u548c\u5f39\u51fa\u5806\u6808\u6307\u4ee4\uff0c\u683c\u5f0f\u662fpush src(\u6e90\u64cd\u4f5c\u6570)\u548cpop dst(\u76ee\u7684\u64cd\u4f5c\u6570)\uff0cpush\u6307\u4ee4\u548cpop\u6307\u4ee4\u9700\u8981\u5339\u914d\u51fa\u73b0\uff0c\u5426\u5219\u5806\u6808\u4f1a\u4e0d\u5e73\u8861\u3002push\u6307\u4ee4\u5c06\u539f\u64cd\u4f5c\u6570src\u538b\u5165\u5806\u6808\uff0c\u540c\u65f6esp-4\uff08\u6808\u9876\u6307\u9488\u51cf\u4e00\u4e2a4\u4f4d\uff09\uff0c\u800cpop\u53cd\u4e4b\uff0c\u4ece\u5806\u6808\u7684\u9876\u90e8\u5f39\u51fa4\u5b57\u8282\u7684\u6570\u503c\u7136\u540e\u653e\u5165dst\u3002\u572832\u4f4d\u7684\u64cd\u4f5c\u7cfb\u7edf\u4e0a\uff0cpush\u548cpop\u7684\u64cd\u4f5c\u662f\u4ee54\u5b57\u8282\u4e3a\u5355\u4f4d\u7684\uff0cpush\u548cpop\u6307\u4ee4\u5e38\u7528\u4e8e\u5411\u51fd\u6570\u4f20\u53c2\u3002</p> <pre><code>push eax // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u4ee54\u5b57\u8282\u538b\u5165\u5806\u6808\uff0c\u540c\u65f6esp-4\npush dword ptr [12FF8589] // \u5c06\u5806\u6808\u9876\u90e8\u76844\u5b57\u8282\u5f39\u51fa\u5230\u5185\u5b58\u5730\u5740\u4e3a12FF8589\u6240\u6307\u5730\u65b9\uff0c\u540c\u65f6esp+4\n-----------------------------------------------------------------------------\npop dword ptr [12FF8589] // \u5c06\u5806\u6808\u9876\u90e8\u76844\u5b57\u8282\u5f39\u51fa\u5230\u5185\u5b58\u5730\u5740\u4e3a12FF8589\u6240\u6307\u7684\u5730\u65b9\uff0c\u540c\u65f6esp+4\npop eax // \u5c06\u5806\u6808\u9876\u90e8\u76844\u5b57\u8282\u5f39\u51fa\u5230eax\u5bc4\u5b58\u5668\uff0c\u540c\u65f6esp+4\n</code></pre>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_14","title":"\u5730\u5740\u4f20\u9001\u6307\u4ee4","text":"<p>x86\u67093\u6761\u5730\u5740\u4f20\u9001\u6307\u4ee4\uff0c\u5206\u522b\u662fLEA\uff0cLDS\u548cLES\u3002\u5176\u5b9eLDS\u548cLES\u6307\u4ee4\u548c\u6bb5\u5bc4\u5b58\u5668\u6709\u5173\uff0c\u572832\u4f4d\u7684windows\u64cd\u4f5c\u7cfb\u7edf\u4e0a\uff0c\u4e00\u822c\u7684\u7a0b\u5e8f\u5458\u90fd\u4e0d\u9700\u8981\u7ba1\u7406\u6bb5\u5bc4\u5b58\u5668\uff0c\u6240\u4ee5\u76f8\u5bf9\u800c\u8a00\uff0cLDS\u548cLES\u5bc4\u5b58\u5668\u4f7f\u7528\u5f97\u6bd4\u8f83\u5c11\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5e38\u89c1\u7684\u53ea\u6709LEA\u6307\u4ee4\u3002</p> <p>LEA</p> <p>\u79f0\u4e3a\u5730\u5740\u4f20\u9001\u6307\u4ee4\uff0c\u683c\u5f0f\u662f\u201cLEA DST, ADDR\u201d\u3002LEA\u5c06ADDR\u5730\u5740\u52a0\u8f7d\u5230DST\uff0c\u5176\u4e2dADDR\u53ef\u4ee5\u662f\u5185\u5b58\uff0c\u4e5f\u53ef\u4ee5\u662f\u5bc4\u5b58\u5668\uff0c\u800cDST\u5fc5\u987b\u662f\u4e00\u4e2a\u901a\u7528\u5bc4\u5b58\u5668\u3002</p> <pre><code>lea eax, [12345678]; // \u6307\u4ee4\u6267\u884c\u540eeax\u5bc4\u5b58\u5668\u7684\u503c\u4e3a12345678H\nmov eax, [12345678]; // \u800cmov eax, [12345678] \u6307\u4ee4\u6267\u884c\u540eeax\u5bc4\u5b58\u5668\u7684\u503c\u4e3a\u5185\u5b58\u5730\u574012345678\u6307\u5411\u7684\u90a3\u4e2a\u6570\u503c\n\n// LEA\u6307\u4ee4\u53ef\u7528\u4e8e\u7b97\u6cd5\u8fd0\u7b97\nlea ecx, [ecx + eax*4];  // ecx = ecx + eax * 4\n// \u76f8\u5f53\u4e8e\u8ba1\u7b97\u51faecx+eax*4\u7684\u6570\u503c\uff0c\u5728[]\u91cc\u662f\u4e00\u4e2a\u5730\u5740\uff0clea\u53d6\u5730\u5740\u540e\u5c31\u53d6\u5230\u4e86\u8fd9\u4e2a\u6570\u503c\n</code></pre>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_15","title":"\u7b97\u6570\u8fd0\u7b97\u6307\u4ee4","text":"<p>80x86\u63d0\u4f9b\u4e868\u6761\u52a0\u51cf\u6cd5\u6307\u4ee4\uff0c4\u6761\u4e58\u9664\u6cd5\u6307\u4ee4\u3002</p> <p>ADD\uff1a\u52a0\u6cd5\u6307\u4ee4</p> <pre><code>add eax, esi; // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u52a0\u4e0aesi\u5bc4\u5b58\u5668\u7684\u503c\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u4fdd\u5b58\u5728eax\u7684\u5bc4\u5b58\u5668\u4e2d\nadd ebx, dword ptr[12345678] // \u5c06ebx\u5bc4\u5b58\u5668\u7684\u503c\u52a0\u4e0a\u5185\u5b58\u5730\u5740\u4e3a12345678\u6240\u5728\u76844\u5b57\u8282\u503c\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u4fdd\u5b58\u5728ebx\u5bc4\u5b58\u5668\u4e2d\n// \u4e0d\u540c\u7684\u5e73\u53f0\u548c\u7f16\u8bd1\u5668\u4e2d\uff0cdword\u5360\u7528\u7684\u5b57\u8282\u6570\u4e0d\u540c\uff0c\u572832\u4f4d\u7684windows\u4e2d\u4e00\u4e2aword\u536016\u5b57\u8282\uff0cdword\u536032\u5b57\u8282\n// 64\u4f4d\u4e2d\u4e00\u4e2aword\u536032\u5b57\u8282\uff0cdword\u536064\u5b57\u8282\n</code></pre> <p>sub \u51cf\u6cd5\u6307\u4ee4</p> <pre><code>sub ecx, 4H; // \u5c06ecx\u5bc4\u5b58\u5668\u7684\u503c\u51cf\u53bb4H\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u4fdd\u5b58\u5728eax\u5bc4\u5b58\u5668\u4e2d\nsub byte ptr[eax], ch; // \u5c06\u5185\u5b58\u5730\u5740\u4e3aeax\u6240\u6307\u5411\u7684\u6570\u636e\u7ed3\u6784\u6309\u5b57\u8282\u4e3a\u5355\u4f4d\u548cch\u5bc4\u5b58\u5668\u76f8\u51cf\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u6309\u5b57\u8282\u4e3a\u5355\u4f4d\u4fdd\u5b58\u5728eax\u6240\u6307\u5411\u7684\u4f4d\u7f6e\n</code></pre> <p>inc\u52a01\u6307\u4ee4</p> <pre><code>inc eax; // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u52a01\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u5b58\u653e\u5728\u539f\u6765\u7684\u5730\u65b9\n</code></pre> <p>dec\u51cf1\u6307\u4ee4</p> <pre><code>dec edx; // \u5c06dec\u5bc4\u5b58\u5668\u7684\u503c\u51cf1\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u5b58\u653e\u5728\u539f\u6765\u7684\u5730\u65b9\n</code></pre> <p>cmp\u6bd4\u8f83\u6307\u4ee4</p> <p>\u79f0\u6bd4\u8f83\u6307\u4ee4\u683c\u5f0f\u662f\u201dcmp oper1, oper2\u201d</p> <p>cmp\u6307\u4ee4\u5c06oper1\u51cf\u53bboper2\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u4e0d\u4fdd\u5b58\uff0c\u53ea\u662f\u76f8\u5e94\u5730\u8bbe\u7f6e\u5bc4\u5b58\u5668eflags\u7684cf\uff0cpf\uff0czf\uff0caf\uff0csf\u548cof\u3002\u4e5f\u5c31\u662f\u8bf4\u53ef\u4ee5\u901a\u8fc7\u6d4b\u8bd5\u5bc4\u5b58\u5668eflags\u76f8\u5173\u7684\u6807\u5fd7\u503c\u5f97\u77e5cmp\u6267\u884c\u540e\u7684\u7ed3\u679c</p> <pre><code>cmp eax, 56H; // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u51cf\u53bb56H\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u4e0d\u4fdd\u5b58\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5bc4\u5b58\u5668eflags\u76f8\u5173\u7684\u6807\u5fd7\u4f4d\n</code></pre> <p>neg</p> <p>neg\uff1a\u53d6\u8865\u6307\u4ee4\uff0c\u683c\u5f0f\u662fneg oper</p> <p>neg\u6307\u4ee4\u5c06oper\u64cd\u4f5c\u6570\u53d6\u53cd\uff0c\u7b80\u800c\u8a00\u4e4b\u5c31\u662f\u5c060\u51cf\u53bboper\u64cd\u4f5c\u6570\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u5b58\u5728oper\u81ea\u8eab\u4e2d\u3002</p> <pre><code>neg eax; \n</code></pre> <p>mul imul</p> <p>\u65e0\u7b26\u53f7\u4e58\u6cd5\u6307\u4ee4\u548c\u6709\u7b26\u53f7\u4e58\u6cd5\u6307\u4ee4\u3002mul\u6307\u4ee4\u9690\u542b\u4e86\u4e00\u4e2a\u53c2\u52a0\u8fd0\u7b97\u7684\u64cd\u4f5c\u6570eax\u5bc4\u5b58\u5668\uff0c\u5c06eax\u5bc4\u5b58\u5668\u91cc\u7684\u503c\u4e58oper\uff0c\u7ed3\u679c\u4fdd\u5b58\u5728eax\u4e2d\u3002\u5982\u679c\u7ed3\u679c\u8d85\u8fc732\u4f4d\u5219\u9ad832\u4f4d\u4f7f\u7528edx\u5bc4\u5b58\u5668\u4fdd\u5b58\uff0ceax\u5bc4\u5b58\u5668\u4fdd\u5b58\u4f4e32\u4f4d\u3002</p> <pre><code>mul edx; // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u4e58\u4ee5edx\u5bc4\u5b58\u5668\u7684\u503c\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u4fdd\u5b58\u5728eax\u5bc4\u5b58\u5668\u4e2d\n</code></pre> <p>div idiv</p> <p>\u9664\u6cd5\u6307\u4ee4\u548c\u6709\u7b26\u53f7\u9664\u6cd5\u6307\u4ee4\u3002</p> <pre><code>div ecx; // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u63094\u5b57\u8282\u4e3a\u5355\u4f4d\u9664\u4ee5ecx\u5bc4\u5b58\u5668\u7684\u503c\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u5546\u4fdd\u5b58\u5728eax\u5bc4\u5b58\u5668\u4e2d\uff0c\u4f59\u6570\u4fdd\u5b58\u5728edx\u5bc4\u5b58\u5668\u4e2d\u3002\ndiv word ptr [esp+36]; // \u5c06eax\u5bc4\u5b58\u5668\u7684\u503c\u6309word\u4e3a\u5355\u4f4d\u9664\u4ee5\u5806\u6808\u5730\u5740\u4e3aesp+36\u6240\u6307\u5411\u7684\u6570\u636e\uff0c\u5f97\u51fa\u7684\u7ed3\u679c\u5546\u4fdd\u5b58\u5728eax\u5bc4\u5b58\u5668\u4e2d\uff0c\u4f59\u6570\u4fdd\u5b58\u5728edx\u5bc4\u5b58\u5668\u4e2d\u3002\n</code></pre>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#80386","title":"\u9ad8\u7ea7\u8bed\u8a00\u4e2d\u7684\u6570\u636e\u7ed3\u6784\u4e0e80386\u95f4\u63a5\u5bfb\u5740","text":"<p>BX BP SI DI</p> <p>BX\uff1a</p> <p>BP\uff1a</p> <p>SI\uff1a</p> <p>DI\uff1a</p> <p>\u95f4\u63a5\u5bfb\u5740\uff1abx\uff0cbp\uff0csi\uff0cdi\uff0c\u53ef\u4ee5\u653e\u5728\u65b9\u62ec\u53f7\u5185</p> <p>\u7f3a\u7701\u6bb5\u5740\uff1ads\u548css\uff0c\u5982\u679c\u65b9\u62ec\u53f7\u5185\u6709bp\uff0c\u4e00\u5b9a\u662fss\uff0cbx\u4e00\u5b9a\u662fds</p> <p>CS (code segment): \u4ee3\u7801\u6bb5\u5bc4\u5b58\u5668\uff0c\u7528\u6765\u5b58\u50a8\u4ee3\u7801\u6bb5\u7684\u6bb5\u5730\u5740\u3002</p> <p>DS (data segment)\uff1a\u6570\u636e\u6bb5\u5bc4\u5b58\u5668\uff0c\u7528\u6765\u5b58\u50a8\u6570\u636e\u6bb5\u7684\u6bb5\u5730\u5740\u3002</p> <p>SS (stack segment)\uff1a\u5806\u6808\u6bb5\u5bc4\u5b58\u5668\uff0c\u7528\u6765\u5b58\u50a8\u5806\u6808\u6bb5\u7684\u6bb5\u5730\u5740\u3002</p> <p>ES (extra segment)\uff1a\u9644\u52a0\u6570\u636e\u6bb5\u5bc4\u5b58\u5668\uff0c\u7528\u6765\u5b58\u653e\u9644\u52a0\u6bb5\u7684\u6bb5\u5730\u5740\u3002\u6709\u65f6\uff0c\u4e00\u4e2a\u6570\u636e\u6bb5\u4e0d\u591f\u7528\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u58f0\u660e\u4e00\u4e2a\u9644\u52a0\u6bb5\u6765\u5b58\u653e\u66f4\u591a\u7684\u6570\u636e\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u58f0\u660e 2 \u4e2a\u6570\u636e\u6bb5\uff0c\u5206\u522b\u7528 DS \u548c ES \u6307\u5411\u3002</p> <p>\u7a0b\u5e8f\u5f00\u59cb\u8fd0\u884c\u65f6\uff0cDOS \u4f1a\u628a ds \u548c es \u8d4b\u503c\u4e3a psp(program segment prefix) \u6bb5\u5730\u5740\u3002psp \u6bb5\u4f4d\u4e8e\u7a0b\u5e8f\u9996\u4e2a\u6bb5\u7684\u524d\u9762\uff0c\u957f\u5ea6\u4e3a 100h \u5b57\u8282\uff0c\u5176\u7528\u9014\u662f\u4fdd\u5b58\u5f53\u524d exe \u76f8\u5173\u7684\u4e00\u4e9b\u4fe1\u606f\uff0c\u5982 psp:80h \u5f00\u59cb\u5b58\u653e\u4e86 exe \u7684\u547d\u4ee4\u884c\u53c2\u6570\u3002</p> <p>\u95f4\u63a5\u5bfb\u5740\uff1a \u53ef\u4ee5\u2f64\u4f5c\u95f4\u63a5\u5bfb\u5740\u7684\u5bc4\u5b58\u5668\u53ea\u6709\u56db\u4e2a\uff1abx, bp, si, di [bx], [bp], [si], [di]\u662f\u6700\u7b80\u5355\u7684\u95f4\u63a5\u5bfb\u5740 [bx + si], [bp + si], [bx + di], [bp + di]\u6ce8\u610f\u524d\u2faf\u5fc5\u987b\u662fbx/bp\uff0c\u540e\u2faf\u5fc5\u987b\u662fdi/si [bx+2] [bp-2] [si+1] [di-1] [bx+si+2] [bx+di-2]</p> <p>[bp+si+1] [bp+di-1] tips\uff1a\u4e24\u4e2a\u5bc4\u5b58\u5668\u76f8\u52a0\u7684\u95f4\u63a5\u5bfb\u5740\u2f45\u5f0f\u4e2d, bx\u6216bp\u901a\u5e38\u2f64\u6765\u8868\u793a\u6570\u7ec4\u7684\u2fb8\u5730\u5740, \u2f7dsi\u6216di\u5219\u2f64\u6765\u8868\u793a\u4e0b \u6807\u3002</p> <p>\u7f3a\u7701\u6bb5\u5740\uff1a\u4e0d\u542bbp\u7684\u6e90\u64cd\u4f5c\u6570\u2f00\u822c\u90fd\u7701\u7565\u7684\u6bb5\u5730\u5740ds\uff0c\u542b\u6709bp\u7684\u6e90\u64cd\u4f5c\u6570\u7701\u7565\u4e86ss\uff0c\u2f7d\u8fd9\u4e2a\u9ed8\u8ba4\u7684\u6bb5\u5730\u5740\u662f \u53ef\u4ee5\u88ab\u6539\u53d8\u7684 </p> <p>\u7528\u5806\u6808\u4f20\u9012\u53c2\u6570\u65f6\uff0c\u5982\u4f55\u7528[bp+]\u5b9e\u73b0\u5bf9\u53c2\u6570\u7684\u5f15\u7528\uff1f</p> <p>bp + \u591a\u5c11\u5c31\u662f\u6808\u91cc\u7684\u591a\u5c11</p> <p>\u738b\u723d\u300a\u6c47\u7f16\u8bed\u2f94\u300b\u7b2c\u56db\u7248 \u9644\u5f554:\u2f64\u6808\u4f20\u9012\u53c2\u6570</p> <pre><code>difcube:\n    mov bp, sp\n    mov ax, [bp+4]  ;a\u7684\u503c\u9001\u5165ax\u4e2d\n    sub ax, [bp+6]  ;\u51cf\u6808\u4e2db\u7684\u503c\n    mov bp, ax\n    mul bp\n    mul bp\n    pop bp\n    ret 4\n\n</code></pre>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_16","title":"\u5176\u5b83\u7684\u7b14\u8bb0","text":""},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#x86","title":"x86\uff1a","text":"<p>Intel\u4ece16\u4f4d\u5fae\u5904\u7406\u56688086\u5f00\u59cb\u7684\u6574\u4e2aCPU\u82af\u7247\u7cfb\u5217\uff0c\u7cfb\u5217\u4e2d\u7684\u6bcf\u79cd\u578b\u53f7\u90fd\u4fdd\u6301\u4e0e\u4ee5\u524d\u7684\u5404\u79cd\u578b\u53f7\u517c\u5bb9\uff0c\u4e3b\u8981\u67098086\uff0c8088\uff0816\u4f4dCPU\uff09\uff0c80186\uff0c80286\uff08\u8fd9\u4e24\u4e2a\u662f\u8fc7\u6e21\u4ea7\u54c1\uff09\uff0c 80386\uff0c80486\u4ee5\u53ca\u4ee5\u540e\u5404\u79cd\u578b\u53f7\u7684Pentium\u82af\u7247\uff0832\u4f4dCPU\uff09\uff0c\u901a\u5e38\u6240\u8bf4\u7684x86\u90fd\u662f\u630732\u4f4dCPU</p> <p>80386: 32\u4f4d\u6c47\u7f16\u3002</p> <p>80836\u5bc4\u5b58\u5668</p> <p>\u901a\u7528\u5bc4\u5b58\u5668(EAX EBX ECX EDX,ESP,EBP,ESI,EDI)</p> <p>\u901a\u7528\u5bc4\u5b58\u5668\u4e0e8086\u7684\u5bc4\u5b58\u5668\u76f8\u6bd4,\u753116\u4f4d\u53d8\u4e3a\u4e8632\u4f4d</p> <p>ESP:\u6808\u9876</p> <p>EBP:\u6808\u5e95</p> <p>EAX\uff0cEBX\uff0cECX\uff0cEDX\u901a\u7528\u5bc4\u5b58\u5668</p> <p>EAX\uff1a\u7d2f\u52a0\u5668\uff08\u4e58\u6cd5\u7684\u65f6\u5019\u5b58\u4f4e\u4f4d\uff09</p> <p>EBX\uff1a\u57fa\u5740\uff08\uff3bEBX\uff0b100\uff28\uff3d\uff09</p> <p>ECX\uff1a\u8ba1\u6570\uff08\u5faa\u73af\u7684\u65f6\u5019\u8ba1\u6570\uff09</p> <p>EDX\uff1a\u6570\u636e\uff08\u9ed8\u8ba4EDX\uff0a10H\uff0b\uff0e\uff0e\uff0e\uff1b\u4e58\u6cd5\u7684\u65f6\u5019\u5b58\u9ad8\u4f4d\uff09</p> <p>ESI\uff0cEDI\uff1a\u53d8\u5740\u5bc4\u5b58\u5668</p> <p>ESI\uff1a\u6e90\u53d8\u5740\u5bc4\u5b58\u5668</p> <p>EDI\uff1a\u76ee\u7684\u53d8\u5740\u5bc4\u5b58\u5668\u3000\u4e0eEBX\u57fa\u5740\u642d\u914d\u4f7f\u7528</p>"},{"location":"CS_Notes/8086%2680386%E6%B1%87%E7%BC%96/#_17","title":"\u53c2\u8003\u6587\u732e","text":"<p>asm_sum.doc</p> <p>xxjj\u7684\u300a\u6c47\u7f16\u8bed\u8a00\u8003\u8bd5\u603b\u7ed3\u300b https://www.yuque.com/xianyuxuan/coding/mkte6u</p> <p>[80386]80x86\u6c47\u7f16\u6307\u4ee4_CarlosX\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_80386\u6307\u4ee4\u96c6</p> <p>80386 \u7b97\u672f\u8fd0\u7b97\u6307\u4ee4\uff0c\u903b\u8f91\u8fd0\u7b97\u6307\u4ee4\uff0c\u79fb\u4f4d\u6307\u4ee4 (\u4e09) _ttzyanswer\u7684\u535a\u5ba2-CSDN\u535a\u5ba2</p>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/","title":"\u722c\u866b","text":"<p>\u89e3\u6790html\u7684\u6b65\u9aa4\uff1a - \u5c42\u6b21\u5316\u7684\u6570\u636e - \u6709\u591a\u4e2a\u89e3\u6790html\u7684\u4e09\u65b9\u5e93\uff0c\u5982\uff1alxml\uff0cbeautifulsoup\uff0chtmlparser</p>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#requests","title":"requests","text":"<pre><code>import requests\n</code></pre> <p>\u53cd\u53cd\u722c\u7684</p> <pre><code>headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n</code></pre>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#beautifulsoup","title":"Beautifulsoup","text":""},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#_1","title":"\u5b89\u88c5\u548c\u521d\u59cb\u5316","text":"<pre><code>pip install beautifulsoup4\n</code></pre> <p>\u89e3\u6790\u7684\u7b2c\u4e00\u6b65\u662f\u6784\u5efa\u4e00\u4e2abeautifulsoup\u5bf9\u8c61</p> <pre><code>from bs4 import BeautifulSoup\nsoup = BeautifulSoup(html_doc, 'html_parser')\n</code></pre>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#_2","title":"\u4ecb\u7ecd","text":"<p>\u7b2c\u4e00\u4e2a\u53c2\u6570html_doc\u662f\u8bfb\u53d6\u7684html\u6587\u6863\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u89e3\u6790\u5668\uff0cbeautifulsoup\u652f\u6301\u4ee5\u4e0b\u89e3\u6790\u5668</p> \u89e3\u6790\u5668 \u4f7f\u7528\u65b9\u6cd5 \u4f18\u52bf \u52a3\u52bf Python\u6807\u51c6\u5e93 BeautifulSoup(markup, \u201chtml.parser\u201d) \u4e2d\u6587\u4e0d\u884c lxml HTML\u89e3\u6790\u5668 BeautifulSoup(markup, \u201clxml\u201d) \u5feb C\u8bed\u8a00\u5e93 lxml XML\u89e3\u6790\u5668 BeautifulSoup(markup, [\u201dlxml-xml\u201d]), BeautifulSoup(markup, \u201cxml\u201d) \u5feb C\u8bed\u8a00\u5e93 htmlSlib BeautifulSoup(markup, \u201chtml5lib\u201d) \u51c6 \u6162 <p>BeautifulSoup\u7c7b\u7684\u57fa\u672c\u5143\u7d20</p> \u57fa\u672c\u5143\u7d20 \u8bf4\u660e Tag \u6807\u7b7e\uff0c\u6700\u57fa\u672c\u7684\u4fe1\u606f\u7ec4\u7ec7\u5355\u5143\uff0c\u5206\u522b\u7528&lt;&gt;\u548c\u6807\u660e\u5f00\u5934\u548c\u7ed3\u5c3e Name \u6807\u7b7e\u7684\u540d\u5b57\uff0c\u5373\u5c16\u62ec\u53f7\u91cc\u7684\u5185\u5bb9 Attribute \u6807\u7b7e\u7684\u5c5e\u6027\uff0c\u8fd4\u56de\u4e00\u4e2a\u5b57\u5178 NavigableString \u6807\u7b7e\u5185\u7684\u975e\u5c5e\u6027\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u4e2aString Comment \u6807\u7b7e\u5185\u5b57\u7b26\u4e32\u7684\u6ce8\u91ca\u90e8\u5206\uff0c\u4e00\u79cd\u7279\u6b8a\u7684Comment\u7c7b\u578b"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#_3","title":"\u4f7f\u7528\u65b9\u6cd5","text":"<p>\u8bbf\u95ee\u6807\u7b7e\uff1a\u7528soup.\u7684\u683c\u5f0f\uff0c\u6bcf\u6b21\u53ea\u80fd\u8fd4\u56de\u7b2c\u4e00\u4e2a\u5339\u914d\u7684tag\u3002 <pre><code>soup = BeautifulSoup(html_doc, 'lxml')\nprint(soup.head) #&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;head&gt;\nprint(soup.head.title) # &lt;title&gt;The Dormouse's story&lt;/title&gt;\nprint(soup.a) # &lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;Elsie&lt;/a&gt;\n</code></pre> <p>\u8bbf\u95ee\u591a\u4e2a\u6807\u7b7e\uff1b\u4f7f\u7528soup.find_all(\u2019\u2019)\u3002\u4f1a\u8fd4\u56de\u4e00\u4e2alist. <pre><code>soup.find_all('a')\n// [&lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;Elsie&lt;/a&gt;, &lt;a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"&gt;Lacie&lt;/a&gt;, &lt;a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"&gt;Tillie&lt;/a&gt;]\nsoup.find_all('a')[0]\n// &lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;Elsie&lt;/a&gt;\n</code></pre> <p>\u53ef\u4ee5\u5728find_all\u65b9\u6cd5\u4e2d\u6dfb\u52a0\u8fc7\u6ee4\u6761\u4ef6\u3002</p> <pre><code>soup.find_all('a', text = 'Elsie')\n// [&lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;Elsie&lt;/a&gt;]\n\nsoup.find_all('a', attrs = {'id': 'link1'})\n// [&lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;Elsie&lt;/a&gt;]\n\nsoup.find_all('a', id = 'link1')\n// \u4f46\u662f\u8fd9\u6837\u5199\u4e0d\u9002\u7528\u4e8e\u6240\u6709\u5c5e\u6027\uff1f\n\nsoup.find_all('p', class_= 'title')\n// [&lt;p class=\"title\"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;]\n// \u8fd9\u79cd\u662fCSS\u9009\u62e9\u5668\n</code></pre>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#_4","title":"\u8bbf\u95ee\u6807\u7b7e\u5185\u5bb9\u548c\u5c5e\u6027","text":"<p>\u901a\u8fc7 name \u548c string \u53ef\u4ee5\u8bbf\u95ee\u6807\u7b7e\u7684\u540d\u5b57\u548c\u5185\u5bb9\uff0c\u901a\u8fc7 get \u548c\u4e2d\u62ec\u53f7\u64cd\u4f5c\u7b26\u53ef\u4ee5\u8bbf\u95ee\u6807\u7b7e\u4e2d\u7684\u5c5e\u6027\u548c\u503c\u3002</p> <pre><code>print(soup.a)\n## &lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;Elsie&lt;/a&gt;\n\nprint(soup.a['class'])\n## ['sister']\n\nprint(soup.a.get('class'))\n## ['sister']\n\nprint(soup.a.name)\n## 'a'\n\nprint(soup.a.string)\n## 'Elsie'\n</code></pre>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#_5","title":"\u89e3\u6790\u7f51\u9875","text":"<pre><code>import requests\nimport chardet\nfrom bs4 import BeautifulSoup\n\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\nurl = \"\"\nrqg = requests.get(url, headers = hearders, timeout = 3.0)\nrqg.encoding = chardet.detect(rqg.content)['encoding']  # requests \u8bf7\u6c42\u8fc7\u7a0b\n\n# \u521d\u59cb\u5316HTML\nhtml = rqg.content.decode('utf-8')\nsoup = BeautifulSoup(html, 'lxml')  # \u751f\u6210 BeautifulSoup \u5bf9\u8c61\nprint('\u8f93\u51fa\u683c\u5f0f\u5316\u7684BeautifulSoup\u5bf9\u8c61\uff1a', soup.prettify())\n\nprint('\u540d\u4e3atitle\u7684\u5168\u90e8\u5b57\u8282\u70b9\uff1a', soup.find_all(\"title\"))\n\nprint('title\u5b50\u8282\u70b9\u7684\u6587\u672c\u5185\u5bb9:', soup.title.string)\nprint('\u4f7f\u7528get_text()\u83b7\u53d6\u7684\u6587\u672c\u5185\u5bb9\uff1a', soup.title.get())\n\ntarget = soup.find_all('ul', class_ = 'menu') # \u6309\u7167CSS\u7c7b\u540d\u5b8c\u5168\u5339\u914d\ntarget = soup.find_all(id = 'menu')  # \u4f20\u5165\u5173\u952e\u5b57id\uff0c\u641c\u7d22\u7b26\u5408\u6761\u4ef6\u7684\u8282\u70b9\ntarget = soup.ul.find_all('a')   # \u6240\u6709\u540d\u79f0\u4e3aa\u7684\u8282\u70b9\n</code></pre>"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#lxmlxpath","title":"lxml\u7684XPath","text":"<p>lxml\u8fd9\u4e2a\u5e93\u540c\u65f6\u652f\u6301HTML\u548cXML\u7684\u89e3\u6790\uff0c\u652f\u6301XPath\u89e3\u6790\u65b9\u5f0f\uff0c\u89e3\u6790\u6548\u7387\u9ad8\u3002</p> <p>\u4f7f\u7528xpath\u9700\u8981\u4ecelxml\u5e93\u4e2d\u5012\u5165etree\u6a21\u5757\uff0c\u9700\u8981\u4f7f\u7528html\u7c7b\u5bf9\u9700\u8981\u5339\u914d\u7684html\u5bf9\u8c61\u8fdb\u884c\u521d\u59cb\u5316\u3002</p> <pre><code>import requests\nimport chardet\nfrom lxml import etree\n\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\nurl = \"\"\nrqg = requests.get(url, headers = hearders, timeout = 3.0)\nrqg.encoding = chardet.detect(rqg.content)['encoding']  # requests \u8bf7\u6c42\u8fc7\u7a0b\n\n# \u521d\u59cb\u5316HTML\nhtml = rqg.content.decode('utf-8')\nhtml = etree.HTML(html, parser = etree.HTMLParser(encoding = 'utf-8'))\n</code></pre> <p>\u5b89\u88c5\u9014\u5f84</p> <pre><code>pip install lxml\n</code></pre> <p>Xpath\u5e38\u7528\u7684\u8868\u8fbe\u5f0f</p> \u8868\u8fbe\u5f0f \u63cf\u8ff0 nodename \u9009\u53d6\u6b64\u8282\u70b9\u7684\u6240\u6709\u5b50\u8282\u70b9\u3002 / \u4ece\u6839\u8282\u70b9\u9009\u53d6\u3002 // \u4ece\u5339\u914d\u9009\u62e9\u7684\u5f53\u524d\u8282\u70b9\u9009\u62e9\u6587\u6863\u4e2d\u7684\u8282\u70b9 . \u9009\u53d6\u5f53\u524d\u8282\u70b9\u3002 \u2026 \u9009\u53d6\u5f53\u524d\u8282\u70b9\u7684\u7236\u8282\u70b9\u3002 @ \u9009\u53d6\u5c5e\u6027\u3002 <p>\u4f7f\u7528\u8868\u8fbe\u5f0f\u5b9a\u4f4dhead\u548ctitle\u8282\u70b9</p> <pre><code>result = html.xpath('head')  ## \u901a\u8fc7\u540d\u79f0\u5b9a\u4e3ahead\u8282\u70b9\nresult1 = html.xpath('/html/heda/title')  ## \u6309\u8282\u70b9\u5c42\u7ea7\u5b9a\u4f4dtitle\u8282\u70b9\nresult2 = html.xpath('//title')  ## \u4e5f\u53ef\u4ee5\u5b9a\u4f4dtitle\u8282\u70b9\n</code></pre> <p>Xpath\u8c13\u8bcd\u5e38\u7528\u7684\u8868\u8fbe\u5f0f</p> \u8868\u8fbe\u5f0f \u7ed3\u679c xpath(\u2019/body/div[1]\u2019) \u9009\u53d6body\u4e0b\u7684\u7b2c\u4e00\u4e2adiv\u8282\u70b9 xpath(\u2019/body/div[last()]\u2019) \u9009\u53d6body\u4e0b\u6700\u540e\u4e00\u4e2adiv\u8282\u70b9 xpath(\u2019/body/div[last()-1]\u2019) \u9009\u53d6body\u4e0b\u5012\u6570\u7b2c\u4e8c\u4e2adiv\u8282\u70b9 xpath(\u2019/body/div[position()&lt;3]\u2019) \u9009\u53d6body\u4e0b\u524d\u4e24\u4e2a\u8282\u70b9 xpath(\u2019/body/div[@class]\u2019) \u9009\u53d6body\u4e0b\u5e26\u6709class\u5c5e\u6027\u7684div\u8282\u70b9 xpath(/body/div[@class=\u201dmain\u201d]\u2019) \u9009\u53d6body\u4e0bclass\u5c5e\u6027\u4e3amain\u7684div\u8282\u70b9 xpath(\u201d/body/div[price&gt;35]\u201d) \u9009\u53d6body\u4e0bprice\u5143\u7d20\u503c\u5927\u4e8e35\u7684\u8282\u70b9"},{"location":"CS_Notes/Crawler%F0%9F%95%B7/#request-html","title":"request-html","text":"<p>requests-html\u7406\u89e3\u4e3a\u53ef\u4ee5\u89e3\u6790HTML\u6587\u6863\u7684request\u5e93</p> <pre><code>pip install requests-html\n</code></pre> <p>\u83b7\u53d6\u4e00\u4e2auser-agent</p> <pre><code>user_agent = requests_html.user_agent()\n</code></pre> <p>\u5bf9JavaScript\u7684\u652f\u6301\u662frequests-html\u6700\u5927\u7684\u4eae\u70b9\uff0c\u4f1a\u7528\u5230render\u51fd\u6570\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\u7b2c\u4e00\u6b21\u4f7f\u7528\u8fd9\u4e2a\u65b9\u6cd5\uff0c\u5b83\u4f1a\u5148\u4e0b\u8f7dChromium\uff0c\u7136\u540e\u4f7f\u7528Chromium\u6765\u6267\u884c\u4ee3\u7801\uff0c\u4f46\u662f\u4e0b\u8f7d\u7684\u65f6\u5019\u53ef\u80fd\u9700\u8981\u4e00\u4e2a\u68af\u5b50\u3002</p> <p>\u793a\u4f8b</p> <pre><code>from requests_html import HTMLSession\n\nsession = HTMLSession()\n\ndef parse():\n        r = session.get('http://www.qdaily.com/')\n    # \u83b7\u53d6\u9996\u9875\u65b0\u95fb\u6807\u7b7e\u3001\u56fe\u7247\u3001\u6807\u9898\u3001\u53d1\u5e03\u65f6\u95f4\n    for x in r.html.find('.packery-item'):\n        yield {\n            'tag': x.find('.category')[0].text,\n            'image': x.find('.lazyload')[0].attrs['data-src'],\n            'title': x.find('.smart-dotdotdot')[0].text if x.find('.smart-dotdotdot') else x.find('.smart-lines')[0].text,\n            'addtime': x.find('.smart-date')[0].attrs['data-origindate'][:-6]\n        }\n</code></pre> <p>\u901a\u8fc7\u7b80\u77ed\u7684\u51e0\u884c\u4ee3\u7801\uff0c\u5c31\u53ef\u4ee5\u628a\u6574\u4e2a\u9996\u9875\u7684\u6587\u7ae0\u6293\u53d6\u4e0b\u6765\u3002</p> <p>\u793a\u4f8b\u4e2d\u4f7f\u7528\u7684\u51e0\u4e2a\u65b9\u6cd5\uff1a</p> <p>\u2460 find( ) \u53ef\u4ee5\u63a5\u6536\u4e24\u4e2a\u53c2\u6570\uff1a</p> <p>\u7b2c\u4e00\u4e2a\u53c2\u6570\u53ef\u4ee5\u662fclass\u540d\u79f0\u6216ID\u7b2c\u4e8c\u4e2a\u53c2\u6570first=True\u65f6\uff0c\u53ea\u9009\u53d6\u7b2c\u4e00\u6761\u6570\u636e</p> <p>\u2461 text \u83b7\u53d6\u5143\u7d20\u7684\u6587\u672c\u5185\u5bb9</p> <p>\u2462 attrs \u83b7\u53d6\u5143\u7d20\u7684\u5c5e\u6027\uff0c\u8fd4\u56de\u503c\u662f\u4e2a\u5b57\u5178</p> <p>\u2463 html \u83b7\u53d6\u5143\u7d20\u7684html\u5185\u5bb9</p> <p>\u4f7f\u7528requests-html\u6765\u89e3\u6790\u5185\u5bb9\u7684\u597d\u5904\u5728\u4e8e\u4f5c\u8005\u90fd\u9ad8\u5ea6\u5c01\u88c5\u8fc7\u4e86\uff0c\u8fde\u8bf7\u6c42\u8fd4\u56de\u5185\u5bb9\u7684\u7f16\u7801\u683c\u5f0f\u8f6c\u6362\u4e5f\u81ea\u52a8\u505a\u4e86\uff0c\u5b8c\u5168\u53ef\u4ee5\u8ba9\u4ee3\u7801\u903b\u8f91\u66f4\u7b80\u5355\u76f4\u63a5\uff0c\u66f4\u4e13\u6ce8\u4e8e\u89e3\u6790\u5de5\u4f5c\u672c\u8eab\u3002</p>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/","title":"\u5df2\u77e5\u95ee\u9898","text":"<ul> <li>\u53ea\u80fd\u4e0ewindows\u7cfb\u7edf\u4e2d\u7684dec++\u6216vs\u517c\u5bb9\u3002windows\u865a\u62df\u673a\u4e0d\u884c\u3002</li> </ul>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#devc","title":"DevC++\u56fe\u5f62\u7f16\u7a0b\u8fc7\u7a0b","text":"<ul> <li>\u4f7f\u7528\u5df2\u6709\u7684\u5de5\u7a0b\u76f4\u63a5\u6253\u5f00</li> <li>\u65b0\u5efa\u6587\u4ef6\u65b9\u6cd5\uff1a<ul> <li>\u2192\u65b0\u5efa</li> <li>\u2192\u9009\u62e9\u52a0\u5165\u5f53\u524d\u5de5\u7a0b</li> <li> <p>\u2192\u4fee\u6539Makefile.win\uff0c\u5728\u672b\u5c3e\u52a0\u5165\uff08\u81ea\u5df1\u5b9e\u8df5\u7684\u65f6\u5019\u8fd9\u6b65\u4e0d\u52a0\u597d\u50cf\u4e5f\u884c\uff09</p> <p><code>cpp gratest1.o:gratest1.c $(CC) -c gratest1.c -o gratest1.o $(CFLAGS)</code></p> </li> </ul> </li> </ul>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_2","title":"\u51fd\u6570\u5e93","text":"<p>graphics.h \u4ec5\u63d0\u4f9b\u4ee5\u4e0b\u5c11\u91cf\u753b\u56fe\u51fd\u6570\u63a5\u53e3</p> <pre><code>InitGraphics();\nMovePen(x, y);\nDrawLine(dx, dy);\nDrawArc(r, start, sweep);\nGetWindowWidth();\nGetWindowHeight();\nGetCurrentX();\nGetCurrentY();\n</code></pre> <p>\u6211\u4eec\u5c06\u5728\u4e0b\u9762\u4ecb\u7ecd\u8fd9\u4e9b\u63a5\u53e3\u7684\u7528\u6cd5\u3002</p>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_3","title":"\u521d\u59cb\u5316\u64cd\u4f5c","text":"<p>\u5728main.c\u91cc\u9700\u8981\u8fdb\u884c\u5982\u4e0b\u521d\u59cb\u5316</p> <pre><code>#include \"graphics.h\"\n#include \"extragraph.h\"\n#include \"imgui.h\"\n\nvoid Main()        // \u6ce8\u610f\u8fd9\u91cc\u9700\u8981\u4f7f\u7528\u5927\u5199Main\n{\n    Set WindowTitle(\"Your Title\");\n    InitGraphics();  // \u8c03\u7528\u4e86\u56fe\u5f62\u6a21\u5f0f\n}\n</code></pre> <p>InitGraphics(); \u8fd9\u4e2a\u51fd\u6570\u4f1a\u6253\u5f00\u4e00\u4e2a\u7a7a\u7684\u56fe\u5f62\u7a97\u53e3\u3002</p>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_4","title":"\u7a97\u53e3","text":"<p>\u4ee5\u4e0b\u56db\u4e2a\u51fd\u6570\u90fd\u4e0d\u9700\u8981\u4f20\u5165\u53c2\u6570\uff0c\u5206\u522b\u8fd4\u56de\u7a97\u53e3\u5bbd\u3001\u9ad8\uff0c\u5f53\u524dX\u3001Y\u5750\u6807\u3002</p> <pre><code>GetWindowWidth();\nGetWindowHeight();\n\nGetCurrentX();\nGetCurrentY();\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_5","title":"\u597d\u7684\u7f16\u5199\u4e60\u60ef","text":"<p>\u5e94\u8be5\u5148\u5b9a\u4e49\u4e00\u4e9b\u5e38\u91cf\uff0c\u7ed9\u8fd9\u4e9b\u5e38\u91cf\u53d6\u540d\u5b57</p> <pre><code>#define HouseHeight 2.0\n#define HouseWidth 3.0\n#define AtticHeight 0.7\n#define DoorWidth 0.4\n#define DoorKnobRadius 0.03\n#define DoorKnobInset 0.07\n#define PaneHeight 0.25\n#define PaneWidth 0.2\n#define FirstFloorWindows 0.3\n#define SecondFloorWindows 1.25\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_6","title":"\u753b\u56fe\u5f62\u7684","text":""},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#movepen","title":"MovePen","text":"<p>\u5c06\u7b14\u79fb\u52a8\u5230(x, y)\u8be5\u5750\u6807\u3002\u6ce8\u610f\u5f53\u753b\u56fe\u5f62\u65f6\uff0c\u540e\u9762\u51e0\u4e2a\u51fd\u6570\u7684\u76f8\u5bf9\u4f4d\u79fb\uff0c\u90fd\u662f\u76f8\u5bf9\u4e8e\u8fd9\u4e2a\u51fd\u6570\u8bbe\u7f6e\u7684\u7b14\u5750\u6807\u79fb\u52a8\u7684\u3002</p> <pre><code>MovePen(double x, double y);\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#drawline","title":"DrawLine","text":"<p>\u5728\u753b\u7ebf\u4e4b\u524d\u4e00\u5b9a\u8981MovePen();</p> <pre><code>DrawLine(double dx, double dy);\n</code></pre> <p>\u753b\u7ebf\u7684\u65b9\u5411\uff1a</p> <p>\u6a2a\u5750\u6807\u6700\u5de6\u8fb9\u662f0\uff0c\u5411\u53f3\u589e\u5927</p> <p>\u7eb5\u5750\u6807\u6700\u4e0b\u9762\u662f0\uff0c\u5411\u4e0a\u589e\u5927</p> <p>\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u5728\u7b2c\u4e00\u8c61\u9650</p>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#drawarc","title":"DrawArc","text":"<p>\u5728\u753b\u5f27\u4e4b\u524d\u4e00\u5b9a\u8981MovePen();</p> <pre><code>DrawArc(double r, double start, double sweep);\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_7","title":"\u6211\u4eec\u5e94\u5f53\u628a\u753b\u77e9\u5f62\u5c01\u88c5\u6210\u4e00\u4e2a\u65b0\u7684\u51fd\u6570","text":"<pre><code>void DrawBox (double x, double y, double width, double height)\n{\n    MovePen(x, y);\n    DrawLine(0, height);\n    DrawLine(width, 0);\n    DrawLine(0, height);\n    DrawLine(-width, 0);\n}\n</code></pre> <pre><code>void DrawCenteredBox(double x, double y, double width, double height)\n{\n    DrawBox(w - width/2, y - height/2, width, height);\n}\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_8","title":"\u753b\u5706\u7684\u51fd\u6570","text":"<pre><code>void DrawCenteredCircle(double x, double y, double r)\n{\n    MovePen(x + r, y);\n    DrawArc(r, 0, 360);\n}\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_9","title":"\u6587\u5b57","text":"<p>\u4ece\u5f53\u524d\u4f4d\u7f6e\u5f00\u59cb\u8f93\u51fa\u6587\u672c\u4e32</p> <pre><code>DrawTextString(string);\n</code></pre> <p>\u8fd9\u4e2a\u51fd\u6570\u7528\u4e8e\u83b7\u53d6\u67d0\u4e2a\u5b57\u7b26\u4e32\u957f\u5ea6</p> <pre><code>double stringLen = TextStringWidth(string); \n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_10","title":"\u67e5\u770b\u56de\u8c03\u51fd\u6570\u7c7b\u578b","text":"<pre><code>typedef void(* KeyboardEventCallback)(int key, int event);\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_11","title":"\u5b9a\u65f6\u5668","text":""},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_12","title":"\u65f6\u95f4\u56de\u8c03\u51fd\u6570","text":"<pre><code>registerTimerEvent(mytimer);  //\u83b7\u53d6\u7535\u8111\u65f6\u949f\u4fe1\u606f\u8fd4\u56de\u7ed9mytimer\nstartTimer(0, (int)(1000/speed));  // \u8981\u8ba8\u8bba\u4f20\u8fdb\u6765\u7684timer\u662f\u4ec0\u4e48\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_13","title":"\u5b9a\u65f6\u5668\u6d88\u606f\u56de\u8c03\u51fd\u6570","text":"<pre><code>void TimerEventProcess(int timerID);\n</code></pre> <p>\u793a\u4f8b</p> <pre><code>typedef enum\n{\n    LabelTimer,\n    BoxTimer,\n} MyTimer;\n</code></pre> <pre><code>void mytimer(int  timerID)\n{\n    switch (timerID)\n    {\n    case LabelTimer:\n        label_x += 0.5;\n        if (label_x &gt; 5.0) \n            label_x = 1.0;\n        display();\n        break;\n    case BoxTimer:\n        box_y += 0.5;\n        if (box_y &gt; 5.0) box_y = 1.0;\n        display();\n        break;\n        break;\n    }\n}\n</code></pre> <pre><code>registerTimerEvent(mytimer);\nstartTimer(LabelTimer, 100);\nstartTimer(BoxTimer, 200);\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_14","title":"\u9f20\u6807","text":""},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_15","title":"\u9f20\u6807\u6d88\u606f\u56de\u8c03\u51fd\u6570","text":"<pre><code>void MouseEventProcess(int x, int y, int button, int event);\n</code></pre> <p>x, y - \u4f4d\u7f6e\u5750\u6807</p> <p>button - \u6309\u4e0b\u7684\u662f\u54ea\u4e2a\u952e</p> <p>event - \u6309\u4e0b\uff0c\u677e\u5f00\uff0c\u79fb\u52a8\u7b49\u4e8b\u4ef6</p> <pre><code>void myMouseEvent (int x, int y, int button, int event)\n{\n    mouse_x = ScaleXInches(x);   // \u8fd9\u4e2a\u51fd\u6570\u5728extragraph\u5e93\u91cc\n    mouse_y = ScaleYInches(y);\n    display();\n}\n</code></pre> <p>\u9700\u8981\u5728Main()\u91cc\u6dfb\u52a0\u8fd9\u4e00\u884c</p> <pre><code>registerMouseEvent(myMouseEvent);\n</code></pre> <p>\u5728display()\u91cc</p> <pre><code>void display()\n{\n    double w = 1.0;\n    double h = GetFontHeight() * 2;\n    // \u6e05\u9664\u5c4f\u5e55\n    DisplayClear();\n    // draw a square\n    SetPenColor(\"Red\");\n    drawLabel(label_x, label_y, \"Lable is Here\");\n\n    //draw a rect/box to trace the mouse\n    //drawRectangle(mouse_x, mouse_y, w, h, 0);\n    SetPenColor(\"Blue\");\n    drawBox(mouse_x, mouse_y, w, h, 1, \"This box follows the mouse\", 'L', \"Red\");\n}\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#linkedlist","title":"\u4f7f\u7528linkedlist\u5e93","text":"<pre><code>#include \"linkedlist.h\"\n</code></pre> <p>\u521b\u5efa\u4e00\u4e2a linkedlist \u540d\u53eb g_polylines</p> <pre><code>linkedlistADT g_polylines = NULL;\n\ng_polylines = NewLinkedList();\ndisplay();\n</code></pre> <pre><code>void display()\n{\n    linkedlistADT poly = NextNode(g_polylines, g_polylines);\n\n    SetPenColor(\"Blue\");\n    if (poly) {\n        Point * p = (Point*) NodeObj(g_polylines, poly);\n        double lx = p-&gt;x;\n        double ly = p-&gt;y;\n        MovePen(lx, ly);\n        while (poly = NextNode(g_polylines, poly))\n        {\n            p = (Point*) NodeObj(g_polylines, poly);\n            DrawLine(p-&gt;x - lx, p-&gt;y - ly);\n            lx = p-&gt;x;\n            ly = p-&gt;y;\n        }\n    }\n}\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#button","title":"\u4f7f\u7528button\u548c\u952e\u76d8","text":"<p>\u8fd9\u6b21\u9700\u8981\u7528\u5230\u7684\u5e93</p> <pre><code>#include &lt;windows.h&gt;\n#include &lt;winuser.h&gt;\n#include \"graphics.h\"\n#include \"extgraph.h\"\n#include \"imgui.h\"\n#include \"linkedlist.h\"\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_16","title":"\u5b57\u7b26\u8f93\u5165\u56de\u8c03\u51fd\u6570","text":"<pre><code>void charEventProcess(char c);\n</code></pre> <p>c - \u8f93\u5165\u5b57\u7b26\u7684ASCII\u7801</p>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_17","title":"\u952e\u76d8\u56de\u8c03\u51fd\u6570","text":"<pre><code>void KeyboardEventProcess(int key, int event);\n</code></pre> <p>key - \u54ea\u4e2a\u952e</p> <p>event - \u6309\u4e0b\u8fd8\u662f\u677e\u5f00</p> <p>\u793a\u4f8b</p> <p>\u5728Main()\u4e2d</p> <pre><code>\n</code></pre> <pre><code>void myKeyboardEvent(int key, int event)\n{\n    uiGetKeyboard(key, event); // needed for using simpleGUI\n    display();\n\n    switch (event)\n    {\n    case KEY_UP:\n        if (key == VK_F1)\n            g_add_point = !g_add_point;\n\n        break;\n\n    default:\n        break;\n    }\n}\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#_18","title":"\u989c\u8272\u5e93","text":"<p>\u81ea\u5e26\u7684\u989c\u8272\u5217\u8868</p> <pre><code>char colorlist[100][100] = {\u201dBlack\u201d, \u201cDark Gray\u201d, \u201cGray\u201d, \u201cLight Gary\u201d, \u201cWhite\u201d, \u201cBrown\u201d, \u201cRed\u201d, \u201cOrange\u201d, \u201cYellow\u201d, \u201cGreen\u201d, \u201cBlue\u201d, \u201cViolet\u201d, \u201cMagenta\u201d, \u201cCyan\u201d};\nconst int colorNumber = 14;\n</code></pre> <p>\u81ea\u5b9a\u4e49\u989c\u8272</p> <p>\u989c\u8272\u4f1a\u88ab\u52a0\u5165\u989c\u8272\u5e93\uff0cRGB\u7684\u53d6\u503c\u8303\u56f4\u90fd\u662f[0, 1]\u800c\u4e0d\u662f[0, 256)</p> <pre><code>DefineColor(\"Color Name\", R, G, B);\n</code></pre>"},{"location":"CS_Notes/C%E5%A4%A7%E7%A8%8Blibgraphics%E8%B8%A9%E5%9D%91%E6%96%87%E6%A1%A3/#libgraphics","title":"libgraphics\u5176\u5b83\u5e38\u7528\u7684\u4e1c\u897f","text":""},{"location":"CS_Notes/C%E8%AF%AD%E8%A8%80/","title":"\u6307\u9488","text":"<p>\u6570\u7ec4\u540d\u662f\u4e00\u4e2a\u6307\u9488\u5e38\u91cf \u6307\u5411\u6307\u9488\u7684\u6570\u7ec4\uff08\u4e8c\u7ea7\u6307\u9488\uff09</p> <pre><code>int a = 10;\nint *p = &amp;a;\nint **p = &amp;p;\n</code></pre> <p>\u6307\u9488\u6570\u7ec4\u4e0e\u6570\u7ec4\u6307\u9488</p> <pre><code>char ccolor[][] = {\"red\", \"blue\", \"yellow\"};\n</code></pre> <p>\u662f\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\uff0c\u6bcf\u4e00\u884c\u90fd\u662f\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\uff0c\u5373ccolor+i\u662f\u4e00\u4e2a\u6307\u9488\uff0c\u6307\u5411\u7b2ci\u884c\u7684\u4e00\u7ef4\u6570\u7ec4\uff0cccolor+i\u7c7b\u578b\u662f\u201c\u957f\u5ea6\u4e3a7\u7684\u4e00\u7ef4\u6570\u7ec4\u201d\u7684\u6307\u9488\u3002ccolor[i]\u662f\u4e00\u7ef4\u6570\u7ec4</p>"},{"location":"CS_Notes/C%E8%AF%AD%E8%A8%80/#_2","title":"\u6307\u9488\u8fdb\u9636","text":"<p>\u7c7b\u578b\u540d* \u6307\u9488\u53d8\u91cf\u540d</p> <p>\u6307\u9488\u7684\u503c\u6216\u5730\u5740\u503c</p> <pre><code>double a, x[10];\ndouble *p1, *p2;\n</code></pre> <p>p1\u548cp2\u90fd\u662f\u6307\u9488\uff1ap1\u7684\u57fa\u7c7b\u578b\u662fdouble\uff0cp2\u7684\u57fa\u7c7b\u578b\u662fdouble*\uff0c\u6b64\u65f6\u90fd\u8fd8\u6ca1\u6709\u786e\u5b9a\u5730\u5740\u503c\uff0c\u9700\u8981\u8d4b\u503c\u3002</p> <pre><code>// \u8bfb\u5165\u4e00\u4e2a\u5b57\u7b26\u4e32\nchar str[100], *s;\nscanf(\"%s\", s);\n\n// \u8bfb\u5165\u4e00\u4e2a\u6574\u6570\nint a, *p;\nscanf(\"%d\", p);\n\n// \u5f15\u7528\u6307\u9488\nint c, a = 2, *p;\nc = 3 + *p;\n</code></pre> <p>\u6307\u9488\u7684\u52a0\u6cd5\u5bf9\u5730\u5740\u503c\u7684\u5f71\u54cd</p> <p>\u5730\u5740\u503c\u7684\u589e\u91cf = sizeof(\u57fa\u7c7b\u578b)</p> \u5b9a\u4e49 \u57fa\u7c7b\u578b p\u5f53\u524d\u6307\u5411\u5730\u5740 p+1 char *p char (1 byte) 20 21 short *p short (2 bytes) 40 42 long *p long (4 bytes) 80 84 <p>\u7406\u89e3\u8fd0\u7b97\u7b26[]</p> <p>a[3]\u7b49\u4ef7\u4e8e3[a]\u7b49\u4ef7\u4e8e*(3+a)</p> <p>\u4e8c\u7ef4\u6570\u7ec4\u4e0e\u884c\u6307\u9488</p> <ul> <li>\u5b83\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u662f\u4e00\u7ef4\u6570\u7ec4</li> <li>a\u4e5f\u662f\u4e00\u4e2a\u6307\u9488\uff0c\u5b83\u7684\u57fa\u7c7b\u578b\u662f\u201c\u957f\u5ea6\u4e3a3\u7684int\u6307\u9488\u201d</li> <li>*(a+i) = a[i]</li> <li>*(a[i] + j) = a[i][j]</li> </ul>"},{"location":"CS_Notes/C%E8%AF%AD%E8%A8%80/#-","title":"\u7ea6\u745f\u592b\u73af - \u516c\u5f0f\u6cd5\uff08\u9012\u63a8\u516c\u5f0f\uff09","text":""},{"location":"CS_Notes/C%E8%AF%AD%E8%A8%80/#_3","title":"\u95ee\u9898\u63cf\u8ff0","text":"<p>N\u4e2a\u4eba\u56f4\u6210\u4e00\u5708\uff0c\u7b2c\u4e00\u4e2a\u4eba\u4ece1\u5f00\u59cb\u62a5\u6570\uff0c\u62a5M\u7684\u5c06\u88ab\u6740\u6389\uff0c\u4e0b\u4e00\u4e2a\u4eba\u4ece1\u5f00\u59cb\u62a5\uff0c\u6700\u540e\u5269\u4e0b\u4e00\u4e2a\uff0c\u6c42\u6700\u540e\u7684\u80dc\u5229\u8005\u3002</p>"},{"location":"CS_Notes/C%E8%AF%AD%E8%A8%80/#_4","title":"\u666e\u901a\u89e3\u6cd5","text":"<p>\u7528\u94fe\u8868\u6a21\u62df\u8fd9\u4e2a\u8fc7\u7a0b\uff0cN\u4e2a\u4eba\u770b\u4f5cN\u4e2a\u8282\u70b9\uff0c\u8282\u70b91\u6307\u5411\u8282\u70b92\uff0c\u8282\u70b92\u6307\u5411\u8282\u70b93\uff0c\u8282\u70b9N\u6307\u5411\u8282\u70b91.</p> <p>\u6bcf\u62a5\u5230M\uff0c\u5c31\u5220\u9664\u8fd9\u4e2a\u6570\u3002\u7f3a\u70b9\u662f\u8981\u6a21\u62df\u6574\u4e2a\u6e38\u620f\u8fc7\u7a0b\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u5c31\u9ad8\u8fbeO(nm)\u3002</p>"},{"location":"CS_Notes/C%E8%AF%AD%E8%A8%80/#_5","title":"\u516c\u5f0f\u6cd5","text":"<p>\u9012\u63a8\u516c\u5f0f</p> <p>$$ f(N, M) = (f(N-1, M)+M)\\%N $$</p> <p>\u5176\u4e2df(M, N) \u8868\u793a N \u4e2a\u4eba\u62a5\u6570\uff0c\u6bcf\u62a5\u5230 M \u65f6\u6740\u6389\u8fd9\u4e2a\u4eba\uff0c\u6700\u540e\u80dc\u5229\u8005\u7684\u7f16\u53f7\u3002</p> <p>\u600e\u6837\u63a8\u5bfc\u8be5\u516c\u5f0f\u3002</p> <p>f(11, 3)</p> <p>\u95ee\u98981: \u5047\u8bbe\u77e5\u905311\u4e2a\u4eba\u65f6\u80dc\u5229\u8005\u7684\u4e0b\u6807\u4e3a6\uff0c\u4e0b\u4e00\u8f6e10\u4e2a\u4eba\u65f6\u80dc\u5229\u8005\u7684\u4e0b\u6807\u4e3a\uff1a\u7b2c\u4e00\u8f6e\u5220\u6389\u7f16\u53f7\u4e3a3\u7684\u4eba\u540e\uff0c\u6240\u6709\u4eba\u90fd\u5f80\u524d\u79fb\u52a8\u4e863\u4f4d\uff0c\u80dc\u5229\u8005\u4e5f\u5f80\u524d\u79fb\u52a8\u4e863\u4f4d\uff0c\u6240\u4ee5\u4e0b\u6807\u75316\u53d83.</p> <p>\u95ee\u98982: \u5047\u8bbe\u5df2\u77e510\u4e2a\u4eba\u65f6\uff0c\u80dc\u5229\u8005\u4e0b\u6807\u4e3a3\uff0c\u90a3\u4e0b\u4e00\u8f6e11\u4e2a\u4eba\u65f6\u80dc\u5229\u8005\u7684\u4e0b\u6807\u662f\uff1f</p> <p>\u53ef\u4ee5\u770b\u4f5c\u4e0a\u4e2a\u8fc7\u7a0b\u7684\u9006\u8fc7\u7a0b\uff0c\u5927\u5bb6\u90fd\u5f80\u540e\u79fb\u52a83\u4f4d\uff0c\u6240\u4ee5f(11, 3) = f(10, 3) + 3\u3002\u4e0d\u8fc7\u6709\u53ef\u80fd\u6570\u7ec4\u4f1a\u8d8a\u754c\uff0c\u6240\u4ee5\u6700\u540e\u6a21\u5f53\u524d\u4eba\u6570\u7684\u4e2a\u6570\uff0cf(11, 3) = (f(10, 3) + 3) %11</p> <p>\u95ee\u98983: \u73b0\u5728\u6539\u6210\u4eba\u6570\u4e3aN\uff0c\u62a5\u5230M\u65f6\u628a\u4eba\u6740\u6389\uff0c\u6570\u7ec4\u662f\u600e\u6837\u79fb\u52a8\u7684\uff1f\u6bcf\u6740\u6389\u4e00\u4e2a\u4eba\uff0c\u4e0b\u4e00\u4e2a\u4eba\u6210\u4e3a\u5934\uff0c\u76f8\u5f53\u4e8e\u628a\u6570\u7ec4\u5411\u524d\u79fb\u52a8M\u4f4d\u3002\u82e5\u5df2\u77e5N-1\u4e2a\u4eba\u65f6\uff0c\u80dc\u5229\u8005\u7684\u4e0b\u6807\u4f4d\u7f6ef(N-1, M)\uff0c\u5219N\u4e2a\u4eba\u65f6\uff0c\u5c31\u662f\u5f80\u540e\u79fb\u52a8M\uff0c\u8003\u8651\u5230\u6570\u7ec4\u8d8a\u754c\uff0c\u8981\u6a21N\uff0c\u5373f(N, M) = (f(N-1, M) + M) % N\u3002</p> <pre><code>int cir(int n, int m)\n{\n    int p = 0;\n    for (int i=2; i&lt;=n; i++)\n    {\n        p=(p+m)%i;\n    }\n    return p+1;\n}\n</code></pre>"},{"location":"CS_Notes/objdump/","title":"Objdump","text":"<p>\u6e90\u4ee3\u7801\u6587\u4ef6\u540dmytest.c</p> <pre><code>gcc -c -g -o mytest mytest.c\nobjdump -s -d main.o &gt; main.o.txt\n</code></pre> <p>\u76ee\u6807\u6587\u4ef6\u53cd\u6c47\u7f16\uff0c\u540c\u65f6\u663e\u793a\u6e90\u4ee3\u7801</p> <pre><code>gcc -g -c -o main.o main.c\nobjdump -S -d main.o &gt; main.o.txt\n</code></pre> <p>\u663e\u793a\u6e90\u4ee3\u7801\u7684\u540c\u65f6\u663e\u793a\u884c\u53f7</p> <pre><code>objdump -j .text -ld -C -S main.o &gt; main.o.txt\n</code></pre> <p>\u53ef\u6267\u884c\u6587\u4ef6\u53cd\u6c47\u7f16</p> <pre><code>gcc -o main main.c\nobjdump -s -d main &gt; main.txt\n</code></pre> <p>\u540c\u65f6\u663e\u793a\u6e90\u4ee3\u7801</p> <pre><code>gcc -g -o main main.c\nobjdump -S -d main &gt; main.txt\n</code></pre>"},{"location":"CS_Notes/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/","title":"\u7f16\u7a0b\u89c4\u8303\u6587\u6863\u6a21\u677f","text":"<p>\u4e00\u4efd\u7528\u4e8eC\u5927\u7a0b\u7684\u7b80\u6613\u7f16\u7a0b\u89c4\u8303\u6587\u6863\u3002 \u4e3a\u7edf\u4e00\u5c0f\u7ec4\u6210\u5458\u5728\u8f6f\u4ef6\u5f00\u53d1\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u4ee3\u7801\u98ce\u683c\uff0c\u65b9\u4fbf\u7ec4\u5458\u4e92\u76f8\u4e4b\u95f4\u534f\u4f5c\uff0c\u7279\u63d0\u51fa\u4ee5\u4e0b\u7f16\u7801\u89c4\u8303\u3002</p>"},{"location":"CS_Notes/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/#_1","title":"\u6392\u7248\u89c4\u8303","text":"<ul> <li>\u51fd\u6570\u7684\u58f0\u660e\u4e0e\u5b9a\u4e49\u89c4\u5219\u3002\u51fd\u6570\u540d\u548c\u5de6\u5706\u62ec\u53f7\u4e4b\u95f4\u6ca1\u6709\u7a7a\u683c\uff0c\u5706\u62ec\u53f7\u4e0e\u53c2\u6570\u4e4b\u95f4\u6ca1\u6709\u7a7a\u683c\u3002\u5de6\u5927\u62ec\u53f7\u603b\u662f\u4e0e\u53c2\u6570\u5217\u8868\u5728\u540c\u4e00\u884c\uff0c\u53f3\u5927\u62ec\u53f7\u603b\u662f\u4f4d\u4e8e\u51fd\u6570\u6700\u540e\u4e00\u884c\u3002\u51fd\u6570\u5185\u5bb9\u603b\u4e0e\u5de6\u8fb9\u680f\u4fdd\u6301\u4e00\u4e2a\u5236\u8868\u7b26\u7684\u7f29\u8fdb\u3002\u53c2\u6570\u95f4\u7684\u9017\u53f7\u540e\u603b\u52a0\u4e00\u4e2a\u7a7a\u683c\u3002\u6bcf\u4e2a\u51fd\u6570\u5728\u5934\u6587\u4ef6\u4e2d\u5e94\u6709\u6ce8\u91ca\u6ce8\u660e\u8be5\u51fd\u6570\u7684\u4f5c\u7528\u3002</li> <li>\u7a7a\u884c\u89c4\u5219\u3002\u5728\u6bcf\u4e2a\u51fd\u6570\u5b9a\u4e49\u7ed3\u675f\u540e\u8981\u52a0\u7a7a\u884c\uff0c\u5728\u51fd\u6570\u5185\u6bcf\u4e2a\u903b\u8f91\u5355\u5143\u540e\u5e94\u5f53\u52a0\u7a7a\u884c\uff0c\u903b\u8f91\u7d27\u5bc6\u7684\u8bed\u53e5\u4e4b\u95f4\u4e0d\u52a0\u7a7a\u884c\u3002</li> <li>\u4ee3\u7801\u884c\u89c4\u5219\u3002\u4e00\u884c\u4ee3\u7801\u53ea\u505a\u4e00\u4ef6\u4e8b\u60c5\uff0c\u5982\u53ea\u5b9a\u4e49\u4e00\u4e2a\u53d8\u91cf\uff0c\u6216\u53ea\u5199\u4e00\u6761\u8bed\u53e5\u3002If\u3001for\u3001while\u3001do\u7b49\u8bed\u53e5\u72ec\u5360\u4e00\u884c\uff0c\u6267\u884c\u8bed\u53e5\u4e0d\u7d27\u8ddf\u5176\u540e\u3002\u5728\u5b9a\u4e49\u53d8\u91cf\u7684\u540c\u65f6\u5fc5\u987b\u521d\u59cb\u5316\u8be5\u53d8\u91cf\u3002</li> <li>\u4ee3\u7801\u5185\u7a7a\u683c\u89c4\u5219\u3002\u2019!\u2019, \u2018~\u2019, \u2019++\u2019, \u2019-\u2019, \u2018&amp;\u2019, \u2018[]\u2019, \u2018.\u2019, \u2018-&gt;\u2019\u7b49\u8fd0\u7b97\u7b26\u524d\u540e\u4e0d\u52a0\u7a7a\u683c\uff0c\u5176\u4f59\u8fd0\u7b97\u7b26\u540e\u9762\u8981\u7559\u7a7a\u683c\u3002</li> <li>\u6ce8\u91ca\u89c4\u5219\u3002\u5982\u679c\u4ee3\u7801\u4e2d\u6b8b\u7559\u6709\u88ab\u6ce8\u91ca\u7684\u4ee3\u7801\uff0c\u5fc5\u987b\u52a0\u4e0a\u8be5\u4ee3\u7801\u88ab\u6ce8\u91ca\u7684\u539f\u56e0\uff0c\u5426\u5219\u5e94\u5f53\u5220\u9664\u3002\u6ce8\u91ca\u4e0d\u53ef\u55a7\u5bbe\u593a\u4e3b\uff0c\u7b80\u6d01\u5373\u53ef\u3002\u5982\u679c\u4ee3\u7801\u672c\u8eab\u662f\u6e05\u695a\u7684\uff0c\u5219\u4e0d\u5fc5\u52a0\u6ce8\u91ca\u3002\u9488\u5bf9\u5355\u884c\u7684\u6ce8\u91ca\uff0c\u5728\u8be5\u884c\u540e\u7528\u2019//\u2019\u4f5c\u6ce8\u91ca\u3002\u9488\u5bf9\u591a\u884c\u7684\u6ce8\u91ca\uff0c\u5728\u8be5\u6bb5\u4ee3\u7801\u524d\u7528\u2019/**/\u2019\u4f5c\u6ce8\u91ca\uff0c\u5e76\u5728\u6bb5\u5c3e\u7528\u7a7a\u884c\u5206\u79bb\u3002\u6ce8\u91ca\u53ef\u653e\u5728\u4ee3\u7801\u7684\u4e0a\u65b9\u6216\u53f3\u65b9\uff0c\u4e0d\u53ef\u653e\u5728\u4e0b\u65b9\u3002</li> </ul>"},{"location":"CS_Notes/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/#_2","title":"\u547d\u540d\u89c4\u5219","text":"<ul> <li>\u6807\u8bc6\u7b26\u5e94\u5f53\u5c3d\u91cf\u76f4\u89c2\u53ef\u4ee5\u62fc\u8bfb\uff0c\u4f7f\u7528\u82f1\u6587\u5355\u8bcd\u53ca\u5176\u590d\u5408\u3002\u5982\u679c\u547d\u540d\u6d89\u53ca\u591a\u4e2a\u5355\u8bcd\u9700\u8981\u4f7f\u7528\u9a7c\u5cf0\u547d\u540d\u6cd5\uff0c\u5373\u5c06\u975e\u9996\u4e2a\u5355\u8bcd\u7684\u9996\u5b57\u6bcd\u5927\u5199\uff0c\u4e0d\u4f7f\u7528\u4e0b\u5212\u7ebf\u8fde\u63a5\u3002</li> <li>\u51fd\u6570\u540d\u5e94\u4f7f\u7528\u201c\u52a8\u8bcd\u201d\u6216\u201c\u52a8\u8bcd+\u540d\u8bcd\u201d\u7ed3\u6784\u3002</li> <li>\u53d8\u91cf\u540d\u5e94\u4f7f\u7528\u201c\u540d\u8bcd\u201d\u6216\u201c\u5f62\u5bb9\u8bcd+\u540d\u8bcd\u201d\u7ed3\u6784\u3002</li> <li>\u6587\u4ef6\u540d\u5e94\u9996\u5355\u8bcd\u9996\u5b57\u6bcd\u5927\u5199\uff0c\u51fd\u6570\u540d\u548c\u53d8\u91cf\u540d\u9996\u5355\u8bcd\u9996\u5b57\u6bcd\u4e0d\u5fc5\u5927\u5199\u3002</li> <li>\u907f\u514d\u53d8\u91cf\u540d\u4e2d\u51fa\u73b0\u7f16\u53f7\uff0c\u9664\u975e\u903b\u8f91\u4e0a\u786e\u5b9e\u9700\u8981\u7f16\u53f7\uff0c\u8fd9\u662f\u4e3a\u4e86\u4ea7\u751f\u53ef\u8bfb\u6027\u5dee\u7684\u53d8\u91cf\u540d\u3002</li> <li>\u9664\u5faa\u73af\u53d8\u91cfi, j, k\u4ee5\u5916\uff0c\u4e0d\u4f7f\u7528\u5355\u4e2a\u5b57\u7b26\u547d\u540d\u53d8\u91cf\u3002</li> </ul>"},{"location":"CS_Notes/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/#_3","title":"\u7f16\u7801\u89c4\u5219","text":"<ul> <li>\u9519\u8bef\u68c0\u67e5\u89c4\u5219\u3002\u7f16\u7a0b\u4e2d\u8981\u8003\u8651\u5230\u51fd\u6570\u7684\u5404\u79cd\u6267\u884c\u60c5\u51b5\uff0c\u5c3d\u53ef\u80fd\u5904\u7406\u6240\u6709\u60c5\u51b5\u3002\u51fd\u6570\u5206\u4e3a\u4e24\u7c7b\uff0c\u4e00\u7c7b\u662f\u4e0e\u56fe\u5f62\u663e\u793a\u65e0\u5173\u7684\u529f\u80fd\u51fd\u6570\uff0c\u5e94\u5f53\u901a\u8fc7\u8fd4\u56de\u503c\u6765\u62a5\u544a\u9519\u8bef\uff1b\u4e00\u7c7b\u662f\u4e0e\u56fe\u5f62\u663e\u793a\u6709\u5173\u7684\u663e\u793a\u51fd\u6570\uff0c\u8981\u5728\u5c4f\u5e55\u4e0a\u7528\u63d0\u793a\u6765\u5411\u7528\u6237\u663e\u793a\u64cd\u4f5c\u9519\u8bef\uff0c\u6dfb\u52a0\u76f8\u5e94\u7684\u9519\u8bef\u5904\u7406\u4f7f\u7a0b\u5e8f\u4e0d\u80fd\u5d29\u6e83\uff0c\u5e76\u63d0\u793a\u7528\u6237\u4fee\u6b63\u64cd\u4f5c\u3002\u9519\u8bef\u5904\u7406\u4ee3\u7801\u4e00\u822c\u653e\u5728\u51fd\u6570\u7684\u672b\u5c3e\u3002</li> <li>\u4f7f\u7528tab\u7f29\u8fdb\u3002</li> <li>\u53d8\u91cf\u4f7f\u7528\u89c4\u5219\u3002\u4e0d\u968f\u610f\u5b9a\u4e49\u5168\u5c40\u53d8\u91cf\uff0c\u9664\u975e\u8be5\u53d8\u91cf\u5728\u591a\u4e2a\u51fd\u6570\u91cc\u9700\u8981\u5171\u4eab\u3002\u5168\u5c40\u53d8\u91cf\u5e94\u5f53\u5728\u5176\u5b83\u4f7f\u7528\u7684\u6587\u4ef6\u91cc\u6807\u8bb0\u4e3aextern\u3002\u4e00\u4e2a\u53d8\u91cf\u53ea\u80fd\u6709\u4e00\u4e2a\u7528\u9014\uff0c\u9664\u975e\u4e3a\u8282\u7701\u5185\u5b58\u7a7a\u95f4\u8003\u8651\u3002</li> </ul>"},{"location":"CS_Notes/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/#_4","title":"\u53c2\u8003\u6587\u732e","text":"<p>\u7f16\u7801\u89c4\u8303\u8bf4\u660e\u6587\u6863_\u7f16\u7801\u89c4\u8303\u6587\u6863_\u67ef\u897f\u6ca1\u79d1\u6c14\u7684\u535a\u5ba2-CSDN\u535a\u5ba2</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","title":"Index","text":"<p>ZJU OS\u64cd\u4f5c\u7cfb\u7edf\u8bfe\u7a0b\u7b14\u8bb0\u3002 \u4f9b\u81ea\u5b66\u800c\u5199\u7684\uff0c\u4e0d\u4fdd\u8bc1\u5199\u5f97\u6613\u61c2\u3002\u56e0\u6b64\u4e0d\u5efa\u8bae\u9605\u8bfb\uff01</p> <p>\u63a8\u8350\u53c2\u8003\u8d44\u6599</p> <p>\u3010\u7b14\u8bb0\u3011RISC-V ISA - \u9e64\u7fd4\u4e07\u91cc\u7684\u7b14\u8bb0\u672c (tonycrane.cc)</p> <p>\u3010\u7b14\u8bb0\u3011Unit 4: \u5b58\u50a8\u7ba1\u7406 | Storage Management [\u672a\u5b8c\u6210] - Isshiki\u4fee's Notebook (isshikih.top)</p> <p>\u3010\u7b14\u8bb0\u30111 \u5199\u5728\u524d\u9762 - \u54b8\u9c7c\u6684\u7684\u4ee3\u7801\u7a7a\u95f4 (xuan-insr.github.io)</p> <p>\u3010\u4e60\u9898\u3011rCore-Tutorial-Book-v3 3.6.0-alpha.1 \u6587\u6863 (rcore-os.cn)</p> <p>\u3010\u6587\u6863\u3011RISC-V\u624b\u518c (riscvbook.com)</p> <p>\u3010\u6587\u6863\u3011makefile\u4ecb\u7ecd \u2014 \u8ddf\u6211\u4e00\u8d77\u5199Makefile 1.0 \u6587\u6863 (seisman.github.io)</p> <p>\u3010\u6587\u6863\u3011riscv-asm-manual/riscv-asm.md at master \u00b7 riscv-non-isa/riscv-asm-manual (github.com)</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/","title":"OS Lecture Overview","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/#_1","title":"\u6210\u7ee9","text":"<ul> <li>\u671f\u672b 50%</li> <li>\u5e73\u65f65% + \u8bfe\u5802\u7ec3\u4e605%</li> <li>\u5b9e\u9a8c\u62a5\u544a20%+\u5b9e\u9a8c\u9a8c\u653620% \u5b9e\u9a8c\u5217\u8868\uff1a \u72ec\u7acb</li> <li>lab0 RV64\u73af\u5883\u719f\u6089 2% 2\u5468</li> <li>lab1 RV64\u7cfb\u7edf\u542f\u52a8\uff1a\u65f6\u949f\u548c\u4e2d\u65ad 6% 2\u5468 \u5408\u4f5c</li> <li>lab2 \u7ebf\u7a0b\u4e0e\u8c03\u5ea6 6% 2\u5468</li> <li>lab3 \u865a\u62df\u5185\u5b58 6% 2\u5468</li> <li>lab4 \u7528\u6237\u7a7a\u95f4 8% 2\u5468</li> <li>lab5 \u7f3a\u9875\u5904\u7406 8% 3\u5468</li> <li>lab6 fork\u673a\u5236 4% 3\u5468</li> <li>lab7 \u6587\u4ef6\u7cfb\u7edf bonus 4%</li> </ul> <p>\u6559\u6750\uff1a\u53ea\u4e0a1-13</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/#1-overview","title":"1. \u64cd\u4f5c\u7cfb\u7edfoverview","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/#11","title":"1.1 \u57fa\u672c\u6982\u5ff5","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/#12","title":"1.2 \u64cd\u4f5c\u7cfb\u7edf\u5386\u53f2/\u7ed3\u6784\u7684\u79cd\u7c7b","text":"<ul> <li>\u6279\u5904\u7406\u7cfb\u7edfbatch processing systems. jobs\u5728\u5185\u5b58\u6216\u8005\u5916\u5b58\u4e2d\u3002\u5185\u5b58\u4e2d\u59cb\u7ec8\u6709\u4e00\u4e2ajob\u5728\u8fd0\u884c\uff0cos\u8d1f\u8d23\u5728\u7ed3\u675f\u540e\u52a0\u8f7d\u4e0b\u4e00\u4e2a\u5f00\u59cb\u8fd0\u884c\uff08\u52a0\u8f7d\u5230\u5185\u5b58\u91cc\u5e76\u8fd0\u884c\u7684\u53eb\u8fdb\u7a0bprocess\uff09</li> <li>\u591a\u9053\u6279\u5904\u7406\u7cfb\u7edfmultiprogramming batch systems\uff0c\u5728\u6279\u5904\u7406\u7cfb\u7edf\u57fa\u7840\u4e0a\uff0c\u5f53\u5f53\u524djob\u53d1\u751fIO\u65f6\uff0c\u64cd\u4f5c\u7cfb\u7edf\u8d1f\u8d23\u8ba9CPU\u8f6c\u800c\u8fd0\u884c\u53e6\u4e00\u4e2ajob\u3002\u591a\u9053\u6279\u5904\u7406\u7cfb\u7edf\u907f\u514d\u4e86\u7b49\u5f85\u7528\u6237IO\u65f6\u7684CPU\u65f6\u95f4\u6d6a\u8d39\uff0c\u4f46\u662f\u4e0d\u591f\u53cb\u597d\uff0c\u5982\u679c\u6ca1\u6709IO\uff0cCPU\u5c31\u53ea\u80fd\u6267\u884c\u4e00\u4e2ajob\u3002</li> <li>\u5206\u65f6\u7cfb\u7edfTime Sharing System\u3002\u5c06CPU\u5212\u5206\u4e3a\u975e\u5e38\u5c0f\u7684\u65f6\u95f4\u7247\uff0cOS\u8d1f\u8d23\u5b89\u6392\u5404\u4e2ajob\u8f6e\u6d41\u8fd0\u884c\u3002\u89e3\u51b3\u4e86\u4e0a\u8ff0\u95ee\u9898\uff1a\u7531\u4e8e\u5207\u6362\u9891\u7387\u5f88\u9ad8\uff0c\u770b\u8d77\u6765\u50cf\u591a\u4e2a\u8fdb\u7a0b\u5728\u540c\u65f6\u8fd0\u884c\u3002\u5206\u65f6\u7cfb\u7edf\u662f\u4e00\u79cd\u591a\u9053\uff08multiprogramming\uff09\u7cfb\u7edf\uff0c\u5141\u8bb8\u591a\u4e2ajob\u5e76\u53d1\uff08concurrently\uff09\u6267\u884c\uff0c\u4f46\u662f\u4e0d\u662f\u6279\u5904\u7406\uff08batch\uff09\u7cfb\u7edf\u3002</li> </ul> <p>\u9664\u4e86kernel\u5916\uff0cOS\u8fd8\u5305\u542b\u4e00\u4e9bsystem programs\u8f85\u52a9kernel\u5de5\u4f5c\u3002\u5176\u5b83\u7a0b\u5e8f\u4e0d\u5c5e\u4e8eOS\uff0c\u88ab\u79f0\u4e3aapplication programs  \u21d2 \u603b\u4e4b\uff0cOS\u662f\u8f6f\u4ef6\u4e2d\u6700\u57fa\u7840\u7684\u90e8\u5206\uff0c\u7528\u4ee5\u63a7\u5236\u548c\u7ba1\u7406\u7cfb\u7edf\u8d44\u6e90\uff0c\u65b9\u4fbf\u7528\u6237\u4f7f\u7528\u8ba1\u7b97\u673a\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/#13","title":"1.3 \u4e2d\u65ad","text":"<p>\u6279\u5904\u7406\u7cfb\u7edf\u662f\u6700\u5bb9\u6613\u7406\u89e3\u7684\uff1a\u6bcf\u4e2a\u7a0b\u5e8f\u50cf\u4e00\u4e2a\u51fd\u6570\u4e00\u6837\u88abOS\u8c03\u7528\u3002</p> <p>\u5176\u5b83\u7cfb\u7edf\uff1a\u7528\u5230\u4e2d\u65ad\uff08interrupt\uff09\u73b0\u4ee3\u64cd\u4f5c\u7cfb\u7edf\u90fd\u662f\u4e2d\u65ad\u9a71\u52a8\u7684</p> <p>CPU\u786c\u4ef6\u6709\u4e00\u6761\u88ab\u79f0\u4e3ainterrupt-request line\u7684\u7ebf\u8def\uff0cCPU\u6bcf\u6267\u884c\u4e00\u6761\u6307\u4ee4\u540e\u90fd\u8981\u68c0\u6d4b\u4e00\u6b21\u3002\u5f53CPU\u4fa6\u6d4b\u5230\u4e00\u4e2a\u8bbe\u5907\u63a7\u5236\u5668\u5728\u8fd9\u6761\u7ebf\u8def\u4e0a\u53d1\u51fa\u7684\u4fe1\u53f7\u65f6\uff0c\u4f1a\u8bfb\u53d6interrupt number\u5e76\u4ee5\u6b64\u4f5c\u4e3ainterrupt vector\u4e2d\u7684index\u6765\u8df3\u8f6c\u5230\u5bf9\u5e94\u7684interrupt-handler routine\u3002</p> <p>\u4e2d\u65ad\u5411\u91cf\u8868\uff08interrupt vector\uff09\u7528\u6765\u51cf\u5c11\u786e\u5b9a\u4e2d\u65ad\u670d\u52a1\u65f6\u7684\u67e5\u627e\u6b21\u6570\uff0c\u5373\u901a\u8fc7\u968f\u673a\u8bbf\u95ee\u800c\u4e0d\u662f\u904d\u5386\u7684\u65b9\u5f0f\u627e\u5230\u5904\u7406\u7a0b\u5e8f\u3002</p> <p>\u5728\u73b0\u4ee3\u64cd\u4f5c\u7cfb\u7edf\u4e0a\uff0c\u9700\u8981\u4e00\u4e9b\u66f4\u590d\u6742\u7684\u4e2d\u65ad\u5904\u7406\u529f\u80fd\uff1a</p> <ol> <li>\u5728\u5173\u952e\u7a0b\u5e8f\u5904\u7406\u671f\u95f4\u5ef6\u8fdf\u4e2d\u65ad\u7684\u5904\u7406</li> <li>\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u5c06\u8bbe\u5907\u4e2d\u65ad\u53d1\u9001\u7ed9\u6b63\u786e\u7684\u4e2d\u65ad\u5904\u7406\u673a\u5236</li> <li>\u9700\u8981\u591a\u7ea7\u4e2d\u65ad\uff0c\u4ece\u800c\u4f7f\u5f97\u64cd\u4f5c\u7cfb\u7edf\u53ef\u4ee5\u533a\u5206\u4e0d\u540c\u4f18\u5148\u7ea7\u7684\u4e2d\u65ad\u5e76\u6839\u636e\u9002\u5f53\u7684\u7d27\u6025\u7a0b\u5ea6\u8fdb\u884c\u54cd\u5e94</li> </ol> <p>\u5728\u73b0\u4ee3\u7684\u8ba1\u7b97\u673a\u786c\u4ef6\u4e2d\uff0c\u8fd9\u4e9b\u7279\u65b0\u7531CPU\u548cinterrupt-controller hardware\u5b9e\u73b0\u3002</p> <p>\u5927\u591a\u6570CPU\u6709\u4e24\u6761interrupt-request line</p> <ul> <li>\u4e00\u6761\u7528\u4e8enonmaskable interrupt\uff0c\u4e3a\u4e0d\u53ef\u6062\u590d\u7684\u5185\u5b58\u9519\u8bef\u4fdd\u7559</li> <li>\u53e6\u4e00\u6761\u662fmaskable\u7684\uff0c\u53ef\u4ee5\u5728\u6267\u884c\u4e0d\u53ef\u6062\u590d\u7684\u4e2d\u65ad\u7684\u5173\u952e\u7a0b\u5e8f\u4e4b\u524d\u88abCPU\u5173\u95ed\uff0c\u7528\u4e8e\u4f20\u9001\u4e00\u4e9b\u8bbe\u5907\u63a7\u5236\u5668\u7684\u4e2d\u65ad\u8bf7\u6c42</li> </ul> <p>\u5728\u8c03\u7528\u51fd\u6570\u65f6\u9700\u8981\u4fdd\u5b58PC\u7b49\u73b0\u573a\u72b6\u6001\uff0c\u6267\u884c\u4e2d\u65ad\u65f6\u4e5f\u8981\u4fdd\u5b58\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4f4e\u7ea7\u4e2d\u65ad\u8981\u88ab\u9ad8\u7ea7\u4e2d\u65ad\u6253\u65ad\uff0c\u4f46\u662f\u4fdd\u5b58\u548c\u56de\u590d\u73b0\u573a\u72b6\u6001\u7684\u8fc7\u7a0b\u4e0d\u5e94\u5f53\u88ab\u6253\u65ad\u3002  \u8ba1\u65f6\u5668\u4e0e\u5206\u65f6\u7cfb\u7edf\u7684\u5b9e\u73b0\uff1a</p> <p>\u5f53\u64cd\u4f5c\u7cfb\u7edf\u5c06CPU\u7684\u63a7\u5236\u6743\u4ea4\u7ed9\u4e00\u4e2a\u7a0b\u5e8f\u524d\uff0c\u4f1a\u8bbe\u5b9a\u597d\u4e00\u4e2a\u8ba1\u65f6\u5668timer\u3002timer\u901a\u8fc7\u4e00\u4e2a\u65f6\u949f\u548c\u4e00\u4e2a\u8ba1\u6570\u5668\u5b9e\u73b0\uff0c\u5f53\u8ba1\u6570\u5668\u7684\u503c\u4e3a0\u65f6\uff0c\u5c31\u4ea7\u751f\u4e00\u4e2a\u4e2d\u65ad\uff0c\u8fd9\u65f6\u63a7\u5236\u6743\u4ea4\u7ed9\u4e86OS\u3002\u53ef\u4ee5\u9632\u6b62\u7a0b\u5e8f\u6267\u884c\u65f6\u95f4\u8fc7\u957f\uff0c\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u5206\u65f6\u7cfb\u7edf\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Lecture_Overview/#14","title":"1.4 \u7528\u6237\u6001\u4e0e\u5185\u6838\u6001\uff0c\u7cfb\u7edf\u8c03\u7528","text":"<p>Dual-mode &amp; multimode</p> <p>OS\u548c\u7528\u6237\u5171\u4eab\u8ba1\u7b97\u673a\u7684\u786c\u4ef6\u548c\u8f6f\u4ef6\u3002\u56e0\u6b64\uff0c\u4e00\u4e2a\u9519\u8bef\u7684\u7a0b\u5e8f\u53ef\u80fd\u5bfc\u81f4\u6574\u4e2a\u7cfb\u7edf\u5d29\u6e83\uff0c\u6216\u8005\u4f7f\u5f97\u5176\u5b83\u7528\u6237\u7684\u6570\u636e\u751a\u81f3OS\u672c\u8eab\u88ab\u4fee\u6539\u3002\u56e0\u6b64OS\u7684\u8bbe\u8ba1\u8981\u4fdd\u8bc1\u4e00\u4e2a\u9519\u8bef\u7684\u7a0b\u5e8f\u4e0d\u4f1a\u9020\u6210\u5176\u5b83\u7a0b\u5e8f\u7684\u9519\u8bef\u8fd0\u884c\u3002</p> <p>\u7cfb\u7edf\u4ee3\u7801\u80fd\u8fd0\u884c\u7684\u6307\u4ee4\uff1aprivileged instructions</p> <p>CPU\u6709\u4e00\u4e2amode bit\uff0c\u503c\u4e3a0\uff0c\u8868\u793a\u5f53\u524d\u5904\u4e8ekernel mode\uff08supervisor/system/privileged mode\uff09\uff0c\u503c\u4e3a1\u8868\u793a\u5904\u4e8euser mode\u3002\u6240\u6709\u7684interrupt handler\u90fd\u8fd0\u884c\u5728kernel mode\u3002</p> <p>\u5982\u679c\u7528\u6237\u771f\u7684\u60f3\u6267\u884c\u7279\u6743\u6307\u4ee4\uff0c\u53ef\u4ee5\u7528system call\uff0c\u7531OS\u4ee3\u4e3a\u5b8c\u6210\u3002 </p> <p>OS\u80fd\u591f\u6267\u884c\u7684system call:</p> <p>Process control - create process, terminate process - load, execute - get process attributes, set process attributes - wait event, signal event - allocate and free memory</p> <p>File management - create file, delete file - open, close - read, write, reposition - get file attribute, set file attribute</p> <p>Device management - request device, release device - read, write, reposition - get file attributes, set device attributes - logically attach or detach devices</p> <p>Information maintenance - get time or date, set time or date - get system data, set system data - get process, file, or device attributes - set process, file, or device attributes</p> <p>Communications - create, delete communication connection - send, receive messages - transfer status information - attach or detach remote devices</p> <p>Protection - get file permissions - set file permissions</p> <p>\u56e0\u6b64\u5f53\u53d1\u751f\u4e2d\u65ad\u3001system call\u3001\u9519\u8bef\uff08\u9664\u4ee50\uff0c\u6216\u8bbf\u95ee\u672a\u77e5\u6307\u4ee4\uff09\u7b49\u60c5\u51b5\u65f6\uff0c\u4f1a\u53d1\u751fuser mode\u5230</p> <p>kernel mode\u7684\u8f6c\u6362</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"OS Lecture \u5185\u5b58/\u5b58\u50a8/\u6587\u4ef6\u7cfb\u7edf","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#8","title":"8. \u4e3b\u5b58","text":"<p>\u5e38\u8bc6\uff1a</p> <p>\u5185\u5b58\u662f\u4e00\u4e2a\u5f88\u5927\u7684\u5b57\u8282\u6570\u7ec4\uff0cCPU\u6839\u636ePC(Program Counter)\u7684\u503c\u4ece\u5185\u5b58\u4e2d\u63d0\u53d6\u6307\u4ee4\u3002\u5185\u5b58\u4e2d\u7684\u8fdb\u7a0b\u8fd0\u884c\u7684\u524d\u63d0\u662f\uff0c\u7a0b\u5e8f\u4ee3\u7801\u548c\u9700\u8981\u8bbf\u95ee\u7684\u6570\u636e\u5728\u5185\u5b58\u4e2d\u3002</p> <p>CPU\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee\u7684\u901a\u7528\u5b58\u50a8\u53ea\u6709main memory\u548cregisters\u3002\u5bf9registers\u7684\u8bbf\u95ee\u901a\u5e38\u53ef\u4ee5\u5728\u4e00\u4e2aCPU\u65f6\u949f\u5468\u671f\u5b8c\u6210\uff0c\u4f46\u662f\u8bbf\u95ee\u5185\u5b58\u9700\u8981\u591a\u4e2a\u65f6\u949f\u5468\u671f\uff0c\u8fd9\u5c31\u4f1a\u5f15\u8d77\u6307\u4ee4\u7684stall\u3002\u56e0\u4e3a\u6211\u4eec\u4e0d\u60f3\u8981stall\uff0c\u6240\u4ee5\u6211\u4eec\u5728CPU\u4e0a\u8bbe\u8ba1\u4e86\u5b58\u53d6\u66f4\u5feb\u7684\u5185\u5b58cache\u3002</p> <p>\u8868\u793a\u6e90\u7a0b\u5e8f\u5730\u5740\u7684\u65b9\u6cd5\uff1aAddress Binding</p> <p>\u6e90\u7a0b\u5e8f\u4e2d\u7684\u5730\u5740\u901a\u5e38\u662f\u7528\u7b26\u53f7\uff08symbolic\uff0c\u4f8b\u5982\u5404\u79cd\u53d8\u91cf\u3001\u51fd\u6570\u540d\u3001\u6c47\u7f16\u4e2d\u7684label\u7b49\uff09\u8868\u793a\u3002\u7f16\u8bd1\u5668\u4f1a\u5c06\u7b26\u53f7\u7ed1\u5230relocatable addresses\uff08\u6bb5\u540d+\u504f\u79fb\u91cf\uff09\u3002\u94fe\u63a5\u5668\u6216\u52a0\u8f7d\u5668\uff08linker/loader\uff09\u4f1a\u5c06relocatable addresses\u7ed1\u5b9a\u5230absolute addresses\u3002\u5f53\u7136\uff0c\u5982\u679c\u7f16\u8bd1\u5668\u5728\u7f16\u8bd1\u65f6\u5c31\u77e5\u9053\u7a0b\u5e8f\u6240\u5904\u7684\u5185\u5b58\u5730\u5740\uff0c\u5219\u4f1a\u751f\u6210absolute code\u3002 </p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#81-partitioning-strategies","title":"8.1 Partitioning Strategies","text":"<p>\u5728Batch\u7cfb\u7edf\u4e2d\uff0c\u6bcf\u6b21\u53ea\u6709\u4e00\u4e2a\u7a0b\u5e8f\u88ab\u52a0\u8f7d\u5165\u7269\u7406\u5185\u5b58\uff0c\u5e76\u8fd0\u884c\u81f3\u7ed3\u675f\u3002\u5982\u679c\u7a0b\u5e8f\u9700\u8981\u7684\u5b58\u50a8\u7a7a\u95f4\u6bd4\u5185\u5b58\u5927\uff0c\u5219\u5c06\u7a0b\u5e8f\u4e00\u5757\u4e00\u5757\u5207\u5f00</p> <p>\u4e0eprehistory\u4e0d\u540c\u7684\u662f\uff0c\u73b0\u5728\u9700\u8981\u628a\u591a\u4e2a\u8fdb\u7a0b\u540c\u65f6\u653e\u5165\uff0c\u5e76\u4e14\u652f\u6301\u5feb\u901f\u5207\u6362\u3002\u6700\u7b80\u5355\u7684\u5185\u5b58\u5206\u914d\u65b9\u6cd5\u662f\u5c06\u5185\u5b58\u5207\u6210partition\uff0c\u6bcf\u4e00\u4e2a\u5305\u542b\u4e00\u5757\u8fdb\u7a0b\u3002\u5207\u5206\u7684\u8981\u6c42\u6709</p> <ul> <li>Protection: \u4fdd\u8bc1\u8fdb\u7a0b\u95f4\u4e0d\u4f1a\u4e92\u76f8\u95ef\u5165\u5bf9\u65b9\u7684\u5b58\u50a8</li> <li>Fast execution: \u4e0d\u80fd\u7531\u4e8eprotection\u964d\u4f4e\u8bbf\u95ee\u5185\u5b58\u7684\u6548\u7387</li> <li>Fast context switch: \u6bcf\u5f53\u8fdb\u884ccontext switch\u65f6\uff0c\u53ef\u4ee5\u6bd4\u8f83\u5feb\u5730\u627e\u5230\u5e76\u8bbf\u95ee\u5f53\u524d\u8fdb\u7a0b\u7684\u5185\u5b58</li> </ul> <p>\u5982\u679c\u8fdb\u7a0b\u8bf7\u6c42\u7a7a\u95f4\u6765\u8fd0\u884c\uff0c\u4f46\u6ca1\u6709\u8db3\u591f\u7684\u5185\u5b58\uff0c\u53ef\u4ee5</p> <ul> <li>\u76f4\u63a5\u62d2\u7edd\u8bf7\u6c42\uff0c\u5e76\u7ed9\u51fa\u4e00\u4e2a\u9519\u8bef\u4fe1\u606f</li> <li>\u52a0\u5165waiting queue\u4e2d\uff0c\u5f53\u6709\u5185\u5b58\u88ab\u91ca\u653e\u7684\u65f6\u5019CPU\u6765\u68c0\u67e5\u662f\u5426\u53ef\u4ee5\u4e3a\u5176\u5206\u914d\u5185\u5b58\u3002</li> </ul> <p>Fixed Partition\uff1a\u56fa\u5b9apartition\u7684\u5927\u5c0f\u3002\u4f46\u662f\u53ef\u80fd\u9020\u6210\u6d6a\u8d39</p> <p>Variable Partition\uff1a\u4e0d\u56fa\u5b9apartition\u7684\u5927\u5c0f\u3002OS\u4f1a\u7ef4\u62a4\u4e00\u4e2a\u8868\u8bb0\u5f55\u53ef\u7528\u548c\u5df2\u7528\u7684\u5185\u5b58\u3002\u5b83\u7684\u7f3a\u70b9\u662f\uff1a\u6700\u5f00\u59cb\u5185\u5b58\u662f\u6574\u4e00\u4e2a\u5f88\u5927\u7684\u5185\u5b58\uff08hole\uff09\uff0c\u7ecf\u8fc7\u4e00\u6bb5\u65f6\u95f4\u8fd0\u884c\u540e\uff0c\u51fa\u73b0\u4e00\u7cfb\u5217\u5927\u5c0f\u4e0d\u7b49\u7684\u5b54\uff0c\u8fd9\u4e9b\u5c0f\u7684\u5b54\u90fd\u4e0d\u80fd\u88ab\u5229\u7528\u3002\u79f0\u4e3aexternal fragmentation\u3002</p> <p>Dynamic Storage-Allocation Problem\uff1a\u6839\u636e\u4e00\u7ec4hole\u6765\u5206\u914d\u5927\u5c0f\u4e3an\u7684\u8bf7\u6c42\uff0c\u79f0\u4e3adynamic storage-allocation problem. </p> <ul> <li>first-fit\uff1a\u5206\u914d\u9996\u4e2a\u8db3\u591f\u5927\u7684hole\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u4f7f\u5f97\u5206\u914d\u96c6\u4e2d\u5728\u4f4e\u5730\u5740\u533a\uff0c\u4f7f\u4f4e\u5730\u5740\u533a\u5148\u4ea7\u751f\u5927\u91cf\u788e\u7247\uff0c\u7136\u540e\u5728\u6bcf\u6b21\u91cd\u65b0\u5206\u914d\u65f6\u53c8\u4ece\u4f4e\u5730\u5740\u533a\u5148\u5f00\u59cb\u5206\u914d\uff0c\u67e5\u627e\u5f00\u9500\u6bd4\u8f83\u5927\u3002</li> <li>best-fit\uff1a\u5206\u914d\u6700\u5c0f\u7684\u8db3\u591f\u5927\u7684hole\u3002\u904d\u5386\u6bd4\u524d\u8005\u6162\uff0c\u4e14\u7559\u4e0b\u788e\u7247\u7684\u53ef\u80fd\u6027\u4e5f\u5f88\u5927\u3002</li> <li>worst-fit\uff1a\u5206\u914d\u6700\u5927\u7684hole\uff0c\u4e5f\u9700\u8981\u5168\u90e8\u904d\u5386\u3002</li> </ul> <p>worst-fit\u5bf9\u4e2d\u5c0f\u8fdb\u7a0b\u8f83\u591a\u7684\u60c5\u51b5\u6709\u7528\uff0c\u56e0\u4e3a\u4f7f\u5f97\u5269\u4e0b\u7684\u7a7a\u95f2\u5757\u6bd4\u8f83\u5927\u3002\u4f46\u662f\u5e73\u5747\u60c5\u51b5\u4e0bfirst-fit\u548cbest-fit\u66f4\u597d\u4e00\u70b9\uff0c\u5176\u4e2dfirst-fit\u66f4\u5feb\uff0c\u5176\u5b83\u6ca1\u6709\u4e0ebest-fit\u6709\u660e\u663e\u5dee\u522b\u3002</p> <p>Protection</p> <p>\u4fdd\u8bc1\u4e00\u4e2a\u8fdb\u7a0b\u53ea\u80fd\u4f7f\u7528\u81ea\u5df1\u7684\u5185\u5b58\uff1a\u4f7f\u7528\u4e24\u4e2a\u5bc4\u5b58\u5668\uff0c\u4e00\u4e2abase\uff0c\u4e00\u4e2alimit\uff0c\u5206\u522b\u8868\u793a\u57fa\u5740\u548c\u504f\u79fb\u91cf\u3002\u5f53context switch\u5230\u4e00\u4e2a\u65b0\u7684\u8fdb\u7a0b or user mode\u60f3\u8981\u8fdb\u884c\u5185\u5b58\u8bbf\u95ee\uff0cCPU\u5c31\u4f1aload\u8fd9\u4e24\u4e2a\u5bc4\u5b58\u5668\u7684\u503c\u3002\u5982\u679c\u975e\u6cd5\u4e86\uff0c\u5c31trap\u6389\uff08\u901a\u5e38\u662fterminate\u8be5\u8fdb\u7a0b\uff09\u3002</p> <p>\u89e3\u51b3external fragmentation\u6709\u4e24\u4e2a\u601d\u8def\uff1a</p> <ul> <li>\u4f7f\u7a0b\u5e8f\u4e0d\u9700\u8981\u90a3\u4e48\u5927\u5757\u7684\u5185\u5b58\uff0c\u800c\u662f\u591a\u4e2a\u5c0f\u5185\u5b58\u4e5f\u53ef\u4ee5 \u2192 segmentation, paging</li> <li>\u4f7f\u591a\u4e2a\u5c0f\u7684\u5185\u5b58\u788e\u7247hole\u53d8\u6210\u4e00\u4e2a\u5927\u7684 \u2192 Compaction \u91cd\u6392</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#82-segmentation","title":"8.2 \u5206\u6bb5 Segmentation","text":"<p>\u4e00\u4e2a\u7a0b\u5e8f\u7531\u4e00\u7ec4\u6bb5(unordered set of)\u7ec4\u6210</p> <ul> <li>\u4e3b\u51fd\u6570</li> <li>\u6570\u7ec4</li> <li>\u7b26\u53f7\u8868</li> <li>\u5b50\u51fd\u6570</li> </ul> <p>\u6bcf\u4e2a\u90fd\u662f\u4e00\u4e2a\u6bb5\uff0c\u5728\u5185\u5b58\u4e2d\u4e0d\u4e00\u5b9a\u662f\u6309\u7167\u7528\u6237\u5199\u7684\u987a\u5e8f\u6392\u5217\u7684\uff0c\u987a\u5e8f\u5f88\u968f\u673a\u3002\u8fd9\u4e2a\u987a\u5e8f\u662f\u7f16\u8bd1\u5668\u6784\u5efa\u7684\u3002\u6240\u4ee5\u6211\u4eec\u9700\u8981\u7528\u4e00\u7ec4\u903b\u8f91\u5730\u5740(logical address)\u6216\u8005\u53eb\u865a\u62df\u5730\u5740(virtual address)\u6765\u8bbf\u95ee\u3002</p> <p>\u903b\u8f91\u5730\u5740 = \u57fa\u5730\u5740 + \u6bb5\u754c</p> <p>\u6211\u4eec\u6709\u4e00\u4e2asegment table\uff0c\u6bcf\u4e2a\u6761\u76ee\u4ee5segment-number\u7d22\u5f15\uff0c\u5b58\u50a8base\u548climit\uff08\u4e5f\u53ef\u80fd\u8fd8\u5305\u62ec\u6743\u9650\u4f4d\uff09\u3002</p> <p>\u903b\u8f91\u5730\u5740\u7684\u6620\u5c04\u65b9\u5f0f\u5982\u4e0b\u56fe  \u4ece\u903b\u8f91\u5730\u5740\u6620\u5c04\u5230\u7269\u7406\u5730\u5740\u7684\u8fd9\u4e00\u8fc7\u7a0b\u662f\u7531\u786c\u4ef6\u8bbe\u5907MMU\uff08memory-management unit\uff0c\u5185\u5b58\u7ba1\u7406\u5355\u5143\u5b8c\u6210\u7684\uff09\u3002CPU\u4f7f\u7528\u903b\u8f91\u5730\u5740\uff0c\u800c\u5bfb\u5740\u7684\u65f6\u5019\u5c31\u8981\u7528\u7269\u7406\u5730\u5740\u4e86\u3002  \u5206\u6bb5\u662f\u89e3\u51b3external fragmentation\u7684\u4e00\u79cd\u5c1d\u8bd5\uff0c\u56e0\u4e3a\u5b83\u628a\u7a0b\u5e8f\u5206\u6210\u4e86\u5f88\u591a\u6bb5\u3002</p> <p>\u8fd9\u79cd\u65b9\u6cd5\u597d\u50cf\u4e5f\u88ab\u53eb\u505a\u6742\u5408\u65b9\u6cd5\uff0c\u56e0\u4e3a\u4e0d\u662f\u4e3a\u6574\u4e2a\u5185\u5b58\u7a7a\u95f4\u63d0\u4f9b\u9875\u8868\uff0c\u800c\u662f\u4e3a\u6bcf\u4e2a\u903b\u8f91\u5206\u6bb5\u63d0\u4f9b\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#83-paging","title":"8.3 \u5206\u9875 Paging","text":"<p>\uff08\u8fd9\u4e2a\u5730\u65b9\u6211\u771f\u7684\u771f\u7684\u6ca1\u770b\u61c2\uff0c\u53ef\u4ee5\u7559\u7740\u505alab\u518d\u770b\uff1a\u634f\u5417\u4eca\u5929lab\u5c31\u662f\u8fd9\u4e2a\u73a9\u610f\uff09</p> <p>\u5141\u8bb8\u8fdb\u7a0b\u7684\u7269\u7406\u5730\u5740\u7a7a\u95f4\u4e0d\u8fde\u7eed\u7684\u5185\u5b58\u7ba1\u7406\u65b9\u6848\u3002</p> <p>\u6211\u4eec\u5c06physical memory\u5207\u6210\u7b49\u5927\u7684\u5757\uff082\u7684\u5e42\uff0c\u901a\u5e38\u4e3a4KB = 2^12 B\uff09\uff0c\u79f0\u4e3aframes\uff08\u5e27\uff09\u3002</p> <p>\u5c06logical memory\u5207\u6210\u540c\u6837\u5927\u5c0f\u7684\u5757\uff0c\u79f0\u4e3apages\uff08\u9875\uff09\u3002</p> <p>\u5728paging\u4e2d\u5bf9\u5e94\u5173\u7cfb\u6709\uff1a</p> <ul> <li>\u6bcf\u4e2a\u7269\u7406\u5185\u5b58\u4e2d\u7684frame\u7b49\u8ddd\u5bf9\u5e94\u4e00\u4e2a\u903b\u8f91\u5730\u5740\u4e2d\u7684page</li> <li>\u6bcf\u4e2aframe base\u4e0d\u7b49\u8ddd\u5bf9\u5e94\u4e00\u4e2aframe number\uff0c\u662fframe\u5f00\u59cb\u7684\u5730\u5740\uff0cnumber\u53ef\u4e58frame\u5927\u5c0f\u6362\u7b97base</li> <li>\u6bcf\u4e2apage base\u4e0d\u7b49\u8ddd\u5bf9\u5e94\u4e00\u4e2apage number\uff0c\u662fpage\u5f00\u59cb\u7684\u5730\u5740\uff0cnumber\u53ef\u4e58page\u5927\u5c0f\u6362\u7b97base</li> <li>\u6bcf\u4e2apage number\u6620\u5c04\u4e00\u4e2aframe base\uff08\u8be5\u6620\u5c04\u5173\u7cfb\u653e\u5728\u4e86page table\u4e2d\uff09</li> <li>\u6bcf\u4e2apage base+offset\u6620\u5c04\u4e00\u4e2aframe base+offset\uff0c\u4e24\u4e2aoffset\u662f\u4e00\u6837\u7684</li> </ul> <p>MMU\u628alogical address\u7ffb\u8bd1\u6210physical address\u7684\u6b65\u9aa4\uff1a</p> <ul> <li>\u83b7\u53d6page number p</li> <li>\u5728page table\u627e\u5230\u7b2cp\u4e2apage\u5bf9\u5e94\u7684frame number</li> <li>frame number\u6362\u7b97frame base\uff0c\u5e76\u52a0\u4e0aoffset\uff0c\u627e\u5230physical address  \u6bd4\u5982logical addr\u662f1101[13]\uff0c\u5148\u53d6page number 11[3]\uff0c\u67e5\u627e\u9875\u8868\u6bd4\u5982\u5f97\u5230frame number 010[2]\uff08frame\u7684\u4f4d\u6570\u4e0d\u4e00\u5b9a\u8ddfpage\u4f4d\u6570\u4e00\u6837\uff09\uff0c\u90a3\u4e48\u4e0eoffset\u62fc\u8d77\u6765\uff0c\u5c31\u5f97\u5230\u4e86\u5b9e\u9645\u5730\u574001001[9]\u3002  \u8fd8\u6709\u4e00\u4e2aframe table\uff0c\u7528\u6765\u4fdd\u5b58\u7269\u7406\u5185\u5b58\u7684\u5206\u914d\u7ec6\u8282\uff0c\u5373\u5171\u6709\u591a\u5c11\u5e27\u3001\u5e27\u662f\u5426\u7a7a\u95f2\u7b49\u3002\u6bcf\u4e2a\u6761\u76ee\u5bf9\u5e94\u4e00\u4e2a\u5e27\uff0c\u662f\u5426\u88ab\u5360\u7528\uff0c\u5982\u679c\u88ab\u5360\u7528\uff0c\u662f\u54ea\u4e2a\u8fdb\u7a0b\u7684\u54ea\u4e2a\u9875\u5360\u7528\u7684\u3002</li> </ul> <p>\u4e3a\u4ec0\u4e48paging\u80fd\u6ee1\u8db3not contiguous\u5462\uff1f\u56e0\u4e3a\u6211\u4eec\u5728PC+1\u6307\u5411\u4e0b\u4e00\u6761\u6307\u4ee4\u65f6\uff0c\u53ea\u8981\u5728logical addr\u4e2d\u662f\u4e0b\u4e00\u6761\u6307\u4ee4\u5c31\u53ef\u4ee5\uff0c\u65e0\u6240\u8c13\u8fd9\u4e2alogical addr\u5bf9\u5e94\u7684physical addr\u5728\u54ea\u91cc\u3002\u6211\u4eec\u518d\u56de\u5fc6\u4e00\u4e0blogical addr\u7684\u683c\u5f0f\u5982\u4e0b  \u53ef\u89c1d\u662f2^n+1\u65f6 +1 \u662f <p>\uff08\u5c31\u662f\u4e8c\u8fdb\u5236\u8fdb\u4e86\u4f4d\uff09\u3002\u8fd9\u65f6\u4e00\u4e2apage\u7ed3\u675f\uff0c\u8fdb\u5165\u4e86\u4e0b\u4e00\u4e2apage\u3002logical addr\u4ecd\u7136\u662f\u8fde\u7eed\u7684\u3002</p> <p>\u786c\u4ef6\u652f\u6301 Hardware Support\uff1apage table\u7684\u786c\u4ef6\u5b9e\u73b0\u6709\u5f88\u591a\u65b9\u6cd5</p> <ul> <li>Register Method<ul> <li>\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u7528\u4e00\u7ec4\u5bc4\u5b58\u5668\u5b58\uff0c\u4f7f\u7528\u65f6\u975e\u5e38\u8fc5\u901f\uff0c\u56e0\u4e3a\u8bbf\u95ee\u5bc4\u5b58\u5668\u975e\u5e38\u9ad8\u6548\u3002\u7f3a\u70b9\u662f\u5bc4\u5b58\u5668\u6570\u91cf\u6709\u9650\uff0cpage table\u5927\u5c0f\u5f88\u5c0f\u65f6\u624d\u80fd\u7528\u3002\u4e14\u56e0\u4e3a\u8fd9\u662f\u6bcf\u4e2a\u8fdb\u7a0b\u5bf9\u5e94\u7684\u7269\u7406\u5185\u5b58\u5730\u5740\uff0c\u6240\u4ee5context switch\u7684\u65f6\u5019\u8fd9\u4e9b\u5bc4\u5b58\u5668\u90fd\u8981\u91cd\u65b0\u52a0\u8f7d\u6210\u522b\u7684\u8fdb\u7a0b\u7684\u3002</li> </ul> </li> <li>Page table in Memory &amp; Page-table Base Register (PTBR)<ul> <li>\u628a\u9875\u8868\u653e\u5728\u5185\u5b58\u4e2d\uff0c\u5e76\u7528PTBR\u6307\u5411\u9875\u8868\u3002\u5728context switch\u7684\u65f6\u5019\u53ea\u9700\u8981\u4fee\u6539PTBR\u3002\u8fd9\u6837\u6bcf\u6b21\u8bbf\u95ee\u7269\u7406\u5730\u5740\u90fd\u9700\u8981\u4e24\u6b21\u5185\u5b58\u8bbf\u95ee\uff1a\u4e00\u6b21\u7528PTBR\u548cpage number\u627e\u5230\u9875\u8868\u5728\u5185\u5b58\u7684\u4f4d\u7f6e\uff0c\u5e76\u5728\u5176\u4e2d\u5f97\u5230page\u5bf9\u5e94\u7684frame number\uff1b\u4e00\u6b21\u7b97\u51faphysical addr\u540e\u8bbf\u95ee\u3002</li> </ul> </li> <li> <p>Translation look-aside buffer (TLB)</p> <ul> <li>\u7528\u8fd9\u6837\u4e00\u4e2a\u4e13\u7528\u7684\u9ad8\u901f\u67e5\u627e\u786c\u4ef6cache\uff08associative memory\uff0c\u652f\u6301parallel search\uff09\u3002TLB\u7684\u6bcf\u4e2a\u6761\u76ee\u7531key&amp;value\u7ec4\u6210\uff0c\u5206\u522b\u8868\u793apage number\u548cframe number\uff0c\u901a\u5e38\u670964-1024\u4e2a\u6761\u76ee\u3002\u5f53\u9700\u8981\u627epage number\u5bf9\u5e94\u7684frame number\u65f6\uff0cTLB\u540c\u65f6\u5bf9\u6240\u6709key\u6bd4\u8f83\uff0cmiss\u5219\u8bbf\u95ee\u5185\u5b58\u3002</li> </ul> <p> \ud83d\udca1 TLB\u548c\u4e00\u822c\u7684cache\u4ec0\u4e48\u533a\u522b\uff1a <p>TLB\u7528\u4e8e\u5b58\u50a8\u865a\u62df\u5730\u5740\u548c\u7269\u7406\u5730\u5740\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5b83\u662fpage table\uff08\u5185\u5b58\u5b50\u96c6\uff09\u7684\u4e00\u4e2acache\u3002</p> <p>cache\u5b58\u50a8\u6700\u8fd1\u4f7f\u7528\u8fc7\u7684\u6570\u636e\u3002\u5b83\u662f\u6574\u4e2a\u5185\u5b58\u7684cache\u3002</p> <p>\u6362\u9875\u7684\u7b56\u7565\u6709\uff1aLRU\uff0cround-robin\uff0crandom\u7b49\u3002 </p> <p>TLB with Address-Space Identifier (ASID)</p> <ul> <li>\u6bcf\u4e2aprocess\u90fd\u6709\u81ea\u5df1\u7684page table\u3002\u6709\u7684\u7cfb\u7edf\u4f1a\u5728TLB\u4e2d\u653e\u4e00\u4e2aASID\uff0c\u552f\u4e00\u6807\u5fd7\u4e00\u4e2a\u8fdb\u7a0b\u3002</li> </ul> <p>Effective Memory-access Time</p> <p>hit ratio = \u6ca1\u6709\u53d1\u751fTLB miss\u7684\u6b21\u6570\u7684\u767e\u5206\u6bd4</p> <p>\u6bcf\u4e00\u6b21\u5185\u5b58\u8bbf\u95ee\u7684\u7528\u65f6\u4e3at\uff0c\u90a3\u4e48TLB hit\u7684\u60c5\u51b5\u4e0b\u8bbf\u95ee\u5b57\u8282\u603b\u5171\u7528\u65f6r\uff0cmiss \u7528\u65f62r</p> <p>\u6709\u6548\u5185\u5b58\u8bbf\u95ee\u65f6\u95f4effective memory-access time EAT = tr + 2t(1-r) = t(2-r)</p> <p>\u76f8\u6bd4\u76f4\u63a5\u5c06page table\u4fdd\u5b58\u5728\u5bc4\u5b58\u5668\uff0c\u5e73\u5747\uff08\uff1f\uff09\u5185\u5b58\u8bbf\u95ee\u65f6\u95f4\u591a\u4e86 [t(2-r)-t]/t = 1-r\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#lab3","title":"\u591a\u7ea7\u9875\u8868\uff08lab3\u7528\u5230\u7684\uff09","text":"<p>\u53e6\u4e00\u79cd\u4e0d\u4f9d\u8d56\u4e8e\u5206\u6bb5\uff0c\u4f46\u4e5f\u80fd\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u6cd5\uff1a\u8bd5\u56fe\u53bb\u6389\u9875\u8868\u4e2d\u6240\u6709\u65e0\u6548\u533a\u57df\uff0c\u800c\u4e0d\u662f\u5c06\u5b83\u4eec\u5168\u90e8\u4fdd\u5b58\u5728\u5185\u5b58\u4e2d\u3002</p> <p>\u79f0\u4e3a\u591a\u7ea7\u9875\u8868\uff0c\u5c06\u7ebf\u6027\u8868\u53d8\u6210\u4e86\u7c7b\u4f3c\u6811\u7684\u4e1c\u897f\u3002</p> <p>\u9996\u5148\u5c06\u9875\u8868\u5206\u6210\u9875\u5927\u5c0f\u7684\u5355\u5143\uff0c\u5982\u679c\u6574\u9875\u7684\u9875\u8868\u9879PTE(page table entry, \u9875\u8868\u6761\u76ee)\u65e0\u6548\uff0c\u5c31\u5b8c\u5168\u4e0d\u5206\u914d\u8be5\u9875\u7684\u9875\u8868\u3002\u4e3a\u4e86\u8ffd\u8e2a\u9875\u8868\u7684\u9875\u662f\u5426\u6709\u6548\uff08\u5982\u679c\u6709\u6548\uff0c\u5728\u5185\u5b58\u4e2d\u7684\u4f4d\u7f6e\uff09\uff0c\u4f7f\u7528\u540d\u4e3a\u9875\u76ee\u5f55\u7684\u65b0\u7ed3\u6784\u3002\u9875\u76ee\u5f55\u544a\u8bc9\u9875\u8868\u7684\u9875\u5728\u54ea\u91cc\uff0c\u6216\u8005\u9875\u8868\u7684\u6574\u4e2a\u9875\u4e0d\u5305\u542b\u6709\u6548\u9875\u3002</p> <p>\u4f8b\u5b50\uff1a</p> <p>\u4e0b\u56fe\u4e2d\uff0c\u5de6\u8fb9\u662f\u4e00\u7ea7\u9875\u8868\uff0c\u5c3d\u7ba1\u7b2c\u4e8c\u4e09\u9875\u6ca1\u6709\u6709\u6548\u5730\u5740\uff0c\u4f46\u662f\u4ecd\u7136\u8981\u5206\u914d\u5185\u5b58\u3002</p> <p>\u53f3\u8fb9\u662f\u4e8c\u7ea7\u9875\u8868\uff0c\u53ef\u4ee5\u770b\u5230\u9875\u8868\u76ee\u5f55\u4ec5\u4e3a\u7b2c\u4e00\u548c\u6700\u540e\u4e00\u9875\u5206\u914d\u5185\u5b58\uff0c\u91ca\u653e\u4e86\u4e2d\u95f4\u7684\u5185\u5b58\u7a7a\u95f4\u3002  \u4e0ePTE\u76f8\u4f3c\uff0c\u9875\u8868\u76ee\u5f55\u6709\u4e2aPDE\uff08\u8868\u793a\u6574\u4e2a\u9875\u8868\u91cc\u7684PTE\u7684\u6216\uff09</p> <p>\u4f18\u70b9</p> <ul> <li>\u591a\u7ea7\u9875\u8868\u5206\u914d\u7684\u9875\u8868\u7a7a\u95f4\uff0c\u4e0e\u6b63\u5728\u4f7f\u7528\u7684\u5730\u5740\u7a7a\u95f4\u5185\u5b58\u91cf\u6210\u6bd4\u4f8b\u3002\u56e0\u6b64\u901a\u5e38\u5f88\u7d27\u51d1\uff0c\u5e76\u652f\u6301\u7a00\u758f\u7684\u5730\u5740\u7a7a\u95f4\u3002</li> <li>\u5982\u679c\u4ed4\u7ec6\u6784\u5efa\uff0c\u9875\u8868\u7684\u6bcf\u4e00\u4e2a\u90e8\u5206\u90fd\u80fd\u6574\u9f50\u5730\u653e\u5165\u4e00\u9875\u4e2d\uff0c\u4ece\u800c\u66f4\u5bb9\u6613\u7ba1\u7406\u5185\u5b58\u3002</li> <li>\u5bf9\u4e8e\u4e00\u4e2a\u5927\u7684\u9875\u8868\uff0c\u53ef\u4ee5\u585e\u8fdb\u96f6\u6563\u7684\u7a7a\u95f4\u91cc</li> </ul> <p>\u7f3a\u70b9</p> <ul> <li>TLB(translation look-aside buffer)\u672a\u547d\u4e2d\u65f6\uff0c\u9700\u8981\u4ece\u5185\u5b58\u91cc\u52a0\u8f7d\u4e24\u6b21\u624d\u80fd\u83b7\u5f97\u6b63\u786e\u7684\u5730\u5740\u8f6c\u6362\u4fe1\u606f\uff08\u4e00\u6b21\u7528\u4e8e\u9875\u76ee\u5f55\uff0c\u4e00\u6b21\u7528\u4e8ePTE\u672c\u8eab\uff09\u3002\u66f4\u591a\u7ea7\u9875\u8868\u9700\u8981\u66f4\u591a\u6b21\u52a0\u8f7d</li> </ul>  \ud83d\udca1 \u21d2 \u65f6\u7a7a\u6298\u4e2d  \u597d\u7684\u7cfb\u7edf\u6784\u5efa\u8005\u6240\u505a\u7684\u662f\uff1a\u5b9e\u73b0\u6700\u5c0f\u590d\u6742\u6027\u7684\u7cfb\u7edf\u6765\u5b8c\u6210\u624b\u4e0a\u7684\u4efb\u52a1\u3002"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#84-swapping","title":"8.4 \u4ea4\u6362 Swapping","text":"<p>\u6211\u4eec\u8ba8\u8bba\u4e00\u79cd\u5185\u5b58\u4e0d\u591f\u65f6\uff0c\u6b63\u5728\u8fd0\u884c\u7684\u8fdb\u7a0b\u7684\u7684\u4e00\u90e8\u5206\u53ef\u4ee5\u4e0d\u5728\u5185\u5b58\u91cc\uff0c\u800c\u662f\u88ab\u4ea4\u6362\u5230\u4e00\u4e2a\u5907\u4efd\u5b58\u50a8\uff08backing store\u4e2d\uff09\uff0c\u76f4\u5230\u7ee7\u7eed\u8fd0\u884c\u7684\u65f6\u5019\u518d\u62ff\u56de\u5230\u5185\u5b58\u3002\u8fd9\u79cd\u601d\u60f3\u5f88\u50cfvirtual memory\u3002</p> <p>\u6bd4\u5982\u5728paging\u673a\u5236\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u53easwap out\u4e00\u4e9bpages\u3002  swapping\u4f1a\u589e\u5927context switching\u7684\u65f6\u95f4\u5f00\u9500\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#9","title":"9. \u865a\u62df\u5185\u5b58","text":"<p>\u4e3a\u4ec0\u4e48\u9700\u8981\u865a\u62df\u5185\u5b58\uff1a\u8fdb\u7a0b\u7684\u4ee3\u7801\u5fc5\u987b\u5728\u5185\u5b58\u4e2d\uff0c\u56e0\u4e3aCPU\u53ea\u6709\u80fd\u529b\u8bbf\u95ee\u5185\u5b58\uff0c\u4e0d\u80fd\u8bbf\u95ee\u78c1\u76d8\u3002\u4f46\u662f\u4e0a\u4e00\u8282\u5f15\u5165\u7684swapping\u673a\u5236\u5141\u8bb8\u6211\u4eec\u628a\u4e00\u90e8\u5206\u5728\u4e3b\u5b58\u4e2d\u6682\u65f6\u7528\u4e0d\u5230\u7684\u5185\u5bb9\u4ea4\u6362\u5230disk\u4e2d\u3002</p> <p>\u8fd9\u6837\u5c31\u9700\u8981\u6211\u4eec\u5f15\u5165\u903b\u8f91\u5730\u5740\u7a7a\u95f4(logical address space)\u7684\u6982\u5ff5\uff0c\u8981\u5927\u4e8e\u7269\u7406\u5730\u5740\u7a7a\u95f4(physical address space)\uff0c\u5bf9\u5e94\u7684\u9875\u8868\u4f1a\u63d0\u4f9b\u865a\u62df\u5730\u5740\u5230\u7269\u7406\u5730\u5740\u7684\u6620\u5c04\u3002</p> <p>CPU\u8bbf\u95ee\u865a\u62df\u5730\u5740\u65f6\uff0c\u4f1a\u7531MMU\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684\u7269\u7406\u5730\u5740\u3002\u5982\u679cpage\u4e0d\u5728\u7269\u7406\u5185\u5b58\u4e2d\uff0c\u4f1a\u89e6\u53d1\u4e00\u6b21page fault\uff08exception\uff09\uff0c\u6709\u4e09\u79cd\u53ef\u80fd\u60c5\u51b5\uff1a</p> <ul> <li>\u5f53\u524d\u8fdb\u7a0b\u7684\u9875\u8868\u4e2d\u6ca1\u6709\u8fd9\u4e2a\u865a\u62df\u5730\u5740\u5bf9\u5e94\u7684page \u2192 \u88abOS\u6740\u6b7b</li> <li>\u6743\u9650\u4e0d\u7b26\uff0c\u6bd4\u5982\u8bd5\u56fe\u8fd0\u884c\u67d0\u4e2a\u6743\u9650\u662fRW-\u7684page\u7684\u4ee3\u7801\uff0c\u6216\u8005\u8bd5\u56fe\u5199\u5165\u67d0\u4e2a\u6743\u9650\u662fR-W\u7684page \u2192 \u88abOS\u6740\u6b7b</li> <li>\u5f53\u524d\u865a\u62df\u5730\u5740\u662f\u5408\u6cd5\u7684\uff0c\u4f46\u662f\u5bf9\u5e94\u7684page\u88abswapped out\u4e86 \u2192 \u8fdb\u7a0b\u88ab\u963b\u585e\uff0c\u628a\u5bf9\u5e94\u7684page\u4ea4\u6362\u56de\u6765\uff0c\u8c03\u9875\u5b8c\u6210\u540e\u5524\u9192\u8fdb\u7a0b\u3002</li> </ul> <p>\u5728\u4e00\u6761\u6307\u4ee4\u6267\u884c\u671f\u95f4\uff0c\u53ef\u80fd\u89e6\u53d1\u591a\u6b21page fault\uff0c\u76f4\u5230\u89e3\u51b3\u540e\u6210\u529f\u8fd0\u884c\u3002</p> <p>Kernel address &amp; Userspace address</p> <p>\u56e0\u4e3a\u6307\u4ee4\u6709privileged\u548cnon-privileged\uff0c\u5730\u5740\u7a7a\u95f4\u4e5f\u5206\u6210\u4e86kernel portion\u548cuser portion\uff0ckernel\u53ea\u80fdprivileged instruction\u8bbf\u95ee\uff0cuser\u90fd\u80fd\u3002\u6240\u6709\u8fdb\u7a0b\u7684kernel portion\u5176\u5b9e\u662f\u540c\u4e00\u5757\u4ee3\u7801\uff0c\u56e0\u4e3a\u6240\u6709\u8fdb\u7a0b\u7528\u5230\u7684\u90fd\u662f\u540c\u4e00\u5757kernel\u3002user portion\u8981\u590d\u5236\u662f\u56e0\u4e3a\u542b\u6709\u7684\u662f\u5404\u4e2a\u8fdb\u7a0b\u7684\u9875\u8868\u3001\u961f\u5217\u7b49\u4e1c\u897f\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#91-lazy-allocation-demand-paging","title":"9.1 Lazy Allocation / Demand Paging","text":"<p>OS\u5728\u5206\u914duser space\u65f6\uff0c\u4f1a\u4f7f\u7528lazy allocation\uff1a\u7528\u6237\u7533\u8bf7\u4e00\u5757\u5185\u5b58\u65f6\uff0cOS\u5e76\u4e0d\u4f1a\u771f\u6b63\u5728\u7269\u7406\u5185\u5b58\u4e2d\u5206\u914d\u5bf9\u5e94\u5185\u5b58\uff0c\u76f4\u5230\u771f\u6b63\u88ab\u8bbf\u95ee\u3002</p> <p>\u8fd9\u6837\u8bbe\u8ba1\u7684\u539f\u56e0\u662f\u5f88\u591a\u7528\u6237\u7a0b\u5e8f\u7533\u8bf7\u7684\u5185\u5b58\u5927\u5c0f\u901a\u5e38\u6bd4\u771f\u6b63\u8981\u4f7f\u7528\u7684\u5927\u3002\u4f8b\u5982buffer\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#92-copy-on-write","title":"9.2 Copy-on-write","text":"<p>\u5141\u8bb8\u5b50\u8fdb\u7a0b\u548c\u7236\u8fdb\u7a0b\u4f7f\u7528\u540c\u4e00\u4e2a\u7269\u7406\u9875\u6765\u5de5\u4f5c\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#93-page-replacement","title":"9.3 Page Replacement","text":"<p>\u4ece\u5185\u5b58\u4e2d\u4ea4\u6362\u5230\u78c1\u76d8\u53bb\u4e00\u6574\u4e2a\u5f53\u524d\u4e0d\u5728\u4f7f\u7528\u7684frame\u3002</p> <p>\u6b65\u9aa4\u662f\uff1a - \u627e\u5230\u8fd9\u4e2avictim frame - \u5c06\u5176\u5185\u5bb9\u5199\u5230\u4ea4\u6362\u9875\uff1a\u53ef\u4ee5\u7528\u4e00\u4e2adirty bit\uff0c\u5982\u679c\u6ca1\u6709\u6539\u8fc7\uff0c\u90a3\u5c31\u4e0d\u7528\u5199\u56de\u4e86 - \u4fee\u6539\u9875\u8868\uff08\u548cTLB\uff09\u4ee5\u8868\u793a\u5b83\u4e0d\u5728\u5185\u5b58\u4e2d\u4e86</p> <p>\u627e\u5230victim frame\u7684\u505a\u6cd5 - Optimal\uff1a\u9009\u62e9\u6700\u957f\u65f6\u95f4\u5185\u4e0d\u518d\u8bbf\u95ee\u7684\u9875\u9762\u6362\u51fa\u3002\u662f\u7406\u60f3\u60c5\u51b5\uff0c\u5b9e\u9645\u5e76\u4e0d\u80fd\u9884\u6d4b\u672a\u6765\u8bbf\u95ee\u60c5\u51b5\u3002\u662f\u4e00\u79cd\u8bc4\u5224\u5176\u5b83\u7b97\u6cd5\u6027\u80fd\u7684\u7406\u8bba\u57fa\u51c6\u3002 - FIFO (First In First Out): \u5f88\u76f4\u89c9\u7684\u505a\u6cd5\uff0c\u4f46\u662f\u5b9e\u9645\u4e0a\u5f88\u591a\u9875\u9762\u7ecf\u5e38\u88ab\u8bbf\u95ee\uff0c\u6240\u4ee5\u5148\u8fdbbuffer\u7684\u6709\u53ef\u80fd\u662f\u975e\u5e38\u7ecf\u5e38\u8bbf\u95ee\u7684\u3002\u5b83\u53ef\u80fd\u51fa\u73b0Belady\u2018s Anomaly\uff1a\u7269\u7406\u5e27\u589e\u52a0\uff0c\u5f02\u5e38\u60c5\u51b5\u53cd\u800c\u66f4\u591a\u4e86 - LRU (Least Recently Used)\uff1a\u6700\u4e45\u6ca1\u6709\u88ab\u8bbf\u95ee\u7684\u9875\u9762\u3002\u53ef\u4ee5\u6bcf\u4e2a\u9875\u8868\u52a0\u4e00\u4e2acounter\uff0c\u4e5f\u53ef\u4ee5\u7528\u6808\u4fdd\u5b58page numebrs\u3002\u5f00\u9500\u90fd\u633a\u5927\u3002 - LRU-Approximation\uff1a\u5f15\u5165\u4e00\u4e2areference bit\uff0c\u5f53\u88ab\u8bbf\u95ee\u65f6\u7f6e1\uff0cOS\u5b9a\u671f\u628a\u5b83\u7f6e0\u3002\u9700\u8981\u6362\u7684\u65f6\u5019\u5c31\u627e0\uff0c\u8bf4\u660e\u5b83\u5728\u6700\u8fd1\u8fd9\u4e00\u6bb5\u65f6\u95f4\u5185\u90fd\u6ca1\u88ab\u8bbf\u95ee\u8fc7\u3002\u6027\u80fd\u66f4\u597d\u4e86\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#94-allocation-of-frames","title":"9.4 Allocation of Frames","text":"<p>\uff08\u8fd9\u4e2a\u5730\u65b9\u5b8c\u5168\u6ca1\u770b\u61c2\uff09</p> <p>\u7ed9\u6bcf\u4e2a\u8fdb\u7a0b\u5206\u914d\u7684frame\u4e2a\u6570\uff1a</p> <ul> <li>\u6700\u5927\u503c\u4e0d\u8d85\u8fc7\u7269\u7406\u5185\u5b58\u7684frame\u4e2a\u6570</li> <li>\u6700\u5c0f\u503c\u7531\u8ba1\u7b97\u673a\u7684\u67b6\u6784\u51b3\u5b9a\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u56e0\u4e3a\u6bcf\u6761\u6307\u4ee4\u53ea\u6709\u89e3\u51b3\u5168\u90e8page fault\u624d\u80fd\u8fd0\u884c\uff0c\u6240\u4ee5frame\u4e2a\u6570\u4e00\u5b9a\u4e0d\u80fd\u5c0f\u4e8e\u5355\u4e2a\u6307\u4ee4\u9700\u8981\u7684page\u4e2a\u6570\u3002</li> </ul> <p>\u66ff\u6362\u65b9\u6cd5</p> <ul> <li>\u5168\u5c40\u7f6e\u6362(global replacement)\uff0c\u6bcf\u6b21\u7f6e\u6362\u4ece\u4e2d\u9009\u62e9\u4e00\u4e2a\u5e27\u6765\u8ba1\u7b97\uff0c\u90a3\u4e48\u4e0d\u4e00\u5b9a\u9700\u8981\u63d0\u524d\u89c4\u5212\u6bcf\u4e2a\u8fdb\u7a0b\u9700\u8981\u7684frame\u4e2a\u6570\u3002\u8fd9\u79cd\u66ff\u6362\u7684\u4f18\u52bf\u662f\u7531\u66f4\u597d\u7684\u7cfb\u7edf\u541e\u5410\u91cf\uff0c\u7f3a\u70b9\u662f\u4e00\u4e2a\u8fdb\u7a0b\u7684page fault rate\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u81ea\u5df1\uff0c\u4e5f\u53d6\u51b3\u4e8e\u5176\u5b83\u8fdb\u7a0b\u3002</li> <li>\u5c40\u90e8\u66ff\u6362\uff0c\u5219\u9700\u8981\u63d0\u524d\u8ba1\u7b97frame\u4e2a\u6570\u3002</li> </ul> <p>\u5982\u679c\u9700\u8981\u4ece\u6700\u5927\u548c\u6700\u5c0f\u4e4b\u95f4\uff0c\u51b3\u5b9a\u4e00\u4e2a\u8fdb\u7a0b\u80fd\u591f\u4f7f\u7528\u7684page\u603b\u6570\uff0c\u6709\u591a\u79cd\u5206\u914d\u7b97\u6cd5</p> <ul> <li>\u5e73\u5747\u5206\u914d</li> <li>\u6309\u8fdb\u7a0b\u5b9e\u9645\u9700\u6c42\u5206\u914d</li> <li>\u6309\u8fdb\u7a0b\u4f18\u5148\u7ea7\u5206\u914d</li> </ul> <p>\u73b0\u4ee3\u8ba1\u7b97\u673a\u90fd\u6709\u591a\u4e2aCPU\uff0c\u6bcf\u4e2aCPU\u6bd4\u5176\u5b83CPU\u66f4\u5feb\u5730\u8bbf\u95ee\u5185\u5b58\u7684\u67d0\u4e9b\u90e8\u5206\u3002\u5982\u679c\u5dee\u5f02\u6bd4\u8f83\u660e\u663e\uff0c\u79f0\u8fd9\u79cd\u7cfb\u7edf\u4e3a\u975e\u5747\u5300\u5185\u5b58\u8bbf\u95ee\uff08NUMA\uff0cnon-uniform memory access\uff09\u7cfb\u7edf\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#95-thrashing","title":"9.5 Thrashing","text":"<p>\u5982\u679c\u8fdb\u7a0b\u53ef\u7528\u7684\u5e27\u8f83\u5c11\uff08\u5c11\u4e8e\u9891\u7e41\u8bbf\u95ee\u7684\u9875\u9762\u6570\u76ee\uff09\uff0c\u90a3\u4e48\u9891\u7e41\u51fa\u73b0page fault\u3002\u540c\u4e00\u4e2apage\u88ab\u9891\u7e41\u6362\u5165\u6362\u51fa\uff0c\u4ee5\u6ee1\u8db3\u8fd0\u884c\u7684\u8981\u6c42\u3002\u8fd9\u79cd\u9ad8\u5f3a\u5ea6\u9875\u9762\u8c03\u5ea6\u53eb\u6296\u52a8\uff08thrashing\uff09\uff0c\u5176\u9875\u9762\u8c03\u5ea6\u7528\u65f6\u751a\u81f3\u53ef\u80fd\u5927\u4e8e\u6267\u884c\u65f6\u95f4\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#96-kernel-memory-allocation","title":"9.6 Kernel Memory Allocation","text":"<p>kernel\u4e2d\u7684\u5f88\u591a\u6570\u636e\u7ed3\u6784\u5927\u5c0f\u533a\u5206\u6bd4\u8f83\u5927\uff0c\u5c0f\u7684\u53ef\u80fd\u4f1a\u5c0f\u4e8e\u4e00\u4e2apage\uff0c\u56e0\u6b64kernel\u7684\u8bbe\u8ba1\u5e94\u5f53\u5c3d\u91cf\u8282\u7701\u5185\u5b58\uff0c\u52aa\u529b\u51cf\u5c11\u788e\u7247\u3002\u539f\u56e0\u662f</p> <ul> <li>kernel\u53ef\u80fd\u4e00\u90e8\u5206\u5e38\u9a7b\u7269\u7406\u5185\u5b58\u4e2d\uff0c\u4e0d\u53d7\u8c03\u9875\u7cfb\u7edf\u7684\u63a7\u5236</li> <li>\u6709\u7684\u786c\u4ef6\u8bbe\u5907\u53ef\u80fd\u548c\u7269\u7406\u5185\u5b58\u76f4\u63a5\u4ea4\u4e92\uff0c\u56e0\u6b64\u9700\u8981\u8fde\u7eed\u7684\u7269\u7406\u5185\u5b58</li> </ul> <p>\u4e24\u8005\u5bf9\u7269\u7406\u5185\u5b58\u7684\u8981\u6c42\u90fd\u6bd4\u8f83\u4e25\u683c</p> <p>\u5206\u914d\u65b9\u6cd5</p> <ul> <li>buddy system\uff1a\u4ece\u7269\u7406\u8fde\u7eed\u7684\u6bb5\u4e0a\u5206\u914d\u5185\u5b58\uff0c\u6bcf\u6b21\u5206\u914d\u5185\u5b58\u5927\u5c0f\u662f2\u7684\u5e42\u6b21\u65b9\u3002\u5f53\u91ca\u653e\u65f6\uff0c\u4f1a\u5408\u5e76\uff08coalesce\uff09\u76f8\u90bb\u7684\u5757\uff0c\u5f62\u6210\u66f4\u5927\u7684\u5757\u4f9b\u4e4b\u540e\u4f7f\u7528</li> <li>slab allocation\uff1aOS\u4e2d\u5f88\u591aobject\u7684\u5927\u5c0f\u662f\u56fa\u5b9a\u4e14\u5df2\u77e5\u7684\u3002\u5185\u5b58\u4f1a\u88ab\u5212\u5206\u4e3a\u82e5\u5e72\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u5757\uff0c\u6bcf\u4e2a\u5206\u914d\u4e00\u4e2a\u5177\u4f53\u7684\u7c7b\u578b\u3002\u5f53\u8fdb\u7a0b\u9700\u8981\u5206\u914d\u5185\u5b58\uff0c\u4f1a\u67e5\u8be2\u7f13\u5b58\uff0c\u5982\u679c\u627e\u5230\u4e00\u4e2a\u7a7a\u95f2\u7684\u5757\u5c31\u4f7f\u7528\u3002</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#10-mass-storage","title":"10. Mass Storage \u5927\u5bb9\u91cf\u5b58\u50a8","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#101-hddnvm","title":"10.1 HDD/NVM","text":"<p>\u73b0\u4ee3\u8ba1\u7b97\u673a\u7684\u5927\u90e8\u5206\u4e8c\u7ea7\u5b58\u50a8\u7531hard disk drives (HDDs) \u548c nonvolatile memory (NVM) devices \u63d0\u4f9b\u3002</p> <ul> <li>HDD \u5c31\u662f\u786c\u76d8\u9a71\u52a8\u5668\u3002</li> <li>NVM \u8bbe\u5907\u6839\u636e\u5b9a\u4e49\u662f\u65ad\u7535\u540e\u5b58\u50a8\u6570\u636e\u8fd8\u80fd\u4fdd\u6301\u7684\u8bbe\u5907\u3002</li> </ul> <p>\u8bfe\u672c\u91cc\u8ba4\u4e3aNVM\uff08electronic\uff09\u4e0d\u5305\u542bHDD\uff08mechanical\uff09</p> <p>HDD  \u7ed3\u6784</p> <ul> <li>\u6bcf\u4e2adisk platter\uff08\u76d8\u7247\uff09\u957f\u5f97\u50cfCD\uff0c\u76f4\u5f84\u4e00\u822c\u662f1.8-3.5 inches\uff08\u8fd9\u662f\u591a\u5c11 \u53cd\u6b63\u4e0d\u5927\uff09\u3002disk platter\u901a\u8fc7\u78c1\u6027\u6750\u6599\u5728\u4e0a\u8fb9\u4fdd\u5b58\u4fe1\u606f\uff0c\u901a\u8fc7\u68c0\u6d4b\u78c1\u6027\u6765\u8bfb\u53d6\u4fe1\u606f\u3002</li> <li>platter \u8868\u9762\u88ab\u5206\u4e3a\u4e86\u5f88\u591atrack\uff08\u78c1\u9053\uff09\uff0c\u518d\u7ec6\u5206\u4e3asector\uff08\u6247\u533a\uff09\u3002\u5728\u4e00\u4e2aarm position\u4e0b\u7684track\u7ec4\u6210\u4e00\u4e2acylinder\uff08\u67f1\u9762\uff09\u3002</li> <li>read-write head\uff1a\u6bcf\u4e2aplatter\u9644\u8fd1\u6709\u4e00\u4e2a\uff0c\u9644\u7740\u5728disk arm\u4e0a\uff0carm\u4f1a\u4f7f\u6240\u6709head\u5f62\u6210\u6574\u4f53\u5171\u540c\u79fb\u52a8\u3002</li> <li>sector\u88ab\u7f16\u53f7\uff0c\u662flogical block addr\u5728disk drive\u4e0a\u7684\u6620\u5c04\u3002\u4ece\u6700\u5916\u5c42\u7684cylinder\u7684\u7b2c\u4e00\u4e2asection\u4e3a0\u53f7\uff0c\u4e00\u76f4\u7f16\u5230\u5185\u90e8\u7684cylinder\u3002</li> </ul> <p>\u53c2\u6570</p> <ul> <li>Rotation Per Minute (RPM) \u6bcf\u5206\u949f\u65cb\u8f6c\u6b21\u6570\u3002\u5e38\u89c1\u7684HDD\u6709\uff1a5400, 7200, 10000, 15000RPM</li> <li>Transfer rate\uff1a\u5728HDD\u548c\u8ba1\u7b97\u673a\u4e4b\u95f4\u6570\u636e\u6d41\u7684\u901f\u7387</li> <li>Positional Time (a.k.a. random-access time): \u5c06disk arm\u79fb\u52a8\u5230\u6240\u9700\u8981\u7684sector\u6240\u7528\u7684\u65f6\u95f4\u3002=<ul> <li>seek time (\u5c06arm\u79fb\u52a8\u5230cylinder\u7528\u65f6\uff0c3ms-12ms) +</li> <li>rotational latency (\u65cb\u8f6c\u5230head\u5728\u6240\u9700sector\u4e0a\u6240\u7528\u65f6\u95f4\uff0c\u4e0e\u8f6c\u901f\u6709\u5173)</li> </ul> </li> </ul> <p>NVM Devices</p> <ul> <li>\u56fa\u6001\u786c\u76d8 (solid-state disks, SDD)</li> <li>USB drives (thumb drive, flash drive)</li> <li>DRAM disk replacement</li> </ul> <p>\u6bd4HDD\u66f4\u53ef\u9760\uff0c\u66f4\u5feb\uff0c\u66f4\u8d35\uff0c\u5bff\u547d\u77ed\uff0c\u5bb9\u91cf\u66f4\u5c0f</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#102-hdd-scheduling","title":"10.2 \u78c1\u76d8\u8c03\u5ea6 HDD Scheduling","text":"<p>\u4e3b\u8981\u4e3a\u4e86\u4f18\u5316\u4e24\u4e2a\u53c2\u6570</p> <ul> <li>access time = seek time  + rotational latency</li> <li>disk bandwidth: data bytes / time from request to completion</li> </ul> <p>\u4e00\u822c\u4f1a\u8003\u8651minimize seek time\uff0c\u56e0\u4e3arotational latency\u4e00\u822c\u7ba1\u4e0d\u5230</p> <p>First-Come First-Served (FCFS)</p> <p>Advantages</p> <ul> <li>every request gets a fair chance</li> <li>no indefinite postponement</li> </ul> <p>Disadvantages:</p> <ul> <li>does not try to optimize seek time</li> <li>may not provide the best possible service</li> </ul> <p>Shortest seek time first (SSTF)</p> <p>\u603b\u662f\u9009\u62e9\u8ddd\u79bb\u5f53\u524d\u6700\u8fd1\u7684request\u3002\u4e0d\u4e00\u5b9a\u6700\u597d</p> <p>cannot calculate seek time in advance</p> <p>high variance</p> <p>\u53ef\u80fd\u5bfc\u81f4starvation</p> <p>SCAN / Elevator algorithm</p> <p>\u975e\u5e38\u5f62\u8c61\uff0c\u4e00\u76f4\u5f80\u4e00\u4e2a\u65b9\u5411\u8d70\u4e0d\u56de\u5934\uff0c\u76f4\u5230\u78b0\u5230\u8fb9\u754c\uff0c\u518d\u8fd4\u56de</p> <p>long waiting time for requests that are just visited.</p> <p>C-SCAN</p> <p>\u4e0d\u662f\u8fb9\u8fd4\u56de\u8fb9\u626b\uff0c\u800c\u662f\u76f4\u63a5\u8fd4\u56de\u5f00\u5934</p> <p>provides more uniform wait time than SCAN</p> <p>LOOK / C-LOOK</p> <p>\u5728 SCAN / C-SCAN \u7684\u57fa\u7840\u4e0a\uff0c\u53ea\u8d70\u5230\u6700\u5927/\u6700\u5c0f\u7684request\u7f16\u53f7\u5c31\u8fd4\u56de\uff0c\u800c\u4e0d\u662f\u8d70\u5230section\u7684\u5934\u3002</p> <p>\u600e\u6837\u9009\u62e9scheduling algorithm\uff1a\u4e00\u822c\u9009\u62e9SSTF\uff0c\u5f53IO\u8d1f\u8377\u6bd4\u8f83\u5927\u65f6\uff0c\u9009\u62e9 LOOK / C-LOOK</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#103","title":"10.3 \u78c1\u76d8\u7ba1\u7406","text":"<p>\u78c1\u76d8\u683c\u5f0f\u5316\u6b65\u9aa4</p> <ul> <li>\u4f4e\u7ea7\u683c\u5f0f\u5316\uff08low-level formatting, aka. \u7269\u7406\u683c\u5f0f\u5316\uff09\uff1a\u628a\u78c1\u76d8\u5206\u6210\u6247\u533a</li> <li>\u5206\u533a\uff08partition\uff09\uff1aOS\u5728\u78c1\u76d8\u4e0a\u5199\uff0c\u628a\u78c1\u76d8\u5206\u6210\u4e00\u4e9bcylinder\u7ec4\u6210\u7684logical disk</li> <li>\u903b\u8f91\u683c\u5f0f\u5316\uff08logical formatting\uff09\uff1aOS\u5c06\u6587\u4ef6\u7cfb\u7edf\u7b49\u5199\u5728\u78c1\u76d8\u4e0a\uff0c\u5f62\u6210\u5377\uff08volume\uff09</li> </ul> <p>boot block</p> <p>\u5728\u521a\u6253\u5f00\u7535\u6e90\u6216\u91cd\u542f\u65f6\uff0c\u4e00\u4e2a\u81ea\u4e3e\uff08bootstrap\uff09\u7a0b\u5e8f\u4f1a\u521d\u59cb\u5316\u7cfb\u7edf\u7684\u5404\u4e2a\u90e8\u5206\uff0c\u5982CPU\u5bc4\u5b58\u5668\u3001\u8bbe\u5907\u63a7\u5236\u5668\u3001\u5185\u5b58\uff0c\u7136\u540e\u627e\u5230OS\u5185\u6838\uff0c\u52a0\u8f7d\u5230\u5185\u5b58\uff0c\u4ece\u800c\u8fd0\u884cOS\u3002</p> <p>\u4e00\u822cbootstrap\u7684\u542f\u52a8\u7a0b\u5e8ftiny bootstrap loader program\u5b58\u5728ROM\uff0c\u5b83\u5728\u78c1\u76d8\u4e2d\u7684boot partition\u628abootstrap\u7a0b\u5e8fload\u8fdb\u6765\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#104-raid","title":"10.4 RAID","text":"<p>\u78c1\u76d8\u5197\u4f59\u9635\u5217\uff08redundant array of independent disk, RAID\uff09\u6280\u672f\u3002</p> <p>\u5b9a\u4e49\u597d\u50cf\u662f\u4e00\u4e2a\u62e5\u6709\u5927\u91cf\u78c1\u76d8\u7684\u7cfb\u7edf\uff0c\u6765\u6539\u5584\u6570\u636e\u7684\u8bfb\u5199\u901f\u7387\uff08\u56e0\u4e3a\u53ef\u4ee5\u5e76\u884c\uff09\uff0c\u4e14\u53ef\u9760\uff08\u4f7f\u7528\u5197\u4f59\u6765\u964d\u4f4e\u51fa\u73b0\u9519\u8bef\u7684\u671f\u671b\uff09\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#11-io","title":"11. IO","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#111","title":"11.1 \u65b9\u5f0f","text":"<ul> <li>\u8f6e\u8be2\uff08polling\uff09: \u5f53PC\u9700\u8981\u548c\u67d0\u4e2aIO\u8bbe\u5907\u4ea4\u4e92\u65f6\uff0c\u67e5\u8be2\u8bbe\u5907\u5bf9\u5e94\u7684IO\u63a7\u5236\u5668\u4e2d\u72b6\u6001\u5bc4\u5b58\u5668\u7684\u76f8\u5173\u4f4d\uff0c\u5f53\u8be5\u4f4d\u8868\u793a\u8bfb\u5199\u53ef\u4ee5\u8fdb\u884c\u65f6\u5c31\u901a\u8fc7\u72b6\u6001\u5bc4\u5b58\u5668\u901a\u77e5\u63a7\u5236\u5668\u3002</li> <li>\u4e2d\u65ad\uff1a\u5728interrupt request line\u4e0a\u901a\u77e5CPU</li> <li>\u76f4\u63a5\u5185\u5b58\u8bbf\u95ee (DMA, Direct Memory Access): \u5bf9\u4e8e\u9700\u8981\u5927\u91cf\u4f20\u8f93\u7684\u8bbe\u5907\uff0c\u4e0a\u8ff0\u4e24\u79cd\u64cd\u4f5c\u8fc7\u591a\u4f1a\u5360\u7528CPU\u8d44\u6e90\uff0c\u56e0\u6b64\u5f88\u591a\u8ba1\u7b97\u673a\u63d0\u51fa\u4e86DMA\uff0c\u5c06IO\u4ea4\u7ed9\u4e00\u4e2aDMA\u63a7\u5236\u5668\u5b8c\u6210\uff0c\u5b83\u8ba9\u8bbe\u5907\u76f4\u63a5\u4e0e\u5185\u5b58\u4ea4\u4e92\u3002\u4f7f\u7528\u865a\u62df\u5730\u5740\u6280\u672f\u7684\u53ebDVMA Direct Virutual-memory Access\u3002</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#112-io","title":"11.2 \u5e94\u7528\u7a0b\u5e8fIO\u63a5\u53e3","text":"<p>IO\u7cfb\u7edf\u76f8\u5173\u7684\u7cfb\u7edf\u8c03\u7528\u5c06\u4e0d\u540c\u7684IO\u8bbe\u5907\u7684\u5de5\u4f5c\u65b9\u5f0f\u5c01\u88c5\u5230\u4e00\u4e9b\u7c7b\u4e2d\uff0c\u4ece\u800c\u5f62\u6210\u8f83\u5c11\u7684\u901a\u7528\u7c7b\u578b\uff0c\u4e3a\u5e94\u7528\u7a0b\u5e8f\u9690\u85cf\u786c\u4ef6\u7684\u5177\u4f53\u5dee\u5f02\u3002</p> <ul> <li>Data transfer mode<ul> <li>character\uff1a\u9010\u4e2a\u5b57\u8282\u4f20\u8f93\uff08\u5982terminal\uff09</li> <li>block\uff1a\u4ee5\u5757\u4e3a\u5355\u4f4d\u4f20\u8f93\uff08\u5982disk\uff09</li> </ul> </li> <li>access method<ul> <li>sequential\uff1a\u5982modem</li> <li>random\uff1a\u5982\uff08CD-ROM\uff09</li> </ul> </li> <li>Transfer method<ul> <li>synchronous\uff08\u540c\u6b65\uff09\uff1a\u9700\u8981\u6309\u9884\u8ba1\u7684\u54cd\u5e94\u65f6\u95f4\u8fdb\u884c\u4f20\u8f93\uff0c\u5e76\u548c\u7cfb\u7edf\u7684\u5176\u5b83\u65b9\u9762\u76f8\u534f\u8c03</li> <li>asynchronous\uff08\u5f02\u6b65\uff09\uff1a\u54cd\u5e94\u65f6\u95f4\u4e0d\u9700\u8981\u89c4\u5219\uff0c\u6216\u8005\u53ef\u9884\u6d4b\uff0c\u4e0d\u9700\u8981\u4e0e\u5176\u5b83\u8ba1\u7b97\u673a\u4e8b\u4ef6\u76f8\u534f\u8c03\uff08\u5982\u7f51\u7edcI/O\uff09</li> </ul> </li> <li>Sharing<ul> <li>sharable\uff1a\u53ef\u4ee5\u88ab\u591a\u4e2a\u8fdb\u7a0b\u6216\u7ebf\u7a0b\u5e76\u53d1\u4f7f\u7528\uff08\u5982keyboard\uff09</li> <li>dedicated\uff1a\u4e0d\u80fd\uff08\u5982tape\uff09</li> </ul> </li> <li>device speed</li> <li>I/O direction\uff1aR-(CD-ROM) / -W(graphic controller) / RW(disk)</li> </ul> <p>\u540c\u65f6\u5927\u591a\u6570\u64cd\u4f5c\u7cfb\u7edf\u4e5f\u652f\u6301\u5e94\u7528\u7a0b\u5e8f\u900f\u660e\u5730\u5411\u4e00\u4e2a\u8bbe\u5907\u9a71\u52a8\u5668\u4f20\u8f93\u4efb\u610f\u6570\u636e\u3002\u5728UNIX\u4e2d\uff0c <code>ioctl()</code> \u7cfb\u7edf\u8c03\u7528\u53ef\u4ee5\u5b9e\u73b0\u8fd9\u4e00\u529f\u80fd\u3002\u8fd9\u4e00\u7cfb\u7edf\u8c03\u7528\u901a\u8fc7\u6587\u4ef6\u63cf\u8ff0\u7b26\uff08file descriptor\uff09\u6765\u786e\u5b9a\u4e00\u4e2a\u8bbe\u5907\uff0c\u56e0\u4e3aUNIX\u4e2d\u8bbe\u5907\u53ef\u4ee5\u901a\u8fc7\u6587\u4ef6\u7684\u65b9\u5f0f\u8bbf\u95ee\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#12","title":"12. \u6587\u4ef6\u7cfb\u7edf\u63a5\u53e3","text":"<p>\u6587\u4ef6\u7cfb\u7edf\uff08file system\uff09\u662f\u4e3a\u4e86\u7ed9\u7528\u6237\u63d0\u4f9bdisk\u7684\u903b\u8f91\u89c6\u56fe\u3002</p> <ul> <li>\u6587\u4ef6\uff08file\uff09</li> <li>\u76ee\u5f55\u7ed3\u6784\uff08directory structure\uff09</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#121","title":"12.1 \u6587\u4ef6","text":"<p>\u5e38\u89c1\u7684\u6587\u4ef6\u5c5e\u6027\u5b57\u6bb5</p> <ul> <li>Name</li> <li>Identifier</li> <li>Type</li> <li>Location</li> <li>Size</li> <li>Prtection</li> <li>Timestamp</li> <li>User identification</li> </ul> <p>\u8fd9\u4e9b\u4fe1\u606f\u5b58\u5728\u76ee\u5f55\u7ed3\u6784\u91cc</p> <p>\u6587\u4ef6\u64cd\u4f5c</p> <ul> <li>create</li> <li>read / write</li> <li>repositioning within a file (aka. seek)</li> <li>delete</li> <li>truncate: \u6e05\u7a7a\u6587\u4ef6\u5185\u5bb9\uff0c\u4f46\u4fdd\u7559\u6587\u4ef6\u5c5e\u6027</li> </ul> <p>\u6587\u4ef6\u6253\u5f00: \u6253\u5f00\u6587\u4ef6\u8868\uff08open-file table\uff09\uff0cfile-open count</p> <p>\u6587\u4ef6\u9501\uff08file lock\uff09\uff1a\u7c7b\u4f3c\u4e8ereader-writer lock\u3002\u5206\u5171\u4eab\u9501\uff08shared lock\uff09\uff0c\u72ec\u5360\u9501\uff08exclusive lock\uff09\u3002\u5206\u5f3a\u5236\u9501\u5b9a\uff08mandatory lock\uff09\u548c\u5efa\u8bae\u9501\u5b9a\uff08advisory lock\uff09\u3002</p> <p>\u6587\u4ef6\u7c7b\u578b\uff1a\u6587\u4ef6\u6269\u5c55\u540d\uff0c\u6216\u6587\u4ef6\u5934\u7684magic number</p> <p>\u6587\u4ef6\u7ed3\u6784\uff1a</p> <ul> <li>\u65e0\u7ed3\u6784 no structure</li> <li>simple record structure</li> <li>complex structures</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#122","title":"12.2 \u8bbf\u95ee\u65b9\u5f0f","text":"<ul> <li>\u987a\u5e8f\u8bbf\u95ee\uff08sequential access\uff09</li> <li>\u76f4\u63a5\u8bbf\u95ee/\u76f8\u5bf9\u8bbf\u95ee/\u968f\u673a\u8bbf\u95ee</li> <li>\u7d22\u5f15\u987a\u5e8f\u8bbf\u95ee\uff08indexed sequential-access\uff09\uff1a\u5148\u786e\u5b9a\u6240\u8bbf\u95ee\u7684\u5185\u5bb9\u5728\u54ea\u4e00\u5757\uff0c\u7136\u540e\u5728\u5bf9\u5e94\u5757\u4e2d\u5bfb\u627e\u3002</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#123","title":"12.3 \u76ee\u5f55\u7ed3\u6784","text":"<ul> <li>\u5355\u7ea7\u76ee\u5f55 single-level directory: \u6240\u6709\u6587\u4ef6\u90fd\u5728\u540c\u4e00\u76ee\u5f55</li> <li>\u4e24\u7ea7\u76ee\u5f55 two-level directory\uff1a\u7b2c\u4e00\u7ea7\u7528\u6237\u6587\u4ef6\u76ee\u5f55\uff0c\u6240\u6709\u7528\u6237\u6587\u4ef6\u76ee\u5f55\u6c47\u96c6\u6210\u4e3b\u6587\u4ef6\u76ee\u5f55</li> <li>\u6811\u5f62\u76ee\u5f55\uff1a\u4e24\u7ea7\u7684\u81ea\u7136\u63a8\u5e7f\u3002\u7edd\u5bf9\u8def\u5f84\u548c\u76f8\u5bf9\u8def\u5f84</li> <li>\u65e0\u73af\u56fe\u76ee\u5f55\uff1a\u652f\u6301\u76ee\u5f55\u5171\u4eab\u5b50\u76ee\u5f55\u6216\u6587\u4ef6\u3002\u8f6f\u94fe\u63a5\uff08\u7528\u6307\u9488\uff09\uff0c\u786c\u94fe\u63a5\uff08\u590d\u5236\u88ab\u5f15\u7528\u6587\u4ef6\u7684\u6240\u6709\u4fe1\u606f\uff0c\u5728\u6539\u5199\u65f6\u9700\u8981\u4e0e\u539f\u6587\u4ef6\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u5f15\u7528\u8ba1\u6570\uff09</li> <li>\u901a\u7528\u56fe\u76ee\u5f55\uff1a\u5141\u8bb8\u76ee\u5f55\u4e2d\u6709\u73af\uff0c\u5783\u573e\u56de\u6536\u9ebb\u70e6</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#124","title":"12.4 \u6587\u4ef6\u7cfb\u7edf\u6302\u8f7d","text":"<p>directory structure \u53ef\u4ee5\u6784\u5efa\u5728\u591a\u4e2avolume\u4e0a\uff0c\u8fd9\u4e9b\uff08\u522b\u7684\uff1f\uff09volume\u5fc5\u987b\u5148\u6302\u8f7d\uff08mount\uff09\u5230\u6587\u4ef6\u7cfb\u7edf\u7684\u67d0\u4e2a\u4f4d\u7f6e\uff0c\u8fd9\u4e2a\u4f4d\u7f6e\u79f0\u4e3a\u6302\u8f7d\u70b9\uff08mount point\uff09\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#125","title":"12.5 \u4fdd\u62a4","text":"<p>Access Control List (ACL): \u6307\u5b9a\u6bcf\u4e2a\u7528\u6237\u53ca\u5141\u8bb8\u7684\u8bbf\u95ee\u7c7b\u578b\u3002</p> <p>e.g. in Linux</p> <ul> <li>owner, group, others</li> <li>read, write, execute</li> </ul>  \ud83d\udca1 \u5f53\u4e00\u4e2a\u6587\u4ef6\u7684 read \u6216 write bit not set \u65f6\uff0croot \u7528\u6237\u4ecd\u7136\u80fd\u591f\u8bfb\u6216\u5199\u5b83\u3002  \u5f53\u4e00\u4e2a\u76ee\u5f55\u7684 execute bit \u5bf9\u4e8e\u4e00\u4e2a\u7528\u6237\u6240\u5728\u7684\u5206\u7c7b not set \u65f6\uff0c\u8be5\u7528\u6237\u4e0d\u80fd\u8fdb\u5165\u8be5\u76ee\u5f55\uff1b\u4f46\u662f root \u7528\u6237\u53ef\u4ee5\u3002  \u4f46\u662f\uff0c\u5982\u679c\u4e00\u4e2a\u6587\u4ef6\u5bf9\u4e09\u7c7b\u7528\u6237\u7684 execute bit \u5747 not set \u65f6\uff0c\u8fd9\u4e2a\u6587\u4ef6\u88ab\u8ba4\u4e3a\u4e0d\u662f\u53ef\u6267\u884c\u7684\uff0c\u56e0\u6b64 root \u7528\u6237\u4e5f\u4e0d\u80fd\u6267\u884c\u8fd9\u4e2a\u6587\u4ef6\u3002"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#13","title":"13. \u6587\u4ef6\u7cfb\u7edf\u5b9e\u73b0","text":"<ul> <li>UNIX \u4f7f\u7528 Unix FS (UFS)\uff0c\u57fa\u4e8eBFFS\uff08Berkeley Fast FS\uff09</li> <li>Windows \u652f\u6301 File Allocation Table (FAT)</li> <li>Linux \u7684\u6807\u51c6\u6587\u4ef6\u7cfb\u7edf\u662fextended file system</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#131","title":"13.1 \u5206\u5c42\u8bbe\u8ba1","text":"<p>\u6587\u4ef6\u7cfb\u7edf\u901a\u5e38\u5206\u5f88\u591a\u5c42</p> <ul> <li>application programs: \u8d1f\u8d23\u7ed9\u51fa read/write/open\u67d0\u4e2a\u76ee\u5f55\u7684\u6307\u4ee4\uff0c\u88ab\u4f20\u9012\u7ed9logical file system</li> <li>logical file system\uff1a\u7ba1\u7406\u6240\u6709\u6587\u4ef6\u7cfb\u7edf\u6240\u9700\u7684metadata\u3002\u6709\u4e00\u4e2aFile Control Block (FCB) \u6765\u7ba1\u7406\u8fd9\u4e9b\u4fe1\u606f\u3002\u8d1f\u8d23\u628arwx\u67d0\u4e2a\u76ee\u5f55\u7684\u6307\u4ee4\u89e3\u6790\u4e3arwx\u67d0\u4e9blogical block\u7684\u6307\u4ee4</li> <li>file-organization module\uff1a\u8d1f\u8d23logical file blocks\u5230physical file blocks\u7684\u8f6c\u6362\u3002\u4e5f\u8d1f\u8d23\u7ba1\u7406free-space\uff0c\u8ddf\u8e2a\u672a\u4f7f\u7528\u7684blocks\uff0c\u5e76\u5728\u9700\u8981\u65f6\u5206\u914d\u3002</li> <li>basic file system\uff1a\u7ba1\u7406file-system\u7684\u7f13\u5b58\uff0c\u63d0\u9ad8\u8bbf\u5b58\u6027\u80fd\u3002\u5982\u679cmiss\u4e86\uff0c\u5c31\u4f20\u9012\u7ed9IO control</li> <li>I/O control\uff1a\u5305\u62ec\u9a71\u52a8\u548c\u4e2d\u65ad\u5904\u7406\u7a0b\u5e8f\uff0c\u4ee5\u5728\u4e3b\u5b58\u548c\u78c1\u76d8\u7cfb\u7edf\u4e4b\u95f4\u4f20\u9012\u4fe1\u606f\u3002\u5c06\u4e0a\u5c42\u7684\u6307\u4ee4\u8f6c\u6362\u4e3alow-level\uff0chardware-specific\u7684\u6307\u4ee4\uff0c\u6765\u5b9e\u73b0\u76f8\u5173\u64cd\u4f5c\u3002</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#132","title":"13.2 \u6570\u636e\u7ed3\u6784","text":"<p>\u4e0a\u8ff0\u6587\u4ef6\u7cfb\u7edf\u4e2d\u7528\u5230\u7684\u7279\u6b8a\u6570\u636e\u7ed3\u6784\u6709</p> <p>In disk structures:</p> <p>File control block (FCB) (per file)\uff1a\u4fdd\u5b58name, ownership, permissions, ref count, timestamps, pointers to data blocks on disk. \u6bcf\u4e2aFCB\u6709\u4e2a\u552f\u4e00\u6807\u8bc6\u53f7\uff0c\u4e0e\u76ee\u5f55\u6761\u76ee\u76f8\u5173\u8054\u3002</p> <p>\u5728unix\u4e2dFCB\u53ebinode</p> <p>\u5728NTFS\u4e2d\uff0c\u6bcf\u4e2aFCB\u662f\u4e00\u4e2a\u53ebmaster file table\u7684\u7ed3\u6784\u7684\u4e00\u884c\u3002  boot control block (per volume):</p> <p>volume control block (per volume): </p> <p>directory (per FS): </p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#133-vfs","title":"13.3 VFS \u865a\u62df\u6587\u4ef6\u7cfb\u7edf","text":"<p>OS\u53ef\u4ee5\u540c\u65f6\u652f\u6301\u591a\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u7cfb\u7edf\u3002\u5b9a\u4e49\u4e86\u4e00\u5957\u901a\u7528\u7684\u6587\u4ef6\u7cfb\u7edf\u8bbf\u95ee\u63a5\u53e3\uff0copen(), read(), write(), close() \u548c file descriptiors \u7b49\uff0c\u4e0e\u5177\u4f53\u7684\u5b9e\u73b0\u5206\u79bb\u3002VFS\u8d1f\u8d23\u5bf9\u5e94\u8fd9\u4e9b\u63a5\u53e3\u548c\u5177\u4f53\u7684\u51fd\u6570\u6307\u9488\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#134","title":"13.4 \u76ee\u5f55\u5b9e\u73b0","text":"<p>\u4fdd\u5b58file name \u5230 FCB \u7684\u6620\u5c04\u5173\u7cfb\u3002</p> <ul> <li>linear list: \u67e5\u627e\u8d39\u65f6</li> <li>\u6709\u5e8f\u8868\uff0c\u5e73\u8861\u6811\uff0cB+\u6811</li> <li>hash table</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#135-disk-block-allocation","title":"13.5 Disk Block Allocation","text":"<p>\u6587\u4ef6\u4fdd\u5b58\u5728disk blocks\u4e0a\u7684\u7b56\u7565\u3002</p> <p>contiguous allocation: \u6bcf\u4e2a\u6587\u4ef6\u5728\u78c1\u76d8\u4e0a\u5360\u6709\u7684blocks\u662f\u8fde\u7eed\u7684\u3002\u4f1a\u9020\u6210\u788e\u7247\u3002\u6587\u4ef6\u662f\u53ef\u6269\u5c55\u7684\u3002\u53ef\u4ee5\u5b9e\u73b0\u786e\u5b9a\u6bcf\u4e2a\u6587\u4ef6\u7684\u6700\u5927\u5927\u5c0f\u3002\u4e5f\u53ef\u4ee5\u5f53\u7a7a\u95f4\u4e0d\u591f\u65f6\u7ef4\u62a4\u4e00\u4e2a\u6307\u9488\uff0c\u8bb0\u5f55\u6dfb\u52a0\u7684\u8fde\u7eed\u7a7a\u95f4\uff08extent\uff09\u7684\u4fe1\u606f\u3002\u76ee\u5f55\u9700\u8981\u8bb0\u5f55\u6bcf\u4e2a\u6587\u4ef6\u7684\u8d77\u6b62\u5730\u5740\u3002</p> <p>linked allocation: \u6bcf\u4e2ablock\u8bb0\u5f55\u4e0b\u4e00\u5757\u7a7a\u95f4\u7684\u5730\u5740\uff0c\u6709\u70b9\u50cf\u94fe\u8868\u3002\u76ee\u5f55\u5219\u53ea\u8bb0\u5f55\u8d77\u6b62\u5730\u5740\u3002</p> <p>indexed allocation: \u7ed9\u6bcf\u4e2a\u6587\u4ef6\u8bb0\u5f55\u4e00\u4e2a\u7d22\u5f15\u5757 (index block)\uff0c\u8bb0\u5f55\u6bcf\u4e2a\u6587\u4ef6\u7684\u7b2ci\u4e2a\u5757\u5728\u78c1\u76d8\u7684\u54ea\u4e2a\u5730\u65b9\u3002\u76ee\u5f55\u53ea\u9700\u8981\u4fdd\u5b58\u7d22\u5f15\u5757\u5728\u54ea\u91cc\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98_%E5%AD%98%E5%82%A8_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/#136","title":"13.6 \u7a7a\u95f2\u7a7a\u95f4\u7ba1\u7406","text":"<p>\u53ef\u4ee5\u7528bitmap\uff0c\u75281\u6807\u8bb0\u7a7a\u95f2\u7684block\u3002\u4e3a\u4e86\u51cf\u5c11bitmap\u5360\u7528\u7684\u7a7a\u95f4\uff0c\u53ef\u4ee5\u4ee5cluster\u4e3a\u5355\u4f4d\u8bb0\u5f55\u3002</p> <p>\u53ef\u4ee5\u5c06free space\u7528\u94fe\u8868\u94fe\u63a5\uff0c\u4f46\u8bbf\u95ee\u6548\u7387\u8f83\u4f4e\u3002</p> <p>\u53ef\u4ee5\u5f15\u5165grouping\uff0c\u7ef4\u62a4\u82e5\u5e72\u4e2ablock\u5f62\u6210\u7684\u94fe\u8868\uff0c\u6bcf\u4e2ablock\u4fdd\u5b58\u82e5\u5e72\u7a7a\u95f2\u5757\u7684\u5730\u5740\u3002</p> <p>counting\uff1a\u7ef4\u62a4\u8fde\u7eed\u7a7a\u95f2\u5757\u7684\u94fe\u8868\uff0c\u5373\uff0c\u94fe\u8868\u7684\u6bcf\u4e2a\u8282\u70b9\u662f\u8fde\u7eed\u7684\u7a7a\u95f2\u5757\u7684\u9996\u5757\u6307\u9488\u548c\u8fde\u7eed\u7684\u957f\u5ea6\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/","title":"OS Lecture \u8fdb\u7a0b\u4e0e\u540c\u6b65","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#2-process","title":"2. \u8fdb\u7a0b Process","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#21","title":"2.1 \u7ec4\u6210","text":"<p>\u8fdb\u7a0bprocess\uff08=\u4f5c\u4e1ajob\uff09\u662f\u88ab\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u6b63\u5728\u8fd0\u884c\u7684\u7a0b\u5e8f\u3002\u591a\u4e2a\u8fdb\u7a0b\u53ef\u80fd\u5bf9\u5e94\u540c\u4e00\u4e2a\u7a0b\u5e8f\u3002\u4e00\u4e2a\u6b63\u5728\u8fd0\u884c\u7684OS\u4e2d\u4f1a\u6709\u591a\u4e2a\u8fdb\u7a0b\uff0c\u8fdb\u7a0b\u662f\u7a0b\u5e8f\u7684\u4e00\u6b21\u6267\u884c\u8fc7\u7a0b\uff0c\u662fOS\u5206\u914d\u8d44\u6e90\u7684\u57fa\u672c\u5355\u4f4d\u3002</p> <p>\u8fdb\u7a0b\u7684\u7ec4\u6210\uff1a\u4e00\u4e2a\u8fdb\u7a0b\u5305\u62ec - code or text     - \u5373\u7a0b\u5e8f\u4ee3\u7801\uff0c\u52a0\u8f7d\u5230\u5185\u5b58\u524d\u4ee5executable file\u7684\u5f62\u5f0f\u5b58\u50a8\u5728disk\u4e2d - program counter     - PC\uff0c\u6307\u5411\u4e0b\u4e00\u4e2a\u8981\u8fd0\u884c\u7684\u6307\u4ee4 - counter of the processor\u2019s registers     - \u5728\u8fdb\u7a0b\u4e4b\u95f4\u5207\u6362\u65f6\uff0c\u9700\u8981\u4fdd\u5b58\u5bc4\u5b58\u5668\u7684\u503c\u4ee5\u4fbf\u4e0b\u6b21\u56de\u5230\u8be5\u8fdb\u7a0b\u65f6\u7ee7\u7eed\u8fd0\u884c - run time stack     - \u5728ICS\u548c\u6c47\u7f16\u4e2d\u5b66\u4e60\u8fc7\u76f8\u5173\u5185\u5bb9\uff0c\u5176\u4e2d\u7684\u6761\u76ee\u79f0\u4e3aactivation records\uff08stack frames\uff09     - \u7531\u7528\u6237\u4ee3\u7801\u63a7\u5236\uff08\u7f16\u8bd1\u65f6\u5b8c\u6210\u5173\u4e8e\u6808\u7684\u76f8\u5173\u8c03\u7528\uff09\uff0c\u5728\u8c03\u7528\u51fd\u6570\u65f6\u6682\u65f6\u5b58\u50a8\u4e00\u4e9b\u6570\u636e\uff0c\u5982local variables, return address, return values, state of registers, parameters\u7b49 - data section     - global variables - heap     - dynamically allocated memory     </p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#22","title":"2.2 \u8fdb\u7a0b\u7684\u72b6\u6001","text":"<p>\u8fdb\u7a0b\u5728\u6267\u884c(execute)\u65f6\u4f1a\u6539\u53d8\u72b6\u6001(state)\uff1a  \u4e00\u4e2a\u5904\u7406\u5668\uff0c\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u53ef\u4ee5running\uff0c\u66f4\u591a\u7684\u5904\u4e8eready\u6216waiting\u72b6\u6001</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#23-process-control-block-pcb-aka-task-control-block","title":"2.3 \u8fdb\u7a0b\u63a7\u5236\u5757Process Control Block (PCB, aka. task control block)","text":"<p>\u8868\u793a\u8fdb\u7a0b\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u6709\u4e14\u4ec5\u6709\u4e00\u4e2aPCB</p> <p>PCB\u5305\u542b\u7684\u5173\u4e8e\u5f53\u524d\u8fdb\u7a0b\u7684\u4fe1\u606f\uff1a - process state \u8fdb\u7a0b\u72b6\u6001 - program counter - CPU registers \u8fdb\u7a0b\u76f8\u5173\u7684\u5bc4\u5b58\u5668\u7684\u503c - CPU scheduling information, properties, scheduling queue pointers, etc. - Memory-management information - Accounting information, CPU \u4f7f\u7528\u65f6\u95f4\uff0c\u65f6\u95f4\u671f\u9650\uff0c\u8bb0\u8d26\u6570\u636e\u7b49 - IO status information, \u5206\u914d\u7ed9\u8fdb\u7a0b\u7684IO\u8bbe\u5907\u5217\u8868\uff0c\u6253\u5f00\u6587\u4ef6\u5217\u8868\u7b49</p> <p>PCB\u7ed3\u6784\u793a\u610f\u56fe  \u4e0d\u540c\u7684\u7cfb\u7edf\u53ef\u80fd\u6709\u4e0d\u540c\u7684PCB\u3002Linux\u4e2d\u7684\u8fdb\u7a0b\u7528\u7ed3\u6784\u4f53task_struct\u5b58\u50a8\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#24-pid","title":"2.4 \u8fdb\u7a0b\u7684\u521b\u5efa\uff0cpid","text":"<p>OS\u901a\u8fc7\u4e00\u4e2a\u552f\u4e00\u7684\u6807\u8bc6\u7b26\uff08process identifier, pid\uff09\u8bc6\u522b\u8fdb\u7a0b\u3002\u4e00\u4e2a\u8fdb\u7a0b\u5728\u8fd0\u884c\u65f6\u53ef\u4ee5\u521b\u5efa\u65b0\u7684\u8fdb\u7a0b\uff0c\u5219\u5b83\u6210\u4e3a\u7236\u8fdb\u7a0b\uff0c\u65b0\u8fdb\u7a0b\u79f0\u4e3a\u5b50\u8fdb\u7a0b\u3002</p> <p>\u7236\u8fdb\u7a0b\u7684pid\u79f0\u4e3a\u5b50\u8fdb\u7a0b\u7684ppid\uff08parent\u2019s pid\uff09\u2192 \u5f62\u6210\u8fdb\u7a0b\u6811\uff08process tree\uff09  \u5f53\u5b50\u8fdb\u7a0b\u521b\u5efa\u65f6\uff0c\u9700\u8981\u7684\u8d44\u6e90\uff08CPU\u65f6\u95f4\u3001\u5185\u5b58\u3001\u6587\u4ef6\u3001IO\u8bbe\u5907\u7b49\uff09\u53ef\u4ee5\u6765\u81eaOS\u4e5f\u53ef\u4ee5\u7ee7\u627f\uff08\u5171\u4eab\uff09\u81ea\u7236\u8fdb\u7a0b\u3002</p> <p>UNIX\u7cfb\u7edf\u901a\u8fc7\u7cfb\u7edf\u8c03\u7528fork()\u521b\u5efa\u65b0\u8fdb\u7a0b\uff0c\u76f8\u5f53\u4e8e\u62f7\u8d1d\u4e86\u4e00\u4efd\u7236\u8fdb\u7a0b\uff0c\u53ea\u6539\u53d8pid\u548cppid\uff0c\u7136\u540e\u628a\u5b50\u8fdb\u7a0b\u5f53\u524d\u5185\u5b58\u4f7f\u7528\u8bb0\u5f55\u8bbe0\u3002fork()\u7ed9\u7236\u8fdb\u7a0b\u8fd4\u56de\u503c\u662f\u5b50\u8fdb\u7a0b\u7684pid\uff0c\u7ed9\u5b50\u8fdb\u7a0b\u8fd4\u56de0\u3002</p> <p>\u4ee3\u7801\u6bb5\uff1acreating a separate process using the UNIX fork() system call.</p> <pre><code>#include &lt;sys/types.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unist.h&gt;\nint main()\n{\n    pid_t pid;\n    /* fork a child process */\n    pid = fork();\n\n    if (pid &lt; 0){\n        /* error occurred */\n        fprintf(stderr, \"Fork Failed\");\n        return 1;\n    }\n    else if (pid == 0) {\n        /* child process */\n        execlp(\"/bin/ls\", \"ls\", NULL);// \u5bf9\u4e8e\u7528\u6237\u7ed9\u51fa\u7684\u6307\u5b9a\u6587\u4ef6\u540d\uff0c\u7a0b\u5e8f\u4f1a\u5728\u5f53\u524dPATH\u73af\u5883\u53d8\u91cf\u4e0b\u641c\u7d22\n    }\n    else {\n        /* parent process */\n        /* parent will wait for the child to complete */\n        wait(NULL);\n        printf(\"child complete\");\n    }\n    return 0;\n}\n\n</code></pre> <p>fork() \u5982\u4f55\u5bf9\u7236\u8fdb\u7a0b\u548c\u5b50\u8fdb\u7a0b\u8fd4\u56de\u4e0d\u540c\u7684\u503c\uff1a\u5f53\u521b\u5efa\u65b0\u8fdb\u7a0b\u65f6\uff0c\u7236\u8fdb\u7a0b\u53ef\u4ee5</p> <ul> <li>\u7ee7\u7eed\u8fd0\u884c\uff08\u548c\u5b50\u8fdb\u7a0b\u5e76\u53d1\u6267\u884c\uff0c\u5373\u540c\u65f6\u6216\u4ea4\u66ff\u8fd0\u884c\uff09\u6216</li> <li>\u7b49\u5f85\u5b50\u8fdb\u7a0b\u8fd0\u884c\u5b8c\u540e\u518d\u8fd0\u884c</li> </ul> <p>\u5b50\u8fdb\u7a0b\u7684\u5730\u5740\u7a7a\u95f4\u6709\u53ef\u80fd</p> <ul> <li>\u4f7f\u7528\u7236\u8fdb\u7a0b\u7684\u62f7\u8d1d\u6216</li> <li>\u52a0\u8f7d\u4e00\u4e2a\u65b0\u7a0b\u5e8f</li> </ul> <p>\u4e3a\u4ec0\u4e48\u8981\u62f7\u8d1d\u4e00\u4efd\uff0c\u6709\u7684\u5b50\u8fdb\u7a0b\u4e0d\u4f1a\u7528copy\u7684\u5730\u5740\u3002\u6240\u4ee5\u90e8\u5206UNIX\u5f15\u5165\u4e86copy-on-write\u673a\u5236\uff0c\u5373\u5c06\u5730\u5740\u7a7a\u95f4\u7684\u590d\u5236\u63a8\u8fdf\u5230\u9700\u8981\u5199\u5165\u7684\u65f6\u5019\u518d\u8fdb\u884c\u3002</p> <p>getpid()\u548cgetppid()\u53ef\u4ee5\u83b7\u5f97\u8fdb\u7a0b\u7684pid\u548cppid\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#25","title":"2.5 \u8fdb\u7a0b\u7684\u7ec8\u6b62","text":"<p>\u8fdb\u7a0b\u8c03\u7528exit()\u5b9e\u73b0\u7ec8\u6b62\u3002\u4e5f\u662fC\u8bed\u8a00main\u51fd\u6570\u8fd4\u56de\u65f6\u9690\u5f0f\u8c03\u7528\u7684\u4e1c\u897f</p> <p>\u5f53\u8fdb\u7a0b\u7ec8\u6b62\u65f6\uff0c\u8fdb\u7a0b\u8fdb\u5165terminated\u72b6\u6001\uff0c\u5176\u8d44\u6e90\u88abOS\u56de\u6536\uff0c\u4f46\u662fpid\uff0c\u7ed3\u675f\u72b6\u6001\uff0c\u8d44\u6e90\u4f7f\u7528\u60c5\u51b5\u4ecd\u7136\u4f1a\u88ab\u4fdd\u5b58\uff0c\u56e0\u4e3a\u7236\u8fdb\u7a0b\u6709\u53ef\u80fd\u4f1a\u8c03\u7528wait()\u6765\u83b7\u53d6\u3002</p> <p>zombie processes: \u5b50\u8fdb\u7a0b\u5df2\u7ec8\u6b62\uff0c\u7236\u8fdb\u7a0b\u8fd8\u6ca1\u6709\u8c03\u7528wait()</p> <p>orphan processes: \u7236\u8fdb\u7a0b\u7ed3\u675f\u4e86\uff0c\u5b50\u8fdb\u7a0b\u6ca1\u7ed3\u675f\u3002\u6709\u4e9bOS\u4f1a\u628a\u5b50\u8fdb\u7a0b\u7ed3\u675f\u6389\uff0cUNIX\u4f1a\u8ba9init\u79f0\u4e3a\u5176\u7236\u8fdb\u7a0b\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#26-ipcinterprocess-communication","title":"2.6 \u8fdb\u7a0b\u95f4\u901a\u4fe1IPC\uff0cInterProcess Communication","text":"<p>\u662f\u4e3a\u4e86\u5728\u8fdb\u7a0b\u7684\u8d44\u6e90\u76f8\u4e92\u9694\u79bb\uff08\uff1f\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u8ba9\u4e0d\u540c\u7684\u8fdb\u7a0b\u80fd\u76f8\u4e92\u8bbf\u95ee\u8d44\u6e90\uff0c\u534f\u8c03\u5de5\u4f5c\u3002</p> <ul> <li>\u5171\u4eab\u5185\u5b58shared memory\uff1a\u4e24\u4e2a\u8fdb\u7a0b\u5404\u6709\u4e00\u5757\u865a\u62df\u5185\u5b58\uff0c\u6620\u5c04\u5230\u540c\u4e00\u5757\u7269\u7406\u5185\u5b58\u3002\u5171\u4eab\u5185\u5b58\u4e5f\u9700\u8981\u4fe1\u53f7\u91cf\u7b49\u540c\u6b65\u624b\u6bb5\u4fdd\u62a4\u3002</li> <li>\u6d88\u606f\u4f20\u9012message passing </li> <li>\u4fe1\u53f7\u91cfsemaphores\uff1a\u672c\u610f\u7528\u6765\u7ebf\u7a0b\u95f4\u540c\u6b65\uff0c\u4f46\u662f\u53ef\u4ee5\u901a\u8fc7sem_open()\u7cfb\u7edf\u8c03\u7528\u6765\u5efa\u7acb\u548c\u7ef4\u62a4\u8fdb\u7a0b\u95f4\u7684\u4fe1\u53f7\u91cf\u3002</li> <li>\u5171\u4eab\u6587\u4ef6</li> <li>\u7ba1\u9053pipe\uff0c\u4e5f\u662f\u4e00\u79cd\u6587\u4ef6\uff0c\u534a\u53cc\u5de5\u4fe1\u9053</li> <li>\u6d88\u606f\u961f\u5217message queue\uff1a\u64cd\u4f5c\u7cfb\u7edf\u7ef4\u62a4\u7684\u94fe\u8868\uff0c\u8fdb\u7a0b\u53ef\u4ee5\u65b0\u5efa\u6216\u8fde\u63a5\u5230\u6d88\u606f\u961f\u5217\uff0c\u5e76\u5199\u5165\u6216\u8bfb\u53d6\u6d88\u606f</li> <li>socket\uff1aTCP/UDP</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#3-scheduling","title":"3. \u8c03\u5ea6Scheduling","text":"<p>\u591a\u9053multiprogramming\u73af\u5883\u4e0b\uff0c\u8fdb\u7a0b\u7684\u4e2a\u6570\u901a\u5e38\u5927\u4e8eCPU\u4e2a\u6570\u3002</p> <p>CPU\u8c03\u5ea6\u662fOS\u5173\u4e8e\u54ea\u4e2aready\u8fdb\u7a0b\u53ef\u4ee5\u8fd0\u884c\u548c\u8fd0\u884c\u591a\u4e45\u7684\u51b3\u5b9a\u3002</p> <p>\u5177\u4f53\u6765\u8bb2\u4e00\u6b21\u8c03\u5ea6\u5e94\u8be5\u662f\u6307OS\u5c06\u4e00\u4e2a\u8fdb\u7a0b\u4ece5\u79cd\u72b6\u6001\u4e2d\u7684\u4e00\u79cd\u5207\u6362\u5230\u4e86\u53e6\u4e00\u79cd\u7684\u8fc7\u7a0b\u3002</p> <p>\u76ee\u6807\u662f\u59cb\u7ec8\u5141\u8bb8\u67d0\u4e2a\u8fdb\u7a0b\u8fd0\u884c\u4ee5\u6700\u5927\u5316CPU\u5229\u7528\u7387\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e00\u5b9a\u516c\u5e73\u6027\u3002</p> <p>\u8c03\u5ea6\u4e0d\u4e00\u5b9a\u662fCPU\u8c03\u5ea6\uff0c\u6709\u53ef\u80fd\u53d1\u751f\u5728\u6240\u6709\u573a\u666f\u3002</p> <p>\u8c03\u5ea6\u7684\u539f\u56e0\u662f\u80fd\u591f\u4f9b\u7ed9\u7684\u8d44\u6e90\u6570\u91cf\u8fdc\u5c0f\u4e8e\u8bf7\u6c42\u7684\u6570\u91cf\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#31","title":"3.1 \u8c03\u5ea6\u7684\u65f6\u673a","text":"<p>CPU\u8c03\u5ea6\u51fa\u73b0\u5728\u4efb\u610f\u4e00\u4e2a\u8fdb\u7a0b\uff0c\u6709\u5982\u4e0b5\u79cd\u8f6c\u6362</p> <ul> <li>running \u2192 waiting, \u5982\u7b49\u5f85IO</li> <li>running \u2192 terminated</li> <li>running \u2192 ready\uff0c\u5f53\u53d1\u751f\u4e86\u4e2d\u65ad\uff0c\u5982\u8ba1\u65f6\u5668\u65f6\u95f4\u5230\u4e86</li> <li>waiting \u2192 ready\uff0c\u5982IO\u5b8c\u6210\u4e86</li> <li>new \u2192 ready</li> </ul> <p>\u597d\u770b\u4e00\u70b9\u7684\u770b\u56fe\u5427  \u8c03\u5ea6\u6309\u65f6\u673a\u5206\u7c7b\u5206\u4e24\u79cd</p> <ul> <li>\u975e\u62a2\u5360\u5f0f\u8c03\u5ea6nonpreemptive\uff1a\u53ea\u4f1a\u505arunning2waiting\u6216\u8005running2terminated\uff0c\u6b64\u65f6\u8fdb\u7a0b\u4e0d\u518d\u8fd0\u884c\u4e86</li> <li>\u62a2\u5360\u5f0f\u8c03\u5ea6preemptive\uff1a\u53d1\u751f\u4e0a\u8ff05\u79cd</li> </ul>  \ud83d\udca1 Q\uff1a\u8c03\u5ea6\u548c\u4e2d\u65ad+\u5f02\u5e38\u7684\u533a\u522b  A\uff1a\uff08\u7528\u6237\u6001\uff09\u8c03\u7528\uff08\u8fdb\u7a0b\uff09\uff0c\u76ee\u6807\u662f\u8fdb\u7a0b\u72b6\u6001\u53d8\u5316\uff1b\uff08\u5185\u6838\u6001\uff09\u5bf9\uff08\u7528\u6237\u6001\uff09\u505atrap\uff0c\u76ee\u6807\u662f\u8c01\u7528CPU  A\uff1a\u5176\u5b9e\u4e2d\u65ad\u7a0b\u5e8f\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u8fdb\u7a0b  \u5728\u6b64\u81f4\u8c22 @isshiki\u4fee \u548c @vinci \u7684\u56de\u7b54"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#32-context-switchin","title":"3.2 \u8fc7\u7a0b\uff08\u4e0a\u4e0b\u6587\u5207\u6362\uff0ccontext switchin\uff09","text":"<p>\u8c03\u5ea6\u7684\u8fc7\u7a0b\u5c31\u662f\u4e0a\u4e0b\u6587\u5207\u6362\uff0c\u611f\u89c9\u8fd9\u4e2a\u540d\u5b57\u8bf4\u7684\u662f\u5bf9\u4e8e\u6b63\u5728\u8fd0\u884c\u7684CPU\u91cc\u7684\u8fdb\u7a0b\uff0c\u6240\u8c13\u4e0a\u4e0b\u6587\u5c31\u662fPCB\u5185\u5bb9\u3002 </p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#33","title":"3.3 \u8c03\u5ea6\u7b97\u6cd5\u8bc4\u4ef7","text":"<ul> <li>Maximize CPU utilization CPU\u4f7f\u7528\u7387\uff1a\u5373CPU\u975e\u7a7a\u95f2\u7684\u65f6\u95f4\u6bd4\u4f8b</li> <li>Maximize Throughput \u541e\u5410\u91cf\uff1a\u6bcf\u4e2a\u65f6\u95f4\u5355\u5143\u5185\u5b8c\u6210\u7684\u8fdb\u7a0b</li> <li>Minimize Turnaround Time \u5468\u8f6c\u65f6\u95f4\uff1a\u4ece\u8fdb\u7a0b\u521b\u7acb\u5230\u8fdb\u7a0b\u5b8c\u6210\u7684\u65f6\u95f4\uff0c\u7b49\u5f85\u8fdb\u5165\u5185\u5b58+\u5728ready queue\u7b49\u5f85+\u5728CPU\u4e0a\u6267\u884c+IO\u6267\u884c+\u2026</li> <li>Minimize Waiting Time \u7b49\u5f85\u65f6\u95f4\uff1a\u5728ready queue\u4e2d\u7b49\u5f85\u6240\u82b1\u7684\u65f6\u95f4\u4e4b\u548c</li> <li>Minimize Response Time \u54cd\u5e94\u65f6\u95f4\uff1a\u4ea4\u4e92\u7cfb\u7edf\u4ece\u8fdb\u7a0b\u521b\u7acb\u5230\u7b2c\u4e00\u6b21\u4ea7\u751f\u54cd\u5e94\u7684\u65f6\u95f4</li> </ul> <p>\u8fd9\u4e9b\u76ee\u6807\u53ef\u80fd\u7684\u51b2\u7a81\uff1a - context switch vs. throughput - context switch vs. response time</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#34","title":"3.4 \u8c03\u5ea6\u7b97\u6cd5","text":"<p>First-come first-serve (FCFS) | Nonpreemptive</p> <p>\u5148\u7533\u8bf7CPU\u7684\u8fdb\u7a0b\u5148\u7528\uff0c\u53ef\u4ee5\u7528\u4e00\u4e2aFIFO\u961f\u5217\u5b9e\u73b0\u3002</p> <p>\u5b83\u4f1a\u5bfc\u81f4convey effort: short process behind long process, \u5c24\u5176\u662f\u5f53\u6709\u7ebf\u7a0b\u8fdb\u5165waiting\u540e\uff0c\u518d\u8fd4\u56de\u7684\u65f6\u5019\u53c8\u8981\u91cd\u65b0\u6392\u961f\u3002</p> <p>Shortest-job-first (SJF)</p> <p>SJF\u7684\u6838\u5fc3\u60f3\u6cd5\u662f\u8ba9\u4e0b\u4e00\u6b21\u8fd0\u884c\u65f6\u95f4\u6700\u77ed\u7684\u8fdb\u7a0b\u5148\u6765\u8fd0\u884c \u21d2 \u80fd\u5f97\u5230\u6700\u5c11\u7684\u5e73\u5747\u7b49\u5f85\u65f6\u95f4</p> <p>\u4e0b\u4e00\u6b21\u8fd0\u884c\u65f6\u95f4 = \uff08\u975e\u62a2\u5360\u5f0f\u8c03\u5ea6\uff09\u8fdb\u7a0b\u603b\u65f6\u95f4\uff08\u56e0\u4e3a\u8fdb\u7a0b\u4e0d\u53ef\u80fd\u88ab\u6253\u65ad\uff09=\uff08\u62a2\u5360\u5f0f\u8c03\u5ea6\uff09\u8fdb\u7a0b\u7684\u5269\u4f59\u8fd0\u884c\u65f6\u95f4</p> <p>\u4f1a\u5206\u5f00\u8ba1\u7b97\u5c31\u884c</p> <p>SJF\u5728\u4e24\u79cd\u8c03\u5ea6\u65b9\u6cd5\u90fd\u80fd\u83b7\u5f97\u6700\u5c0f\u5e73\u5747\u7b49\u5f85\u65f6\u95f4</p> <p>\u95ee\u9898\u662f\u6211\u4eec\u4e0d\u77e5\u9053\u4e0b\u4e00\u6b21\u8fd0\u884c\u65f6\u95f4 \u2192 \u6240\u4ee5\u8981\u731c\uff0c\u731c\u7684\u7b97\u6cd5\u662f\u4e4b\u524dCPU\u6267\u884c\u957f\u5ea6\u7684\u6307\u6570\u5e73\u5747</p> <p>Round-robin (RR) in preemptive</p> <p>\u505a\u6cd5\uff1a\u5b9a\u4e49\u4e00\u4e2a\u65f6\u95f4\u7247\uff08time slice/time quantum\uff09\uff0c\u5373\u4e00\u4e2a\u56fa\u5b9a\u7684\u8f83\u5c0f\u7684\u65f6\u95f4\u5355\u5143\uff0c\u5982\u679cprocess\u4e0d\u662f\u552f\u4e00\u5728ready queue\u4e2d\u7684\u8fdb\u7a0b\uff0c\u90a3\u5c31\u4e0d\u4f1a\u8fde\u7eed\u8fd0\u884c\u8d85\u8fc7\u4e00\u4e2a\u65f6\u95f4\u7247\u7684\u65f6\u95f4\u3002ready queue\u662fFIFO\u7684\u3002</p> <p>\u6027\u80fd\uff1a\u6bd4\u8d77SJF\u5e73\u5747\u7b49\u5f85\u65f6\u95f4\u66f4\u957f\uff0c\u4f46\u662f\u964d\u4f4e\u4e86response time\u3002\u6027\u80fd\u597d\u574f\u57fa\u672c\u4e0a\u53d6\u51b3\u4e8e\u65f6\u95f4\u7247\u5927\u5c0f\uff0cresponse time\u548coverhead\u51b2\u7a81\u3002\u5982\u679c\u65f6\u95f4\u7247\u2192inf\uff0c\u76f8\u5f53\u4e8eRR\u2192FCFS</p> <p>\u65f6\u95f4\u7247\u4e00\u822c\u752810~100ms, context-switch\u4e00\u822c\u82b110mius</p> <p>Priority Scheduling</p> <p>\u4f18\u5148\u8c03\u5ea6\u4f18\u5148\u7ea7\u6700\u9ad8\u7684\u8fdb\u7a0b\uff08\u6839\u636e\u8bfe\u672c\u7684\u4f8b\u5b50\uff0c\u4f18\u5148\u7ea7\u597d\u50cf\u662f\u4e0d\u4f1a\u91cd\u590d\u7684\uff09</p> <p>\u4f18\u5148\u7ea7\u6807\u51c6\uff1a</p> <ul> <li>internal: \u4e00\u4e9b\u6d4b\u91cf\u6570\u636e\uff0c\u5982SJF\u662fpriority\u7684\u4e00\u4e2a\u7279\u4f8b\uff0c\u5373\u4f18\u5148\u7ea7\u7531CPU\u9884\u6d4b\u8fd0\u884c\u65f6\u95f4\u51b3\u5b9a</li> <li>external: \u7528\u6237\u6307\u5b9a</li> </ul> <p>\u53ef\u4ee5\u7528priority queue\u5b9e\u73b0</p> <p>\u53ef\u4ee5\u4e0eRR\u7ed3\u5408\uff0c\u8fd9\u65f6\u5019ready queue\u662f\u7528priority queue\u5b9e\u73b0\u7684</p> <p>Priority Aging\uff1a\u89e3\u51b3indefinite blocking / starvation\uff0c\u5373\u4f4e\u4f18\u5148\u7ea7\u7684\u8fdb\u7a0b\u53ef\u80fd\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u6267\u884c\u3002\u53ef\u4ee5\u6839\u636e\u7b49\u5f85\u65f6\u95f4\u9010\u6e10\u589e\u52a0priority\u3002</p> <p>Multilevel Queue Scheduling</p> <p>\u53ef\u4ee5\u5c06\u8fdb\u7a0b\u5206\u4e3a\u4e0d\u540c\u7684\u7ec4\uff0c\u6bcf\u4e2a\u7ec4\u5185\u6709\u4e0d\u540c\u8c03\u5ea6\u7b97\u6cd5\u7684ready queue\uff0c\u7ec4\u548c\u7ec4\u4e4b\u95f4\u4e5f\u8981\u8c03\u5ea6\u3002</p> <p>\u7ec4\u5185\uff1a\u4e00\u822c\u524d\u53f0\u961f\u5217\u4f7f\u7528RR\u4ee5\u4fdd\u8bc1response\uff0c\u540e\u53f0\u53ef\u4ee5FCFS</p> <p>\u7ec4\u95f4\uff1a\u901a\u5e38\u7ed9\u961f\u5217\u8bbe\u7f6e\u4f18\u5148\u7ea7\uff0c\u7528preemptive priority scheduling\u3002\u4e5f\u53ef\u4ee5\u4f7f\u7528\u7ec4\u95f4time-slicing</p> <p>Multilevel Feedback Queue Scheduling</p> <p>\u4e0a\u4e00\u4e2a\u7248\u672c\u7684\u52a0\u5f3a\u7248\u3002\u5141\u8bb8\u8fdb\u7a0b\u5728\u7ec4\u95f4\u8fc1\u79fb\u3002</p> <p>\u8fc7\u7a0b</p> <ul> <li>\u6309\u7167FCFS\u539f\u5219\uff0c\u8bbe\u7f6eN\u4e2a\u5c31\u7eea\u961f\u5217\u4e3aQ1\uff0cQ2\uff0c\u2026QN\uff0c\u6bcf\u4e2a\u961f\u5217\u4e4b\u95f4\u53ef\u4ee5\u653e\u5f88\u591a\u4f5c\u4e1a</li> <li>\u4e3aN\u4e2a\u5c31\u7eea\u961f\u5217\u8d4b\u4e88\u4e0d\u540c\u4f18\u5148\u7ea7\uff0c\u7b2c\u4e00\u4e2a\u961f\u5217\u4f18\u5148\u7ea7\u6700\u9ad8\uff0c\u7b2c\u4e8c\u4e2a\u961f\u5217\u6b21\u4e4b\uff0c\u5176\u4f59\u9010\u4e2a\u964d\u4f4e</li> <li>\u8bbe\u7f6e\u6bcf\u4e2a\u5c31\u7eea\u65f6\u95f4\u7247\u4f18\u5148\u6743\u8d8a\u9ad8\uff0c\u7b97\u6cd5\u8d4b\u4e88\u961f\u5217\u7684\u65f6\u95f4\u7247\u8d8a\u5c0f\u3002\u6309\u7167\u5b9e\u9645\u4f5c\u4e1a\uff08\u8fdb\u7a0b\uff09\u7684\u9700\u8981\u8c03\u6574</li> <li>\u8fdb\u7a0b\u7b49\u5f85\u65f6\u9996\u5148\u8fdb\u5165\u5f85\u8c03\u5ea6\u7684\u961f\u5217\u7b49\u5f85\u65f6\uff0c\u9996\u5148\u8fdb\u5165\u4f18\u5148\u7ea7\u6700\u9ad8\u7684Q1\u7b49\u5f85</li> <li>\u9996\u5148\u8c03\u5ea6\u4f18\u5148\u7ea7\u6700\u9ad8\u7684\u961f\u5217\u4e2d\u7684\u8fdb\u7a0b\uff0c\u82e5\u9ad8\u4f18\u5148\u7ea7\u4e2d\u961f\u5217\u4e2d\u6ca1\u6709\u5df2\u8c03\u5ea6\u7684\u8fdb\u7a0b\uff0c\u5219\u8c03\u5ea6\u6b21\u4f18\u5148\u961f\u5217\u4e2d\u7684\u8fdb\u7a0b</li> <li>\u5bf9\u4e8e\u4e00\u4e2a\u961f\u5217\u4e2d\u7684\u5404\u4e2a\u8fdb\u7a0b\uff0c\u6309\u7167\uff08\u65f6\u95f4\u7247\u8f6e\u8f6c\u53bb\u8c03\u5ea6\uff09\uff0c\u6bd4\u5982Q1\u7684\u65f6\u95f4\u7247\u4e3aN\uff0c\u90a3\u4e48Q1\u7684\u4f5c\u4e1a\u5728\u7ecf\u5386\u4e86\u65f6\u95f4\u7247\u4e3aN\u7684\u65f6\u95f4\u540e\uff0c\u82e5\u8fd8\u6ca1\u6709\u5b8c\u6210\uff0c\u5219\u8fdb\u5165Q2\uff0c\u8fd9\u6837\u4e00\u76f4\u8fdb\u5165\u4e0b\u4e00\u7ea7\uff0c\u76f4\u5230\u6700\u540e\u4e00\u7ea7\u662fFCFS</li> <li>\u5728\u4f4e\u4f18\u5148\u7ea7\u7684\u961f\u5217\u4e2d\u7684\u8fdb\u7a0b\u5728\u8fd0\u884c\u65f6\uff0c\u53c8\u5230\u8fbe\u65b0\u7684\u4f5c\u4e1a\uff0c\u90a3\u5728\u8fd0\u884c\u5b8c\u8fd9\u4e2a\u65f6\u95f4\u7247\u540e\uff0cCPU\u9a6c\u4e0a\u5206\u914d\u7ed9\u65b0\u5230\u8fbe\u7684\u4f5c\u4e1a\u5373\u62a2\u5360\u5f0f\u8c03\u5ea6CPU</li> </ul> <p>\u8fd9\u79cd\u7b97\u6cd5\u7684performance\u6839\u636e\u5177\u4f53\u64cd\u4f5c\u7cfb\u7edf\u548c\u5177\u4f53\u5b9e\u73b0\u800c\u5f02\u3002 </p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#4-threads","title":"4. \u7ebf\u7a0b threads","text":""},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#41","title":"4.1 \u52a8\u673a\u548c\u6982\u5ff5","text":"<p>\u5f00\u9500\uff1a</p> <ul> <li>\u8fdb\u7a0b\u5728fork\uff08\u521b\u5efa\uff09\u7684\u65f6\u5019\u6709\u8f83\u5927\u7684\u5f00\u9500</li> <li>\u4e0a\u4e0b\u6587\u5207\u6362\u6709\u8f83\u5927\u7684\u5f00\u9500</li> </ul> <p>\u56e0\u4e3a\u82e5\u5e72\u8fdb\u7a0b\u53ef\u80fd\u5171\u4eab\u4e00\u4e9b\u5185\u5bb9\uff0c\u5982\u679cOS\u77e5\u9053\u8fd9\u4e9b\u5171\u4eab\uff0c\u5c31\u80fd\u51cf\u5c11\u65b0\u5efa\u8fdb\u7a0b\u7684\u5f00\u9500\u53ca\u8fdb\u7a0b\u5207\u6362\u7684\u65f6\u5ef6\u3002</p> <p>\u21d2 \u5f15\u5165\u7ebf\u7a0bthreads\uff0c\u7ebf\u7a0b\u5c5e\u4e8e\u8fdb\u7a0b</p> <p>\u5b83\u4e5f\u6709thread id (tid), PC, register set \u548c runtime stack\u3002</p> <p>\u7ebf\u7a0b\u4e0e\u540c\u4e00\u8fdb\u7a0b\u7684\u5176\u5b83\u7ebf\u7a0b\u5171\u4eabcode section, data section, heap, open files, signals</p> <p>Linux\u4e2d\u7ebf\u7a0b\u4e5f\u53eb\u8f7b\u91cf\u7ea7\u8fdb\u7a0bLight Weight Process\u3002</p> <p>\u5982\u679cOS\u652f\u6301\u7ebf\u7a0b\uff0c\u90a3\u8c03\u5ea6\u7684\u5c31\u662f\u5185\u6838\u7ea7\u7ebf\u7a0b\u800c\u4e0d\u662f\u8fdb\u7a0b\uff0c\u4e5f\u5c31\u662f\u8bf4\u7ebf\u7a0b\u662f\u8fd0\u884c\u4ee5\u53caCPU\u8c03\u5ea6\u7684\u57fa\u672c\u5355\u5143\u3002</p> <p>\u533a\u5206\uff1a\u8fdb\u7a0b\u662f\u5206\u914d\u8d44\u6e90\u7684\u57fa\u672c\u5355\u5143</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#42","title":"4.2 \u4f18\u7f3a\u70b9","text":"<p>\u591a\u7ebf\u7a0b\u7f16\u7a0bMulti-Threaded Programming\u7684\u4f18\u70b9\u6709\uff1a</p> <ul> <li>economy\uff1a\u5efa\u7acb\u7ebf\u7a0b\u7ecf\u6d4e\uff0c\u56e0\u4e3acode data heap\u90fd\u5df2\u7ecf\u5728\u5185\u5b58\u91cc\u4e86\uff08\u4e0d\u7528\u518dcopy\uff1f\uff09\uff0c\u53e6\u5916\u540c\u4e00\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u4e4b\u95f4context switch\u4e5f\u4f1a\u66f4\u5feb\uff0c\u56e0\u4e3a\u4e0d\u7528flush cache\u3002</li> <li>resource sharing\uff1a\u540c\u4e00\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u4e4b\u95f4\u5929\u7136\u5171\u4eab\u5185\u5b58\uff0c\u56e0\u6b64\u65e0\u9700\u4e3a\u4e4b\u7f16\u5199IPC\uff0c\u4e5f\u5141\u8bb8\u5bf9\u540c\u4e00\u5757\u5185\u5b58\u8fdb\u884c\u5e76\u884c\u5904\u7406\u3002</li> <li>responsiveness\uff1a\u591a\u7ebf\u7a0b\u8fdb\u7a0b\u4f1a\u6709\u66f4\u597d\u7684\u54cd\u5e94\u6027\u3002</li> <li>scalability\uff1a\u591a\u5904\u7406\u5668\u7684\u4f53\u7cfb\u7ed3\u6784\u4e0a\u591a\u7ebf\u7a0b\u8fdb\u7a0b\u53ef\u4ee5\u66f4\u597d\u53d1\u6325\u4f5c\u7528\uff0c\u56e0\u4e3a\u6bcf\u4e00\u4e2a\u7ebf\u7a0b\u8fd0\u884c\u5728\u4e00\u4e2a\u5904\u7406\u5668\u4e0a\uff0c\u5bf9\u6bd4\u5355\u7ebf\u7a0b\u8fdb\u7a0b\u53ea\u80fd\u8fd0\u884c\u5728\u4e00\u4e2a\u5904\u7406\u5668\u4e0a\u3002</li> </ul> <p>\u7f3a\u70b9</p> <ul> <li>\u4e00\u4e2a\u7ebf\u7a0b\u51fa\u73b0\u9519\u8bef\uff0c\u6574\u4e2a\u8fdb\u7a0b\u90fd\u4f1a\u53bb\u4e16\uff08\u6bd4\u5982\u6d4f\u89c8\u5668\u4e00\u4e2a\u7f51\u9875\u6302\u6389\u4f7f\u6574\u4e2a\u6d4f\u89c8\u5668\u6302\u6389\uff09</li> <li>OS\u5bf9\u6bcf\u4e2a\u8fdb\u7a0b\u5730\u5740\u7a7a\u95f4\u5927\u5c0f\u9650\u5236\uff0c\u4f46\u591a\u7ebf\u7a0b\u4f1a\u5360\u66f4\u591a\u5185\u5b58</li> <li>\u5171\u4eab\u5185\u5b58\u4f7f\u5185\u5b58\u4fdd\u62a4\u53d8\u590d\u6742</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#43","title":"4.3 \u5b9e\u73b0\u65b9\u5f0f\uff1a\u7528\u6237\u7ea7/\u5185\u6838\u6001\uff0c\u591a\u7ebf\u7a0b\u6a21\u578b","text":"<p> - \u7528\u6237\u7ea7\u7ebf\u7a0buser-level thread\uff1a\u5728OS\u4e0a\u53ea\u662f\u4e00\u4e2a\u8fdb\u7a0b\uff0c\u8fd9\u4e2a\u8fdb\u7a0b\u5305\u542b\u7ebf\u7a0b\u5e93thread library\uff0c\u8d1f\u8d23\u7ebf\u7a0b\u7684\u521b\u5efa\u548c\u5207\u6362\uff1b\u5185\u6838\u7ea7\u7ebf\u7a0b\u7531OS\u652f\u6301\u8fd9\u4e9b\u64cd\u4f5c     - \u7528\u6237\u901a\u8fc7OS\u63d0\u4f9b\u7684\u7ebf\u7a0b\u5e93\u51fd\u6570\u521b\u5efa\uff0c     - \u4f18\u70b9\uff1a1\uff09\u4e0d\u5360\u7528OS\u7684tid\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u652f\u6301\u6bd4\u5185\u6838\u7ea7\u7ebf\u7a0b\u66f4\u591a\u7684\u7ebf\u7a0b\u6570 2\uff09\u8c03\u5ea6\u7b49\u64cd\u4f5c\u5728\u7528\u6237\u6001\uff0c\u4e0d\u9700\u8981\u8fdb\u5165\u5185\u6838\u6001 3\uff09\u5bb9\u6613\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7684\u8c03\u5ea6\u7b97\u6cd5     - \u7f3a\u70b9\uff1a1\uff09\u4e00\u65e6\u5f53\u524d\u6b63\u5728\u8fd0\u884c\u7684\u7ebf\u7a0b\u963b\u585e\uff0c\u90a3\u4e48OS\u770b\u6765\u5c31\u662f\u6574\u4e2a\u8fdb\u7a0b\u88ab\u963b\u585e\u4e86\uff0c\u5c31\u4f1a\u8ba4\u4e3a\u8be5\u8fdb\u7a0b\u7684\u5176\u5b83\u7ebf\u7a0b\u4e5f\u963b\u585e\u4e86\u3002\u5982\u679c\u662f\u5185\u6838\u7ea7\u7ebf\u7a0b\u5c31\u53ea\u963b\u585e\u8fd9\u4e2a\u7ebf\u7a0b 2\uff09\u540c\u4e00\u4e2a\u8fdb\u7a0b\u4e2d\u7684\u591a\u4e2a\u7528\u6237\u7ea7\u7ebf\u7a0b\u65e0\u6cd5\u5728\u591a\u6838\u4e0a\u5206\u522b\u8fd0\u884c - \u5185\u6838\u7ea7\u7ebf\u7a0bkernel-level thread\uff1a</p> <p>\u591a\u7ebf\u7a0b\u6a21\u578b\uff1a\u6709\u7684OS\u540c\u65f6\u652f\u6301\u7528\u6237\u7ea7\u548c\u5185\u6838\u7ea7\uff0c\u6709\u51e0\u79cd\u7528\u6237\u7ea7\u548c\u5185\u6838\u7ea7\u7684\u6620\u5c04\u65b9\u6cd5</p> <p>\uff081\uff09\u7b49\u4e8e\u53ea\u652f\u6301\u7528\u6237\u7ea7  \uff082\uff09\u7b49\u4e8e\u53ea\u652f\u6301\u5185\u6838\u7ea7  \uff083\uff09m\u4e2a\u7528\u6237\u7ea7\u53ef\u4ee5\u6620\u5c04\u5230n\u4e2a\u5185\u6838\u7ea7  Linux\u7ebf\u7a0b\uff1a\u6ca1\u6709\u7279\u522b\u533a\u5206\u8fdb\u7a0b\u548c\u7ebf\u7a0b\uff0c\u90fd\u662f\u53ebtask</p> <p>\u4e0d\u77e5\u9053\u8fd9\u91cc\u8003\u4e0d\u8003\u8981\u662f\u8003\u4e86\u56de\u53bbrefer\u4e00\u4e0b</p> <p>5 \u7ebf\u7a0b - \u54b8\u9c7c\u6684\u7684\u4ee3\u7801\u7a7a\u95f4 (xuan-insr.github.io)</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#5-synchronization","title":"5. \u540c\u6b65\u548c\u540c\u6b65\u5de5\u5177 Synchronization","text":"<p>Synchronization\u5c31\u662f\u89c4\u5b9a\u8fdb\u7a0b\u6240\u505a\u7684\u5de5\u4f5c\u4e4b\u95f4\u7684\u987a\u5e8f\u6216\u8005\u5148\u5e8f\u5173\u7cfb\uff0c\u4ece\u800c\u9632\u6b62\u4e00\u4e9b\u975e\u6cd5\u60c5\u51b5\u53d1\u751f\u7684\u65b9\u6cd5\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#51-cs-problem","title":"5.1 \u5f15\u5165\u548cCS Problem","text":"<p>Cooperation process\u662f\u53ef\u4ee5\u5f71\u54cd\u7cfb\u7edf\u4e2d\u5176\u5b83\u8fd0\u884c\u8fdb\u7a0b\u6216\u88ab\u5176\u5b83\u8fdb\u7a0b\u5f71\u54cd\u7684\u8fdb\u7a0b\u3002</p> <p>Cooperating System\u4f1a</p> <ul> <li>\u5171\u540c\u4f7f\u7528\u4e00\u4e9b\u6570\u636e\uff0c\u53ef\u80fd\u662f\u76f4\u63a5\u4f7f\u7528\u540c\u4e00\u6bb5\u5730\u5740\u7a7a\u95f4\uff08\u4ee3\u7801+\u6570\u636e\uff09\uff0c\u6216\u8005\u662f\u901a\u8fc7\u5171\u4eab\u7684\u5185\u5b58\u6216\u4fe1\u606f\u5171\u7528\u4e00\u4e9b\u6570\u636e</li> <li>\u5bf9\u6570\u636e\u7684\u540c\u65f6\u8bbf\u95eeconcurrent access\u53ef\u80fd\u4f1a\u5bfc\u81f4data inconsistency\uff0c\u56e0\u4e3a\u6570\u636e\u7684\u4e00\u81f4\u6027\u9700\u8981cooperating process\u6709\u5e8f\u7684\u8fd0\u884c</li> </ul> <p>e.g. Bounded-buffer problem</p> <p>\u7ed9\u5b9a\u4e24\u4e2a\u8fdb\u7a0bproducer\u548cconsumer\uff0c\u5171\u7528\u5927\u5c0f\u4e3an\u7684buffer\u3002</p> <p>producer\u751f\u4ea7\u6570\u636e\u653e\u5165buffer\uff0cconsumer\u4ecebuffer\u4e2d\u4f7f\u7528\u6570\u636e</p> <p>\u9650\u5b9a\u6761\u4ef6\uff1aproducer\u4e0d\u5e94\u5728buffer\u6ee1\u65f6\u653e\u5165\u6570\u636e\uff0cconsumer\u4e5f\u4e0d\u5e94\u5f53\u5728buffer\u7a7a\u65f6\u53d6\u51fa\u6570\u636e</p> <p>\u60f3\u8c61\u4e2d\u7684\u4e24\u4e2a\u8fdb\u7a0b</p> <pre><code>/* producer process */\nwhile (true){\n    /* produce an item in nert_produced */\n    while (count == BUFFER_SIZE)\n        ; /* do nothing */\n    buffer[in] = next_produced;\n    in = (in+1) % BUFFER_SIZE;\n    count++;\n}\n/* Consumer Process */\nwhile (true){\n    while (count == 0)\n        ; /* do nothing */\n    next_consumed = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    count --;\n    /* consume the item in next_consumed */\n}\n\n</code></pre> <p>\u5982\u679ccount\u7684\u503c\u662f\u9519\u8bef\u7684\uff1f  \u4f8b\u5b50\u7684\u610f\u601d\u662f\uff0c++\u548c\u2014\u90fd\u662f\u7cfb\u7edf\u5b9e\u73b0\u7684\uff0c\u5982\u679c\u5171\u7528count\u8bfb\u53d6\u7684\u65f6\u95f4\u6070\u597d\u649e\u4e0a\uff0ccount\u7684\u503c\u5c31\u4e0d\u5bf9</p> <p>\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\u7684\u539f\u56e0\u662f\u6211\u4eec\u5141\u8bb8\u4e24\u4e2a\u8fdb\u7a0b\u540c\u65f6\u64cd\u7eb5\u53d8\u91cfcount\u3002</p> <p>e.g. kernel\u4e2d\uff1a\u4e24\u4e2a\u8fdb\u7a0b P0\u00a0\u548c P1\u00a0\u540c\u65f6\u00a0<code>fork()</code>\u00a0\u65f6\uff0c\u5982\u679c\u4e0d\u52a0\u9650\u5236\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u7c7b\u4f3c\u524d\u4f8b\u7684\u60c5\u51b5\uff0c\u5373\u5728\u67d0\u4e00\u4e2a\u8fdb\u7a0b\u628a\u5f53\u524d\u7684\u00a0<code>next_avaliable_pid</code>\u00a0\u5206\u914d\u7ed9\u4ed6\u7684 child \u540e\uff0c\u5728\u6ca1\u6765\u5f97\u53ca\u66f4\u65b0\u00a0<code>next_avaliable_pid</code>\u00a0\u524d\uff0c\u53e6\u4e00\u4e2a\u8fdb\u7a0b\u4f7f\u7528\u4e86\u00a0<code>next_avaliable_pid</code>\u00a0\u6765\u7ed9 child \u5206\u914d PID\uff0c\u8fd9\u5c31\u4f1a\u5bfc\u81f4\u4e24\u4e2a\u4e0d\u540c\u7684\u7ebf\u7a0b\u4f7f\u7528\u540c\u4e00\u4e2a PID \u7684\u60c5\u51b5\u3002</p> <p>Race Condition\uff1a\u591a\u4e2a\u8fdb\u7a0b\u540c\u65f6\u64cd\u63a7\u4e00\u4e2a\u6570\u636e\uff0c\u7531\u64cd\u63a7\u51fa\u73b0\u7684\u987a\u5e8f\u51b3\u5b9a\u7ed3\u679c</p> <p>\u5fc5\u987b\u4fdd\u8bc1\u540c\u4e00\u4e2a\u65f6\u95f4\u53ea\u80fd\u6709\u4e00\u4e2a\u8fdb\u7a0b\u64cd\u63a7\u67d0\u4e2a\u53d8\u91cf\u3002</p> <p>The Critical-Section Problem \uff08CS Problem\uff09</p> <p>\u8003\u8651\u4e00\u4e2a\u6709n\u4e2a\u8fdb\u7a0b\u7684\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u4e2d\u90fd\u6709\u4e00\u6bb5\u4ee3\u7801\u53ef\u80fd\u4fee\u6539\u5176\u4ed6\u81f3\u5c11\u4e00\u4e2a\u8fdb\u7a0b\u516c\u7528\u7684\u6570\u636e\uff0c\u79f0\u4e3acritical section\u3002\u8fd9\u4e2a\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u7684\u91cd\u8981\u6027\u8d28\u662f\uff0c\u5f53\u4e00\u4e2a\u8fdb\u7a0b\u6b63\u5728\u8fd0\u884ccritical section\u65f6\uff0c\u5176\u5b83\u8fdb\u7a0b\u90fd\u4e0d\u80fd\u8fdb\u5165critical section</p> <p>\u5c06\u8fd9\u4e2a\u95ee\u9898\u79f0\u4e3acritical section problem\uff0c\u4e5f\u5c31\u662f\u8981\u8bbe\u8ba1\u4e00\u79cd\u8fbe\u6210\u4e00\u81f4\u884c\u7684\u65b9\u6cd5\u3002\u6216\u8005\u8bf4\u8bbe\u8ba1\u4e00\u79cd\u8ba9\u5404\u79cd\u8fdb\u7a0b\u540c\u6b65\u4ece\u800c\u5b89\u5168\u5171\u4eab\u6570\u636e\u7684\u534f\u8bae\u3002</p> <p>\u8fd9\u6bb5\u7a0b\u5e8f\u7684\u793a\u610f\u56fe\u5982\u4e0b\uff1a  \u6bcf\u4e2a\u8fdb\u7a0b\u5fc5\u987b\u5728entry section\u4e2d\u7533\u8bf7\u8fdb\u5165critical section\u7684\u8bb8\u53ef\uff1b\u5728critical section\u8fd0\u884c\u7ed3\u675f\u540e\u8fdb\u5165exit section\uff0c\u5728\u8fd9\u91cc\u8bb8\u53ef\u88ab\u91ca\u653e\u3002</p> <p>\u2757\u2757\u2757</p> <p>Critical section problem\u7684\u89e3\u51b3\u65b9\u6cd5\u5fc5\u987b\u6ee1\u8db3\u5982\u4e0b\u4e09\u4e2a\u8981\u6c42</p> <ul> <li>Mutual exclusion\uff1a\u6ca1\u6709\u4e24\u4e2a\u8fdb\u7a0b\u53ef\u4ee5\u540c\u65f6\u5728\u8fd0\u884ccritical section</li> <li>Progress\uff1a\u7cfb\u7edf\u6574\u4f53\u4e0a\u662f\u5728\u8fd0\u884c\u7684<ul> <li>\u8981\u4e48\u6709\u4e00\u4e2a\u8fdb\u7a0b\u5728\u8fd0\u884c\u5b83\u7684critical section</li> <li>\u8981\u4e48\u6ca1\u6709\u8fdb\u7a0b\u5728critical section</li> <li>\u8981\u4e48\u6709\u9650\u65f6\u95f4\u5185\u8981\u6709\u4e00\u4e2a\u8fdb\u7a0b\u88ab\u9009\u5165\u5b83\u7684critical section</li> </ul> </li> <li>Bounded waiting\uff1a\u4efb\u4f55\u4e00\u4e2a\u8fdb\u7a0b\u7b49\u5f85\u8fdb\u5165critical section\u7684\u65f6\u95f4\u662f\u6709\u9650\u7684\u3002\u5373\u5f53\u4e00\u4e2a\u8fdb\u7a0b\u8fdb\u5165critical section\u7684\u8bf7\u6c42\u540e\uff0c\u53ea\u6709\u6709\u9650\u4e2a\uff08\u6b21\uff09\u8fdb\u7a0b\u4f1a\u5728\u5b83\u4e4b\u524d\u8fdb\u5165critical section\u3002</li> </ul> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u4ecb\u7ecd\u7684\u7b97\u6cd5\u90fd\u662f\u5728\u4e00\u6b65\u4e00\u6b65\u6ee1\u8db3\u8fd9\u4e09\u4e2a\u8981\u6c42</p> <p>Kernel\u4e2d\u7684CS Problem</p> <ul> <li>\u5bf9\u4e8e\u5355\u6838\u7cfb\u7edf\uff1a\u53ef\u4ee5\u5728entry section\u4e2d\uff0c\u5bf9critical section\u7981\u6b62\u4e2d\u65ad\uff0c\u7136\u540e\u5728exit section\u4e2d\u6062\u590d</li> <li>\u5bf9\u4e8e\u591a\u6838\u7cfb\u7edf\uff1a\u4e2d\u65ad\u6d88\u606f\u9700\u8981\u4f20\u5230\u6240\u6709\u5904\u7406\u5668\uff0c\u6d88\u606f\u4f20\u9012\u4f1a\u5ef6\u8fdf\u8fdb\u5165\u4e34\u754c\u533a\uff0c\u4f1a\u964d\u4f4e\u6548\u7387\u3002\u540c\u65f6\u4e5f\u5f71\u54cd\u65f6\u949f\u4e2d\u65ad\u3002</li> </ul> <p>\u9700\u8981\u4fdd\u8bc1kernel\u7684\u8bbe\u8ba1\u5b9e\u73b0\u4e86critical section</p> <p>kernel\u7684\u5b9e\u73b0\u5206\u4e24\u79cd\u7c7b\u578b\uff1a</p> <ul> <li>\u62a2\u5360\u5f0f\u5185\u6838 preemptive kernel</li> <li>\u975e\u62a2\u5360\u5f0f\u5185\u6838 nonpreemptive kernel</li> </ul> <p>\u533a\u522b\u662f\u662f\u5426\u5141\u8bb8kernel mode\u88ab\u62a2\u5360</p> <p>\u62a2\u5360\u5f0f\u5185\u6838\u66f4\u96be\u8bbe\u8ba1\uff0c\u4f46\u540c\u65f6\u4e5f\u54cd\u5e94\u66f4\u5feb\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#52-petersons-solution","title":"5.2 Peterson\u2019s Solution","text":"<p>\u7701\u6d41\uff1a\u8ba9\u4e24\u4e2a\u8fdb\u7a0b\u5171\u4eab\u4e00\u4e2a\u53d8\u91cf\uff0c\u65e2\u6709turn\uff08\u8f6e\u5230\u8c01\u80fd\u8fdb\u53bb\uff09\u4e5f\u6709flag\uff08\u8fdb\u7a0b\u662f\u5426ready\uff09\u3002\u5f53flag[\u67d0\u4e2a\u8fdb\u7a0b]\u4e14turn=\u8be5\u8fdb\u7a0b\uff0c\u5c31\u53ef\u4ee5\u8fdb\u53bb\u3002</p>  \ud83d\udca1 \u60f3\u8981\u7406\u89e3PS\u7b97\u6cd5\uff0c\u8bf7\u60f3\u8c61\u4e24\u4e2a\u4eba\u4e92\u76f8\u8ba9\u5ea7\uff0cA\u5148\u8bf4\u4f60\u5750\u5427\uff0cB\u518d\u8bf4\u4f60\u5750\u5427\uff0c\u8fd9\u65f6A\u5750\u4e0b\u3002  A\u83b7\u5f97\u6905\u5b50\u6709\u4e24\u4e2a\u5145\u8981\u6761\u4ef6\uff1a  A\u60f3\u5750: flag[A] = 1  \u5728B\u8ba9\u5ea7\u4e4b\u524d\uff0cA\u5df2\u7ecf\u8ba9\u8fc7\u5ea7\u4e86: turn \u2260 A \u8bf4\u660e\u4e4b\u524dturn\u66fe\u7ecf\u88ab\u8d4b\u4e3aA\uff0c\u73b0\u5728\u662fB   <pre><code>int turn;         // who is allowed to enter\nboolean flag[2];  // ready to enter its CS\n\nvoid foo(){\n    while (true){\n        flag[i] = true; // mark self ready\n        turn = 1-i;     // assert that if the other process wishes to enter its CS, it can do so;\n        while (flag[1-i] &amp;&amp; turn = 1-i); // wait\n        /* critical section */\n        flag[i] = false;  // set ready to false\n        /* reminder section */\n    }\n}\n\n</code></pre> <p>\u5176\u4e2d <code>i</code> \u662f0\u62161\uff0c\u8868\u793a\u7b2ci\u4e2a\u8fdb\u7a0b\u3002 <code>turn</code> \u662f\u5f53\u524d\u6709\u6743\u8fdb\u5165critical section\u7684\u8fdb\u7a0b\uff080\u62161\uff09; <code>flag</code> \u662f\u7b2ci\u4e2a\u8fdb\u7a0b\u662f\u5426\u51c6\u5907\u597d\u8fdb\u5165critical section\uff0c\u521d\u59cb\u503c\u5747\u4e3aFALSE\u3002</p> <p>To enter the critical section, process Pi first sets <code>flag[i]</code> to be true and then sets <code>turn</code> to the value <code>1-i</code> (the other process), thereby asserting that is the other process wishes to enter the critical section, it can do so. If both processes try to enter at the same time, <code>turn</code> will be set to both <code>0</code> and <code>1</code> at roughly the same time. Only one of these assignments will last; the other will occur but will be overwritten immediately. The eventual value of <code>turn</code> determines which of the two processes is allowed to enter its critical section first.</p> <p>Peterson\u2019s Solution\u6ee1\u8db3\u540c\u6b65\u7b97\u6cd5\u5fc5\u987b\u6ee1\u8db3\u7684\u4e09\u4e2a\u6027\u8d28\uff1a</p> <ul> <li>Mutual exclusion \u4e92\u65a5<ul> <li>\u7528\u4e86\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u4e0d\u53ef\u80fd\u6709\u4e24\u4e2a\u8fdb\u7a0b\u540c\u65f6\u8fdb\u5165Critical Section</li> </ul> </li> <li>Progress Requirement \u7a7a\u95f2\u8ba9\u8fdb<ul> <li>\u5982\u679c\u6ca1\u6709\u8fdb\u7a0b\u5728CS\uff0c\u800c\u6709\u4e00\u4e9b\u8fdb\u7a0b\u5728Enter section\uff0c\u4e0d\u80fd\u8ba9\u60f3\u8981\u8fdb\u5165CS\u7684\u8fdb\u7a0b\u65e0\u9650\u7b49\u5f85</li> <li>\u7ecf\u8fc7\u6709\u9650\u6b21\u7b49\u5f85\u4ee5\u540e\uff0c\u9700\u8981\u8fdb\u5165\uff0c\u907f\u514dStarvation</li> </ul> </li> <li>Bounded Waiting \u8ba9\u6743\u7b49\u5f85<ul> <li>\u662f\u5426\u80fd\u8fdb\u5165critical section\u9700\u8981\u5176\u5b83\u8fdb\u7a0b\u6765\u51b3\u5b9a</li> </ul> </li> </ul> <p>Bakery Algorithm\uff1a</p> <p>2\u4e2a\u8fdb\u7a0b\u7248\u672c\u7684PS\u3002\u9700\u8981\u904d\u5386\u6240\u6709\u8fdb\u7a0b\u67e5\u770b\u5927\u5bb6\u7684turn </p> <p>Reordering \u91cd\u6392\u5e8f</p> <p>PS\u7684\u7f3a\u70b9\u662f\u5728\u73b0\u4ee3\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u4e0a\u4e0d\u4e00\u5b9a\u9002\u7528\u3002\u56e0\u4e3a\u73b0\u4ee3\u7684\u5904\u7406\u5668\u548c\u7f16\u8bd1\u5668\u53ef\u80fd\u4f1a\u4e3a\u4e86\u4f18\u5316\u6027\u80fd\u800c\u5bf9\u4e00\u4e9b\u8bfb\u5199\u64cd\u4f5c\u8fdb\u884c\u91cd\u6392\u3002</p> <p>\u91cd\u6392\u7684\u65f6\u5019\u4f1a\u8003\u8651\u91cd\u6392\u5728\u5355\u7ebf\u7a0b\u7a0b\u5e8f\u4e2d\u7684\u5408\u7406\u6027\uff08\u8ba1\u7b97\u7ed3\u679c\u662f\u7a33\u5b9a\u4e14\u6b63\u786e\u7684\uff09\u3002\u4f46\u662f\u8fd9\u6837\u4e0d\u80fd\u4fdd\u8bc1\u5728\u591a\u7ebf\u7a0b\u5171\u7528\u6570\u636e\u65f6\u7684\u6b63\u786e\u6027\uff0c\u53ef\u80fd\u5728\u591a\u7ebf\u7a0b\u5171\u7528\u65f6\u51fa\u73b0\u4e0d\u786e\u5b9a\u6216\u4e0d\u5bf9\u7684\u8f93\u51fa\u3002</p> <p>e.g. \u7f16\u8bd1\u5668\u548c\u5904\u7406\u5668\u53ef\u80fd\u4f1a\u5bf9\u6570\u636e\u8bfb\u53d6\u987a\u5e8f\u8fdb\u884creorder\uff0c\u4ee5\u4f7f\u4e0d\u9700\u8981\u4ea4\u66ff\u8bfb\u53d6\u4e24\u4e2a\u6570\u636e\u7684\u503c\uff0c\u800c\u662f\u76f8\u540c\u8bfb\u53d6\u653e\u5728\u4e00\u8d77\u3002</p> <p>\u4e3a\u4e86\u89e3\u51b3\u91cd\u6392\u5e8f\u5bfc\u81f4\u7684\u5728\u591a\u7ebf\u7a0b\u4e0b\u4e0d\u7a33\u5b9a\uff0c\u6211\u4eec\u5f15\u5165\uff1a</p> <p>Memory Barrier</p> <p>\u5b83\u7528\u6765\u4fdd\u8bc1\u5176\u4e4b\u524d\u7684\u5185\u5b58\u8bbf\u95ee\u5148\u4e8e\u4e4b\u540e\u7684\u5b8c\u6210\u3002\u5373\uff0c\u5728\u67d0\u4e2a\u64cd\u4f5c\u524d\uff0c\u5185\u5b58\u7684\u6539\u53d8\u5bf9\u5176\u5b83\u5904\u7406\u5668\u4e0a\u7684\u8fdb\u7a0b\u90fd\u662f\u53ef\u89c1\u7684\u3002</p> <p>\u52a0memory barrier\u7684\u4e00\u79cd\u65b9\u6cd5</p> <pre><code>while (!flag)\n    memory_barrier();\nprint x;\n\n</code></pre> <p>\u8fd9\u6837\u5c31\u4fdd\u8bc1\u4e86flag\u5728x\u4e4b\u524d\u88ab\u52a0\u8f7d\u4e86\u3002</p> <p>Memory Model</p> <p>\u53e6\u5916\uff0c\u5728\u73b0\u4ee3\u7684\u4f53\u7cfb\u7ed3\u6784\u4e0a\uff0c\u4e00\u4e2a\u7ebf\u7a0b\u5199\u4e86\u5bf9\u5e94\u7684\u53d8\u91cf\u540e\u53ef\u80fd\u4e0d\u4f1a\u7acb\u5373\u5199\u56de\u5185\u5b58\uff0c\u8fd9\u4e5f\u6709\u53ef\u80fd\u5bfc\u81f4\u95ee\u9898\u3002</p> <p>\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u51b3\u5b9a\u54ea\u5757\u5185\u5b58\u7ed9\u54ea\u4e2a\u7a0b\u5e8f\u7684\u65b9\u6cd5\uff0c\u53eb\u505amemory model\u3002memory model\u6709\u4e24\u79cd\u7c7b\u578b</p> <ul> <li>Strongly ordered: a memory modification on one processor is immediately visible to all other processors.</li> <li>Weakly ordered: modification to other memory on one processor may not be immediately visible to other processors.</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#53","title":"5.3 \u786c\u4ef6\u6307\u4ee4","text":"<p>\u6709\u4e24\u4e2a\u786c\u4ef6\u6307\u4ee4\u80fd\u5e2e\u52a9\u5b9e\u73b0\u4e92\u65a5\u548c\u540c\u6b65</p> <p>\u8bb8\u591a\u73b0\u4ee3\u7cfb\u7edf\u63d0\u4f9b\u786c\u4ef6\u6307\u4ee4\u6765\u4fee\u6539word\u7684\u5185\u5bb9\uff0c\u6216\u8005\u7528\u4e8eatomically (uniterruptably\uff0c\u4e0d\u53ef\u88ab\u6253\u65ad\u5730)\u4ea4\u6362\u4e24\u4e2aword\u3002</p> <p>\u7528\u6237\u4e00\u822c\u4e0d\u7528\u5173\u5fc3\u7279\u5b9a\u673a\u5668\u6307\u4ee4\uff0c\u53ef\u4ee5\u7528\u6307\u4ee4 <code>test_and_set()</code> \u548c <code>compare_and_swap()</code> \u62bd\u8c61\u4e86\u89e3\u8fd9\u4e9b\u673a\u5668\u6307\u4ee4\u80cc\u540e\u7684\u542b\u4e49\u3002</p> <p><code>test_and_set</code> \u7684\u5b9a\u4e49\u662f\u628a\u4e00\u4e2atrue\u8f93\u5165\u5230\u786c\u4ef6\uff0c\u5e76\u4e14\u628a\u53d8\u91cf\u539f\u6765\u7684\u503c\u8fd4\u56de\u3002\u5b83\u662f\u4e00\u4e2a\u57fa\u672c\u6307\u4ee4\u5668\u4ef6\u3002</p> <pre><code>bool test_and_set(bool *target) {\n    bool rv = *target;\n    *target = true;\n    return rv;\n}\n\n</code></pre> <p>\u5b83\u7684\u91cd\u8981\u7279\u5f81\u662f\uff0c\u5b83\u7684\u6267\u884c\u662fatomic\u7684\u3002</p> <p>\u8fd9\u4e2a\u6307\u4ee4\u53ef\u4ee5\u7528\u6765\u5b9e\u73b0mutual exclusive: \u5b9a\u4e49\u4e00\u4e2abool\u53d8\u91cf <code>lock</code>\uff0c\u521d\u59cb\u5316\u4e3afalse\u3002</p> <p>\u4e3a\u4ec0\u4e48\u53ef\u4ee5\uff1a\u5982\u679c\u00a0<code>lock</code>\u00a0\u5728 Entry Section \u65f6\u4e3a true\uff0c\u90a3\u4e48\u00a0<code>test_and_set(&amp;lock)</code>\u00a0\u5c06\u8fd4\u56de true\uff0c\u56e0\u6b64\u4f1a\u59cb\u7ec8\u5728 while \u5faa\u73af\u4e2d\u8be2\u95ee\u3002\u76f4\u5230\u67d0\u4e2a\u65f6\u523b\u00a0<code>lock</code>\u00a0\u4e3a false\uff0c\u90a3\u4e48\u00a0<code>test_and_set(&amp;lock)</code>\u00a0\u5c06\u8fd4\u56de false \u540c\u65f6\u5c06\u00a0<code>lock</code>\u00a0\u7f6e\u4e3a true\uff0c\u8fdb\u7a0b\u8fdb\u5165 Critical Section\uff0c\u540c\u65f6\u4fdd\u8bc1\u5176\u4ed6\u8fdb\u7a0b\u65e0\u6cd5\u8fdb\u5165 Critical Section\u3002\u5f53\u6301\u9501\u7684\u8fdb\u7a0b\u5b8c\u6210 Critical Section \u7684\u8fd0\u884c\uff0c\u5b83\u5728 Exit Section \u4e2d\u91ca\u653e\u00a0<code>lock</code>\u00a0\uff0c\u4ece\u800c\u5141\u8bb8\u5176\u4ed6\u8fdb\u7a0b\u8fdb\u5165 Critical Section\u3002\u800c\u5982\u679c\u67d0\u4e2a\u65f6\u523b\u00a0<code>lock</code>\u00a0\u4e3a false\uff0c\u800c\u6709\u4e24\u4e2a\u6216\u591a\u4e2a\u8fdb\u7a0b\u51e0\u4e4e\u540c\u65f6\u8c03\u7528\u4e86\u00a0<code>test_and_set(&amp;lock)</code>\u00a0\u3002\u4f46\u7531\u4e8e\u5b83\u662f atomic\uff08none-or-all\uff09\u7684\uff0c\u56e0\u6b64\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u53ef\u4ee5\u8fd4\u56de false\u3002</p> <p>\u4e0d\u80fd\u5b9e\u73b0bounded waiting\u600e\u4e48\u529e\uff0c\u6709\u7684\u8fdb\u7a0b\u53ef\u80fd\u5c31\u4e00\u76f4\u6ca1\u6709\u62ff\u5230\u9501\uff1a\u52a0\u4e00\u4e2a\u5faa\u73af\u904d\u5386\u627e\u4e0b\u4e00\u4e2a\u53ef\u4ee5\u8fdb\u5165\u7684\u8fdb\u7a0b\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u6700\u591a\u7b49\u5168\u90e8\u904d\u5386\u5b8c\u4e00\u904d\u5c31\u8f6e\u5230\u81ea\u5df1</p> <pre><code>while (true){\n    /* Entry Section */\n    while (test_and_set(&amp;lock))\n        ; /* do something */\n    /* Critical Section */\n\n    /* Exit Section */\n    j = (i + 1) % n;\n    while ((j != i) &amp;&amp; !waiting[j]))\n        j = (j + 1) % n;\n    if (j == i)\n        lock = false;\n    else\n        waiting[j] = false;\n\n    /* Remainder Section */\n\n}\n\n</code></pre> <p><code>compare_and_swap()</code> \u7528\u8f6f\u4ef6\u6765\u5b9e\u73b0\u6027\u80fd\u975e\u5e38\u5dee\uff0c\u7528\u8f6f\u4ef6\u6765\u5b9e\u73b0\u4f1a\u53d8\u597d\u3002\u5b83\u7684\u5b9a\u4e49\u662f</p> <pre><code>int compare_and_swap(int *value, int expected, int new_value){\n    int temp = *value;\n    if (*value == expected)\n        *value = new_value;\n    return temp;\n}\n\n</code></pre> <p>\u53ef\u89c1\u5176\u5b9e<code>compare_and_swap()</code> \u4e0e<code>test_and_set()</code> \u4f5c\u7528\u7c7b\u4f3c\u3002</p> <p>\u7528<code>compare_and_swap()</code> \u5b9e\u73b0mutual exclusive</p> <pre><code>while (true) {\n    /* Entry Section */\n    while (compare_and_swap(&amp;lock, 0, 1) != 0)\n        ; /* do nothing */\n\n    /* Critical Section */\n\n    /* Exit Section */\n    lock = 0;\n\n    /* Remainder Section */\n}\n\n</code></pre>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#54-semaphores","title":"5.4 \u4fe1\u53f7\u91cf Semaphores","text":"<p>\u662f\u4e00\u4e2a\u6574\u578b\u53d8\u91cf\uff0c\u9664\u4e86\u521d\u59cb\u5316\u5916\uff0c\u53ea\u80fd\u901a\u8fc7\u4e24\u4e2aatomic\u64cd\u4f5c <code>wait()</code> \u548c <code>signal()</code> \u6765\u8bbf\u95ee\u3002</p> <pre><code>void wait(S){\n    while (S &lt;= 0)\n        ; /* busy waiting */\n    S--;\n}\nvoid signal(S){\n    S++;\n}\n\n</code></pre> <p>\u6709\u4e24\u79cdsemaphore\uff1a</p> <ul> <li>counting semaphore\uff1aS\u7684\u503c\u4e0d\u53d7\u9650\u5236</li> <li>binary semaphore: S\u7684\u503c\u53ea\u80fd\u662f0\u62161\uff0c\u7c7b\u4f3c\u4e0e\u4e92\u65a5\u9501\u3002</li> </ul> <p>e.g. Consider P1 and P2 that require S1 to happen before S2, create a semaphore \u201csynch\u201d initialized to 0.</p> <pre><code>P1:\n    S1;\n    signal(synch);\nP2:\n    wait(synch);\n    S2;\n\n</code></pre> <p>\u5982\u679c\u60f3\u8981\u89e3\u51b3semaphore\u7684busy waiting\u95ee\u9898\uff0c\u53ef\u4ee5\u5f15\u5165waiting queue</p> <pre><code>typedef struct {\n    int value;\n    struct list_head * waiting_queue;\n} semaphore;\n\nwait(semaphore *S) {\n    S-&gt;value--;\n    if (S-&gt;value &lt; 0) {\n        add this process to S-&gt;list;\n        block();\n    }\n}\nsignal(semaphore *S) {\n    S-&gt;value++;\n    if (S-&gt;value &lt;= 0) {\n        remove a process P from S-&gt;list;\n        wakeup(P);\n    }\n}\n\n</code></pre> <p>\u53ef\u80fd\u4f1a\u5bfc\u81f4deadlock</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#55-atomic-variable","title":"5.5 Atomic Variable","text":"<p>\u90a3\u5c31\u76f4\u63a5\u7528<code>compare_and_swap()</code> \u6765\u505a\u6210\u4e00\u4e9batomic\u7684\u673a\u5668\u6307\u4ee4\u5de5\u5177</p> <p>e.g. count++ \u662f\u53ef\u4ee5\u6253\u65ad\u7684\uff0c\u4f46\u662f\u53ef\u4ee5\u8bbe\u8ba1\u4e00\u4e2a\u4e0d\u53ef\u6253\u65ad\u7684increment(&amp;count)</p> <pre><code>void increment(atomic_int *v){\n    int temp;\n    do {\n        temp = *v;\n    } while (temp != compare_and_swap(v, temp, temp+1));  // \u5b83\u4e0d\u4f1a\u88ab\u6253\u65ad\n}\n\n</code></pre> <p>\u8981\u8bb0\u5f97\u5b83\u53ea\u80fd\u89e3\u51b3\u53d8\u91cf\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u7684race condition\u3002\u6b64\u65f6\u53ea\u6709\u5f85\u66f4\u65b0\u53d8\u91cf\u4e00\u4e2a\u53d8\u91cf\u5728\u7b49\u5f85\u8bfb\u53d6\u3002\u5982\u679c\u6709\u4e24\u4e2aconsumer\u7b49\u5f85\u8bfb\u53d6\uff0c\u4f46count\u6539\u53d8\u65f6\u53ea\u4f1a\u4ea7\u751f\u4e00\u4e2a\u503c\u5728buffer\u91cc\uff0c\u90a3\u5c31\u4e0d\u884c\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#56-mutex-mutual-exclusion-lock","title":"5.6 Mutex (Mutual Exclusion Lock)","text":"<p>\u7528\u8f6f\u4ef6\u65b9\u6cd5\u89e3\u51b3CS\u3002</p> <p>\u8ba9\u8fdb\u7a0b\u5148\u5728entry section\u7533\u8bf7acquire()\u4e00\u4e2a\u9501\uff0c\u7136\u540e\u5728exit section release()\u4e00\u4e2a\u9501\u3002\u7136\u540e\u7528\u4e00\u4e2abool\u53d8\u91cf\u6765\u770b\u5b83\u662f\u5426available</p> <pre><code>while (true){\n    acquire();\n    /* critical section */\n    release();\n    /* remainder section */\n}\n\nvoid acquire(){\n    while (!available)\n    ; /* busy waiting */\n    available = false;\n}\n\nvoid release(){\n    availble = true;\n}\n\n</code></pre> <p>\u56e0\u4e3a\u8fd8\u9700\u8981\u4fdd\u8bc1\u4e92\u65a5\uff0c\u9700\u8981\u4fdd\u8bc1acquire\u662f\u539f\u5b50\u6027\u7684\uff0c\u90a3\u5c31\u7528\u4e0a\u8ff0\u4e24\u4e2a\u786c\u4ef6\u5de5\u5177\u6765\u5b9e\u73b0\u3002\u4ee3\u7801\u540c\u5bf9\u5e94\u8282\uff0c\u4e0d\u8d58\u8ff0\u3002</p> <p>\u7f3a\u70b9\uff1a\u9700\u8981busy waiting\uff0c\u5f53\u6709\u4e00\u4e2a\u8fdb\u7a0b\u5728CS\u4e2d\u65f6\uff0c\u5176\u5b83\u8fdb\u7a0b\u9700\u8981\u5728acquire()\u4e2dspin\uff0c\u6240\u4ee5\u4e5f\u79f0\u4e3aspinlock\u3002\u5982\u679c\u6709N\u4e2a\u8fdb\u7a0b\u540c\u65f6\u4f7f\u7528\u4e00\u4e2aCPU\uff0c\u90a3\u4e48\u5c06\u5927\u7ea6\u6709(N-1)/N\u7684\u6d6a\u8d39\u3002\u5982\u679c\u6709\u8fdb\u7a0b\u5728\u4f01\u56feacquire\u4e00\u4e2a\u9501\u65f6\u88ab\u7ec4\u7ec7\uff0c\u79f0\u5b83\u4e3acontended\uff08\u88ab\u4e89\u593a\uff09\uff1b\u53cd\u4e4b\u79f0\u4e3auncontended\u3002</p> <p>\u8fd8\u53ef\u4ee5\u8003\u8651\u4e0b\u9762\u7684\u8bbe\u8ba1\uff0c\u5176\u4e2dyield()\u4f1a\u4f7f\u7a0b\u5e8f\u4ecerunning\u8f6c\u4e3aready\uff0c\u4ece\u800c\u8ba9\u51faCPU</p> <pre><code>void acquire() {\n    while (compare_and_swap(&amp;avaliable, 1, 0) != 1)\n        yield();\n}\n\nvoid release() {\n    avaliable = true;\n}\n\n</code></pre> <p>\uff08\u8fd9\u4e2a\u5730\u65b9\u771f\u7684\u771f\u7684\u6ca1\u770b\u61c2\uff09</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#57-priority-inversion","title":"5.7 Priority Inversion","text":"<p>e.g.</p> <p>Three processes PL, PM and PN with priority PL &lt; PM &lt; PH.</p> <p>PL holds a lock that was requested by PH \u2192 PH is blocked.</p> <p>PM becomes ready and preempted the PL</p> <p>It effectively inverts the relative priorities of PM and PH.</p> <p>\u5177\u6709\u4e2d\u7b49\u4f18\u5148\u7ea7\u7684PM\u5f71\u54cd\u4e86\u9ad8\u4f18\u5148\u7ea7\u7684PH\u7684\u7b49\u5f85\u65f6\u95f4\uff0c\u8fd9\u6837\u662f\u4e0d\u5bf9\u7684\u3002</p> <p>\u89e3\u51b3\u65b9\u6848\uff1a</p> <p>\u53ef\u4ee5\u901a\u8fc7\u4f18\u5148\u7ea7\u7ee7\u627fpriority inheritance\u6765\u89e3\u51b3\u3002\u6240\u6709\u6b63\u5728\u8bbf\u95ee\u8d44\u6e90\u7684\u8fdb\u7a0b\uff08\u5982PL\uff09\u9700\u8981\u83b7\u5f97\u8bbf\u95ee\u8fd9\u4e2a\u8d44\u6e90\u7684\u66f4\u9ad8\u4f18\u5148\u7ea7\u7684\u8fdb\u7a0b\u7684\u4f18\u5148\u7ea7\uff08PH\uff09\uff0c\u76f4\u5230\u5176\u7528\u5b8c\u6709\u5173\u8d44\u6e90\u4e3a\u6b62\u3002\u6bd4\u5982\u4e0a\u4f8b\u4e2d\uff0cPL\u4f1a\u4e34\u65f6\u7ee7\u627fPL\u7684\u4f18\u5148\u7ea7\uff0c\u7136\u540ePH\u8fd0\u884c\uff0c\u6700\u540ePM\u8fd0\u884c\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#6","title":"6. \u7ecf\u5178\u540c\u6b65\u95ee\u9898","text":"<p>\u4e00\u822c\u6211\u4eec\u7528\u4fe1\u53f7\u91cf\u89e3\u51b3\u95ee\u9898</p> <p>\u4fe1\u53f7\u91cf\u7684\u903b\u8f91\uff1a\u4e00\u4e2a\u4fe1\u53f7\u91cf\u7528\u6765\u8868\u793a\u4e00\u7c7b\u201c\u8d44\u6e90\u201d\u7684\u4f59\u91cf\u3002wait()\u7b49\u5f85\u5230\u5176\u6709\u4f59\u91cf\u65f6\u4ece\u4e2d\u53d6\u8d70\u4e00\u4e2a\uff0c\u800csignal()\u91ca\u653e\u4e00\u4e2a\u8d44\u6e90\u3002</p> <p>\uff08\u4e0a\u8fb9\u8fd9\u6bb5\u5728\u5199\u4ec0\u4e48\uff09</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#61-bounded-buffer-problem","title":"6.1 Bounded-buffer Problem","text":"\ud83d\udca1 \u7ed9\u5b9a\u4e24\u4e2a\u8fdb\u7a0b\uff1aproducer\u548cconsumer\uff0c\u5171\u7528\u5927\u5c0f\u4e3an\u7684buffer\u3002producer\u751f\u4ea7\u6570\u636e\u653e\u5165buffer\uff0cconsumer\u4ecebuffer\u4e2d\u53d6\u51fa\u6570\u636e\u5e76\u4f7f\u7528\u4e4b\u3002  \u8be5\u95ee\u9898\u9700\u8981\u4fdd\u8bc1\uff1aproducer\u4e0d\u5e94\u5f53\u5728buffer\u6ee1\u65f6\u653e\u5165\u6570\u636e\uff0cconsumer\u4e5f\u4e0d\u5e94\u5f53\u5728buffer\u7a7a\u65f6\u53d6\u51fa\u6570\u636e\u3002   <p>\u9996\u5148\uff0c\u6839\u636e\u6211\u4eec\u5728\u524d\u4e00\u8282\u4e2d\u7684\u8ba8\u8bba\uff0cproduce\u548cconsume\u7684\u8fc7\u7a0b\u4f1a\u8bbf\u95ee\u5230buffer\u7684\u8d44\u6e90\uff0c\u56e0\u6b64\u8bbf\u95eebuffer\u662fcritical section\uff0c\u6211\u4eec\u9700\u8981\u4f7f\u7528\u4e00\u4e2a\u9501\uff08\u6216\u8005\u4fe1\u53f7\u91cf\uff09\u6765\u63a7\u5236\u5bf9buffer\u7684\u8bbf\u95ee\u3002</p> <p>\u8ba8\u8bba\u4e86\u4e00\u4e0b\u9501\u6c38\u8fdc\u4e0d\u53ef\u80fd\u6709\u6700\u4f18\u89e3\uff1a\u6ca1\u770b\u61c2</p> <pre><code>semaphore lock = 1;\nsemaphore eslot = BUFFER_SIZE; // \u7a7a\u95f2buffer\u7684\u6570\u91cf\nsemaphore fslot = 0;\n\nproducer(){\n    while (true){\n        wait (eslot); // if buffer is full. i.e. eslot == 0, wait. else eslot --\n        wait (lock);\n        add_to_buffer(next_produced);\n        signal(lock);\n        signal(fslot); // fslot ++\n    }\n}\n\nconsumer(){\n    while(true){\n        wait(fslot);  // if buffer is empty. i.e. fslot == 0, wait. else fslot--\n        wait(lock);\n        next_consumed = take_from_buffer();\n        signal(lock);\n        signal(eslot); // eslot ++\n    }\n}\n\n</code></pre>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#62-reader-writer-problem","title":"6.2 Reader-Writer Problem","text":"\ud83d\udca1 \u5bf9\u4e00\u4e2a\u6570\u636e\uff0creaders\u8bfb\uff0cwriters\u8bfb\u548c\u5199  \u8bbe\u8ba1\u65b9\u6848\u4fdd\u8bc1\uff1a\u591a\u4e2areaders\u53ef\u4ee5\u540c\u65f6\u8bfb\u53d6\uff0c\u4f46\u662fwriter\u8fdb\u884c\u8bfb\u5199\u65f6\u4e0d\u80fd\u6709\u5176\u5b83writers\u548creaders\u3002   <pre><code>semaphore write_lock = 1;\nint reader_count = 0;\nsemaphore reader_count_lock = 1;\nsemaphore writer_first = 1;\n\nwriter() {\n    while (true) {\n        wait(writer_first);\n        wait(write_lock);\n        read_and_write();\n        signal(write_lock);\n        signal(writer_first);\n    }\n}\n\nreader() {\n    while (true) {\n        wait(writer_first);\n        wait(reader_count_lock);\n        reader_count++;\n        if (reader_count == 1)\n            wait(write_lock);\n        signal(reader_count_lock);\n        signal(writer_first);\n\n        read();\n\n        wait(reader_count_lock);\n        reader_count--;\n        if (reader_count == 0)\n            signal(write_lock);\n        signal(reader_count_lock);\n    }\n}\n\n</code></pre>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#63-dining-philosophers-problem","title":"6.3 Dining-Philosophers Problem","text":"\ud83d\udca1 5\u4e2a\u54f2\u5b66\u5bb6\u4e00\u8d77\u5403\u996d\u3002\u6bcf\u4e24\u4e2a\u54f2\u5b66\u5bb6\u4e4b\u95f4\u6709\u4e00\u6839\u7b77\u5b50\uff0c\u6bcf\u4e2a\u4eba\u4e00\u6b21\u53ef\u4ee5\u62ff\u8d77\u4e00\u6839\u7b77\u5b50\uff0c\u62ff\u5230\u4e24\u6839\u7b77\u5b50\u7684\u5c31\u53ef\u4ee5\u5403\u4e00\u6bb5\u65f6\u95f4\uff0c\u5403\u5b8c\u601d\u8003\u4e00\u6bb5\u65f6\u95f4\u3002  ![OS%20Lecture%20%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5%208a4f18b7687b4834a9402d982a22680e/Untitled%2013.png](OS%20Lecture%20%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5%208a4f18b7687b4834a9402d982a22680e/Untitled%2013.png)   <p>\u4e09\u79cd\u89e3\u51b3\u65b9\u6848\uff1a</p> <ul> <li>\u53ef\u4ee5\u7684\u8bdd\uff0c\u6240\u6709\u4eba\u62ff\u8d77\u5de6\u8fb9\u7684\u7b77\u5b50 \u2192 \u6709\u7684\u65f6\u5019\u53ef\u80fd\u6bcf\u4e2a\u4eba\u540c\u65f6\u62ff\u8d77\u5de6\u8fb9\u7684\u7b77\u5b50\uff0c\u5bfc\u81f4\u6b7b\u9501</li> <li>\u53ea\u5141\u8bb8\u540c\u65f6\u62ff\u8d77\u4e24\u6839\u7b77\u5b50\uff1a\u8f6e\u6d41\u8be2\u95ee\u6bcf\u4e2a\u4eba\u662f\u5426\u80fd\u62ff\u8d77\u4e24\u6839\u7b77\u5b50\uff0c\u5982\u679c\u80fd\u5219\u62ff\u8d77\uff0c\u4e0d\u80fd\u5219\u7b49\u5f85\u653e\u4e0b</li> <li>\u5947\u6570\u4eba\u5148\u62ff\u5de6\u8fb9\u7b77\u5b50\uff0c\u5076\u6570\u4eba\u5148\u62ff\u53f3\u8fb9\u7b77\u5b50</li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#7-deadlocks","title":"7. \u6b7b\u9501 Deadlocks","text":"<p>\u662f\u6307\u591a\u4e2a\u8fdb\u7a0b\u56e0\u7ade\u4e89\u8d44\u6e90\u5bfc\u81f4\u7684\u4e00\u79cd\u50f5\u5c40\uff0c\u5373\u82e5\u5e72\u8fdb\u7a0b\u5404\u6301\u6709\u4e00\u4e9b\u8d44\u6e90\uff0c\u540c\u65f6\u7b49\u5f85\u83b7\u53d6\u53e6\u4e00\u4e2a\u8fdb\u7a0b\u6301\u6709\u7684\u8d44\u6e90\uff0c\u5f62\u6210\u7684\u4e92\u76f8\u7b49\u5f85\u5c40\u9762\u3002</p> <p>e.g.</p> <p>\u4e24\u4e2a\u8fdb\u7a0b\uff0c\u4e24\u4e2a\u78c1\u76d8\u9a71\u52a8\u5668</p> <pre><code>semaphore first_mutex = 1;\nsemaphore second_mutex = 1;\n\nthread_one() {\n    wait(first_mutex);  // \u6301\u6709\u4e00\u4e2a\n    wait(second_mutex); // \u60f3\u8981\u53e6\u4e00\u4e2a\n    // ...\n}\n\nthread_two() {\n    wait(second_mutex);\n    wait(first_mutex);\n    // ...\n}\n\n</code></pre> <p>\u53ef\u4ee5\u901a\u8fc7\u5206\u914d\u4f18\u5148\u7ea7\u6765\u89e3\u51b3\uff0c\u4f46\u662f\u4f18\u5148\u7ea7\u53ef\u80fd\u5bfc\u81f4starvation</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#71-system-resource-allocation-graph","title":"7.1 \u8d44\u6e90\u5206\u914d\u56fe system resource-allocation graph","text":"<p>\u662f\u4e00\u79cd\u5bf9\u7cfb\u7edf\u8d44\u6e90\u548c\u60f3\u4f7f\u7528\u8d44\u6e90\u7684\u5b9e\u4f8b\u8fdb\u884c\u5efa\u6a21\u7684\u89c4\u8303\u5316\u4f5c\u56fe\u6807\u51c6</p> <p>\u5047\u8bbe\u6709m\u4e2a\u8d44\u6e90(resources) R1\u2026 Rm\uff0c\u6bcf\u79cd\u8d44\u6e90\u6709W\u4e2a\u5b9e\u4f8b\uff08instance\uff09\u3002\u5404\u4e2a\u6d3b\u52a8\u8fdb\u7a0bP1\u2026Pn\u4f1a\u5229\u7528\u8fd9\u4e9b\u8d44\u6e90\uff0c\u6bcf\u4e2a\u8d44\u6e90\u7684\u5229\u7528\u7531request, use, release\u4e09\u6b65\u7ec4\u6210\u3002  \u8d44\u6e90\u5206\u914d\u56fe\u662f\u4e00\u79cd\u6709\u5411\u56fe</p> <ul> <li>\u70b9\u96c6 V = P \\and R<ul> <li>\u6d3b\u52a8\u8fdb\u7a0b\u96c6\u5408 P = {P1, \u2026 Pn} \u7528\u5706\u8868\u793a</li> <li>\u8d44\u6e90\u7c7b\u578b\u96c6\u5408 R = {R1, \u2026 Rn} \u7528\u77e9\u5f62\u8868\u793a\uff0c\u91cc\u9762\u7528\u5706\u70b9\u4e2a\u6570\u8868\u793a\u5404\u4e2a\u8d44\u6e90\u5b9e\u4f8b</li> </ul> </li> <li>\u8fb9\u96c6<ul> <li>\u7533\u8bf7\u8fb9 request edge P \u2192 R \u8868\u793a\u8fdb\u7a0b\u5df2\u7533\u8bf7\u5e76\u5728\u7b49\u5f85\u8d44\u6e90\u3002\u5706\u6307\u5411\u77e9\u5f62</li> <li>\u5206\u914d\u8fb9 assignment edge R \u2192 P \u8868\u793a\u8d44\u6e90\u5df2\u7ecf\u5206\u914d\u7ed9\u4e86\u8fdb\u7a0b\u3002\u77e9\u5f62\u91cc\u7684\u5706\u70b9\u6307\u5411\u5706</li> </ul> </li> </ul> <p>\u6ca1\u6709\u73af\u4e00\u5b9a\u6ca1\u6709\u6b7b\u9501\uff0c\u6709\u73af\u53ef\u80fd\u4f46\u4e0d\u4e00\u5b9a\u6709\u6b7b\u9501\uff0c\u6709\u73af\u4e14\u6bcf\u4e2a\u8d44\u6e90\u53ea\u6709\u4e00\u4e2a\u5b9e\u4f8b\u4e00\u5b9a\u6709\u6b7b\u9501\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#72","title":"7.2 \u6b7b\u9501\u7684\u5fc5\u8981\u6761\u4ef6","text":"\ud83d\udca1 \u60f3\u8981\u7406\u89e3\u8fd9\u4e00\u5757\uff0c\u8bf7\u60f3\u8c61\u56db\u4e2a\u6210\u73af\u7684\u516c\u4ea4\u8def\u53e3\uff0c\u6bcf\u4e2a\u516c\u4ea4\u8def\u53e3\u90fd\u5835\u7740\u4e00\u6392\u60f3\u8981\u987a\u65f6\u9488\u524d\u884c\u7684\u8f66\u3002\u6bcf\u4e2a\u8f66\u90fd\u60f3\u8fdb\u5165\u4e0b\u4e00\u4e2a\u8def\u53e3\uff0c\u4f46\u662f\u6bcf\u4e2a\u8def\u53e3\u90fd\u88ab\u4e0a\u4e00\u8f86\u8f66\u5835\u7740   <p>\u4e0b\u9762\u56db\u70b9\u7684\u4ea4</p> <p>\u5fc5\u8981\u6761\u4ef6\u2192\u6253\u7834\u4efb\u610f\u4e00\u70b9\u5c31\u80fd\u907f\u514d\u6b7b\u9501</p> <ul> <li>Mutual exclusion\uff1a\u81f3\u5c11\u4e00\u4e2a\u8d44\u6e90\u5904\u4e8e\u975e\u5171\u4eab\u6a21\u5f0f\uff08\u5373\u6bcf\u4e2a\u8d44\u6e90\u53ea\u6709\u4e00\u4e2a\u5b9e\u4f8b\uff09</li> <li>Hold and wait\uff1a\u6bcf\u4e2a\u8fdb\u7a0b\u5360\u6709\u81f3\u5c11\u4e00\u4e2a\u8d44\u6e90\uff0c\u5e76\u7b49\u5f85\u53e6\u4e00\u4e2a\u88ab\u5360\u636e\u7684\u8d44\u6e90\u3002</li> <li>No preemption\uff1a\u8d44\u6e90\u4e0d\u80fd\u88ab\u62a2\u5360\uff0c\u53ea\u80fd\u5728\u8fdb\u7a0b\u7ed3\u675f\u540e\u4e3b\u52a8\u91ca\u653e\u3002</li> <li>Circular wait\uff1a\u4e00\u7ec4\u7b49\u5f85\u8fdb\u7a0b\u8ddf\u60f3\u8981\u7684\u8d44\u6e90\u7684\u5360\u6709\u8005\u8fdb\u7a0b\u6210\u73af\uff0c\u4e5f\u5c31\u662f\u8fdb\u7a0b\u7f16\u53f7\u4e0e\u9700\u8981\u7684\u8d44\u6e90\u7f16\u53f7\u5f62\u6210\u4e00\u4e2a\u5b8c\u5168\u8f6e\u6362\uff08\u6ca1\u6709\u4e00\u4e2a\u8fdb\u7a0b\u5bf9\u5e94\u4e0e\u5176\u7f16\u53f7\u76f8\u540c\u7684\u8d44\u6e90\uff0c\u800c\u7f16\u53f7\u76f8\u540c\u7684\u8d44\u6e90\u6307\u8be5\u8fdb\u7a0b\u5f53\u524d\u6b63\u6301\u6709\u7684\u90a3\u4e2a\u8d44\u6e90\uff09\uff08\u6211\u662f\u8fd9\u4e48\u7406\u89e3\u7684\uff09\u3002\u5728\u9610\u8ff0\u8fd9\u4e00\u70b9\u65f6\uff0c\u53ef\u4ee5\u5217\u51fa\u8fd9\u4e2a\u8f6e\u6362\u3002</li> </ul> <p>\u5904\u7406\u6b7b\u9501\u7684\u56db\u79cd\u65b9\u6cd5</p> <ul> <li>\u4fdd\u8bc1\u7cfb\u7edf\u4e0d\u4f1a\u8fdb\u5165\u6b7b\u9501<ul> <li>\u6b7b\u9501\u9884\u9632 (deadlock prevention)</li> <li>\u6b7b\u9501\u907f\u514d (deadlock avoidance)</li> </ul> </li> <li>\u5728\u7cfb\u7edf\u8fdb\u5165\u6b7b\u9501\u72b6\u6001\u540e\u6062\u590d<ul> <li>\u6b7b\u9501\u68c0\u6d4b\u548c\u6062\u590d (deadlock detection and recovery): \u4f8b\u5982\u6570\u636e\u5e93</li> </ul> </li> <li>\u5047\u88c5\u7cfb\u7edf\u4e0d\u4f1a\u53d1\u751f\u6b7b\u9501\uff0c\u771f\u53d1\u751f\u4e86\u5c31\u5bc4\uff1a\uff1f<ul> <li>\u5927\u591a\u6570\u64cd\u4f5c\u7cfb\u7edf(including Linux and Win)\u91c7\u7528\uff0c\u9700\u8981\u8f6f\u4ef6\u6765\u5904\u7406\u6b7b\u9501</li> </ul> </li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#73","title":"7.3 \u9884\u9632\uff0c\u94f6\u884c\u5bb6\u7b97\u6cd5","text":"<p>\u9884\u9632\u7684\u6838\u5fc3\u601d\u8def\u5c31\u662f\u6253\u7834\u5fc5\u8981\u6761\u4ef6\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\u3002\u5206\u522b\u8ba8\u8bba\u56db\u4e2a\u6761\u4ef6\u5982\u4f55\u7834\u574f</p> <ul> <li>Mutual Exclusion<ul> <li>\u901a\u8fc7\u4fdd\u8bc1\u7cfb\u7edf\u8d44\u6e90\u80fd\u591f\u5171\u4eab\u6765\u6253\u7834</li> <li>\u4f46\u662f\u4e0d\u4e00\u5b9a\u80fd\u5b9e\u73b0\uff0c\u5f88\u591a\u8d44\u6e90\u4e0d\u80fd\u5171\u4eabe.g. \u4fe1\u53f7\u91cf</li> </ul> </li> <li>Hold and Wait<ul> <li>\u901a\u8fc7\u4fdd\u8bc1\u6bcf\u4e2a\u8fdb\u7a0b\u7533\u8bf7\u8d44\u6e90\u65f6\u4e0d\u80fd\u5360\u6709\u5176\u5b83\u8d44\u6e90</li> <li>\u7a0b\u5e8f\u76f4\u5230\u5f00\u59cb\u6267\u884c\u524d\u624d\u7533\u8bf7\u6240\u6709\u8d44\u6e90</li> <li>\u6216\u8005\u53ea\u5141\u8bb8\u8fdb\u7a0b\u5728\u6ca1\u6709\u8d44\u6e90\u65f6\u624d\u7533\u8bf7\u8d44\u6e90</li> <li>\u7f3a\u70b9\u662f\u8d44\u6e90\u5229\u7528\u7387\u4f1a\u53d8\u4f4e\uff0c\u9700\u8981\u8d44\u6e90\u8f83\u591a\u7684\u8fdb\u7a0b\u4f1a\u53d1\u751fstarvation</li> </ul> </li> <li>No Preemption<ul> <li>\u5f53\u4e00\u4e2a\u8fdb\u7a0b\u8bf7\u6c42\u8d44\u6e90\u4f46\u6ca1\u6709\u5f97\u5230\u6ee1\u8db3\u65f6\uff0c\u5b83\u5fc5\u987b\u91ca\u653e\u5df2\u7ecf\u6301\u6709\u7684\u6240\u6709\u8d44\u6e90\uff0c\u76f4\u5230\u5b83\u9700\u8981\u7684\u6240\u6709\u8d44\u6e90\uff08\u5305\u62ec\u521a\u624d\u91ca\u653e\u7684\u90a3\u4e9b\u8d44\u6e90\uff09\u90fd\u53ef\u7528\u65f6\u624d\u80fd\u4e00\u5e76\u83b7\u53d6\u5e76\u7ee7\u7eed\u6267\u884c\u3002</li> <li>\u4fe1\u53f7\u91cf\u4e0d\u80fd\u8fd9\u6837\u91ca\u653e</li> <li>\u4f1a\u964d\u4f4e\u8d44\u6e90\u5229\u7528\u7387</li> </ul> </li> <li>Circular Wait<ul> <li>\u5bf9\u6240\u6709\u8d44\u6e90\u8fdb\u884c\u6392\u5e8f\uff0c\u8981\u6c42\u6bcf\u4e2a\u8fdb\u7a0b\u6309\u7167\u9012\u589e\u987a\u5e8f\u7533\u8bf7\u8d44\u6e90</li> <li>\u5982\u679c\u7a0b\u5e8f\u5f00\u53d1\u8005\u6ca1\u6709\u6309\u6b64\u987a\u5e8f\u6267\u884c\uff0c\u5c31\u4f1a\u6b7b\u9501</li> <li>\u4e5f\u53ef\u80fd\u5f71\u54cd\u8d44\u6e90\u5229\u7528\u7387</li> </ul> </li> </ul>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#74","title":"7.4 \u907f\u514d","text":"<p>\u907f\u514d\u6b7b\u9501\u5219\u662f\u9760\u9884\u6d4b\u8fdb\u7a0b\u672a\u6765\u9700\u8981\u4f7f\u7528\u54ea\u4e9b\u8d44\u6e90\u3001\u8d44\u6e90\u7684\u4f7f\u7528\u987a\u5e8f\u7b49\u3002\u7cfb\u7edf\u9700\u8981\u8bbe\u8ba1\u7b97\u6cd5\u8ba1\u7b97\u4e00\u4e0b\u6765\u907f\u514d\u3002\u6240\u4ee5\u65e2\u9700\u8981\u989d\u5916\u4fe1\u606f\uff0c\u53c8\u9700\u8981\u989d\u5916\u7b97\u6cd5\u3002</p> <p>\u989d\u5916\u4fe1\u606f\u5305\u62ec</p> <p>\u8d44\u6e90\u5206\u914d\u72b6\u6001resource allocation state:</p> <ul> <li>\u6bcf\u4e2a\u8fdb\u7a0b\u58f0\u660e\u53ef\u80fd\u5bf9\u6bcf\u79cd\u8d44\u6e90\u7c7b\u578b\u7684\u6700\u5927\u9700\u6c42\uff08maximum demands\uff09</li> <li>\u5f53\u524d\u7cfb\u7edf\u7684available\u548callocated\u7684\u8d44\u6e90\u6570\u76ee</li> </ul> <p>\u8d44\u6e90\u5206\u914d\u56fe\u7b97\u6cd5\uff1a\u9002\u7528\u4e8e\u6bcf\u79cd\u8d44\u6e90\u90fd\u53ea\u6709\u4e00\u4e2a\u5b9e\u4f8b\u7684\u60c5\u51b5</p> <p>\u5728\u8d44\u6e90\u5206\u914d\u56fe\u4e0a\u52a0\u4e00\u79cd\u8fb9\uff1aclaim edge\u3002\u8868\u793a\u4e00\u4e2a\u8fdb\u7a0b\u53ef\u80fd\u4f1a\u9700\u8981\u67d0\u79cd\u8d44\u6e90\uff0c\u7528\u865a\u7ebf\u8868\u793a\u3002\u8f6c\u5316\u5173\u7cfb\u4e3a</p> <pre><code>graph TD\n    claim_edge --\u9700\u6c42\u51fa\u73b0--&gt; request_edge\n    request_edge --\u4e0d\u4f1a\u51fa\u73b0\u73af\u7684\u8bdd\u5c31\u9700\u6c42\u6ee1\u8db3--&gt; assignment_edge\n    assignment_edge --\u8d44\u6e90\u91ca\u653e--&gt; claim_edge\n\n</code></pre> <p>\u5b89\u5168\u72b6\u6001 Safe State</p> <p>\u662f\u6307\u6309\u7167\u4e00\u5b9a\u987a\u5e8f\u4e3a\u6bcf\u4e2a\u8fdb\u7a0b\u5206\u914d\u8d44\u6e90\uff0c\u540c\u65f6\u907f\u514d\u6b7b\u9501\u3002</p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u5982\u679c\u67d0\u4e2a\u8d44\u6e90\u6709A\u4e2a\u7a7a\u95f2\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u6d3b\u52a8\u8fdb\u7a0bPi\uff0c\u5404\u81ea\u6301\u6709Ci\u4e2a\u8be5\u8d44\u6e90\uff0c\u5e76\u4e14\u4ecd\u7136\u9700\u8981Di\u4e2a\u8d44\u6e90\u3002</p> <p>\u5982\u679c\u4e00\u4e2a\u5e8f\u5217\u4f7f\u5f97\u5bf9\u4e8e\u4efb\u610fPi\uff0c\u90fd\u6709A+\\sum[j&lt;i][j=1]{Ci} \u2265 Di, \u5219\u7cfb\u7edf\u5904\u4e8e\u5b89\u5168\u72b6\u6001\u3002 <p>\u53ef\u4ee5\u7528\u5f52\u7eb3\u6cd5\u8bc1\u660e\uff1a\u5982\u679cPi\u7684\u9700\u6c42\u4e0d\u80fd\u88ab\u7acb\u523b\u6ee1\u8db3\uff0c\u53ea\u9700\u8981\u7b49\u5f85Pj | j&lt;i \u5168\u90e8\u5b8c\u6210\u3002Pi\u5c31\u80fd\u83b7\u5f97\u6240\u9700\u8d44\u6e90  \u5b89\u5168\u72b6\u6001\u662f\u975e\u6b7b\u9501\u72b6\u6001\u7684\u5b50\u96c6</p> <p>\u94f6\u884c\u5bb6\u7b97\u6cd5 Banker\u2019s Algorithm</p> <p>\u901a\u8fc7available, max, allocation, need \u8fd9\u56db\u4e2a\u77e9\u9635\u523b\u753b\u4e00\u4e2a\u65f6\u95f4\u5185\u5404\u4e2a\u8fdb\u7a0b\u5bf9\u5404\u79cd\u8d44\u6e90\u7684\u6301\u6709\u548c\u9700\u6c42\u72b6\u51b5\uff0c\u4ee5\u53ca\u5f53\u524d\u7cfb\u7edf\u7684\u8d44\u6e90\u60c5\u51b5\u3002OS\u5e94\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u5224\u65ad\u7cfb\u7edf\u662f\u5426\u5b89\u5168\u72b6\u6001\u3002</p> <p>\u627e\u4e00\u4e2a\u5b89\u5168\u5e8f\u5217\u7684\u57fa\u672c\u601d\u8def\u662f\uff1a\u9009\u4e00\u4e2aneed\uff08\u7684\u6bcf\u4e00\u9879\u5bf9\u5e94\u5730\uff09\u5c0f\u4e8eavailable\uff08\u7684\u5bf9\u5e94\u9879\uff09\u7684\u8fdb\u7a0b\uff0c\u8fd0\u884c\u5b8c\u540e\u4f1a\u5c06allocation\u91ca\u653e\u56deavailable.</p> <p>\u5047\u8bbe\u8fd9\u4e2a\u9700\u6c42\u88ab\u63a5\u53d7\u4e86\uff0c\u66f4\u65b0\u5bf9\u5e94\u7684need\uff0cavailable\uff0callocation</p> <p>\u5728\u6b64\u72b6\u6001\u4e0b\u63a8\u6f14\u662f\u5426\u6709\u5408\u6cd5\u7684\u5b89\u5168\u5e8f\u5217\u3002</p> <p>\u800c\u51b3\u5b9a\u4e00\u4e2a\u9700\u6c42\u662f\u5426\u5e94\u5f53\u88ab\u6ee1\u8db3\u7684\u65b9\u6848\u662f\uff0c\u5047\u8bbe\u88ab\u63a5\u53d7\u4e86\uff0c\u6839\u636e\u8be5\u9700\u6c42\u66f4\u65b0need\uff0cavailable\uff0callocation\uff0c\u5728\u6b64\u72b6\u6001\u63a8\u6f14\u662f\u5426\u6709\u5408\u6cd5\u7684\u5b89\u5168\u5e8f\u5217\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#75","title":"7.5 \u68c0\u6d4b","text":"<p>Single Instance Resources</p> <p>wait-for graph\u6765\u89e3\u51b3</p> <p>\u5728\u8fd9\u4e2a\u56fe\u91cc\u627e\u73af\uff0c\u7528\u62d3\u6251\u6392\u5e8f\u65f6\u95f4\u590d\u6742\u5ea6\u662fO(V+E)\u7684\uff0c\u6700\u5dee\u60c5\u51b5\u4e0b\u662fO(n^2)\u7684\u3002  Multi-Instance Resources</p> <p>\u7c7b\u4f3c\u94f6\u884c\u5bb6\u7b97\u6cd5\uff0c\u5982\u679c\u627e\u4e0d\u5230\u4efb\u4f55\u5b89\u5168\u5e8f\u5217\uff0c\u8bf4\u660e\u7cfb\u7edf\u5904\u4e8e\u6b7b\u9501\u3002</p>"},{"location":"CS_Notes/OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%90%8C%E6%AD%A5/#76","title":"7.6 \u6062\u590d","text":"<ul> <li> <p>\u8fdb\u7a0b\u7ec8\u6b62Terminate deadlocked processes</p> <p>\u5b83\u548c\u8d44\u6e90\u62a2\u5360\u7684\u533a\u522b\u4f3c\u4e4e\u662f\uff0c\u8fdb\u7a0b\u7ec8\u6b62\u4ee3\u4ef7\u975e\u5e38\u5927\uff0c\u5176\u4e00\u662f\u9700\u8981\u7ef4\u62a4\u7ec8\u6b62\u65f6\u7684\u72b6\u6001\uff0c\u5e76\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\u4e00\u4e9b\u5185\u5bb9\uff0c\u5e76\u9700\u8981\u907f\u514d\u4ea7\u751f\u91cd\u590d\u7684\u526f\u4f5c\u7528\u3002</p> <p>\u76f4\u63a5\u653e\u5f03\u6240\u6709\u8fdb\u7a0b\u82b1\u8d39\u4f1a\u5f88\u5927\u3002</p> <p>\u53ef\u4ee5\u9009\u62e9\u6bcf\u6b21\u653e\u5f03\u4e00\u4e2a\u8fdb\u7a0b\uff0c\u76f4\u5230\u6240\u6709\u6b7b\u9501\u73af\u89e3\u9664\u3002</p> <p>\u5982\u4f55\u9009\u62e9\u653e\u5f03\u54ea\u4e2a\u8fdb\u7a0b\uff1a\u4e00\u7cfb\u5217\u6307\u6807</p> <ul> <li>\u8fdb\u7a0b\u7684\u4f18\u5148\u7ea7</li> <li>\u5df2\u7ecf\u7b97\u4e86\u591a\u4e45\uff0c\u8fd8\u8981\u7b97\u591a\u4e45</li> <li>\u7528\u4e86\u54ea\u4e9b\u3001\u591a\u5c11\u8d44\u6e90\uff0c\u662f\u5426\u5bb9\u6613\u88ab\u62a2\u5360</li> <li>\u8fd8\u9700\u8981\u591a\u5c11\u8d44\u6e90</li> <li>\u7ec8\u6b62\u8fd9\u4e00\u8fdb\u7a0b\u7684\u524d\u63d0\u662f\u8fd8\u9700\u7ec8\u6b62\u591a\u5c11\u8fdb\u7a0b</li> <li>\u8fdb\u7a0b\u662f\u4ea4\u4e92\u7684\u8fd8\u662f\u6279\u5904\u7406\u7684</li> <li>\u8d44\u6e90\u62a2\u5360 Resource Preemption</li> </ul> <p>\u4e0d\u65ad\u62a2\u5360\u8d44\u6e90\u7ed9\u5176\u5b83\u8fdb\u7a0b\uff0c\u76f4\u5230\u6d88\u9664\u6b7b\u9501\u73af\u4e3a\u6b62</p> <p>\u9700\u8981\u8003\u8651\u4e09\u4e2a\u95ee\u9898</p> <ul> <li>\u9009\u62e9\u727a\u7272\u8fdb\u7a0b select a victim\uff1a\u4e0e\u8fdb\u7a0b\u7ec8\u6b62\u7684\u9009\u6cd5\u76f8\u4f3c</li> <li>\u56de\u6eda\uff08Rollback\uff09\uff1a\u5f53\u4e00\u4e2a\u8fdb\u7a0b\u7684\u82e5\u5e72\u8d44\u6e90\u88ab\u62a2\u5360\uff0c\u9700\u8981\u5c06\u8fd9\u4e2a\u8fdb\u7a0b\u56de\u6eda\u5230\u67d0\u4e2a\u5b89\u5168\u72b6\u6001\uff0c\u5373\u56de\u6eda\u5230\u7533\u8bf7\u90a3\u4e9b\u88ab\u62a2\u5360\u7684\u8d44\u6e90\u4e4b\u524d</li> <li>\u9965\u997f\uff08Starvation\uff09\uff1a\u5982\u4f55\u4fdd\u8bc1\u4e0d\u4f1a\u6c38\u8fdc\u4ece\u4e00\u4e2a\u8fdb\u7a0b\u4e2d\u62a2\u5360\u8d44\u6e90\uff0c\u53ef\u4ee5\u5728\u4ee3\u4ef7\u8bc4\u4ef7\u4e2d\u52a0\u4e00\u4e2a\u6307\u6807\u56de\u6eda\u6b21\u6570\u3002\u8fd9\u4e2a\u6307\u6807\u7684\u8bbe\u8ba1\u601d\u60f3\u7c7b\u4f3c\u4e8epriority aging</li> </ul> </li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/","title":"ZJU\u671f\u672b\u590d\u4e60","text":"<p>\u9762\u5411\u671f\u672b\u9898\u7684\u76f8\u4f3c\u77e5\u8bc6\u70b9\u805a\u7c7b</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_1","title":"\u6784\u9020\u987a\u5e8f","text":"<p>\uff081\uff09main\u51fd\u6570\u4ee5\u5916\u7684\u5bf9\u8c61\uff0c\u5168\u5c40\u7c7b\u5b9a\u4e49\u540e\u76f4\u63a5\u5b9a\u4e49\u7684\u7c7b\u5bf9\u8c61 \uff082\uff09main\u51fd\u6570\u5185\u7684\u5bf9\u8c61 \uff083\uff09\u7236\u7c7b\u6784\u9020 \uff084\uff09\u5b50\u7c7b\u7c7b\u6210\u5458 \uff085\uff09\u5b50\u7c7b\u6784\u9020 \u6790\u6784\u987a\u5e8f\u76f8\u53cd</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_2","title":"\u4ec0\u4e48\u65f6\u5019\u751f\u6210\u9ed8\u8ba4\u6784\u9020\u51fd\u6570\uff1f","text":"<p>\u5982\u679c\u5df2\u7ecf\u6709\u6784\u9020\u51fd\u6570\uff0c\u7f16\u8bd1\u5668\u4e0d\u4f1a\u751f\u6210\u9ed8\u8ba4\u6784\u9020\u51fd\u6570 \u6ca1\u6709\u7684\u65f6\u5019\u4e5f\u4e0d\u4e00\u5b9a\u4f1a\u751f\u6210 \u9700\u8981\u7528\u624d\u751f\u6210</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_3","title":"\u91cd\u8f7d\u89c4\u5219","text":"<p>\u4e0d\u80fd\u91cd\u8f7d\u7684\u6709\uff1a - \u4f5c\u7528\u57df\u64cd\u4f5c\u7b26:: - \u6761\u4ef6\u64cd\u4f5c\u7b26?:\uff08\u5e94\u8be5\u662f\u95ee\u53f7\u8868\u8fbe\u5f0f\uff1f\uff09 - \u70b9\u64cd\u4f5c\u7b26\u3001\u7c7b\u6210\u5458\u6307\u9488 - \u9884\u5904\u7406\u7b26\u53f7#</p> <p>\u53ea\u80fd\u91cd\u8f7d\u4e3a\u53cb\u5143\u4e0d\u80fd\u6210\u5458\u51fd\u6570\uff1a - &lt;&lt;\u548c&gt;&gt; \u539f\u56e0\u662f\u6210\u5458\u51fd\u6570\u91cd\u8f7d\uff0c\u53ea\u80fd\u5e26\u4e00\u4e2a\u53c2\u6570\uff0clhs\u5fc5\u987b\u662f\u6210\u5458\u81ea\u8eab</p> <p>\u4f46\u662f\u6d41\u64cd\u4f5c\u7b26\u5de6\u8fb9\u662fcin\u6216cout\uff0c\u91cd\u8f7d\u4e3a\u53cb\u5143\u51fd\u6570\u65f6\uff0c\u53ef\u4ee5\u6bd4\u6210\u5458\u51fd\u6570\u591a\u8bf4\u660e\u4e00\u4e2a\u5f62\u53c2\u505alhs</p> <p>\u91cd\u8f7d\u548c\u91cd\u5199\u90fd\u662f\u591a\u6001\uff1a \u91cd\u8f7d\uff1a\u8fd0\u884c\u65f6\u591a\u6001 \u91cd\u5199\uff1a\u7f16\u8bd1\u65f6\u591a\u6001</p> <p>static\u548cvirtual\u53ea\u80fd\u6709\u4e00\u4e2a</p> <p>\u6790\u6784\u51fd\u6570\u4e0d\u80fd\u5e26\u53c2\u6570</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_4","title":"\u5b50\u7c7b\u548c\u7236\u7c7b\u6307\u9488","text":"<ul> <li>\u5b50\u7c7b\u6307\u5b50\u7c7b\uff1a     \u5982\u679c\u5b50\u7c7b\u8986\u76d6\u4e86\u7236\u7c7b\u7684\u6210\u5458\u53d8\u91cf\u548c\u6210\u5458\u51fd\u6570\uff0c\u5219\u8bbf\u95ee\u5b50\u7c7b\u7684     \u6ca1\u6709\u8986\u76d6\u7684\u5c31\u8bbf\u95ee\u7236\u7c7b\u7684</li> <li>\u7236\u7c7b\u6307\u9488\u53ef\u4ee5\u76f4\u63a5\u6307\u5411\u5b50\u7c7b</li> <li>\u5982\u679c\u4e0d\u662fvirtual\uff1a\u8bbf\u95ee\u7236\u7c7b\u6709\u7684\u6210\u5458\u53d8\u91cf\u548c\u51fd\u6570\uff08\u5176\u5b9e\u6ca1\u6709\u7684\u4e5f\u80fd\uff0c\u9700\u8981\u4e00\u4e9b\u5199\u6cd5\uff09     \u5982\u679c\u662fvirtual\uff1a\u8bbf\u95ee\u7684\u662f\u5b50\u7c7b\u91cd\u5199\u8fc7\u7684\u7248\u672c</li> <li>\u7236\u7c7b\u6ca1\u6709\u7684\u5b50\u7c7b\u65b0\u51fd\u6570\u5c31\u8bbf\u95ee\u4e0d\u5230\uff08\u7531\u7c7b\u578b\u5927\u5c0f\u63a7\u5236\uff09</li> <li>\u5b50\u7c7b\u6307\u9488\u4e0d\u80fd\u76f4\u63a5\u6307\u5411\u7236\u7c7b\uff0c\u9700\u8981\u8fdb\u884c\u7c7b\u578b\u8f6c\u6362</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#static_castdynamic_cast","title":"static_cast\u548cdynamic_cast","text":"<ul> <li>static cast\u53ef\u4ee5\u7236\u5230\u5b50\uff0c\u53ef\u4ee5\u5b50\u5230\u7236\uff0c\u4e0d\u53ef\u4ee5\u65e0\u7ee7\u627f\u5173\u7cfb\u7684\u4e24\u4e2a\u7c7b</li> <li>dynamic cast\u4e0d\u5141\u8bb8\u7236\u5230\u5b50\uff08\u56e0\u4e3a\u4e0d\u77e5\u9053\u5b50\u7c7b\u591a\u4e86\u54ea\u4e9b\u5b9e\u73b0\uff0c\u8fd4\u56de\u7a7a\u6307\u9488\uff09\uff0c\u5728\u7236\u7c7b\u91cc\u9762\u6709virtual function\u7684\u65f6\u5019\u5141\u8bb8\u5b50\u5230\u7236\uff0c\u6ca1\u6709virtual function\u5c31\u4e0d\u80fd\u505a\u3002\u8981\u6c42\u7236\u7c7b\u5fc5\u987b\u662f\u591a\u6001\u7c7b</li> <li>reinterpret cast\u53ef\u4ee5\u65e0\u7ee7\u627f\u5173\u7cfb\u7684\u4e24\u4e2a\u7c7b</li> <li>const cast\u53ea\u7528\u6765remove const</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_5","title":"\u5f15\u7528","text":"<p>\u4ec0\u4e48\u65f6\u5019\u5fc5\u987b\u7528\u5e38\u5f15\u7528\uff08const &amp;\uff09\uff1a\u5f15\u7528\u578b\u53c2\u6570\u5e94\u5f53\u5728\u80fd\u5b9a\u4e49\u4e3aconst\u7684\u60c5\u51b5\u4e0b\u5c3d\u91cf\u5b9a\u4e49\u4e3aconst\u3002</p> <p>\u4f7f\u7528\u5f15\u7528\u7684\u4e3b\u8981\u539f\u56e0\uff1a \u7a0b\u5e8f\u80fd\u591f\u4fee\u6539\u8c03\u7528\u51fd\u6570\u4e2d\u7684\u6570\u636e\u5bf9\u8c61 \u901a\u8fc7\u4f20\u9012\u5f15\u7528\u800c\u4e0d\u662f\u6574\u4e2a\u6570\u636e\u5bf9\u8c61\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7a0b\u5e8f\u7684\u8fd0\u884c\u901f\u5ea6</p> \u53ea\u4f7f\u7528\u4f20\u9012\u8fc7\u6765\u7684\u503c\u800c\u4e0d\u4fee\u6539 \u9700\u8981\u4fee\u6539\u4f20\u9012\u8fc7\u6765\u7684\u503c \u5185\u7f6e\u6570\u636e\u7c7b\u578b\uff08\u5c0f\u578b\u7ed3\u6784\uff09 \u6309\u503c\u4f20\u9012 \u6307\u9488\u4f20\u9012 \u6570\u7ec4 \u6307\u9488\u4f20\u9012 \u6307\u9488\u4f20\u9012 \u8f83\u5927\u7684\u7ed3\u6784\uff09 \u6307\u9488\u6216\u5f15\u7528 \u6307\u9488\u6216\u5f15\u7528 \u7c7b/\u5bf9\u8c61 \u5f15\u7528\u4f20\u9012 \u5f15\u7528\u4f20\u9012 <p>\u5f15\u7528\u548c\u6307\u9488\u7684\u533a\u522b\uff1a \u53ef\u4ee5\u628a\u5f15\u7528\u7406\u89e3\u6210\u4e00\u4e2a\u5e38\u91cf\u6307\u9488\uff0c\u56e0\u6b64\u5f15\u7528\u58f0\u660e\u65f6\u5c31\u5fc5\u987b\u521d\u59cb\u5316\uff0c\u4e00\u7ecf\u58f0\u660e\u4e0d\u80fd\u518d\u548c\u5176\u5b83\u5bf9\u8c61\u7ed1\u5b9a\u3002</p> <p>Copy constructor must pass its first argument by reference</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_6","title":"\u7c7b\u5185\u9759\u6001\u6210\u5458\u7684\u521d\u59cb\u5316","text":"<p>const static\u53ef\u4ee5\u5728\u7c7b\u5185\u76f4\u63a5\u521d\u59cb\u5316\uff0c\u975econst static\u6210\u5458\u9700\u8981\u5728\u7c7b\u5916\u521d\u59cb\u5316\u3002</p> <p>\u53ef\u4ee5\u8c03\u7528\u9ed8\u8ba4\u521d\u59cb\u5316A::n\uff0c\u81ea\u52a8\u521d\u59cb\u5316\u4e3a0\u3002\u6b64\u65f6\u8c03\u7528\u9ed8\u8ba4\u6784\u9020\u4e0d\u80fd\u7528n()\uff0c\u5426\u5219\u8ba4\u4e3a\u662f\u4e2a\u51fd\u6570\u3002\u6216\u8005\u5e26\u521d\u59cb\u503c\u521d\u59cb\u5316A::n(9)</p> <p>static\u548cconst - \u6ca1\u6709static\u5c31\u662fconst\u7684\u8bf4\u6cd5</p> <p>const\u7684\u51e0\u79cd\u5f62\u5f0f</p> <pre><code>const int&amp; fun(int&amp; a); // \u4fee\u9970\u8fd4\u56de\u503c \nint&amp; fun(const int&amp; a); // \u4fee\u9970\u5f62\u53c2 \nint&amp; fun(int&amp; a) const {} // const\u6210\u5458\u51fd\u6570\n</code></pre> <p>const\u8fd4\u56de\u503c\uff1a\u662f\u4fee\u9970\u8fd4\u56de\u503c\u5f15\u7528\u7c7b\u578b\u7684\u65f6\u5019\uff0c\u4e3a\u4e86\u907f\u514d\u8fd4\u56de\u503c\u88ab\u4fee\u6539\u7684\u60c5\u51b5</p> <p>\u8fd4\u56de\u503c\u662f\u5f15\u7528\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u5f15\u7528\u5fc5\u7136\u4e0d\u662f\u4e34\u65f6\u5bf9\u8c61\u7684\u5f15\u7528\uff0c\u4e00\u5b9a\u662f\u6210\u5458\u53d8\u91cf\u6216\u8005\u51fd\u6570\u53c2\u6570\u3002\uff08\u53ea\u8981\u53c2\u6570\u4e0d\u9700\u8981\u4fee\u6539\u4e00\u5b9a\u52a0\u4e0aconst\uff09</p> <p>const\u53c2\u6570\u5fc5\u987b\u4f20\u7b7e\u540d\u540e\u5e26const\u7684\u51fd\u6570\uff1a\u8981\u628athis\u6307\u9488\u53d8\u6210const</p> <p>\u600e\u6837\u6784\u6210\u91cd\u8f7d - \u4e0d\u91cd\u8f7d\u7684     <code>C++     const int&amp; fun(int&amp; a); // \u53c2\u6570\u5217\u8868\u6ca1\u6709\u53d8      int&amp; fun(const int a); // \u56e0\u4e3a\u662f\u503c\u4f20\u9012\uff0c\u4e0d\u662fconst\u7684\u4e5f\u80fdtype conversion</code></p> <ul> <li>\u91cd\u8f7d\u7684\uff1a\u53ea\u770b\u53c2\u6570\u5217\u8868\u53d8\u6ca1\u53d8</li> </ul> <pre><code>    int&amp; fun(const int&amp; a); // \u56e0\u4e3a\u662f\u53d8\u91cf\u4f20\u9012\uff0c\u8981\u6c42\u68c0\u67e5\u53c2\u6570\u7684const\uff0c\u662f\u53c2\u6570\u5217\u8868\u53d8\u4e86 \n    int&amp; fun(int&amp; a) const {} // \u56e0\u4e3a\u9690\u542b\u53c2\u6570this\u7684const\u4e0e\u5426\u4e0d\u4e00\u6837\uff0c\u4e5f\u662f\u53c2\u6570\u5217\u8868\u53d8\u4e86\n</code></pre> <p>\u200b</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#inline-function","title":"inline function","text":"<p>\u4ee3\u66ff\u5b8f\u7684\u4e00\u79cd\u64cd\u4f5c\uff0c\u5728\u7f16\u8bd1\u9636\u6bb5\u628a\u6240\u6709\u51fd\u6570\u540d\u66ff\u6362\u6210inline function\u7684\u5b9e\u73b0 \u6bd4\u51fd\u6570\u7684\u4f18\u70b9\uff1a\u4e0d\u7528\u9891\u7e41\u8fdb\u6808\u51fa\u6808 \u6bd4\u5b8f\u7684\u4f18\u70b9\uff1a\u6709\u7c7b\u578b\u68c0\u67e5\uff0c\u80fd\u5199\u591a\u884c\uff0c\u80fd\u64cd\u4f5c\u7c7b\u7684\u79c1\u6709\u6210\u5458 inline\u5173\u952e\u5b57\u53ea\u6709\u51fa\u73b0\u5728\u51fd\u6570\u7684\u5b9a\u4e49\u800c\u4e0d\u662f\u58f0\u660e\u524d\u65f6\u624d\u6709\u7528\u3002 \u9759\u6001\u7ed1\u5b9a\u00a0Static\u00a0Binding \u3002\u80fd\u591f\u660e\u786e\u8fd0\u884c\u7684\u662f\u54ea\u4e2a\u7c7b\u7684\u65b9\u6cd5\u65f6\u4f1a\u53d1\u751f\u9759\u6001\u7ed1\u5b9a \u3002\u53d1\u751f\u5728\u7f16\u8bd1\u65f6\u523b\uff0c\u6240\u4ee5\u53c8\u53eb\u65e9\u7ed1\u5b9a \u52a8\u6001\u7ed1\u5b9aDynamic\u00a0Binding \u3002\u51fa\u73b0\u591a\u6001\uff0c\u7f16\u8bd1\u5668\u4e0d\u80fd\u660e\u786e\u5230\u5e95\u4f7f\u7528\u54ea\u4e2a\u7c7b\u7684\u65b9\u6cd5\u65f6\u53d1\u751f\u52a8\u6001\u7ed1\u5b9a \u3002\u53d1\u751f\u5728\u8fd0\u884c\u65f6\u523b\uff0c\u6240\u4ee5\u53c8\u53eb\u665a\u7ed1\u5b9a \u3002\u53ea\u6709\u5b58\u5728\u00a0virtual\u00a0\u65e6\u901a\u8fc7\u6307\u9488\u8bbf\u95ee\u65f6\uff0c\u624d\u4f1a\u53d1\u751f\u52a8\u6001\u7ed1\u5b9a</p> <p>static binding \u7f16\u8bd1\u65f6</p> <pre><code>class Animal { \npublic: \n    void eat() { \n        cout &lt;&lt; \"Animal eats\" &lt;&lt; endl; \n    } \n}; \nclass Dog : \npublic Animal { \npublic: \n    void eat() { \n        cout &lt;&lt; \"Dog eats\" &lt;&lt; endl; \n    } \n};\n</code></pre> <p>dynamic binding \u8fd0\u884c\u65f6</p> <pre><code>class Animal { \npublic: \n    virtual void eat() { \n        cout &lt;&lt; \"Animal eats\" &lt;&lt; endl; \n    } \n}; \nclass Dog : \npublic Animal { \npublic: \n    void eat() { \n    cout &lt;&lt; \"Dog eats\" &lt;&lt; endl; \n    } \n};\n</code></pre> <p>\u200b</p> <p>\u5728\u4e0b\u9762\u7684\u60c5\u51b5\u4e0b\uff0c\u6784\u9020\u51fd\u6570\u4f1a\u88ab\u8c03\u7528\uff1a - \u5bf9\u4e8e\u5168\u5c40\u5bf9\u8c61\uff0c\u5728main()\u4e24\u6570\u8fd0\u884c\u4e4b\u524d\uff0c\u6216\u8005\u5728\u540c\u4e00\u4e2a\u7f16\u8bd1\u5355\u5143\u5185\u5b9a\u4e49\u7684\u4efb\u4e00\u51fd\u6570\u6216\u5bf9\u8c61 \u88ab\u4f7f\u7528\u4e4b\u524d\u3002\u5728\u540c\u4e00\u4e2a\u7f16\u8bd1\u5355\u5143\u5185\uff0c\u5b83\u4eec\u7684\u6784\u9020\u4e24\u6570\u6309\u7167\u58f0\u660e\u7684\u987a\u5e8f\u521d\u59cb\u5316\u3002 - \u5bf9\u4e8e static\u00a0local\u00a0variables\uff0c\u00a0\u5728\u7b2c\u4e00\u6b21\u8fd0\u884c\u5230\u5b83\u7684\u58f0\u660e\u7684\u65f6\u5019. - \u5bf9\u4e8e automatic\u00a0storage\u00a0duration\u00a0\u7684\u5bf9\u8c61\uff0c\u5728\u5176\u58f0\u660e\u88ab\u8fd0\u884c\u65f6\u3002 - \u5bf9\u4e8e dynamic\u00a0storage\u00a0duration\u00a0\u7684\u5bf9\u8c61\uff0c\u5728\u5176\u7528\u00a0new\u00a0\u8868\u8fbe\u5f0f\u521b\u5efa\u65f6\u3002</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_7","title":"\u667a\u80fd\u6307\u9488","text":"<pre><code>std::unique_ptr&lt;T&gt; //\u72ec\u5360\u8d44\u6e90\u6240\u6709\u6743\u7684\u6307\u9488\u3002 \nstd::shared_ptr&lt;T&gt; //\u5171\u4eab\u8d44\u6e90\u6240\u6709\u6743\u7684\u6307\u9488\u3002 \nstd::weak_ptr&lt;T&gt; //\u5171\u4eab\u8d44\u6e90\u7684\u89c2\u5bdf\u8005\uff0c\u9700\u8981\u548cstd::shared_ptr \u4e00\u8d77\u4f7f\u7528\uff0c\u4e0d\u5f71\u54cd\u8d44\u6e90\u7684\u751f\u547d\u5468\u671f\u3002\n</code></pre> <p>\u4f7f\u7528\u88f8\u6307\u9488 \u6240\u4ee5\u9ed8\u8ba4\u53c2\u6570\u662f\u548c\u865a\u8868\u65e0\u5173\u4e0e\u5f53\u524d\u7c7b\u578b\u6709\u5173\u5417 \u662f\u7684 \u9ed8\u8ba4\u53c2\u6570\u4e0d\u8fdb\u865a\u8868 \u2192 upcasting\u7684\u65f6\u5019</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/ZJU%20%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#upcasting","title":"upcasting","text":"<ul> <li>\u57fa\u7c7b\u6307\u9488\u6307\u5b50\u7c7b</li> <li>\u9ed8\u8ba4\u53c2\u6570\u662f\u57fa\u7c7b\u7684</li> <li>\u57fa\u7c7b\u7684virtual\u51fd\u6570\uff0c\u8c03\u7528\u5b50\u7c7b\u7684</li> <li>\u57fa\u7c7b\u7684virtual\u51fd\u6570\u5728\u4e0b\u9762\u5168\u90fd\u662fvirtual</li> <li>\u57fa\u7c7b\u7684const\u548c\u5b50\u7c7b\u975econst\u4e0d\u662f\u4e00\u4e2a\u51fd\u6570</li> <li>\u57fa\u7c7b\u975evirtual\uff0c\u7528\u57fa\u7c7b\u6307\u9488\u8c03\u8c03\u7684\u662f\u57fa\u7c7b\u7684</li> <li>\u57fa\u7c7b\u975evirtual\uff0c\u7528\u5b50\u7c7b\u6307\u9488\u8c03\u8c03\u7684\u662f\u5b50\u7c7b\u7684</li> <li>\u57fa\u7c7b\u4e2d\u5b50\u7c7b\u4e0d\u5b58\u5728\u51fd\u6570\uff0c\u5b50\u7c7b\u80fd\u8c03\u57fa\u7c7b\u7684\u3002\u4f18\u5148\u7528\u5b50\u7c7b\u7684type conversion</li> <li>static\u5728\u5168\u5c40\u521d\u59cb\u5316\u540e\u624d\u80fd\u7528</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/","title":"\u5173\u4e8eCS106B\u548cCS106L","text":"<p>CS106B\u504f\u7b80\u5355\uff0c\u76f8\u5f53\u4e8eZJU\u7684\u6570\u636e\u7ed3\u6784+C++\u7684STL\u7528\u6cd5\u4e00\u5757\u8bb2\uff0c\u53e6\u5916\u518d\u8bb2\u4e00\u4e9bFDS\u7684\u7b97\u6cd5\u3002 CS106L\u662f\u4e13\u95e8\u8bb2C++\u8fdb\u9636\u7279\u6027\u7684\u3002</p> <p>\u56e0\u4e3a\u5728\u542cCS106B\u4e4b\u524d\u5b66\u8fc7FDS\uff0cCS106B\u82b1\u4e00\u5929\u901f\u901a\u4e86\u4e00\u4e0b\uff0c\u91cd\u590d\u5185\u5bb9\u6709\u70b9\u591a\uff0c\u622a\u4e0b\u4e86\u4e00\u5e45\u56fe\u3002 </p> <p>CS106L\u63d0\u4f9b\u7684C++\u5b66\u4e60\u8def\u7ebf\u56fe </p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#zju","title":"ZJU\u8bfe\u7a0b","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_1","title":"\u8bfe\u7a0b\u53c2\u8003\u8d44\u6599","text":"<p>CPP Reference Standard  C++ CppCon</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_2","title":"\u4e0a\u8bfe\u5fc3\u5f97","text":"<p>\u6211\u8ddf\u7684\u662fcx\u8001\u5e08\u7684\u73ed\uff0c\u5e94\u8be5\u662f\u6559\u5f97\u6700\u597d\u7684\u4e00\u6863orz  \u4f46\u662f\u4e0a\u8bfe\u5185\u5bb9\u4ecd\u4e0d\u80fd\u8986\u76d6\u4f5c\u4e1a\u548c\u671f\u672b\u7684\u5185\u5bb9\uff0c\u89c9\u5f97\u542c\u8bfe\u5185\u5bb9\u53ea\u80fd\u8d77\u5230\u4e00\u4e2a\u9aa8\u67b6\u4f5c\u7528\uff0c\u8bfe\u540e\u9700\u8981\u82b1\u4e0a\u8bfe2\u81f33\u500d\u7684\u65f6\u95f4\u81ea\u5b66\u81ea\u5df1\u6574\u7406\u7b14\u8bb0\uff0c\u591a\u8bfb\u591a\u5199\u4ee3\u7801\uff0c\u4e0d\u7136\u671f\u672b\u4f1a\u9047\u5230\u6ca1\u89c1\u8fc7\u7684\u7279\u6027\uff0c\u4f1a\u6709\u70b9\u60e8orz\uff08\u50cf\u6211\u4e00\u6837\uff09</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_3","title":"\u9762\u5411\u5bf9\u8c61\u56db\u5927\u7279\u6027","text":"<ul> <li>\u62bd\u8c61</li> <li>\u5c01\u88c5</li> <li>\u7ee7\u627f</li> <li>\u591a\u6001</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_4","title":"\u7c7b\u548c\u5bf9\u8c61/\u6784\u9020\u51fd\u6570\u548c\u6790\u6784\u51fd\u6570","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#class-struct","title":"class \u4e0e struct \u7684\u6bd4\u8f83","text":"<ul> <li>\u7c7b\u662fC++\u5bf9C\u4e2d\u7ed3\u6784\u7684\u6269\u5c55</li> <li>C\u8bed\u8a00\u4e2d\u7684struct\u662f\u6570\u636e\u6210\u5458\u96c6\u5408\uff0cC++\u4e2d\u7684\u7c7b\u662f\u6570\u636e\u6210\u5458\u548c\u6210\u5458\u51fd\u6570\u7684\u96c6\u5408</li> <li>\u7c7b\u662f\u4e00\u79cd\u6784\u9020\u6570\u636e\u7c7b\u578b</li> <li>\u7c7b\u5c06\u6570\u636e\u548c\u4e0e\u4e4b\u5173\u8054\u7684\u6570\u636e\u5c01\u88c5\u5728\u4e00\u8d77\uff0c\u5f62\u6210\u4e00\u4e2a\u6574\u4f53\uff0c\u5177\u6709\u826f\u597d\u7684\u5916\u90e8\u63a5\u53e3\u53ef\u4ee5\u9632\u6b62\u6570\u636e\u672a\u7ecf\u6388\u6743\u7684\u8bbf\u95ee\uff0c\u63d0\u4f9b\u4e86\u6a21\u5757\u4e4b\u95f4\u7684\u72ec\u7acb\u6027\u3002</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_5","title":"\u7c7b\u7684\u7ed3\u6784\uff1a\u6570\u636e\u6210\u5458\u548c\u6210\u5458\u51fd\u6570","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_6","title":"\u7c7b\u7684\u58f0\u660e\u683c\u5f0f","text":"<pre><code>class Name\n{\n    public:\n        public_data;\n        public_functions;\n    protected:\n        protected_data;\n        protected_functions;\n    private:\n        private_data;\n        private_functions;\n}\n</code></pre> <ul> <li>private\u662f\u7c7b\u7684\u79c1\u6709\u90e8\u5206\uff0c\u53ea\u80fd\u7531\u672c\u7c7b\u7684\u6210\u5458\u51fd\u6570\u8bbf\u95ee\uff0c\u6765\u81ea\u5916\u90e8\u7684\u4efb\u4f55\u8bbf\u95ee\u90fd\u662f\u975e\u6cd5\u7684\u3002</li> <li>public\u662f\u7c7b\u7684\u5171\u6709\u90e8\u5206\uff0c\u5bf9\u5916\u5b8c\u5168\u5f00\u653e\uff0c\u53ef\u4ee5\u7531\u5916\u90e8\u4efb\u610f\u8bbf\u95ee\u3002</li> <li>protected\u662f\u7c7b\u7684\u4fdd\u62a4\u90e8\u5206\uff0c\u53ef\u4ee5\u7531\u672c\u7c7b\u548c\u672c\u7c7b\u7684\u6d3e\u751f\u7c7b\u7684\u6210\u5458\u51fd\u6570\u8bbf\u95ee\uff0c\u5176\u5b83\u8bbf\u95ee\u90fd\u662f\u975e\u6cd5\u7684\u3002</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_7","title":"\u4e60\u60ef","text":"<ul> <li>\u7c7b\u58f0\u660e\u683c\u5f0f\u7684\u4e09\u4e2a\u90e8\u5206\u4e0d\u4e00\u5b9a\u5168\u90fd\u6709\uff0c\u4f46\u81f3\u5c11\u6709\u5176\u4e2d\u7684\u4e00\u4e2a\u90e8\u5206\u3002</li> <li>\u4e00\u822c\u5c06\u6570\u636e\u6210\u5458\u58f0\u660e\u4e3a\u79c1\u6709\u6210\u5458\uff0c\u6210\u5458\u51fd\u6570\u58f0\u660e\u4e3a\u5171\u6709\u6210\u5458\u3002</li> <li>private\u5904\u4e8e\u7c7b\u4e2d\u7684\u7b2c\u4e00\u90e8\u5206\u65f6\uff0cprivate\u5173\u952e\u5b57\u53ef\u4ee5\u7701\u7565\u3002</li> <li>\u6570\u636e\u6210\u5458\u53ef\u4ee5\u662f\u4efb\u4f55\u6570\u636e\u7c7b\u578b\uff0c\u4f46\u4e0d\u80fd\u7528auto regitser\u6216extern\u8fdb\u884c\u58f0\u660e\u3002</li> <li>\u4e0d\u80fd\u5728\u7c7b\u58f0\u660e\u4e2d\u7ed9\u6570\u636e\u6210\u5458\u8d4b\u503c\uff0c\u53ea\u6709\u5728\u7c7b\u5bf9\u8c61\u5b9a\u4e49\u4e4b\u540e\u624d\u80fd\u7ed9\u6570\u636e\u6210\u5458\u8d4b\u503c\u3002</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_8","title":"\u7c7b\u5916\u5b9a\u4e49","text":"<p>\u8fd4\u56de\u7c7b\u578b \u7c7b\u540d::\u6210\u5458\u51fd\u6570\u540d\uff08\u53c2\u6570\u8868\uff09 {     // \u51fd\u6570\u4f53 }</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_9","title":"\u5185\u8054\u51fd\u6570\u548c\u5916\u8054\u51fd\u6570","text":"<ul> <li>\u5185\u8054\u51fd\u6570\u662f\u5b9a\u4e49\u5728\u7c7b\u4f53\u91cc\u7684\u6210\u5458\u51fd\u6570\uff0c\u5373\u8be5\u51fd\u6570\u7684\u51fd\u6570\u4f53\u653e\u5728\u7c7b\u4f53\u91cc\u3002\u7f16\u8bd1\u65f6\u4f1a\u76f4\u63a5\u7528\u51fd\u6570\u5b9a\u4e49\u66ff\u6362\u8c03\u7528\u4ee3\u7801\uff0c\u63d0\u5347\u8fd0\u884c\u901f\u5ea6\u3002\u5185\u8054\u51fd\u6570\u50cf\u5b9a\u4e49\u4f18\u5316\u4e86\u7684\u5b8f\u3002</li> <li>\u5916\u8054\u51fd\u6570\u662f\u8bf4\u660e\u5728\u7c7b\u4f53\u91cc\uff0c\u5b9a\u4e49\u5728\u7c7b\u4f53\u5916\u7684\u51fd\u6570\u3002\u53ea\u8981\u5728\u51fd\u6570\u5b9a\u4e49\u65f6\u524d\u9762\u52a0\u4e0ainline\u5c31\u53ef\u4ee5\u53d8\u6210\u5185\u8054\u51fd\u6570\uff0c\u5fc5\u987b\u548c\u51fd\u6570\u4f53\u653e\u5728\u4e00\u8d77\u3002</li> <li>\u5185\u8054\u51fd\u6570\u53ef\u4ee5\u52a0inline\u4e5f\u53ef\u4ee5\u4e0d\u52a0inline\u3002</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_10","title":"\u5bf9\u8c61","text":"<p>\u53ef\u4ee5\u628a\u76f8\u540c\u6570\u636e\u7ed3\u6784\u548c\u76f8\u540c\u64cd\u4f5c\u96c6\u7684\u5bf9\u8c61\u770b\u4f5c\u5c5e\u4e8e\u540c\u4e00\u7c7b\u3002\u5bf9\u8c61\u662f\u7c7b\u7684\u5b9e\u4f8b\u3002</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_11","title":"\u5bf9\u8c61\u7684\u5b9a\u4e49","text":"<ul> <li>\u53ef\u4ee5\u76f4\u63a5\u5728\u58f0\u660e\u7c7b\u7684\u540c\u65f6\u5b9a\u4e49\uff08\u5168\u5c40\u53d8\u91cf\uff09\uff0c\u4e5f\u53ef\u4ee5\u7c7b\u540d+\u5b9a\u4e49\u3002</li> <li>\u53ea\u58f0\u660e\u7c7b\u4e0d\u58f0\u660e\u5bf9\u8c61\u65f6\u4e0d\u5206\u914d\u5b58\u50a8\u7a7a\u95f4\uff0c\u58f0\u660e\u5bf9\u8c61\u540e\u624d\u5206\u914d\u5b58\u50a8\u7a7a\u95f4\u3002</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_12","title":"\u5bf9\u8c61\u4e2d\u6210\u5458\u7684\u8bbf\u95ee","text":"<p>\u5bf9\u8c61\u540d.\u6570\u636e\u6210\u5458\u540d\uff08\u662f \u5bf9\u8c61\u540d.\u7c7b\u540d::\u6210\u5458\u540d \u7684\u7f29\u5199\uff09 \u5bf9\u8c61\u540d.\u6210\u5458\u51fd\u6570\u540d\uff08\u53c2\u6570\u8868\uff09</p> <pre><code>class Sample\n{\n    public:\n        int k;\n        int geti(){return i;}\n        int getj(){return j;}\n        int getk(){return k;}\n\n    private:\n        int i;\n\n    protected:\n        int j;\n};\n\nint main()\n{\n    Sample a;\n    a.i;        // \u975e\u6cd5\n    a.j:        // \u975e\u6cd5\n    a.k;        // \u5408\u6cd5\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_13","title":"\u7c7b\u7684\u4f5c\u7528\u57df","text":"<ul> <li>\u4e00\u4e2a\u7c7b\u7684\u6240\u6709\u6210\u5458\u90fd\u5728\u7c7b\u7684\u4f5c\u7528\u57df\u4e2d\uff0c\u4e00\u4e2a\u7c7b\u7684\u4efb\u4f55\u6210\u5458\u53ef\u4ee5\u8bbf\u95ee\u8be5\u7c7b\u7684\u5176\u4ed6\u6210\u5458\u3002</li> <li>\u4e00\u4e2a\u7c7b\u7684\u6210\u5458\u51fd\u6570\u53ef\u4ee5\u4e0d\u53d7\u9650\u5236\u5730\u8bbf\u95ee\u8be5\u7c7b\u7684\u6210\u5458\uff0c\u5728\u7c7b\u7684\u5916\u90e8\u5c31\u4e0d\u884c\u3002</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_14","title":"\u6784\u9020\u51fd\u6570\u4e0e\u6790\u6784\u51fd\u6570","text":"<p>\u7c7b\u7684\u6784\u9020\u51fd\u6570\u662f\u7c7b\u7684\u4e00\u4e2a\u7279\u6b8a\u6210\u5458\u51fd\u6570\uff0c\u6ca1\u6709\u8fd4\u56de\u7c7b\u578b\uff08\u4e0d\u662fvoid\uff09\uff0c\u53ef\u4ee5\u6709\u53c2\u6570\uff0c\u51fd\u6570\u540d\u548c\u7c7b\u540d\u4e00\u6837\u3002\u5f53\u521b\u5efa\u7c7b\u7684\u4e00\u4e2a\u65b0\u5bf9\u8c61\u65f6\uff0c\u81ea\u52a8\u8c03\u7528\u6784\u9020\u51fd\u6570\uff0c\u5b8c\u6210\u521d\u59cb\u5316\u5de5\u4f5c\u3002</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#namespace","title":"Namespace","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#namespace_1","title":"\u4ec0\u4e48\u662fnamespace\uff1f","text":"<p>\u662f\u5355\u4e00\u7684\u5168\u5c40\u540d\u5b57\u7a7a\u95f4\u3002\u9632\u6b62\u5728\u4e00\u4e2a\u7a7a\u95f4\u4e2d\u76f8\u540c\u7684\u540d\u5b57\u5f15\u8d77\u51b2\u7a81\u3002 \u4f8b\u5b50\uff1a</p> <pre><code>namespace myown1\n{\n    string user_name = \"myown1\";\n}\n\nnamespace myown2\n{\n    string user_name = \"myown2\";\n}\n\nint main()\n{\n    // using namespace myown1; \n    cout &lt;&lt; \"\\\\n\" &lt;&lt; \"Hello, \"\n    &lt;&lt; myown1::user_name\n    &lt;&lt; \"...and goodbye!\\\\n\"\n\n    cout &lt;&lt; \"\\\\n\" &lt;&lt; \"Hello, \"\n    &lt;&lt; myown2::user_name\n    &lt;&lt; \"...and goodbye!\\\\n\"\n\n    return 0;\n}\n</code></pre> <p>\u5173\u952e\u8bcdusing\u5c06\u4e00\u4e2a\u540d\u5b57\u7a7a\u95f4\u53d8\u4e3a\u53ef\u89c1\uff0c\u4e0d\u4f1a\u8986\u76d6\u5f53\u524d\u7684namespace\u3002</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_15","title":"\u7ee7\u627f\u4e0e\u6d3e\u751f\u7c7b","text":"<ul> <li>\u7ee7\u627f\uff1a\u4fdd\u6301\u5df2\u6709\u7c7b\u7684\u7279\u6027\u800c\u6784\u9020\u65b0\u7c7b\u7684\u8fc7\u7a0b\u3002\u88ab\u7ee7\u627f\u7684\u7c7b\u79f0\u4e3a\u57fa\u7c7b/\u7236\u7c7b\u3002</li> <li>\u6d3e\u751f\uff1a\u5728\u5df2\u6709\u7c7b\u7684\u57fa\u7840\u4e0a\u65b0\u589e\u81ea\u5df1\u7684\u7279\u6027\u800c\u4ea7\u751f\u65b0\u7c7b\u7684\u8fc7\u7a0b\u3002\u6d3e\u751f\u51fa\u7684\u7c7b\u79f0\u4e3a\u6d3e\u751f\u7c7b\u3002</li> </ul> \u76ee\u7684 \u4ee3\u7801\u7684\u91cd\u7528\u548c\u4ee3\u7801\u7684\u6269\u5145 \u7ee7\u627f\u79cd\u7c7b \u5355\u7ee7\u627f/\u591a\u7ee7\u627f \u7ee7\u627f\u5185\u5bb9 \u9664\u6784\u9020\u51fd\u6570/\u6790\u6784\u51fd\u6570/\u79c1\u6709\u6210\u5458\u5916\u7684\u6240\u6709\u6210\u5458"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%90%AC%E8%AF%BE%EF%BC%88ZJU%20%26%20Stanford%20CS106B%EF%BC%89/#_16","title":"\u7ee7\u627f\u7684\u8bbf\u95ee\u63a7\u5236","text":"<p>\u6d3e\u751f\u7c7b\u7ee7\u627f\u4e86\u57fa\u7c7b\u4e2d\u9664\u6784\u9020\u51fd\u6570\u548c\u6790\u6784\u51fd\u6570\u4e4b\u5916\u7684\u6240\u6709\u6210\u5458\u3002\u6d3e\u751f\u7c7b\u7684\u6210\u5458\u5305\u62ec\uff1a - \u7ee7\u627f\u57fa\u7c7b\u7684\u6210\u5458 - \u6d3e\u751f\u7c7b\u5b9a\u4e49\u65f6\u58f0\u660e\u7684\u6210\u5458</p> <p>\u4ece\u5df2\u6709\u7c7b\u6d3e\u751f\u51fa\u65b0\u7c7b\u65f6\uff0c\u53ef\u4ee5\u5728\u6d3e\u751f\u7c7b\u5185\u5b8c\u6210\u4ee5\u4e0b\u51e0\u79cd\u529f\u80fd\uff1a - \u589e\u52a0\u65b0\u7684\u6570\u636e\u6210\u5458 - \u589e\u52a0\u65b0\u7684\u6210\u5458\u51fd\u6570 - \u91cd\u65b0\u5b9a\u4e49\u57fa\u7c7b\u4e2d\u5df2\u6709\u7684\u6210\u5458\u51fd\u6570 - \u53ef\u4ee5\u6539\u53d8\u73b0\u6709\u6210\u5458\u7684\u5c5e\u6027</p> <p>\u58f0\u660e\u4e00\u4e2a\u6d3e\u751f\u7c7b\u7684\u4e00\u822c\u683c\u5f0f</p> <pre><code>class \u6d3e\u751f\u7c7b\u540d:\u7ee7\u627f\u65b9\u5f0f \u57fa\u7c7b\u540d\n{\n        // \u6d3e\u751f\u7c7b\u65b0\u589e\u7684\u6570\u636e\u6210\u5458\u548c\u6210\u5458\u51fd\u6570\n};\n</code></pre> <p>\u4e09\u79cd\u7ee7\u627f\u65b9\u5f0f</p> <pre><code>class employee: public person\n{};\n\n// default\nclass employee: private person\n{};\n\nclass employee: protected person\n{};\n</code></pre> <p>\u57fa\u7c7b\u6210\u5458\u5728\u6d3e\u751f\u7c7b\u4e2d\u7684\u8bbf\u95ee\u5c5e\u6027</p> \u5728\u57fa\u7c7b\u4e2d\u7684\u8bbf\u95ee\u5c5e\u6027 \u7ee7\u627f\u65b9\u5f0f \u5728\u6d3e\u751f\u7c7b\u4e2d\u7684\u8bbf\u95ee\u5c5e\u6027 \u89e3\u91ca private public inaccessible \u57fa\u7c7b\u4e2dprivate\u7684\u5bf9\u8c61\u5728\u7c7b\u5916\u5f53\u7136\u4e0d\u53ef\u8bbf\u95ee private private inaccessible private protected inaccessible public public public \u57fa\u7c7b\u4e0d\u7ba1 public private private public protected protected protected public protected \u6743\u9650\u4f1a\u88ab\u7ee7\u627f\u65b9\u5f0f\u7f29\u5c0f\u800c\u4e0d\u4f1a\u653e\u5927 protected private private protected protected protected <p>\u6d3e\u751f\u7c7b\u5bf9\u57fa\u7c7b\u7684\u8bbf\u95ee\u89c4\u5219 - \u5185\u90e8\u8bbf\u95ee\uff1a\u7531\u6d3e\u751f\u7c7b\u4e2d\u65b0\u589e\u6210\u5458\u5bf9\u57fa\u7c7b\u7ee7\u627f\u6765\u7684\u6210\u5458\u7684\u8bbf\u95ee\u3002 - \u5bf9\u8c61\u8bbf\u95ee\uff1a\u5728\u6d3e\u751f\u7c7b\u5916\u90e8\uff0c\u901a\u8fc7\u6d3e\u751f\u7c7b\u7684\u5bf9\u8c61\u5bf9\u4ece\u57fa\u7c7b\u7ee7\u627f\u6765\u7684\u6210\u5458\u7684\u8bbf\u95ee\u3002</p> \u57fa\u7c7b\u6210\u5458 private\u6210\u5458 public\u6210\u5458 protected\u6210\u5458 \u5185\u90e8\u8bbf\u95ee \u4e0d\u53ef\u8bbf\u95ee \u53ef\u8bbf\u95ee \u53ef\u8bbf\u95ee \u5bf9\u8c61\u8bbf\u95ee \u4e0d\u53ef\u8bbf\u95ee \u4e0d\u53ef\u8bbf\u95ee \u4e0d\u53ef\u8bbf\u95ee <p>\u79c1\u6709\u7ee7\u627f\u4e3e\u4f8b</p> <pre><code>class Point\n{\n    public:\n        void InitP(float x = 0, float y = 0)\n        {\n            this-&gt;X = x;\n            this-&gt;Y = y;\n        }\n        void Move(float offX, float offY)\n        {\n            X += offX;\n            Y += offY;\n        }\n        float GetX() const{return X;}\n        float GetY() const{return Y;}\n    private:\n        float X, Y;\n};\n\nclass Rectangle: private Point // \u6d3e\u751f\u7c7b\u58f0\u660e\n{\n    public: //\u65b0\u589e\u5916\u90e8\u63a5\u53e3\n        void InitR(float x, float y, float w, float h)\n        {\n            InitR(x, y);\n            W = w;\n            H = h;\n        } // \n        void Move(float xOff, float yOff)\n        {\n            Point::\n        }\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%20Namespace/","title":"\u547d\u540d\u7a7a\u95f4","text":"<p>\u547d\u540d\u7a7a\u95f4\uff1a \u540d\u79f0name\u53ef\u4ee5\u662f\u7b26\u53f7\u5e38\u91cf\uff0c\u53d8\u91cf\uff0c\u51fd\u6570\uff0c\u7ed3\u6784\uff0c\u679a\u4e3e\uff0c\u7c7b\u548c\u5bf9\u8c61\u7b49\u3002</p> <p>\u5b9a\u4e49</p> <pre><code>namespace A{\n    int a = 100;\n}\n\nnamespace B{\n    int b = 200;\n}\n\nvoid test(){\n\n    cout &lt;&lt; A::a &lt;&lt; endl;\n    cout &lt;&lt; B::a &lt;&lt; endl;\n}\n</code></pre> <ul> <li>namespace\u5fc5\u987b\u662f\u5168\u5c40\u7684\uff0c\u4e0d\u80fd\u5728\u51fd\u6570\u4e2d\u5b9a\u4e49namespace</li> <li> <p>namespace\u53ef\u4ee5\u5d4c\u5957\uff0c\u53ef\u4ee5\u5728namespace\u4e2d\u5b9a\u4e49namespace     ```cpp     namespace A{         int a = 100;         namespace B{             int a = 2000;             }     }</p> <p>void test(){     cout &lt;&lt; A::a &lt;&lt; endl;     cout &lt;&lt; A::B::a &lt;&lt; endl; } ```</p> </li> <li> <p>namespace\u662f\u5f00\u653e\u7684\uff0c\u5373\u53ef\u4ee5\u968f\u65f6\u628a\u65b0\u6210\u5458\u52a0\u5165\u5df2\u6709\u7684namespace\u4e2d     ```cpp     namespace A{         int a = 100;         int b = 200;     }     // \u5c06c\u6dfb\u52a0\u5230\u5df2\u6709\u7684namespace\u4e2d     namespace A{         int c = 300;     }</p> <p>void test(){     cout &lt;&lt; A::a &lt;&lt; endl;     cout &lt;&lt; A::c &lt;&lt; endl; } ```</p> </li> <li> <p>namespace\u53ef\u4ee5\u5b58\u653e\u53d8\u91cf\u548c\u51fd\u6570</p> <p>```cpp namespace A{     int a = 100;     void func(){         cout &lt;&lt; a &lt;&lt; endl;     } }</p> <p>void test(){     cout &lt;&lt; a &lt;&lt; endl;     A::func(); } ```</p> </li> <li> <p>namespace\u4e2d\u7684\u51fd\u6570\u53ef\u4ee5\u5728namespace\u5916\u5b9a\u4e49     ```cpp     namespace A{         int a = 100;         void func();     }</p> <p>// \u6210\u5458\u51fd\u6570 void A::func(){     cout &lt;&lt; a &lt;&lt; endl; } // \u666e\u901a\u51fd\u6570 void funcb(){     cout &lt;&lt; A::a &lt;&lt; endl; }</p> <p>void test(){     A::func();     funcb(); } ```</p> </li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%20Namespace/#namespace","title":"\u4ec0\u4e48\u65f6\u5019\u9700\u8981\u4f7f\u7528namespace\uff1f","text":"<ul> <li>\u53ef\u4ee5\u4f7f\u4e0d\u540c\u7528\u6237\u5728\u76f8\u540c\u5de5\u7a0b\u4e0b\u7684\u540d\u79f0\u76f8\u540c\u7684\u53d8\u91cf\u5206\u9694\u5f00\u6765\uff0c\u53ef\u4ee5\u4f7f\u6548\u7387\u66f4\u9ad8</li> <li>\u4f7f\u7528\u547d\u540d\u7a7a\u95f4\u53ef\u4ee5\u66f4\u6e05\u6670\u660e\u4e86\u5730\u8868\u660e\u7528\u6237\u5b9a\u4e49\u7684\u53d8\u91cf\u3001\u51fd\u6570\u5728\u54ea\u4e2a\u5730\u65b9</li> <li>\u4e0d\u540c\u4f5c\u7528\u57df\u4e0b\u4f7f\u5b9a\u4e49\u7684\u53d8\u91cf\u51fd\u6570\u66f4\u4e25\u8c28</li> </ul> <p>\u53d8\u91cf\u540d\u51b2\u7a81\u7684\u89e3\u51b3\u65b9\u6cd5</p> <p>\u5982\u679c\u5168\u5c40\u53d8\u91cf\u4e0e\u5c40\u90e8\u53d8\u91cf\u51b2\u7a81\uff0c\u90a3\u4e48\u6309\u5c31\u8fd1\u539f\u5219\u6765\u4f7f\u7528\u3002\uff08\uff1f\uff09</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%20File%20IO/","title":"\u6587\u4ef6\u8bfb\u5199","text":"<pre><code>#include &lt;fstream&gt;\n</code></pre> <pre><code>ifstream fin;\nofstream fout;\n</code></pre> <p>\u6587\u4ef6\u6253\u5f00\u65b9\u5f0f</p> ios::in \u53ea\u8bfb ios::out \u53ea\u5199 ios::app \u4ece\u6587\u4ef6\u672b\u5c3e\u5f00\u59cb\u5199 ios::binary \u4e8c\u8fdb\u5236\u6a21\u5f0f"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/","title":"\u6a21\u677fTemplate","text":"<p>\u9700\u6c42\uff1a\u8ba9\u6211\u4eec\u7684\u4ee3\u7801\u72ec\u7acb\u4e8e\u5177\u4f53\u7684\u7c7b\u578b\u5de5\u4f5c\u3002</p> <p>\u6211\u4eec\u5199\u51fa\u4e00\u4e2a\u9002\u7528\u4e8e\u6240\u6709\u7c7b\u578b\u7684\u6570\u636e\u7ed3\u6784\u7684\u7c7b\u6216\u7b97\u6cd5\uff08\u51fd\u6570\uff09\uff0c\u5728\u771f\u6b63\u9700\u8981\u4f7f\u7528\u65f6\u751f\u6210\u4e00\u4e2a\u9002\u7528\u4e8e\u6240\u9700\u7c7b\u578b\u7684\u5b9e\u4f8b\u3002\u8fd9\u79cd\u7f16\u7a0b\u8303\u5f0f\u79f0\u4e3a\u8303\u578b\u7f16\u7a0b\u3002</p> <p>\u6a21\u677f\u7c7b\u7684\u5199\u6cd5</p> <pre><code>template&lt;typename T&gt;\nclass Container{\n    T *data;\n    unsigned size, capa;\npiblic:\n    Container(unsigned capa = 512): data(new T[capa]){}\n    ~Container() {delete[] data;}\n    T&amp; operator[](unsigned index) {return data[index];}\n}\n</code></pre> <p>\u8fd9\u91cctemplate T\u8868\u660e\u5b83\u63a5\u53d7\u4e00\u4e2a\u7c7b\u578b\u4f5c\u4e3a\u53c2\u6570\uff0c\u540d\u5b57\u662fT\u3002\u5728\u6a21\u677f\u7684\u5b9a\u4e49\u5185\u90e8\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5230\u8fd9\u4e2a\u7c7b\u578b\u53d8\u91cfT\u3002</p> <p>\u7279\u5316\uff1a\u6839\u636e\u6a21\u677f\u751f\u6210\u5b9e\u9645\u7684\u7c7b\u7684\u8fc7\u7a0b</p> <pre><code>Container&lt;int&gt; ci;\nContainer&lt;double&gt; cd;\n</code></pre> <p>\u6a21\u677f\u51fd\u6570\u8981\u600e\u4e48\u5199</p> <pre><code>template&lt;typename T&gt;\nT abs(T x) {return x&gt;0?x:-x;}\n</code></pre> <p>\u6a21\u677f\u8fd0\u7b97\u7b26\u91cd\u8f7d\u600e\u4e48\u5199</p> <pre><code>template&lt;typename T&gt;\nclass Container {\n    T* data;\n    unsigned size = 0, capa;\n\npublic: \n    Container(unsigned capa = 512) : data(new T[capa]), capa(capa){}\n    ~Container(){delete[] data;}\n\n    T&amp; operator[](unsigned index) {return data[index];}\n    const T&amp; operator[](unsigned idnex) const {return data[index];}\n\n    unsigned getSize() const {return size;}\n    unsigned getCapa() const {return capa;}\n\n    Container &amp;add(T val){\n    data[size++] = val;\n    return *this;\n    }\n};\n\ntemplate&lt;typename T&gt;\nostream &amp; operator&lt;&lt;(ostream&amp; os, const Container&lt;T&gt;&amp;c){\n    for (unsigned i = 0; i &lt; c.getSize(); i++){\n        os &lt;&lt; c[i] &lt;&lt; ' ';\n    return os;\n    }\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#reference","title":"Reference","text":"<p>7 \u6a21\u677f (I) - \u57fa\u672c\u77e5\u8bc6\u4e0e STL \u4f7f\u7528 - \u54b8\u9c7c\u6684\u7684\u4ee3\u7801\u7a7a\u95f4</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#template_1","title":"\u53ef\u53d8\u53c2\u6570\u6a21\u677f template <p>C++11\u7684\u65b0\u7279\u6027 \u5bf9\u53c2\u6570\u9ad8\u5ea6\u6cdb\u5316\uff0c\u53ef\u4ee5\u8868\u793a0\u5230\u4efb\u610f\u4e2a\u4efb\u610f\u7c7b\u578b\u7684\u53c2\u6570\u3002</p> <p>\u8bed\u6cd5</p> <pre><code>template &lt;class ...T&gt;  // \u58f0\u660e\u4e00\u4e2a\u53c2\u6570\u5305\uff0c\u8fd9\u4e2a\u53c2\u6570\u5305\u4e2d\u5305\u542b0\u5230\u4efb\u610f\u4e00\u4e2a\u53c2\u6570\u6a21\u677f\nvoid f(T... args);     // \u5728\u6a21\u677f\u5b9a\u4e49\u7684\u53f3\u8fb9\uff0c\u53ef\u4ee5\u5c06\u53c2\u6570\u5305\u5c55\u5f00\u6210\u4e00\u4e2a\u4e00\u4e2a\u72ec\u7acb\u53c2\u6570\n</code></pre> <p>\u6700\u5927\u7684\u96be\u70b9\uff1a\u5982\u4f55\u5c55\u5f00\u53ef\u53d8\u6a21\u677f\u53c2\u6570</p> <p>\u6253\u5370\u53c2\u6570\u4e2a\u6570\uff1a</p> <pre><code>template&lt;class ...T&gt;\nvoid f(T... args)\n{\n        cout &lt;&lt; sizeof...(args) &lt;&lt; endl;\n}\n\nf();\nf(1, 2);\nf(1, 2.5, \"\");\n</code></pre> <p>\u9012\u5f52\u65b9\u5f0f\u5c55\u5f00\u53c2\u6570\u5305</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\n// \u9012\u5f52\u7ec8\u6b62\u51fd\u6570\nvoid print(){\n    cout &lt;&lt; \"empty\" &lt;&lt; endl;\n}\n\n// \u5c55\u5f00\u51fd\u6570\ntemplate&lt;class T, class ...Args&gt;\nvoid print(T head, Args... rest){\n    cout &lt;&lt; \"parameter\" &lt;&lt; head &lt;&lt; endl;\n    print(rest...);\n}\n\nint main(){\n    print(1, 2, 3, 4);\n    return 0;\n}\n</code></pre> <p>\u4e0a\u8ff0\u4f8b\u5b50\u4f1a\u8f93\u51fa\u6bcf\u4e00\u4e2a\u53c2\u6570\uff0c\u76f4\u5230\u7a7a\u65f6\u8f93\u51faempty\u3002\u5c55\u5f00\u53c2\u6570\u5305\u7684\u51fd\u6570\u6709\u4e24\u4e2a\uff0c\u4e00\u4e2a\u662f\u9012\u5f52\u51fd\u6570\uff0c\u53e6\u4e00\u4e2a\u662f\u9012\u5f52\u7ec8\u6b62\u51fd\u6570\uff0c\u53c2\u6570\u5305Args\u2026\u5728\u5c55\u5f00\u7684\u8fc7\u7a0b\u4e2d\u9012\u5f52\u8c03\u7528\u81ea\u5df1\uff0c\u6bcf\u8c03\u7528\u4e00\u6b21\uff0c\u53c2\u6570\u5305\u4e2d\u7684\u53c2\u6570\u5c31\u5c11\u4e00\u4e2a\uff0c\u76f4\u5230\u6240\u6709\u53c2\u6570\u90fd\u5c55\u5f00\u4e3a\u6b62\u3002\u5f53\u6ca1\u6709\u53c2\u6570\u65f6\uff0c\u5219\u8c03\u7528\u975e\u6a21\u677f\u51fd\u6570print()\u7ec8\u6b62\u9012\u5f52\u8fc7\u7a0b\u3002</p> <p>\u7ec8\u6b62\u51fd\u6570\u4e5f\u53ef\u4ee5\u5199\u6210</p> <pre><code>template&lt;class T&gt;\nvoid print(T t){\n    cout &lt;&lt; t &lt;&lt; endl;\n}\n</code></pre> <p>\u53ef\u53d8\u6a21\u677f\u53c2\u6570\u6c42\u548c</p> <pre><code>template&lt;typename T&gt;\nT sum(T t){\n    return t;\n}\ntemplate&lt;typename T, typename ... Types&gt;\nT sum(T first, Types ...rest){\n    return first + sum&lt;T&gt; (rest...);\n}\n\nsum(1, 2, 3, 4);\n</code></pre> <p>\u9012\u5f52\u51fd\u6570\u5c55\u5f00\u53c2\u6570\u5305\u662f\u4e00\u79cd\u6807\u51c6\u505a\u6cd5\uff0c\u4e5f\u6bd4\u8f83\u597d\u7406\u89e3\uff0c\u4f46\u662f\u7f3a\u70b9\u65f6\u5fc5\u987b\u8981\u4e00\u4e2a\u91cd\u8f7d\u7684\uff08\u540c\u540d\uff09\u9012\u5f52\u7ec8\u6b62\u51fd\u6570\u6765\u7ec8\u6b62\u9012\u5f52\u3002</p> <p>\u6216\u8005\u4e0d\u9012\u5f52\u65b9\u5f0f\uff0c\u8fd9\u79cd\u65b9\u5f0f\u9700\u8981\u501f\u52a9\u9017\u53f7\u8868\u8fbe\u5f0f\u548c\u521d\u59cb\u5316\u5217\u8868\u3002\u524d\u9762\u7684print\u53ef\u4ee5\u8fd9\u4e48\u5199</p> <pre><code>template&lt;class T&gt;\nvoid printarg(T t){\n    cout &lt;&lt; t &lt;&lt; endl;\n}\n\ntemplate &lt;class ...Args&gt;\nvoid expand(Args... args){\n    int arr[] = {(printarg(args), 0)...};\n}\n\nexpand(1, 2, 3, 4);\n</code></pre> <p>arr\u8fd9\u4e2a\u6570\u7ec4\u7684\u76ee\u7684\u5355\u7eaf\u662f\u5c55\u5f00\u53c2\u6570\u5305</p> <p>\u5982\u679c\u5c06\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\uff0c\u5c31\u53ef\u4ee5\u652f\u6301lambda\u8868\u8fbe\u5f0f</p> <pre><code>template&lt;class F, class... Args&gt; void expand(const F&amp; f, Args&amp;&amp;...args){\ninitializer_list&lt;int&gt;{(f(std::forward&lt; Args&gt;(args)), 0)};\n}\nexpand([](int i){cout &lt;&lt; i &lt;&lt; endl;}, 1,2,3);\n</code></pre> <p>\u53ef\u4ee5\u5e26\u4efb\u610f\u4e2a\u6570\u4e0d\u540c\u7684\u53c2\u6570\uff0c\u6bd4\u5982std::tuple</p> <pre><code>template&lt;class... Types&gt;\nclass tuple;\n</code></pre> <p>\u6a21\u677f\u504f\u7279\u5316\u548c\u9012\u5f52\u65b9\u5f0f\u5c55\u5f00\u53c2\u6570\u5305</p> <p>\u53ef\u53d8\u53c2\u6570\u6a21\u677f\u7c7b\u7684\u5c55\u5f00\u4e00\u822c\u9700\u8981\u5b9a\u4e49\u4e24\u5230\u4e09\u4e2a\u7c7b\uff0c\u5305\u62ec\u7c7b\u58f0\u660e\u548c\u504f\u7279\u5316\u7684\u6a21\u677f\u7c7b</p> <pre><code>// \u524d\u5411\u58f0\u660e\ntemplate&lt;typename... Args&gt;\nstruct Sum;\n\n// \u57fa\u672c\u5b9a\u4e49\ntemplate&lt;typename First, typename... Rest&gt;\nstruct Sum&lt;First, Rest...&gt;{\n    enum { value = Sum&lt;First&gt;::value + Sum&lt;Rest...&gt;::value };\n}\n\n// \u9012\u5f52\u7ec8\u6b62\ntemplate&lt;typename Last&gt;\nstruct Sum&lt;Last&gt;{\n    enum { value = sizeof(Last) };\n}\n</code></pre>","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#stl","title":"\u6807\u51c6\u6a21\u677f\u5e93 STL <p>STL\u516d\u5927\u90e8\u4ef6\uff1a\u5bb9\u5668\uff08containers\uff09\uff0c\u5206\u914d\u5668\uff08allocators\uff09\uff0c\u7b97\u6cd5\uff08algorithm\uff09\uff0c\u8fed\u4ee3\u5668\uff08iterator\uff09\uff0c\u9002\u914d\u5668\uff08adapters\uff09\uff0c\u4eff\u51fd\u6570\uff08functors\uff09</p>","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#_1","title":"\u5e38\u7528\u7684\u5bb9\u5668","text":"<p>vector, deque, list, set/multiset, map/multimap \u7b49</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#1-vector","title":"1. Vector","text":"<p>Vector\u662f\u4e00\u79cd\u53d8\u957f\u6570\u7ec4\u3002</p> <pre><code>#include&lt;vector&gt;\nusing namespace std;\n\nvector&lt;int&gt; name;\nvector&lt;double&gt; name;\nvector&lt;char&gt; name;\nvector&lt;struct node&gt; name;\n\n// \u8fd9\u4e24\u4e2a\u4e3b\u8981\u6709\u901f\u5ea6\u4e0a\u7684\u533a\u522b\uff0carray\u975e\u5e38\u6162\uff0cvector\u5feb\u4e00\u4e9b\nvector&lt; vector&lt;int&gt; &gt; name; // &gt; &gt;\u4e4b\u95f4\u8981\u52a0\u7a7a\u683c\uff0c\u65b0\u6807\u51c6\u4e0d\u7528\u52a0\u4e86\nvector&lt;int&gt; array[SIZE]; // \u8fd9\u4e2a\u4e0d\u662f\u5f88\u5e38\u7528\uff0c\u56e0\u4e3a\u5bb9\u6613\u51fa\u9519\uff0c\u4e14\u6570\u7ec4\u4e0d\u77e5\u9053\u81ea\u5df1\u7684\u957f\u5ea6\uff0c\u8fd8\u6709std::array\n</code></pre> <p>\u8bbf\u95ee\u65b9\u5f0f</p> <pre><code>// 1. \u901a\u8fc7\u4e0b\u6807\n#include&lt;iostream&gt;\n#include&lt;vector&gt;\nusing namespace std;\n\nint main()\n{\n    vector&lt;int&gt; vi;\n    vi.push_back(1);\n    cout&lt;&lt;vi[0]&lt;&lt;endl;\n    return 0;\n}\n\n// 2. \u901a\u8fc7\u8fed\u4ee3\u5668\nvector&lt;int&gt;::iterator\nvector&lt;double&gt;::iterator\n\n// \u4f8b\n#include&lt;iostream&gt;\n#include&lt;vector&gt;\nint main()\n{\n    vector&lt;int&gt; v;\n    for(int i = 0; i &lt; 5; i++)\n    {\n        v.push_back(i); \n    }\n    vector&lt;int&gt;::iterator it=v.begin();\n    for(int i = 0; i &lt; v.size(); i++)\n    {\n        cout &lt;&lt; it[i] &lt;&lt; \" \";\n        // \u4e5f\u53ef\u4ee5\u5199\u6210 cout &lt;&lt; * (it + i) &lt;&lt; \" \";\n    }\n    return 0;\n}\n\n// \u6216\u8005\u4f18\u96c5\u7684\u5199\u6cd5\n// \u56e0\u4e3a\u8fed\u4ee3\u5668\u4e0d\u652f\u6301 it &lt; v.end()\u7684\u5199\u6cd5\uff0c\u53ea\u80fd\u5199!=\nfor (vector&lt;int&gt;::iterator it=v.begin(); it!=v.end();it++)\n{\n    cout &lt;&lt; *it &lt;&lt; \" \";\n}\n</code></pre> <p>\u5e38\u7528\u51fd\u6570</p> <pre><code>push_back(item) // \u5728vector\u540e\u9762\u6dfb\u52a0\u4e00\u4e2a\u5143\u7d20\npop_back(item) // \u5728vector\u540e\u9762\u5220\u9664\u4e00\u4e2a\u5143\u7d20\nsize(vector) // \u8fd4\u56de\u5143\u7d20\u4e2a\u6570\uff0c\u65f6\u95f4\u590d\u6742\u5ea6O(1)\nclear(vector) // \u6e05\u9664\u6240\u6709\u5143\u7d20\uff0c\u65f6\u95f4\u590d\u6742\u5ea6O(N)\ninsert(position, x) // \u5728position\u7684\u5730\u65b9\u63d2\u5165\u4e00\u4e2ax\n// \u4f8b\nv.insert(v.begin()+2, -1); // \u76f8\u5f53\u4e8e\u5728v[2]\u5904\u63d2\u5165\u4e00\u4e2a-1\nerase(position);\nerase(positionBegin, positionEnd);  // \u5de6\u95ed\u53f3\u5f00\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#2-set","title":"2. set","text":"<p>\u96c6\u5408\u662f\u4e0d\u5141\u8bb8\u5143\u7d20\u91cd\u590d\u7684\u65e0\u5e8f\u5bb9\u5668</p> <pre><code>#include&lt;set&gt;\nusing namespace std;\n\nset&lt;int&gt; name;\nset&lt;double&gt; name;\nset&lt;char&gt; name;\nset&lt;struct node&gt; name;\nset&lt;set&lt;int&gt; &gt; name;\n</code></pre> <p>\u56e0\u4e3a\u65e0\u5e8f\uff0cset\u53ea\u80fd\u901a\u8fc7iterator\u8bbf\u95ee\uff0c\u9664\u4e86vector\u548cstring\u4e4b\u5916\u7684\u5bb9\u5668\u90fd\u4e0d\u80fd\u901a\u8fc7\u4e0b\u6807\u8bbf\u95ee</p> <pre><code>set&lt;int&gt;::iterator it;\nset&lt;char&gt;::iterator it;\n</code></pre> <p>\u5e38\u7528\u51fd\u6570</p> <pre><code>st.insert(X);\nst.find(X); // \u8fd4\u56deset\u4e2dvalue\u6240\u5bf9\u5e94\u7684\u8fed\u4ee3\u5668\uff0c\u4e5f\u5c31\u662fvalue\u7684\u6307\u9488\n// \u4f8b\nset&lt;int&gt;::iterator it = st.find(2);\ncout &lt;&lt; *it &lt;&lt; endl;\n// \u53ef\u4ee5\u76f4\u63a5\u5199\u6210\ncout &lt;&lt; *(st.find(2)) &lt;&lt; endl;\nst.erase(it); // \u5220\u9664\u67d0\u4e2a\u5730\u5740\u7684\u5143\u7d20\uff0c\u65f6\u95f4\u590d\u6742\u5ea6O(1)\nst.erase(X); // \u5220\u9664\u67d0\u4e2a\u5143\u7d20\uff0c\u65f6\u95f4\u590d\u6742\u5ea6O(N)\nst.erase(itBegin, itEnd);\nst.size();\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#3-deque","title":"3. deque","text":"<p>deque\u662f\u7531\u4e00\u6bb5\u5b9a\u91cf\u8fde\u7eed\u7a7a\u95f4\u6784\u6210\uff0c\u4e00\u65e6\u8981\u5728deque\u7684\u524d\u7aef\u548c\u5c3e\u7aef\u589e\u52a0\u7a7a\u95f4\uff0c\u4fbf\u914d\u7f6e\u4e00\u6bb5\u8fde\u7eed\u7a7a\u95f4\uff0c\u4e32\u5728\u6574\u4e2adeque\u7684\u5934\u90e8\u548c\u5c3e\u90e8.</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#4-list","title":"4. list","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#5-mapunordered_map","title":"5. map/unordered_map","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#6-string","title":"6. string","text":"<pre><code>// init\n#include&lt;string&gt;\nstring str;\nstring str = \"Hello\";\ncin &gt;&gt; str;\ncout &lt;&lt; str;\n\n\n// assignment\nchar cstr1[20];\nchar cstr2[20] = \"jaguar\";\n\nstring str1;\nstring str2 = \"panther\";\n\ncstr1 = cstr2; // illegal\nstr1 = str2; // legal\n\n\n// concatenation\nstring str3;\nstr3 = str1 + str2;\nstr1 += str2;\nstr1 += \"a string literal\";\n\n// constructors (Ctors)\nstring (const char *cp, int len);\nstring (const string&amp; s2, int pos);\nstring (const string&amp; s2, int pos, int len);\n\n// sub-string\nsubstr (int pos, int len);\n\n// modification\nassign (...);\ninsert (...);\ninsert (int pos, const string&amp; s);\nerase (...);\nappend (...);\nreplace (...);\nreplace (int pos, int len, const string&amp; s);\n...\n\n// search\nfind (const string&amp; s);\n\n\n// File I/O\n#include &lt;ifstream&gt; // read from file\n#include &lt;ofstream&gt;  // write to file\n\n// write into file\nofstream File1(\"...\");\nFile1 &lt;&lt; \"Hello world\" &lt;&lt; std::enl;\n\n// read from file\nifstream File2(\"...\");\nstd::string str;\nFile2 &gt;&gt; str;\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#_2","title":"\u7b97\u6cd5","text":"<p>\u7b97\u6cd5\u90e8\u5206\u4e3b\u8981\u7531<code>&lt;algorithm&gt; &lt;numeric&gt; &lt;functional&gt;</code>\u7ec4\u6210 <code>&lt;algorithm&gt;</code>\u662f\u6700\u5927\u7684\u4e00\u4e2a <code>&lt;numeric&gt;</code>\u4f53\u79ef\u5f88\u5c0f\uff0c\u53ea\u5305\u62ec\u51e0\u4e2a\u5728\u5e8f\u5217\u4e0a\u8fdb\u884c\u7b80\u5355\u6570\u5b66\u8fd0\u7b97\u7684\u6a21\u677f\u51fd\u6570 <code>&lt;functional&gt;</code>\u5b9a\u4e49\u4e86\u4e00\u4e9b\u6a21\u677f\u7c7b\uff0c\u7528\u4ee5\u58f0\u660e\u51fd\u6570\u5bf9\u8c61</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#iterator","title":"\u8fed\u4ee3\u5668 Iterator","text":"<p>\u7528\u8fed\u4ee3\u5668\u53ef\u4ee5\u8bfb\u53d6\u5b83\u6307\u5411\u7684\u5143\u7d20\u3002\u8fed\u4ee3\u5668\u540d\u5c31\u8868\u793a\u8fed\u4ee3\u5668\u6307\u5411\u7684\u5143\u7d20\uff0c\u901a\u8fc7\u975e\u5e38\u91cf\u8fed\u4ee3\u5668\u8fd8\u80fd\u4fee\u6539\u5176\u6307\u5411\u7684\u5143\u7d20\u3002</p> <pre><code>#include&lt;iostream&gt; \n#include&lt;vector&gt; \nusing namespace std; \nint main() { \n    vector&lt;int&gt; v; \n    for (int n = 0; n &lt; 5; ++n) \n        v.push_back(n); \n    vector&lt;int&gt;::iterator i; \n    for (i = v.begin(); i != v.end(); i++) { \n        cout &lt;&lt; *i &lt;&lt; \" \"; // *i \u662f i \u6307\u5411\u7684\u5143\u7d20 *i *= 2; \n    } \n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#stl_1","title":"\u7c7b\u5e93\u548cSTL <p>STL\u662f\u8303\u578b\u7a0b\u5e8f\u8bbe\u8ba1\u7684\u4e00\u4e2a\u8303\u4f8b\uff0c\u542b\uff1a\u5bb9\u5668\uff08container\uff09\u3001\u8fed\u4ee3\u5668\uff08iterator\uff09\u3001\u7b97\u6cd5\uff08algorithm\uff09\u3001\u51fd\u6570\u5bf9\u8c61\uff08function object\uff09\u3002\u7c7b\u5e93\u662f\u7c7b\u7684\u96c6\u5408\uff0c\u662f\u4e00\u79cd\u9884\u5b9a\u4e49\u7684\u9762\u5411\u5bf9\u8c61\u7684\u7a0b\u5e8f\u5e93\u3002</p>","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#c","title":"C++\u7684\u6807\u51c6\u5e93","text":"<p>using namespace std;</p> <ul> <li>\u57fa\u672c\u7684\u8fd0\u884c\u5e93\uff1a\u4f8b\u5982\u652f\u6301\u52a8\u6001\u5185\u5b58\u5206\u914d\u3001\u8fd0\u884c\u65f6\u7c7b\u578b\u4fe1\u606fRTTI</li> <li>C\u8bed\u8a00\u7684\u6807\u51c6\u5e93</li> <li>\u6807\u51c6\u6a21\u677f\u5e93STL</li> <li>\u8f93\u5165\u8f93\u51fa\u6d41\u7c7b\u5e93\uff08I/O stream\uff09\u548c\u5b57\u7b26\u4e32</li> <li>\u6570\u503c\u8ba1\u7b97\u5e93</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#stl_2","title":"STL\u4e2d\u7684\u5bb9\u5668\u7c7b","text":"<p>\u5bb9\u5668\uff08container\uff09\u7c7b\u662f\u7528\u6765\u5bb9\u7eb3\u3001\u5305\u542b\u4e00\u7ec4\u5143\u7d20\u6216\u5143\u7d20\u96c6\u5408\u7684\u5bf9\u8c61\u7684\u3002STL\u4e2d\u5b9a\u4e49\u4e86\u591a\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u5bb9\u5668\uff0c\u4f8b\u5982</p> <ul> <li>\u5411\u91cf vector</li> <li>\u7ebf\u6027\u8868 list</li> <li>\u961f\u5217 queue</li> <li>\u6620\u5c04 map</li> <li>\u96c6\u5408 set</li> <li>\u5b57\u7b26\u4e32 string</li> <li>stack: stack</li> <li>associative array: map</li> </ul>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#vector","title":"\u5411\u91cf vector","text":"<p>\u5b9a\u4e49</p> <pre><code>vector&lt;int&gt; iv;\nvector&lt;int&gt; cv(5);\nvector&lt;int&gt; cv(5, 'x');\nvector&lt;int&gt; iv2(iv);\n</code></pre> <p>\u4f7f\u7528</p> <pre><code>#include&lt;iostream&gt;\n#include&lt;vector&gt;\nusing namespace std;\nint main()\n{\n    vector&lt;char&gt; v;  // create zero-len vector\n    int i;\n\n    // put values into a vector\n    for (i = 0; i &lt; 10; i++)\n        v.push_back('A' + i);\n\n    // can access vector contents using subsripting\n    for (i = 0; i &lt; 10; i++)\n        cout &lt;&lt; v[i] &lt;&lt; \" \";\n    cout &lt;&lt; endl;\n\n    // access via iterator\n    vector&lt;char&gt;::iterator p = v.begin();\n    while(p != v.end())\n    {\n        cout &lt;&lt; *p &lt;&lt; \" \";\n        p++;\n    }\n    return 0;\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#list","title":"\u7ebf\u6027\u8868 list","text":"<p>\u5b9a\u4e49\u4e86\u53cc\u5411\u7684\u7ebf\u6027\u8868\uff0c\u53c8\u53ef\u79f0\u4e3a\u53cc\u5411\u94fe\u8868\u3002list\u7c7b\u53ea\u652f\u6301\u987a\u5e8f\u8bbf\u95ee\u3002</p> <pre><code>// sort a list\n#include&lt;iostream&gt;\n#include&lt;list&gt;\n#include&lt;cstdlib&gt;\nusing namespace std;\n\nint main()\n{\n    int i;\n    list&lt;char&gt; lst;\n    // create a list of random characters\n    for (i = 0; i &lt; 10; i++)\n        list.push_back('A' + (rand()%26));\n\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#set","title":"\u96c6\u5408 set","text":"<pre><code>#include&lt;set&gt;\n#include&lt;iostream&gt;\n#include&lt;string&gt;\nint main()\n{\n    std::set&lt;std::string&gt; source;\n    std::string input;\n    for(int i=0;i&lt;6;i++)\n    {\n        std::cin&gt;&gt;input;\n        source.insert(input);\n    }\n    std::set&lt;std::string&gt;::iterator at = source.begin();\n    while(at != source.end())\n        std::cour &lt;&lt; * at++ &lt;&lt; std::endl;\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#multiset","title":"multiset","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#map","title":"\u6620\u5c04 map","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#queue","title":"\u961f\u5217 queue","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#stdstack","title":"std::stack","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#stdpair","title":"std::pair","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#string","title":"\u5b57\u7b26\u4e32string","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#_3","title":"\u7b97\u6cd5\u5e93 ` <ul> <li>\u6392\u5e8f sort()</li> <li>\u67e5\u627e find()</li> <li>\u66ff\u6362 replace()</li> <li>\u5408\u5e76 merge()</li> <li>\u53cd\u5e8f reverse()</li> <li>\u7edf\u8ba1 count()</li> </ul>","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#sort","title":"\u6392\u5e8f\u7b97\u6cd5sort","text":"<pre><code>#include&lt;algorithm&gt;\n#include&lt;iostream&gt;\n#include&lt;string&gt;\n#include&lt;vector&gt;\nusing namespace std;\nvoid load(vector&lt;string&gt;&amp;);\nvoid print(vector&lt;string&gt;);\nconst int SIZE = 8;\nint main()\n{\n    vector&lt;string&gt; v(SIZE);\n    load(v);\n    sort(v.begin(), v.end());  // \u6307\u5b9a\u6392\u5e8f\u7684\u8d77\u6b62\u4f4d\u7f6e\n    print(v);\n    return 0;\n}\n// \u4f1a\u6309\u7167\u5b57\u6bcd\u5e8f\u6392\u5e8f\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#_4","title":"\u8fed\u4ee3\u5668 <p>\u662f\u4e00\u79cd\u7c7b\u4f3c\u6307\u9488\u7684\u5bf9\u8c61\uff0c\u53ef\u4ee5\u4f7f\u7528\u8fed\u4ee3\u5668\u6765\u8bbf\u95ee\u5bb9\u5668\u4e2d\u7684\u5143\u7d20\u3002</p> <ul> <li>\u968f\u673a\u8bbf\u95ee\u8fed\u4ee3\u5668 RandIter</li> <li>\u53cc\u5411\u8fed\u4ee3\u5668 BiIter</li> <li>\u524d\u5411\u8fed\u4ee3\u5668 ForIter</li> <li>\u8f93\u5165\u8fed\u4ee3\u5668 InIter</li> <li>\u8f93\u51fa\u8fed\u4ee3\u5668 OutIter</li> </ul>","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#reverse-iterator","title":"\u53cd\u5411\u8fed\u4ee3\u5668 reverse iterator","text":"<pre><code>#include&lt;list&gt;\n#include&lt;iostream&gt;\nint main()\n{\n    using namespace std;\n    list&lt;int&gt; c1;\n    list&lt;int&gt;::iterator c1_Iter;\n    list&lt;int&gt;::reverse_iterator c1_rIter;\n\n    c1_rIter = c1.rbegin(); // the last element\n\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%A8%A1%E6%9D%BF%E5%92%8C%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93%20Template%20%26%20STL/#_5","title":"\u53c2\u8003\u8d44\u6599 <p>https://zhuanlan.zhihu.com/p/344558356 LJJ PPT</p>","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B7%B1%E6%8B%B7%E8%B4%9D%20Shallow%20copy%20%26%20Deep%20copy/","title":"\u6d45\u62f7\u8d1d\u548c\u6df1\u62f7\u8d1d","text":"<p>\u6d45\u62f7\u8d1d\uff08\u9ed8\u8ba4\u62f7\u8d1d\u51fd\u6570\uff09\uff1a\u5c06\u539f\u5bf9\u8c61\u6216\u539f\u6570\u7ec4\u7684\u5f15\u7528\u76f4\u63a5\u8d4b\u503c\u7ed9\u65b0\u5bf9\u8c61\u3001\u65b0\u6570\u7ec4\uff0c\u65b0\u5bf9\u8c61/\u65b0\u6570\u7ec4\u53ea\u662f\u539f\u5bf9\u8c61\u7684\u4e00\u4e2a\u5f15\u7528\u3002 \u6df1\u62f7\u8d1d\uff1a\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u5bf9\u8c61\u548c\u6570\u7ec4\uff0c\u5c06\u539f\u5bf9\u8c61\u7684\u5404\u9879\u5c5e\u6027\u7684\u201c\u503c\u201d\uff08\u6570\u7ec4\u91cc\u7684\u6240\u6709\u5143\u7d20\uff09\u62f7\u8d1d\u8fc7\u6765\u3002\u662f\u201c\u503c\u201d\u800c\u4e0d\u662f\u5f15\u7528\u3002</p> <p>\u4f7f\u7528\u65f6\u6ce8\u610f\uff1a \u6df1\u62f7\u8d1d\u4f1a\u5728\u5806\u5185\u5b58\u91cc\u53e6\u5916\u7533\u8bf7\u7a7a\u95f4\u6765\u50a8\u5b58\u6570\u636e\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u6307\u9488\u60ac\u6302\u95ee\u9898\u3002\u5f53\u6570\u636e\u6210\u5458\u4e2d\u6709\u6307\u9488\u65f6\uff0c\u5fc5\u987b\u4f7f\u7528\u6df1\u62f7\u8d1d\u3002</p> <p>\u6df1\u62f7\u8d1d\u7684\u5199\u6cd5</p> <pre><code>class MyString\n{\n    private:\n       char *str;\n    public:\n       MyString(const char *p=nullstr)//\u7f3a\u7701\u6784\u9020\u51fd\u6570\n           :str(nullptr)\n      {\n         if(p!=nullptr)\n        {\n          int len=strlen(p)+1;\n          str=new char[len];\n          strcpy_s(str,lrn,p);\n         }\n      }\n\n       MyString(const MyString&amp; ms)//\u62f7\u8d1d\u6784\u9020\u51fd\u6570\uff0c\u6df1\u62f7\u8d1d\n      {\n         int n = strlen(ms.str) + 1;\n         *str = new char[n];\n         strcpy_s = (str, n, ms.str);\n         //int *str\n         // this-&gt;str=new int(*ms.str)\n      }\n\n       ~MyString()//\u6790\u6784\u51fd\u6570\n      {\n      }\n}\uff1b\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/","title":"\u7c7b\u578b\u548c\u7c7b\u578b\u8f6c\u6362","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/#type-info","title":"Type info \u5e93","text":"<pre><code>#include &lt;typeinfo&gt;\n</code></pre> <p>\u7b80\u4ecb - \u548csizeof\u8fd9\u7c7b\u64cd\u4f5c\u7b26\u4e00\u6837\uff0ctypeid\u662fc++\u7684\u5173\u952e\u5b57\u4e4b\u4e00 - typeid\u64cd\u4f5c\u7b26\u8fd4\u56de\u7684\u7ed3\u679c\u662f\u540d\u4e3atype_info\u7684\u6807\u51c6\u5e93\u7c7b\u578b\u7684\u5bf9\u8c61\u7684\u5f15\u7528\uff08\u5728\u5934\u6587\u4ef6typeinfo\u4e2d\u5b9a\u4e49\uff09 - c++\u5e76\u6ca1\u6709\u89c4\u5b9atypeid\u5b9e\u73b0\u6807\u51c6\uff0c\u5404\u4e2a\u7f16\u8bd1\u5668\u53ef\u80fd\u4f1a\u4e0d\u4e00\u6837 - \u7f16\u8bd1\u5668\u4f1a\u4e3a\u6bcf\u4e00\u79cdtypeid\u64cd\u4f5c\u7684\u7c7b\u578b\u751f\u6210\u4e00\u4efd\u4fdd\u5b58\u5728\u6570\u636e\u6bb5\u7684type_info\u6570\u636e - \u6bcf\u79cd\u7c7b\u578b\u7684type_info\u6570\u636e\u957f\u5ea6\u4f9d\u8d56\u4e8e\u7c7b\u578b\u540d\u79f0\uff0c\u81f3\u5c119\u4e2a\u5b57\u8282</p> <p>\u7528\u6cd5 - \\== \u548c!=\u64cd\u4f5c</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;typeinfo&gt;\n\nstruct Base{};\nstruct Derived: Base {};\nstruct Poly_Base {virtual void Member(){}};\nstruct Poly_Derived: Poly_Base {};\n\ntypedef int my_int_type;\n\nint main()\n{\n    std::cout &lt;&lt; std::boolalpha;\n\n    std::cout &lt;&lt; \"int vs my_int_type: \";\n    std::cout &lt;&lt; (typeid(int) == typeid(my_int_type)) &lt;&lt; '\\\\n';\n\n    std::cout &lt;&lt; \"Base vs Derived: \";\n    std::cout &lt;&lt; (typeid(Base) == typeid(Derived)) &lt;&lt; '\\\\n'; // \u8f93\u51fafalse\n\n    Base* pbase = new Derived;\n\n}\n</code></pre> <ul> <li>name\u64cd\u4f5c\uff1a\u83b7\u53d6type\u7684\u540d\u5b57\uff0c\u8fd9\u4e2a\u540d\u5b57\u662fc\u98ce\u683c\u7684\u5b57\u7b26\u4e32\u6307\u9488</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;typeinfo&gt;\n\nstruct Base{}\nstruct Derived: Base{};\ntemplate &lt;class T&gt;\nvoid swap(T a, T b){\n    std::cout &lt;&lt; \"T is: \" &lt;&lt; typeid(T).name() &lt;&lt; '\\\\n';\n    T temp = a;\n    a = b;\n    b = temp;\n}\n\nint main(){\n\n    int i;\n    int* ptr;\n    std::cout &lt;&lt; \"int is: \" &lt;&lt; typeid(int).name() &lt;&lt; '\\\\n';\n    std::cout &lt;&lt; \"  i is: \" &lt;&lt; typeid(i).name() &lt;&lt; '\\\\n';\n\n}\n</code></pre> <p>\u53c2\u8003 C++\u4e2d\u7684typeInfo\u7528\u6cd5\u603b\u7ed3_\u975e\u665a\u975e\u665a\u7684\u535a\u5ba2-CSDN\u535a\u5ba2</p>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/#_1","title":"\u7c7b\u578b\u8f6c\u6362","text":""},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/#const_cast","title":"const_cast","text":"<pre><code>const_cast&lt;new_type&gt;(expression);\n</code></pre> <ul> <li>returns a value of type new_type</li> <li>\u5c06\u5bf9\u8c61\u7684\u5e38\u91cf\u6027\u8f6c\u9664\uff08cast away the constness\uff09</li> </ul> <pre><code>#include &lt;iostream&gt;\n\nstruct type\n{\n    int i;\n\n    type(): i(3) {}\n\n    void f(int v) const\n    {\n        // this-&gt;i = v;                 // compile error: this is a pointer to const\n        const_cast&lt;type*&gt;(this)-&gt;i = v; // OK as long as the type object isn't const\n    }\n};\n\nint main()\n{\n    int i = 3;                 // i is not declared const\n    const int&amp; rci = i;\n    const_cast&lt;int&amp;&gt;(rci) = 4; // OK: modifies i\n    std::cout &lt;&lt; \"i = \" &lt;&lt; i &lt;&lt; '\\\\n';\n\n    type t; // if this was const type t, then t.f(4) would be undefined behavior\n    t.f(4);\n    std::cout &lt;&lt; \"type::i = \" &lt;&lt; t.i &lt;&lt; '\\\\n';\n\n    const int j = 3; // j is declared const\n    [[maybe_unused]]\n    int* pj = const_cast&lt;int*&gt;(&amp;j);\n    // *pj = 4;      // undefined behavior\n\n    [[maybe_unused]]\n    void (type::* pmf)(int) const = &amp;type::f; // pointer to member function\n    // const_cast&lt;void(type::*)(int)&gt;(pmf);   // compile error: const_cast does\n                                              // not work on function pointers\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/#dynamic_cast","title":"dynamic_cast","text":"<pre><code>dynamic_cast&lt;new_type&gt;(expression);\n</code></pre> <ul> <li>returns a value of type new_type</li> <li>\u5b89\u5168\u5411\u4e0b\u8f6c\u578b\u201dsafe downcasting\u201d</li> <li>\u7528\u6765\u51b3\u5b9a\u5bf9\u8c61\u662f\u5426\u5c5e\u4e8e\u7ee7\u627f\u4f53\u7cfb\u4e2d\u7684\u67d0\u4e2a\u7c7b\u578b</li> <li>exclusively for handling polymorphism</li> </ul> <pre><code>#include &lt;iostream&gt;\n\nstruct V\n{\n    virtual void f() {} // must be polymorphic to use runtime-checked dynamic_cast\n};\n\nstruct A : virtual V {};\n\nstruct B : virtual V\n{\n    B(V* v, A* a)\n    {\n        // casts during construction (see the call in the constructor of D below)\n        dynamic_cast&lt;B*&gt;(v); // well-defined: v of type V*, V base of B, results in B*\n        dynamic_cast&lt;B*&gt;(a); // undefined behavior: a has type A*, A not a base of B\n    }\n};\n\nstruct D : A, B\n{\n    D() : B(static_cast&lt;A*&gt;(this), this) {}\n};\n\nstruct Base\n{\n    virtual ~Base() {}\n};\n\nstruct Derived: Base\n{\n    virtual void name() {}\n};\n\nint main()\n{\n    D d; // the most derived object\n    A&amp; a = d; // upcast, dynamic_cast may be used, but unnecessary\n\n    [[maybe_unused]]\n    D&amp; new_d = dynamic_cast&lt;D&amp;&gt;(a); // downcast\n    [[maybe_unused]]\n    B&amp; new_b = dynamic_cast&lt;B&amp;&gt;(a); // sidecast\n\n    Base* b1 = new Base;\n    if (Derived* d = dynamic_cast&lt;Derived*&gt;(b1); d != nullptr)\n    {\n        std::cout &lt;&lt; \"downcast from b1 to d successful\\\\n\";\n        d-&gt;name(); // safe to call\n    }\n\n    Base* b2 = new Derived;\n    if (Derived* d = dynamic_cast&lt;Derived*&gt;(b2); d != nullptr)\n    {\n        std::cout &lt;&lt; \"downcast from b2 to d successful\\\\n\";\n        d-&gt;name(); // safe to call\n    }\n\n    delete b1;\n    delete b2;\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/#reinterpret_cast","title":"reinterpret_cast","text":"<pre><code>reinterpret_cast&lt;new_type&gt;(expression)\n</code></pre> <ul> <li>returns a value of type new_type</li> <li>\u610f\u56fe\u6267\u884c\u4f4e\u7ea7\u8f6c\u578b\uff0c\u5b9e\u9645\u52a8\u4f5c\u53d6\u51b3\u4e8e\u7f16\u8bd1\u5668\u2192\u4e0d\u53ef\u79fb\u690d</li> <li>\u4e0d\u5e38\u89c1</li> <li>most dangerous cast</li> </ul> <pre><code>#include &lt;cassert&gt;\n#include &lt;cstdint&gt;\n#include &lt;iostream&gt;\n\nint f() { return 42; }\n\nint main()\n{\n    int i = 7;\n\n    // pointer to integer and back\n    std::uintptr_t v1 = reinterpret_cast&lt;std::uintptr_t&gt;(&amp;i); // static_cast is an error\n    std::cout &lt;&lt; \"The value of &amp;i is \" &lt;&lt; std::showbase &lt;&lt; std::hex &lt;&lt; v1 &lt;&lt; '\\\\n';\n    int* p1 = reinterpret_cast&lt;int*&gt;(v1);\n    assert(p1 == &amp;i);\n\n    // pointer to function to another and back\n    void(*fp1)() = reinterpret_cast&lt;void(*)()&gt;(f);\n    // fp1(); undefined behavior\n    int(*fp2)() = reinterpret_cast&lt;int(*)()&gt;(fp1);\n    std::cout &lt;&lt; std::dec &lt;&lt; fp2() &lt;&lt; '\\\\n'; // safe\n\n    // type aliasing through pointer\n    char* p2 = reinterpret_cast&lt;char*&gt;(&amp;i);\n    std::cout &lt;&lt; (p2[0] == '\\\\x7' ? \"This system is little-endian\\\\n\"\n                                 : \"This system is big-endian\\\\n\");\n\n    // type aliasing through reference\n    reinterpret_cast&lt;unsigned int&amp;&gt;(i) = 42;\n    std::cout &lt;&lt; i &lt;&lt; '\\\\n';\n\n    [[maybe_unused]] const int &amp;const_iref = i;\n    // int &amp;iref = reinterpret_cast&lt;int&amp;&gt;(\n    //     const_iref); // compiler error - can't get rid of const\n    // Must use const_cast instead: int &amp;iref = const_cast&lt;int&amp;&gt;(const_iref);\n}\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2Type%20%26%20Type%20Conversion/#static_cast","title":"static_cast","text":"<pre><code>static_cast&lt;new_type&gt;(expression)\n</code></pre> <ul> <li>returns a value of type new_type</li> <li>\u5f3a\u8f6c</li> <li>static_cast is the first cast should attempt to use.</li> <li>can cast through inheritance hierarchies.</li> </ul> <pre><code>struct B {}; \nstruct D : B { \n    B b; \n}; D d; \nB&amp; br1 = d; \nB&amp; br2 = d.b; \nstatic_cast&lt;D&amp;&gt;(br1); // OK: lvalue denoting the original d object \nstatic_cast&lt;D&amp;&gt;(br2); // UB: the b subobject is not a base class subobject\n</code></pre>"},{"location":"CS_Notes/%E6%88%91%E7%9A%84C%2B%2B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E7%BB%A7%E6%89%BF%20Inheritance/","title":"\u7ee7\u627f","text":"<p>is_a \u903b\u8f91</p> <pre><code>#include &lt;&gt;\n\nclass B{\npublic:\n    int f(int i) {cout &lt;&lt; \"f(int)\"; return i+1; }\n};\n\nclass D: public B{\npublic:\n    using B::f;  // \u4fdd\u8bc1\u4e0d\u4f1a\u8986\u76d6\u6389B\u4e2d\u7684f\n    double f(double d)  \n}\n\n</code></pre> <p>\u8bbf\u95ee\u63a7\u5236\uff1aprivate\u548cprotected\u7ee7\u627f</p> <pre><code>int a;\nclass X{\n    int a;\n};\n\nclass XX: public X{\n    void \n}\n</code></pre> <p>\u865a\u7ee7\u627f</p> <p>\u5411\u4e0a\u8f6c\u578b</p> <pre><code>Base *pb = &amp;derived;\n</code></pre> <p>\u8fd9\u4e2a\u4e0d\u4e00\u5b9a\u53ef\u884c</p> <pre><code>Shape s = c;   // object slicing\ns = c;         // copy assignment\n</code></pre> <p>virtual \u5173\u952e\u5b57</p> <p>\u8bf4\u660e\u4e00\u4e2a non-static member function \u662f\u4e00\u4e2a virtual function</p> <p>\u884c\u4e3a\u53ef\u4ee5\u88ab\u6d3e\u751f\u7c7boverride\uff08\u91cd\u5199/\u8986\u76d6\uff09</p> <p>Base::vf\uff0c\u5b50\u7c7b\u6709\u4e00\u4e2a\u540d\u5b57\u3001\u53c2\u6570\u5217\u8868</p> <pre><code>struct Base {\n    virtual void print() {cout &lt;&lt; \"Base\\\\n\"; }\n};\n\nstruct Derived: public Base{\n    void \n}\n</code></pre> <p>virtual call \u53ea\u5173\u5fc3\u5bf9\u8c61\u7684\u7c7b\u578b\uff0ccall\u5bf9\u5e94\u7c7b\u7684\u51fd\u6570</p> <p>\u53ea\u8981\u8c03\u7528\u865a\u51fd\u6570\u5c31\u662f\u865a\u8c03\u7528</p> <pre><code>virtual void do_draw() = 0;   // \u662f\u7eaf\u865a\u51fd\u6570\uff0c\u4e0d\u5fc5\u6709\u5b9e\u73b0\uff0c\u4f46\u662f\u53ef\u4ee5\u6709\u5b9e\u73b0\n</code></pre> <p>\u5982\u679c\u6709\u81f3\u5c11\u4e00\u4e2a\u7eaf\u865a\u51fd\u6570\uff0c\u662f\u62bd\u8c61\u7c7b\uff0c\u62bd\u8c61\u7c7b\u4e0d\u80fd\u7528\u4e8e\u58f0\u660e\u6210\u5458\uff0c\u53ea\u80fd\u4f5c\u4e3a\u57fa\u7c7b</p> <p>final \u5173\u952e\u5b57\uff1a\u4e0d\u80fd\u88ab\u91cd\u5199\uff0c\u4e0d\u80fd\u88ab\u7ee7\u627f</p> <p>\u865a\u51fd\u6570\u7684\u901a\u5e38\u5b9e\u73b0\uff1avirtual table (vtable)</p> <p>static vtable \u865a\u8868</p> <pre><code>class Der: public Base {\npublic:\n    virtual arbiturary_return_type vir0{}\n    virtual arbiturary_return_type vir1{}\n    virtual arbiturary_return_type vie2{}\n}\n</code></pre> <p>\u5b83\u7684\u865a\u51fd\u6570\u8868</p> <pre><code>FunctionPtr Der::__vtable[5]{\n    &amp;Der::vir0, &amp;Der::vir1, &amp;Der::vir2, &amp;Base::vir3, &amp;Base::vir4\n}\n</code></pre> <p>\u597d\u50cf\u5b9e\u9645\u4e0a\u76f8\u5f53\u4e8e\u8fd9\u4e48call\u7684</p> <pre><code>b.__vptr[3](b);\n</code></pre> <p>template\u548cOOP\u7684\u533a\u522b\uff0c\u8bed\u4e49\u4e0d\u4e00\u6837\u3002</p>"},{"location":"DL_Notes/","title":"\u7d22\u5f15","text":"<p>\u672c\u7ae0\u8282\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba+\u5de5\u7a0b\u7b14\u8bb0\uff0c\u5df2\u5b8c\u6210\u4ee5\u4e0b\u5185\u5bb9 - \u5e38\u7528\u7684python\u547d\u4ee4 - \u5e38\u7528\u7684terminal\u547d\u4ee4 - NLP\u5b66\u4e60\u548c\u5de5\u7a0b\u7b14\u8bb0</p>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/","title":"Note on Transformer Code","text":""},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#introduction","title":"Introduction","text":"<p>This note only focuses on the classes and eliminates all other packages or data processing lines.</p> <p>To implement a Transformer model, the following classes need to be implemented. - embeddings: positional encoding, token embedding, transformer embedding - layers: layer norm, multi-head attention, position-wise feed forward, scale dot product attention - blocks: encoder-layer, decoder-layer - model: encoder, decoder, Transformer</p>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#utils","title":"Utils","text":"<pre><code>import torch\nfrom torch import nn\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#positional-embedding","title":"Positional embedding","text":"<pre><code>class PositionalEncoding(nn.Module):\n    \"\"\"\n    compute sinusoid encoding.\n    \"\"\"\n    def __init__(self, d_model, max_len, device):\n        \"\"\"\n        constructor of sinusoid encoding class\n\n        :param d_model: dimension of model\n        :param max_len: max sequence length\n        :param device: hardware device setting\n        \"\"\"\n        super(PositionalEncoding, self).__init__()\n\n        # same size with input matrix (for adding with input matrix)\n        self.encoding = torch.zeros(max_len, d_model, device=device)\n        self.encoding.requires_grad = False  # we don't need to compute gradient\n\n        pos = torch.arange(0, max_len, device=device)\n        pos = pos.float().unsqueeze(dim=1)\n        # 1D =&gt; 2D unsqueeze to represent word's position\n\n        _2i = torch.arange(0, d_model, step=2, device=device).float()\n        # 'i' means index of d_model (e.g. embedding size = 50, 'i' = [0,50])\n        # \"step=2\" means 'i' multiplied with two (same with 2 * i)\n\n        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n        # compute positional encoding to consider positional information of words\n\n    def forward(self, x):\n        # self.encoding\n        # [max_len = 512, d_model = 512]\n\n        batch_size, seq_len = x.size()\n        # [batch_size = 128, seq_len = 30]\n\n        return self.encoding[:seq_len, :]\n        # [seq_len = 30, d_model = 512]\n        # it will add with tok_emb : [128, 30, 512]\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#token-embedding","title":"Token Embedding","text":"<pre><code>class TokenEmbedding(nn.Embedding):\n    \"\"\"\n    Token Embedding using torch.nn\n    they will dense representation of word using weighted matrix\n    \"\"\"\n\n    def __init__(self, vocab_size, d_model):\n        \"\"\"\n        class for token embedding that included positional information\n\n        :param vocab_size: size of vocabulary\n        :param d_model: dimensions of model\n        \"\"\"\n        super(TokenEmbedding, self).__init__(vocab_size, d_model, padding_idx=1)\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#transformer-embedding","title":"Transformer Embedding","text":"<p>Transformer adopts an embedding which is a summation of the token embedding and the positional embedding.</p> <pre><code>class TransformerEmbedding(nn.Module):\n    \"\"\"\n    token embedding + positional encoding (sinusoid)\n    positional encoding can give positional information to network\n    \"\"\"\n\n    def __init__(self, vocab_size, d_model, max_len, drop_prob, device):\n        \"\"\"\n        class for word embedding that included positional information\n\n        :param vocab_size: size of vocabulary\n        :param d_model: dimensions of model\n        \"\"\"\n        super(TransformerEmbedding, self).__init__()\n        self.tok_emb = TokenEmbedding(vocab_size, d_model)\n        self.pos_emb = PositionalEncoding(d_model, max_len, device)\n        self.drop_out = nn.Dropout(p=drop_prob)\n\n    def forward(self, x):\n        tok_emb = self.tok_emb(x)\n        pos_emb = self.pos_emb(x)\n        return self.drop_out(tok_emb + pos_emb)\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#scale-dot-product-attention","title":"Scale dot product attention","text":"<pre><code>class ScaleDotProductAttention(nn.Module):\n    \"\"\"\n    compute scale dot product attention\n    Query : given sentence that we focused on (decoder)\n    Key : every sentence to check relationship with Qeury(encoder)\n    Value : every sentence same with Key (encoder)\n    \"\"\"\n    def __init__(self):\n        super(ScaleDotProductAttention, self).__init__()\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, q, k, v, mask=None, e=1e-12):\n        # input is 4 dimension tensor\n        # [batch_size, head, length, d_tensor]\n        batch_size, head, length, d_tensor = k.size()\n\n        # 1. dot product Query with Key^T to compute similarity\n        k_t = k.transpose(2, 3)  # transpose\n        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n\n        # 2. apply masking (opt)\n        if mask is not None:\n            score = score.masked_fill(mask == 0, -10000)\n\n        # 3. pass them softmax to make [0, 1] range\n        score = self.softmax(score)\n\n        # 4. multiply with Value\n        v = score @ v\n        return v, score\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#multi-head-attention","title":"Multi-head Attention","text":"<p>A multi-head attention is a self-attention running in parallel.  The multi-head attention module output an attention output and an attention weight matrix with the scaled-dot product module.</p> <pre><code>class MultiHeadAttention(nn.Module):\n    \"\"\"\n    q, k, v: with dimension of d_model to d_model. Each is a weight matrix.\n    \"\"\"\n    def __init__(self, d_model, n_head):\n        super(MultiHeadAttention, self).__init__()\n        self.n_head = n_head\n        self.attention = ScaleDotProductAttention()\n        self.w_q = nn.Linear(d_model, d_model)\n        self.w_k = nn.Linear(d_model, d_model)\n        self.w_v = nn.Linear(d_model, d_model)\n        self.w_concat = nn.Linear(d_model, d_model)\n\n    def forward(self, q, k, v, mask=None):\n        \"\"\"\n        query = [batch size, query len, hid dim]\n        key = [batch size, key len, hid dim]\n        value = [batch size, value len, hid dim]\n        \"\"\"\n        # 1. dot product with weight matrices\n        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n        # 2. split tensor by number of heads\n        q, k, v = self.split(q), self.split(k), self.split(v)\n        # 3. do scale dot product to compute similarity\n        out, attention = self.attention(q, k, v, mask=mask)\n        # 4. concat and pass to linear layer\n        out = self.concat(out)\n        out = self.w_concat(out)\n        return out\n\n    def split(self, tensor):\n        \"\"\"\n        split tensor by number of head\n        :param tensor: [batch_size, length, d_model]\n        :return: [batch_size, head, length, d_tensor]\n        \"\"\"\n        batch_size, length, d_model = tensor.size()\n        # head dimension = hidden dimension // number of heads\n        d_tensor = d_model // self.n_head\n        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)\n        # it is similar with group convolution (split by number of heads)\n        return tensor\n\n    def concat(self, tensor):\n        \"\"\"\n        inverse function of self.split(tensor : torch.Tensor)\n        :param tensor: [batch_size, head, length, d_tensor]\n        :return: [batch_size, length, d_model]\n        \"\"\"\n        batch_size, head, length, d_tensor = tensor.size()\n        d_model = head * d_tensor\n        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n        return tensor\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#position-wise-feed-forward-layer","title":"Position-wise Feed Forward Layer","text":"<p>Another main block inside the encoder is the positionwise ffd. The input is transformed from hid_dim to pf_dim, where pf_dim is usually much larger than the hid_dim. The original transformer has a hid_dim of 512 while a pf_dim of 2048. The purpose of this block is not explained in the Transformer paper.</p> <pre><code>class PositionwiseFeedForward(nn.Module):\n    def __init__(self, d_model, hidden, drop_prob=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.linear1 = nn.Linear(d_model, hidden)\n        self.linear2 = nn.Linear(hidden, d_model)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=drop_prob)\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.linear2(x)\n        return x\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#layer-norm","title":"Layer Norm","text":"<pre><code>class LayerNorm(nn.Module):\n    def __init__(self, d_model, eps=1e-12):\n        super(LayerNorm, self).__init__()\n        self.gamma = nn.Parameter(torch.ones(d_model))\n        self.beta = nn.Parameter(torch.zeros(d_model))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        var = x.var(-1, unbiased=False, keepdim=True)\n        # '-1' means last dimension. \n\n        out = (x - mean) / torch.sqrt(var + self.eps)\n        out = self.gamma * out + self.beta\n        return out\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#encoder","title":"Encoder","text":"<p>First we build an encoder layer.</p> <pre><code>class EncoderLayer(nn.Module):\n\n    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n        super(EncoderLayer, self).__init__()\n        self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n        self.norm1 = LayerNorm(d_model=d_model)\n        self.dropout1 = nn.Dropout(p=drop_prob)\n\n        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n        self.norm2 = LayerNorm(d_model=d_model)\n        self.dropout2 = nn.Dropout(p=drop_prob)\n\n    def forward(self, x, src_mask):\n        # 1. compute self attention\n        _x = x\n        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n        # 2. add and norm\n        x = self.dropout1(x)\n        x = self.norm1(x + _x)\n        # 3. positionwise feed forward network\n        _x = x\n        x = self.ffn(x)\n        # 4. add and norm\n        x = self.dropout2(x)\n        x = self.norm2(x + _x)\n        return x\n\n</code></pre> <p>And then the whole encoder.</p> <pre><code>class Encoder(nn.Module):\n    \"\"\"\n    enc_voc_size: dictionary size\n    max_len: max input length\n    n_layers: defines #encoder_layers to stack in the encoder\n    \"\"\"\n    def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n    super().__init__()\n    self.emb = TransformerEmbedding(d_model = d_model, max_len = max_len, \n                        voacb_size = enc_voc_size, drop_prob = drop_prob, device = device)\n    # a stacked encoder\n    self.layers = nn.ModuleList([EncoderLayer(d_model = d_model, ffn_hidden = ffn_hidden, \n                                n_head = n_head, drop_prob = drop_prob)\n                                for _ in range(n_layers)])\n\n    def forward(self, x, src_mask):  # src_mask: during Transformer's training, a forward mask\n        x = self.emb(x)\n        for layer in self.layers:\n            x = layer(x, src_mask)\n        return x\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#decoder","title":"Decoder","text":"<p>First we build a decoder layer.</p> <pre><code>class DecoderLayer(nn.Module):\n    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n        super(DecoderLayer, self).__init__()\n        self.self_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n        self.norm1 = LayerNorm(d_model=d_model)\n        self.dropout1 = nn.Dropout(p=drop_prob)\n\n        self.enc_dec_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n        self.norm2 = LayerNorm(d_model=d_model)\n        self.dropout2 = nn.Dropout(p=drop_prob)\n\n        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n        self.norm3 = LayerNorm(d_model=d_model)\n        self.dropout3 = nn.Dropout(p=drop_prob)\n\n    def forward(self, dec, enc, trg_mask, src_mask):\n        # 1. compute self attention\n        _x = dec   # ideal target\n        x = self.self_attention(q=dec, k=dec, v=dec, mask=trg_mask)   # predicted target\n        # 2. add and norm\n        x = self.dropout1(x)\n        x = self.norm1(x + _x)\n        if enc is not None:\n            # 3. compute encoder - decoder attention\n            _x = x\n            x = self.enc_dec_attention(q=x, k=enc, v=enc, mask=src_mask)\n            # 4. add and norm\n            x = self.dropout2(x)\n            x = self.norm2(x + _x)\n        # 5. positionwise feed forward network\n        _x = x\n        x = self.ffn(x)\n        # 6. add and norm\n        x = self.dropout3(x)\n        x = self.norm3(x + _x)\n        return x\n</code></pre> <p>And then the whole decoder.</p> <pre><code>class Decoder(nn.Module):\n    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n        super().__init__()\n        self.emb = TransformerEmbedding(d_model = d_model, drop_prob = drop_prob, \n                        max_len = max_len, vocab_size = dec_voc_size, device = devoce)\n        # a stacked decoder layer\n        self.layers = nn.ModuleList([DecoderLayer(d_model = d_model, ffn_hidden = ffn_hidden, \n                                    n_head = n_head, drop_prob = drop_prob)\n                                    for _ in range(n_layers)])\n        self.linear = nn.Linear(d_model, dec_voc_size)\n    \"\"\"\n    trg = [batch size, trg len]\n    enc_src = [batchsize, src len, hid dim]\n    trg_mask = [batch size, 1, trg len, trg len]\n    src_mask = [batch size, 1, 1, src len] \n    \"\"\"\n    def forward(self, trg, enc_src, trg_mask, src_mask):\n        trg = self.emb(trg)\n        for layer in self.layers:\n            trg = layer(trg, enc_src, trg_mask, src_mask)\n        # pass to LM head\n        output = self.linear(trg)\n        return output\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#transformer-model","title":"Transformer Model","text":"<p>The model use forward's src and trg to receive the input and output during both training and testing procedures. During training, the trgs are as references of calculating training loss, while during testing, the testing loss. In the DecoderLayer class, the ideal target and predicted target are compared.</p> <pre><code>class Transformer(nn.Module):\n    \"\"\"\n    src_pad_idx: A matrix indicating &lt;pad&gt; positions in the input. &lt;pad&gt;s are not paid attention\n    trg_pad_idx: A matrix indicating &lt;pad&gt; positions in the output. &lt;pad&gt;s are not paid attention\n    trg_sos_idx: A matrix indicating &lt;sos&gt; positions in the output. Sentence initial.\n    enc_voc_size: input encoding size\n    dec_voc_size: output encoding size\n    d_model: Usually an emphirical value of \\sqrt[4]{#classes}. Originally 512\n    n_head: number of heads. Originally 8.\n    max_len: limit on the input length\n    ffn_hidden: number of hidden layers in the ffn\n    n_layers: #layers in stacked encoder and decoder. Originally 6.\n    drop_prob: drop out probability\n    device: cpu or gpu\n    \"\"\"\n    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len, ffn_hidden, n_layers, drop_prob, device):\n        super().__init__()\n        self.src_pad_idx = src_pad_idx\n        self.trg_pad_idx = trg_pad_idx\n        self.trg_sos_idx = trg_sos_idx\n        self.device = device\n        self.encoder = Encoder(d_model=d_model,\n                               n_head=n_head,\n                               max_len=max_len,\n                               ffn_hidden=ffn_hidden,\n                               enc_voc_size=enc_voc_size,\n                               drop_prob=drop_prob,\n                               n_layers=n_layers,\n                               device=device)\n        self.decoder = Decoder(d_model=d_model,\n                               n_head=n_head,\n                               max_len=max_len,\n                               ffn_hidden=ffn_hidden,\n                               dec_voc_size=dec_voc_size,\n                               drop_prob=drop_prob,\n                               n_layers=n_layers,\n                               device=device)\n\n    def forward(self, src, trg):\n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        enc_src = self.encoder(src, src_mask)\n        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n        return output\n\n    def make_src_mask(self, src):\n        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n        return src_mask\n\n    def make_trg_mask(self, trg):\n        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n        trg_len = trg.shape[1]\n        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n        trg_mask = trg_pad_mask &amp; trg_sub_mask\n        return trg_mask\n\n</code></pre> <p>Let's finally see the default configs.</p> <pre><code># GPU device setting\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# model parameter setting\nbatch_size = 128\nmax_len = 256\nd_model = 512\nn_layers = 6\nn_heads = 8\nffn_hidden = 2048\ndrop_prob = 0.1\n\n# optimizer parameter setting\ninit_lr = 1e-5\nfactor = 0.9\nadam_eps = 5e-9\npatience = 10\nwarmup = 100\nepoch = 1000\nclip = 1.0\nweight_decay = 5e-4\ninf = float('inf')\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/Note%20on%20Transformer%20Code/#references","title":"References","text":"<p>Vaswani et al. Attention is all you need. 2017 hyunwoongko/transformer: PyTorch Implementation of \"Attention Is All You Need\" (github.com) 6 - Attention is All You Need.ipynb - Colaboratory (google.com)</p>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS224n/","title":"\u3010TODO\u3011CS224n","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS224n/#attention-based-nmt","title":"Attention-based NMT","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS224n/#convnet-based-nmt","title":"ConvNet-based NMT","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS224n/#final-project-implementing-a-model-to-challenge-sqaud","title":"Final project: implementing a model to challenge SQaUD","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS224n/#qanet","title":"QANet","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS231n/","title":"\u3010TODO\u3011CS231n","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS231n/#pytorch","title":"Pytorch","text":"<p>Output size calculation</p> <pre><code>output_size = (input_size + 2 * padding - kernel_size) / stride + 1\n</code></pre> <p>RuntimeError: mat2 must be a matrix, got 1-D tensor</p> <pre><code>torch.unsqueeze(fc_b, dim=1)\n</code></pre> <p>turns (10, ) list to (10, 1) tensor.</p> <p></p>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS231n/#self-supervised-learning","title":"Self-supervised Learning","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS231n/#gan","title":"GAN","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91CS231n/#transformer-image-caption","title":"Transformer Image Caption","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/","title":"\u3010TODO\u3011ML \u516b\u80a1 zero to hero","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/#ml","title":"ML","text":"<p>\u8bbe\u8ba1\u6a21\u578b\u7684\u65f6\u5019\uff0c\u5982\u4f55\u786e\u5b9aembedding\u7684size? embedding\u7684\u5927\u5c0f\u4e00\u822c\u662f\u4e00\u4e2a\u7ecf\u9a8c\u503c\uff0c\u5047\u8bbeembedding\u5bf9\u5e94\u7684\u539f\u59cbfeature\u7684\u53d6\u503c\u6570\u91cf\u4e3an\uff0c\u5219\u4e00\u822c\u4f1a\u91c7\u7528$log_2(n)$\u6216\u8005$k\\sqrt[4]{n} (k&lt;16)$\u6765\u505a\u521d\u59cb\u7684size\uff0c\u7136\u540e2\u500d\u6269\u5927\u6216\u7f29\u5c0f\u3002</p> <p>Self Attention\u7684\u8868\u8fbe\u5f0f $$Softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$ \u5bf9QK\u8fdb\u884cscaling\u7684\u76ee\u7684\u662f\uff0cscaling\u540e\u8fdb\u884csoftmax\u64cd\u4f5c\u53ef\u4ee5\u4f7f\u8f93\u5165\u6570\u636e\u7684\u5206\u5e03\u53d8\u5f97\u66f4\u597d\u3002\u6570\u503c\u4f1a\u8fdb\u5165\u654f\u611f\u533a\u95f4\uff0c\u9632\u6b62\u68af\u5ea6\u6d88\u5931\uff0c\u8ba9\u6a21\u578b\u66f4\u5bb9\u6613\u8bad\u7ec3\u3002</p> <p>attention\u8ba1\u7b97\u65b9\u5f0f\u53ca\u53c2\u6570\u91cf\uff1f\u9ed8\u5199multi-headed attention? \u7b80\u7ea6\u7248</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model   # d_model is a emphirical number\n        assert d_model % self.num_heads == 0\n\n        # define the dimension of each head or subspace\n        self.d_k = d_model // self.num_heads\n\n        # these are still of dimension d_model. They will be split into numbers\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n\n        # Output of all sub-layers need to be of dimension d_model\n        self.W_o = nn.Linear(d_model, d_model)\n\n    def scaled_dot_product_attention(self, Q, K, V, mask = None):\n        batch_size = Q.size(0)   # layernorm?\n        K_length = K.size(-2)    # \n        # scaling by d_k so that the soft(arg)max doesn't explode\n        QK = torch.matmul(Q, K.transpose(-2, -1) / math.sqrt(self.d_k))# matrix product of tensors\n        # apply the mask\n        if mask is not None:  # mask is a matrix with 0 to be masked\n            QK = QK.maksed_fill(mask.to(QK.type) == 0, float('-inf'))\n        # calculate the attention weights (softmax over the lask dimension)\n        weights = F.softmax(QK, dim = -1)\n        # apply the self attention to the values\n        attention = torch.matmul(weights, V)\n        return attention, weights\n\n    def split_heads(self, x, batch_size):\n        \"\"\"\n        The original tensor \n        with dimension batch_size * seq_length * d_model is divided by num_heads\n        d_model // num_heads = d_k\n        so now batch_size * seq_length * d_k\n        \"\"\"\n        return x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n\n    def forward(self, q, k, v, mask = None):\n        batch_size = q.size(0)\n        # linear layers\n        q = self.W_q(q)\n        k = self.W_k(k)\n        v = self.W_v(v)\n        # split into multiple heads\n        q = self.split_heads(q, batch_size)\n        k = self.split_heads(k, batch_size)\n        v = self.split_heads(v, batch_size)\n        # self attention\n        scores, weights = self.scaled_dot_product_attention(q, k, v, mask)\n        # concatenate heads\n        concat = scores.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model())\n        # final linear layer\n        output = self.W_o(concat)\n\n        return output, weights\n</code></pre> <p>Multi-headed attention \u5f97\u5230\u7684\u662f\u4e24\u4e2a\u8f93\u51fa\uff0c\u4e00\u4e2aoutput\uff081 * d_model\uff09\u662f\u7ebf\u6027\u7684attention\u7ed3\u679c\uff0c\u4e00\u4e2aweight\u77e9\u9635\u662f\uff1f\u7ef4\u7684. \u51fa\u4e8e\u8fd0\u7b97\u901f\u5ea6\u7684\u8003\u8651\uff0c\u6211\u4eec\u8ba4\u4e3a\u201c\u4e00\u6b21\u5927\u7684\u77e9\u9635\u4e58\u6cd5\u7684\u6267\u884c\u901f\u5ea6\u6bd4\u591a\u6b21\u8f83\u5c0f\u7684\u77e9\u9635\u4e58\u6cd5\u66f4\u5feb\u201d\uff0c\u56e0\u6b64\u4f60\u53ef\u4ee5\u5728__init__\u4e2d</p> <pre><code>self.qkv = nn.Linear(d_model, 3 * d_model)\n</code></pre> <p>\u5728forward\u65b9\u6cd5\u4e2d</p> <pre><code>qkv = self.qkv(x)\nq, k, v = torch.split(qkv, self.d_model, dim = -1)  # split into three tensors\n</code></pre> <p>Lora\u53ef\u80fd\u5b58\u5728\u7684\u95ee\u9898\uff1f \uff081\uff09\u57fa\u4e8e\u4f4e\u79e9\u7684\u5fae\u8c03\u53ef\u80fd\u4e0dalways work\uff0c\u6bd4\u5982finetune\u4e0epretrain\u4efb\u52a1\u7684gap\u8fc7\u5927\u7684\u65f6\u5019\uff08\u5982\uff1a\u4e2d\u82f1\u5dee\u5f02\uff09\u3002\u5f53\u7136\u8fd9\u4e00\u70b9\u5728LLM\u65f6\u4ee3\u53ef\u80fd\u5e76\u4e0d\u7a81\u51fa\uff0c\u56e0\u4e3a\u6211\u4eec\u8ba4\u4e3aLLM\u5728\u4e0e\u8bad\u7ec3\u9636\u6bb5\u5df2\u7ecfget\u4e86\u57fa\u672c\u6240\u6709\u7684\u77e5\u8bc6\uff0cfinetune\u4e5f\u53ea\u662f\u5728\u5fae\u8c03\u683c\u5f0f\uff0c\u56e0\u6b64\u53ef\u80fd\u4e0d\u4f1a\u6709\u4e0a\u8ff0gap\u8fc7\u5927\u7684\u60c5\u51b5\u3002 \uff082\uff09\u7528LoRA\u65f6\u4e5f\u8981\u8bbe\u7f6er\u548ctarget module\u7b49\uff0c\u8fd9\u90e8\u5206\u8d85\u53c2\u7684\u8bbe\u7f6e\u9700\u8981\u8003\u8651\u3002</p> <p>\u5404\u79cdnorm\u65b9\u5f0f\u7684\u4f18\u7f3a\u70b9 \u5e38\u89c1\u7684norm\u65b9\u5f0f\u6709\u4ee5\u4e0b\u56db\u79cd\uff1a  Batch norm: \u628a\u6bcf\u4e2abatch\u4e2d\u6bcf\u53e5\u8bdd\u76f8\u540c\u4f4d\u7f6e\u7684\u5b57\u5411\u91cf\u770b\u6210\u4e00\u7ec4\u505a\u5f52\u4e00\u5316\u3002\u5728\u5904\u7406\u5e8f\u5217\u6570\u636e\uff08\u5982\u6587\u672c\uff09\u65f6\uff0cbatch norm\u53ef\u80fd\u4e0d\u4f1a\u8868\u73b0\u5f88\u597d\uff0c\u56e0\u4e3a\u5e8f\u5217\u6570\u636e\u901a\u5e38\u957f\u5ea6\u4e0d\u4e00\uff0c\u5e76\u4e14\u4e00\u6b21\u8bad\u7ec3\u4e2dbatch\u7684\u53e5\u5b50\u957f\u5ea6\u53ef\u80fd\u4f1a\u6709\u5f88\u5927\u7684\u5dee\u5f02\uff0c\u6b64\u5916\uff0cbatch norm\u5bf9batch\u7684\u5927\u5c0f\u4e5f\u975e\u5e38\u654f\u611f\uff0c\u5bf9\u4e8e\u8f83\u5c0f\u7684batch\u5927\u5c0f\uff0cbatch norm\u53ef\u80fd\u4e5f\u4f1a\u8868\u73b0\u4e0d\u597d\uff0c\u56e0\u4e3a\u6bcf\u4e2abatch\u7684\u7edf\u8ba1\u7279\u6027\u53ef\u80fd\u4f1a\u6709\u8f83\u5927\u6ce2\u52a8\u3002</p> <p>Layer norm: \u5728\u6bcf\u4e2a\u53e5\u5b50\u4e2d\u8fdb\u884c\u5f52\u4e00\u5316\u3002Layer norm\u662f\u5bf9\u6bcf\u4e2a\u6837\u672c\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u56e0\u6b64\u5b83\u4eec\u5bf9batch\u5927\u5c0f\u4e0d\u654f\u611f\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u5904\u7406\u5e8f\u5217\u6570\u636e\u7684\u65f6\u5019\u8868\u73b0\u5f97\u66f4\u597d\uff0c\u53e6\u5916layer norm\u5728\u5904\u7406\u4e0d\u540c\u957f\u5ea6\u7684\u5e8f\u5217\u65f6\u4e5f\u66f4\u7075\u6d3b\u3002</p> <p>Instance norm: \u6bcf\u4e00\u4e2a\u5b57\u7684\u5b57\u5411\u91cf\u770b\u6210\u4e00\u7ec4\u505a\u5f52\u4e00\u5316\u3002\u4f18\u70b9\u662f\u5bf9\u6bcf\u4e2a\u6837\u672c\u7684\u6bcf\u4e2a\u7279\u5f81\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u56e0\u6b64\u53ef\u4ee5\u6355\u6349\u5230\u66f4\u591a\u7684\u7ec6\u8282\u4fe1\u606f\uff0c\u80fd\u5728\u98ce\u683c\u8fc1\u79fb\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u7ec6\u8282\u5f88\u91cd\u8981\u3002\u7f3a\u70b9\u662f\u53ef\u80fd\u4f1a\u8fc7\u5ea6\u5f3a\u8c03\u7ec6\u8282\u4fe1\u606f\uff0c\u5ffd\u7565\u4e86\u66f4\u5b8f\u89c2\u7684\u4fe1\u606f\u3002\u6b64\u5916instance norm\u7684\u8ba1\u7b97\u6210\u672c\u76f8\u6bd4batch norm\u548clayer norm\u4e5f\u66f4\u9ad8\u3002</p> <p>Group norm: \u628a\u6bcf\u53e5\u8bdd\u7684\u6bcf\u51e0\u4e2a\u5b57\u7684\u5b57\u5411\u91cf\u770b\u6210\u4e00\u7ec4\u505a\u5f52\u4e00\u5316\u3002group norm\u662fbatch norm\u548cinstance norm\u7684\u6298\u4e2d\u65b9\u6848\uff0c\u5728\u4e00\u4e2a\u5b50\u96c6\uff08\u5373\u7ec4\uff09\u4e0a\u8fdb\u884c\u5f52\u4e00\u5316\u3002\u8fd9\u4f7f\u5f97group norm\u65e2\u53ef\u4ee5\u6355\u6349\u5230batch\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u53c8\u53ef\u4ee5\u6355\u6349\u5230\u6837\u672c\u7684\u7ec6\u8282\u4fe1\u606f\u3002\u6b64\u5916\uff0cgroup norm\u5bf9batch\u5927\u5c0f\u4e5f\u4e0d\u654f\u611f\u3002\u7f3a\u70b9\u662fgroup norm\u7684\u6027\u80fd\u53d6\u51b3\u4e8e\u7ec4\u7684\u5927\u5c0f\uff0c\u9700\u8981\u901a\u8fc7\u5b9e\u9a8c\u786e\u5b9a\u6700\u4f18\u7ec4\u7684\u5927\u5c0f\u3002\u6b64\u5916group norm\u7684\u8ba1\u7b97\u6210\u672c\u4e5f\u6bd4batch norm\u548clayer norm\u66f4\u9ad8\u3002</p> <p>Gradient Clipping RNN\u53ef\u80fd\u9047\u5230\u68af\u5ea6\u7206\u70b8\u95ee\u9898\u3002\u4e00\u4e2a\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u5982\u679c\u68af\u5ea6\u53d8\u5f97\u5f88\u5927\uff0c\u6211\u4eec\u5c06\u68af\u5ea6\u653e\u7f29\u4f7f\u5176\u53d8\u5c0f\u3002 \u7b97\u6cd5\u662f\uff1a\u5f53\u68af\u5ea6\u5927\u4e8e\u4e00\u4e2a\u5e38\u6570c\u7684\u65f6\u5019\uff0c\u6267\u884c $g\\leftarrow c\\times g/||g||$\u3002</p> <p>\u4e3a\u4ec0\u4e48\u4f7f\u7528Dropout \u5982\u679c\u53c2\u6570\u592a\u591a\u800c\u8bad\u7ec3\u6837\u672c\u8fc7\u5c11\uff0c\u5bb9\u6613\u51fa\u73b0\u8fc7\u62df\u5408\u3002\u5177\u4f53\u8868\u73b0\u4e3a\uff1a\u5728dev set\u4e0aloss\u5f88\u5c0f\uff0c\u5728test set\u4e0aloss\u5f88\u5927\u3002 \u8fc7\u53bb\u4f1a\u9009\u62e9\u6a21\u578b\u96c6\u6210\uff0c\u8bad\u7ec3\u591a\u4e2a\u6a21\u578b\u8fdb\u884c\u7ec4\u5408\u3002Dropout\u80fd\u6bd4\u8f83\u6709\u6548\u7f13\u89e3\u8fc7\u62df\u5408\u3002\u7531Hinton\u57282012\u5e74\u63d0\u51fa\uff0c\u5e76\u5e94\u7528\u4e8eAlexNet\u3002 Dropout\u7684\u539f\u7406\u662f\u5728\u524d\u5411\u4f20\u64ad\u7684\u65f6\u5019\uff0c\u8ba9\u67d0\u4e2a\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u503c\u4ee5\u4e00\u5b9a\u6982\u7387p\u505c\u6b62\u5de5\u4f5c\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\uff0c\u56e0\u4e3a\u4e0d\u4f1a\u592a\u4f9d\u8d56\u67d0\u4e9b\u5c40\u90e8\u7279\u5f81\u3002  \u5de5\u4f5c\u6d41\u7a0b\uff1a 1\uff09\u968f\u673a\uff08\u4e34\u65f6\uff09\u5220\u9664\u4e00\u534a\u7684\u9690\u85cf\u795e\u7ecf\u5143\uff0c\u4fdd\u7559\u8f93\u5165\u8f93\u51fa\u795e\u7ecf\u5143\u4e0d\u53d8\uff0c\u88ab\u5220\u9664\u7684\u4fdd\u7559\u53c2\u6570\u4e0d\u53d8\u3002 2\uff09\u5c06\u8f93\u5165\u524d\u5411\u4f20\u64ad\u540e\u540e\u5411\u4f20\u64ad\uff0c\u53ea\u66f4\u65b0\u5269\u4e0b\u795e\u7ecf\u5143\u4e0a\u7684\u53c2\u6570\u3002 3\uff09\u6062\u590d\u88ab\u5220\u6389\u7684\u795e\u7ecf\u5143\uff08\u6b64\u65f6\u88ab\u5220\u9664\u7684\u795e\u7ecf\u5143\u4fdd\u6301\u539f\u6837\uff0c\u800c\u6ca1\u6709\u88ab\u5220\u9664\u7684\u795e\u7ecf\u5143\u5df2\u7ecf\u66f4\u65b0\uff09\u3002 4\uff09\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u3002</p> <p>\u4e0b\u9762\u7684\u4e00\u7bc7\u4e00\u7bc7\u6574\u7406 - Microstrong\uff1a\u6df1\u5ea6\u5b66\u4e60\u4e2dDropout\u539f\u7406\u89e3\u6790 - \u795e\u7ecf\u7f51\u7edcDropout\u5c42\u4e2d\u4e3a\u4ec0\u4e48dropout\u540e\u8fd8\u9700\u8981\u8fdb\u884crescale\uff1f - bingo\u9171\uff1aL1\u6b63\u5219\u5316\u4e0eL2\u6b63\u5219\u5316 - \u97e6\u4f1f\uff1a\u4ece\u53cd\u5411\u4f20\u64ad\u63a8\u5bfc\u5230\u68af\u5ea6\u6d88\u5931and\u7206\u70b8\u7684\u539f\u56e0\u53ca\u89e3\u51b3\u65b9\u6848\uff08\u4eceDNN\u5230RNN\uff0c\u5185\u9644\u8be6\u7ec6\u53cd\u5411\u4f20\u64ad\u516c\u5f0f\u63a8\u5bfc\uff09 - Will\uff1a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u4e0e\u68af\u5ea6\u7206\u70b8 - LSTM\u5982\u4f55\u6765\u907f\u514d\u68af\u5ea6\u5f25\u6563\u548c\u68af\u5ea6\u7206\u70b8\uff1f - LSTM\u5982\u4f55\u6765\u907f\u514d\u68af\u5ea6\u5f25\u6563\u548c\u68af\u5ea6\u7206\u70b8\uff1f</p>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/#_1","title":"\u56db\u3001\u673a\u5668\u5b66\u4e60","text":"<ul> <li>\u6f2b\u6f2b\u6210\u957f\uff1a\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09</li> <li>\u963f\u6cfd\uff1a\u3010\u673a\u5668\u5b66\u4e60\u3011\u903b\u8f91\u56de\u5f52\uff08\u975e\u5e38\u8be6\u7ec6\uff09</li> <li>\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1 \u503c\u3001ROC\u3001AUC \u5404\u81ea\u7684\u4f18\u7f3a\u70b9\u662f\u4ec0\u4e48\uff1f</li> <li>\u963f\u6cfd\uff1a\u3010\u673a\u5668\u5b66\u4e60\u3011\u652f\u6301\u5411\u91cf\u673a SVM\uff08\u975e\u5e38\u8be6\u7ec6\uff09</li> <li>\u4e22\u4e22\uff1a\u4e00\u7bc7\u6587\u7ae0\u641e\u5b9aGBDT\u3001Xgboost\u548cLightGBM\u7684\u9762\u8bd5</li> <li>\u963f\u6cfd\uff1a\u3010\u673a\u5668\u5b66\u4e60\u3011\u51b3\u7b56\u6811\uff08\u4e0a\uff09\u2014\u2014ID3\u3001C4.5\u3001CART\uff08\u975e\u5e38\u8be6\u7ec6\uff09</li> <li>\u963f\u6cfd\uff1a\u3010\u673a\u5668\u5b66\u4e60\u3011\u51b3\u7b56\u6811\uff08\u4e2d\uff09\u2014\u2014Random Forest\u3001Adaboost\u3001GBDT \uff08\u975e\u5e38\u8be6\u7ec6\uff09</li> <li>\u963f\u6cfd\uff1a\u3010\u673a\u5668\u5b66\u4e60\u3011\u51b3\u7b56\u6811\uff08\u4e0b\uff09\u2014\u2014XGBoost\u3001LightGBM\uff08\u975e\u5e38\u8be6\u7ec6\uff09</li> </ul>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/#_2","title":"\u56db\u3001\u8bcd\u5411\u91cf","text":"<ul> <li>\u5929\u96e8\u7c9f\uff1a\u7406\u89e3 Word2Vec \u4e4b Skip-Gram \u6a21\u578b</li> <li>\u68a6\u91cc\u5bfb\u68a6\uff1a\uff08\u5341\u4e94\uff09\u901a\u4fd7\u6613\u61c2\u7406\u89e3\u2014\u2014Glove\u7b97\u6cd5\u539f\u7406</li> <li>Luke\uff1a\u6df1\u5165\u7406\u89e3NLP Subword\u7b97\u6cd5\uff1aBPE\u3001WordPiece\u3001ULM</li> <li>\u963f\u5317\uff1aNLP\u4e09\u5927Subword\u6a21\u578b\u8be6\u89e3\uff1aBPE\u3001WordPiece\u3001ULM</li> <li>\u97e6\u4f1f\uff1a\u53f2\u4e0a\u6700\u5168\u8bcd\u5411\u91cf\u8bb2\u89e3\uff08LSA/word2vec/Glove/FastText/ELMo/BERT\uff09</li> <li>\u5411\u9633\u6811\uff1a\u8bcd\u5d4c\u5165\uff1aELMo\u539f\u7406</li> <li>\u5f20\u4fca\u6797\uff1aXLNet:\u8fd0\u884c\u673a\u5236\u53ca\u548cBert\u7684\u5f02\u540c\u6bd4\u8f83</li> <li>\u6d77\u6668\u5a01\uff1a\u53f2\u4e0a\u6700\u7ec6\u8282\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406NLP/Transformer/BERT/Attention\u9762\u8bd5\u95ee\u9898\u4e0e\u7b54\u6848</li> <li>\u5982\u4f55\u770b\u5f85\u7626\u8eab\u6210\u529f\u7248BERT\u2014\u2014ALBERT\uff1f</li> <li>Mr.robot\uff1a\u9762\u8bd5\u4e2d\u7406\u89e3ALBERT\uff1f\uff08NLP\u9762\u7ecf\uff09</li> <li>JayJay\uff1anlp\u4e2d\u7684\u8bcd\u5411\u91cf\u5bf9\u6bd4\uff1aword2vec/glove/fastText/elmo/GPT/bert</li> </ul>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/#_3","title":"\u4e94\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc","text":"<ul> <li>\u9648\u8bda\uff1a\u4eba\u4eba\u90fd\u80fd\u770b\u61c2\u7684GRU</li> <li>\u9648\u8bda\uff1a\u4eba\u4eba\u90fd\u80fd\u770b\u61c2\u7684LSTM</li> <li>Alan Lee\uff1a\u5982\u4f55\u8ba1\u7b97 LSTM \u7684\u53c2\u6570\u91cf</li> </ul>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/#_4","title":"\u516d\u3001\u6ce8\u610f\u529b\u673a\u5236","text":"<ul> <li>\u8d75\u5f3a\uff1a\u4e00\u6587\u770b\u61c2 Attention\uff08\u672c\u8d28\u539f\u7406+3\u5927\u4f18\u70b9+5\u5927\u7c7b\u578b\uff09</li> <li>\u5927\u5e08\u5144\uff1a\u8be6\u89e3Transformer \uff08Attention Is All You Need\uff09</li> <li>\u5c0f\u9e7f\u9e7flulu\uff1a\u5982\u4f55\u4f18\u96c5\u5730\u7f16\u7801\u6587\u672c\u4e2d\u7684\u4f4d\u7f6e\u4fe1\u606f\uff1f\u4e09\u79cdpositional encoding\u65b9\u6cd5\u7b80\u8ff0</li> </ul>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91ML%20%E5%85%AB%E8%82%A1%20zero-to-hero/#_5","title":"\u4e03\u3001\u5176\u5b83","text":"<ul> <li>\u5b59\u5b59\uff1a\u6700\u901a\u4fd7\u6613\u61c2\u7684BiLSTM-CRF\u6a21\u578b\u4e2d\u7684CRF\u5c42\u4ecb\u7ecd</li> <li>\u8c22\u7389\u5f3a\uff1a\u8bba\u6587\u7b14\u8bb0 \u2014\u2014 Transformer-XL</li> <li>\u6d77\u6668\u5a01\uff1aNLP \u4e2d\u7684Mask\u5168\u89e3</li> <li>\u673a\u5668\u5b66\u4e60\u201c\u5224\u5b9a\u6a21\u578b\u201d\u548c\u201c\u751f\u6210\u6a21\u578b\u201d\u6709\u4ec0\u4e48\u533a\u522b\uff1f</li> <li>\u5982\u4f55\u7528\u7b80\u5355\u6613\u61c2\u7684\u4f8b\u5b50\u89e3\u91ca\u6761\u4ef6\u968f\u673a\u573a\uff08CRF\uff09\u6a21\u578b\uff1f\u5b83\u548cHMM\u6709\u4ec0\u4e48\u533a\u522b\uff1f</li> <li>\u5982\u4f55\u901a\u4fd7\u5730\u8bb2\u89e3 viterbi \u7b97\u6cd5\uff1f</li> <li>\u5c0f\u5c0f\u5c06\uff1a\u4f60\u5fc5\u987b\u8981\u77e5\u9053CNN\u6a21\u578b\uff1aResNet</li> <li>transformer\u4e2d\u7684attention\u4e3a\u4ec0\u4e48scaled?</li> <li>\u89e6\u6478\u58f9\u7f15\u9633\u5149\uff1a\u4e00\u6587\u8be6\u89e3Softmax\u51fd\u6570</li> <li>\u9676\u5c06\uff1a\u4f18\u5316\u7b97\u6cd5Optimizer\u6bd4\u8f83\u548c\u603b\u7ed3</li> <li>\u4f59\u660c\u9ed4\uff1a\u6df1\u5ea6\u5b66\u4e60\u6700\u5168\u4f18\u5316\u65b9\u6cd5\u603b\u7ed3\u6bd4\u8f83\uff08SGD\uff0cAdagrad\uff0cAdadelta\uff0cAdam\uff0cAdamax\uff0cNadam\uff09</li> <li>\u5927\u5e08\u5144\uff1a\u6a21\u578b\u4f18\u5316\u4e4bLayer Normalization</li> <li>\u5929\u96e8\u7c9f\uff1aBatch Normalization\u539f\u7406\u4e0e\u5b9e\u6218</li> <li>\u6768\u660e\u96ea\uff1a\u8c08\u8c08\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u4e3a\u4ec0\u4e48\u4e0d\u80fd\u521d\u59cb\u5316\u4e3a0</li> <li>\u674erumor\uff1aBERT\u6a21\u578b\u84b8\u998f\u5b8c\u5168\u6307\u5357\uff08\u539f\u7406/\u6280\u5de7/\u4ee3\u7801\uff09</li> </ul>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/","title":"\u3010TODO\u3011Note on BERT Code","text":"<p>Bert is an encoder-only Transformer structured model. </p> <p>To implement a Bert, the following classes are required.  - embedding: positional embedding,  - </p>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#positional-embedding","title":"Positional Embedding","text":"<pre><code>class PositionalEmbedding(torch.nn.Module):  \n    def __init__(self, d_model, max_len=128):  \n        super().__init__()  \n\n        # Compute the positional encodings once in log space.  \n        pe = torch.zeros(max_len, d_model).float()  \n        pe.require_grad = False  \n\n        for pos in range(max_len):  \n        # for each dimension of the each position  \n            for i in range(0, d_model, 2):  \n            pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))  \n            pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))  \n\n        # include the batch size  \n        self.pe = pe.unsqueeze(0)  \n        # self.register_buffer('pe', pe)  \n\n    def forward(self, x):  \n        return self.pe\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#bert-embedding","title":"Bert Embedding","text":"<pre><code>class BERTEmbedding(torch.nn.Module):  \n    \"\"\"  \n    BERT Embedding which is consisted with under features  \n    1. TokenEmbedding : normal embedding matrix  \n    2. PositionalEmbedding : adding positional information using sin, cos  \n    2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)  \n    sum of all these features are output of BERTEmbedding  \n    \"\"\"  \n    def __init__(self, vocab_size, embed_size, seq_len=64, dropout=0.1):  \n        \"\"\"  \n        :param vocab_size: total vocab size  \n        :param embed_size: embedding size of token embedding  \n        :param dropout: dropout rate  \n        \"\"\"  \n\n        super().__init__()  \n        self.embed_size = embed_size  \n        # (m, seq_len) --&gt; (m, seq_len, embed_size)  \n        # padding_idx is not updated during training, remains as fixed pad (0)  \n        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)  \n        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0)  \n        self.position = PositionalEmbedding(d_model=embed_size, max_len=seq_len)  \n        self.dropout = torch.nn.Dropout(p=dropout)  \n\n    def forward(self, sequence, segment_label):  \n        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)  \n        return self.dropout(x)\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#multiheadattention","title":"MultiHeadAttention","text":"<pre><code>### attention layers  \nclass MultiHeadedAttention(torch.nn.Module):  \n\n    def __init__(self, heads, d_model, dropout=0.1):  \n        super(MultiHeadedAttention, self).__init__()  \n\n        assert d_model % heads == 0  \n        self.d_k = d_model // heads  \n        self.heads = heads  \n        self.dropout = torch.nn.Dropout(dropout)  \n\n        self.query = torch.nn.Linear(d_model, d_model)  \n        self.key = torch.nn.Linear(d_model, d_model)  \n        self.value = torch.nn.Linear(d_model, d_model)  \n        self.output_linear = torch.nn.Linear(d_model, d_model)  \n\n    def forward(self, query, key, value, mask):  \n        \"\"\"  \n        query, key, value of shape: (batch_size, max_len, d_model)  \n        mask of shape: (batch_size, 1, 1, max_words)  \n        \"\"\"  \n        # (batch_size, max_len, d_model)  \n        query = self.query(query)  \n        key = self.key(key)  \n        value = self.value(value)  \n\n        # (batch_size, max_len, d_model) --&gt; (batch_size, max_len, h, d_k) --&gt; (batch_size, h, max_len, d_k)  \n        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n\n        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --&gt; (batch_size, h, max_len, max_len)  \n        scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))  \n\n        # fill 0 mask with super small number so it wont affect the softmax weight  \n        # (batch_size, h, max_len, max_len)  \n        scores = scores.masked_fill(mask == 0, -1e9)  \n\n        # (batch_size, h, max_len, max_len)  \n        # softmax to put attention weight for all non-pad tokens  \n        # max_len X max_len matrix of attention  \n        weights = F.softmax(scores, dim=-1)  \n        weights = self.dropout(weights)  \n\n        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --&gt; (batch_size, h, max_len, d_k)  \n        context = torch.matmul(weights, value)  \n\n        # (batch_size, h, max_len, d_k) --&gt; (batch_size, max_len, h, d_k) --&gt; (batch_size, max_len, d_model)  \n        context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)  \n\n        # (batch_size, max_len, d_model)  \n        return self.output_linear(context)\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#feedforward","title":"FeedForward","text":"<pre><code>class FeedForward(torch.nn.Module):  \n    \"Implements FFN equation.\"  \n\n    def __init__(self, d_model, middle_dim=2048, dropout=0.1):  \n        super(FeedForward, self).__init__()  \n\n        self.fc1 = torch.nn.Linear(d_model, middle_dim)  \n        self.fc2 = torch.nn.Linear(middle_dim, d_model)  \n        self.dropout = torch.nn.Dropout(dropout)  \n        self.activation = torch.nn.GELU()  \n\n    def forward(self, x):  \n        out = self.activation(self.fc1(x))  \n        out = self.fc2(self.dropout(out))  \n        return out  \n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#encoder-layer","title":"Encoder Layer","text":"<pre><code>class EncoderLayer(torch.nn.Module):  \n    def __init__(  \n    self,  \n    d_model=768,  \n    heads=12,  \n    feed_forward_hidden=768 * 4,  \n    dropout=0.1  \n    ):  \n    super(EncoderLayer, self).__init__()  \n    self.layernorm = torch.nn.LayerNorm(d_model)  \n    self.self_multihead = MultiHeadedAttention(heads, d_model)  \n    self.feed_forward = FeedForward(d_model, middle_dim=feed_forward_hidden)  \n    self.dropout = torch.nn.Dropout(dropout)  \n\n    def forward(self, embeddings, mask):  \n    # embeddings: (batch_size, max_len, d_model)  \n    # encoder mask: (batch_size, 1, 1, max_len)  \n    # result: (batch_size, max_len, d_model)  \n    interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))  \n    # residual layer  \n    interacted = self.layernorm(interacted + embeddings)  \n    # bottleneck  \n    feed_forward_out = self.dropout(self.feed_forward(interacted))  \n    encoded = self.layernorm(feed_forward_out + interacted)  \n    return encoded\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#bert-model","title":"Bert model","text":"<pre><code>class BERT(torch.nn.Module):  \n    \"\"\"  \n    BERT model : Bidirectional Encoder Representations from Transformers.  \n    \"\"\"  \n    def __init__(self, vocab_size, d_model=768, n_layers=12, heads=12, dropout=0.1):  \n        \"\"\"  \n        :param vocab_size: vocab_size of total words  \n        :param hidden: BERT model hidden size  \n        :param n_layers: numbers of Transformer blocks(layers)  \n        :param attn_heads: number of attention heads  \n        :param dropout: dropout rate  \n        \"\"\"  \n\n        super().__init__()  \n        self.d_model = d_model  \n        self.n_layers = n_layers  \n        self.heads = heads  \n\n        # paper noted they used 4 * hidden_size for ff_network_hidden_size  \n        self.feed_forward_hidden = d_model * 4  \n\n        # embedding for BERT, sum of positional, segment, token embeddings  \n        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=d_model)  \n\n        # multi-layers transformer blocks, deep network  \n        self.encoder_blocks = torch.nn.ModuleList(  \n            [EncoderLayer(d_model, heads, d_model * 4, dropout) for _ in range(n_layers)])  \n\n    def forward(self, x, segment_info):  \n        # attention masking for padded token  \n        # (batch_size, 1, seq_len, seq_len)  \n        mask = (x &gt; 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)  \n\n        # embedding the indexed sequence to sequence of vectors  \n        x = self.embedding(x, segment_info)  \n\n        # running over multiple transformer blocks  \n        for encoder in self.encoder_blocks:  \n            x = encoder.forward(x, mask)  \n        return x  \n\n    class NextSentencePrediction(torch.nn.Module):  \n        \"\"\"  \n        2-class classification model : is_next, is_not_next  \n        \"\"\"  \n\n        def __init__(self, hidden):  \n            \"\"\"  \n            :param hidden: BERT model output size  \n            \"\"\"  \n            super().__init__()  \n            self.linear = torch.nn.Linear(hidden, 2)  \n            self.softmax = torch.nn.LogSoftmax(dim=-1)  \n\n        def forward(self, x):  \n            # use only the first token which is the [CLS]  \n            return self.softmax(self.linear(x[:, 0]))  \n\n    class MaskedLanguageModel(torch.nn.Module):  \n        \"\"\"  \n        predicting origin token from masked input sequence  \n        n-class classification problem, n-class = vocab_size  \n        \"\"\"  \n\n        def __init__(self, hidden, vocab_size):  \n            \"\"\"  \n            :param hidden: output size of BERT model  \n            :param vocab_size: total vocab size  \n            \"\"\"  \n            super().__init__()  \n            self.linear = torch.nn.Linear(hidden, vocab_size)  \n            self.softmax = torch.nn.LogSoftmax(dim=-1)  \n\n        def forward(self, x):  \n            return self.softmax(self.linear(x))  \n</code></pre> <pre><code>    class BERTLM(torch.nn.Module):  \n        \"\"\"  \n        BERT Language Model  \n        Next Sentence Prediction Model + Masked Language Model  \n        \"\"\"  \n\n        def __init__(self, bert: BERT, vocab_size):  \n            \"\"\"  \n            :param bert: BERT model which should be trained  \n            :param vocab_size: total vocab size for masked_lm  \n            \"\"\"  \n            super().__init__()  \n            self.bert = bert  \n            self.next_sentence = NextSentencePrediction(self.bert.d_model)  \n            self.mask_lm = MaskedLanguageModel(self.bert.d_model, vocab_size)  \n\n        def forward(self, x, segment_label):  \n            x = self.bert(x, segment_label)  \n            return self.next_sentence(x), self.mask_lm(x)\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20BERT%20Code/#how-to-write-a-bert-trainer","title":"How to Write A BERT Trainer?","text":"<p>In this section we will discuss how to train a BERT model. The loss function and optimizer are defined in the trainer as well.</p> <pre><code>criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n</code></pre> <pre><code>model = BERT()\nbatch = make_batch()\ninput_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n</code></pre> <pre><code>for epoch in range(100):\n    # initialize the parameters in optim with zero\n    optimizer.zero_grad() \n    # the arguments are input to the model\n    # input_ids: \n    # segment_ids:\n    # masked pos:\n    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n    # transpose to the masked_tokens' shape, and calculate the loss\n    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n    # calculate the average loss\n    loss_lm = (loss_lm.float()).mean()\n    # sentence classification loss\n    loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n    loss = loss_lm + loss_clsf\n    if (epoch + 1) % 10 == 0:\n       print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n    # performs back propogation\n    loss.backward()\n    # the optimizer takes a step based on the computed gradients.\n    optimizer.step()\n\n# Predict mask tokens\ninput_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[0]))\nprint(text)\nprint([number_dict[w.item()] for w in input_ids[0] if number_dict[w.item()] != '[PAD]'])\n\nlogits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\nlogits_lm = logits_lm.data.max(2)[1][0].data.numpy()\nprint('masked tokens list : ',[pos.item() for pos in masked_tokens[0] if pos.item() != 0])\nprint('predict masked tokens list : ',[pos for pos in logits_lm if pos != 0])\n\nlogits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\nprint('isNext : ', True if isNext else False)\nprint('predict isNext : ',True if logits_clsf else False)\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20GPT%20Code/","title":"\u3010TODO\u3011Note on GPT Code","text":"<p>GPT's implementation involves only the decoder of the Transformer model.</p> <pre><code>class GPT(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        embed_dim = config.embed_dim\n        self.max_len = config.max_len\n        self.tok_embed = nn.Embedding(\n            config.vocab_size, embed_dim\n        )\n        self.pos_embed = nn.Parameter(\n            torch.zeros(1, config.max_len, embed_dim)\n        )\n        self.dropout = nn.Dropout(config.embed_dropout)\n        self.blocks = nn.Sequential(\n            *[DecoderBlock(config) for _ in range(config.num_blocks)]\n        )\n        self.ln = nn.LayerNorm(embed_dim)\n        self.fc = nn.Linear(embed_dim, config.vocab_size)\n\n    def forward(self, x, target=None):\n        # batch_size = x.size(0)\n        seq_len = x.size(1)\n        assert seq_len &lt;= self.max_len, \"sequence longer than model capacity\"\n\n        tok_embedding = self.tok_embed(x)\n        # tok_embedding.shape == (batch_size, seq_len, embed_dim)\n        pos_embedding = self.pos_embed[:, :seq_len, :]\n        # pos_embedding.shape == (1, seq_len, embed_dim)\n        x = self.dropout(tok_embedding + pos_embedding)\n        x = self.blocks(x)\n        x = self.ln(x)\n        x = self.fc(x)\n        # x.shape == (batch_size, seq_len, vocab_size)\n        return x\n</code></pre> <pre><code>class DecoderBlock(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        embed_dim = config.embed_dim\n        self.ln1 = nn.LayerNorm(embed_dim)\n        self.ln2 = nn.LayerNorm(embed_dim)\n        self.attn = MultiheadAttention(config)\n        self.ff = nn.Sequential(\n            nn.Linear(embed_dim, embed_dim * 4),\n            nn.GELU(),\n            nn.Linear(embed_dim * 4, embed_dim),\n            nn.Dropout(config.ff_dropout),\n        )\n\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.ff(self.ln2(x))\n        return x\n</code></pre> <pre><code>class MultiheadAttention(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        embed_dim = config.embed_dim\n        self.num_heads = config.num_heads\n        assert embed_dim % self.num_heads == 0, \"invalid heads and embedding dimension configuration\"\n        self.key = nn.Linear(embed_dim, embed_dim)\n        self.value = nn.Linear(embed_dim, embed_dim)\n        self.query = nn.Linear(embed_dim, embed_dim)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.attn_dropout = nn.Dropout(config.attn_dropout)\n        self.proj_dropout = nn.Dropout(config.ff_dropout)\n        self.register_buffer(\n            \"mask\", \n            torch.tril(torch.ones(config.max_len, config.max_len))\n            .unsqueeze(0).unsqueeze(0)\n        )\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        seq_len = x.size(1)\n        # x.shape == (batch_size, seq_len, embed_dim)\n        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, -1).permute(0, 2, 3, 1)\n        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n        # shape == (batch_size, num_heads, seq_len, head_dim)\n\n        attn = torch.matmul(q, k_t) / math.sqrt(q.size(-1))\n        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n        mask = self.mask[:, :, :seq_len, :seq_len]\n        attn = attn.masked_fill(mask == 0, float(\"-inf\"))\n        attn = self.attn_dropout(attn)\n        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n        attn = F.softmax(attn, dim=-1)\n        y = torch.matmul(attn, v)\n        # y.shape == (batch_size, num_heads, seq_len, head_dim)\n        y = y.transpose(1, 2)\n        # y.shape == (batch_size, seq_len, num_heads, head_dim)\n        y = y.reshape(batch_size, seq_len, -1)\n        # y.shape == (batch_size, seq_len, embed_dim)\n        y = self.proj_dropout(self.proj(y))\n        return y\n\n</code></pre> <p>Finally we will see its default configuration.</p> <pre><code>class GPTConfig:\n    attn_dropout = 0.1\n    embed_dropout = 0.1\n    ff_dropout = 0.1\n\n    def __init__(\n        self, vocab_size, max_len, **kwargs\n    ):\n        self.vocab_size = vocab_size\n        self.max_len = max_len\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\nclass GPT1Config(GPTConfig):\n    num_heads = 12\n    num_blocks = 12\n    embed_dim = 768\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/","title":"\u3010TODO\u3011Note on LLaMA Code","text":""},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#introduction","title":"Introduction","text":"<p>This note only focuses on the classes and eliminates all other packages or data processing lines.</p> <p>LLaMA is a decoder-only Transformer architecture. To implement a LLaMA, the following modules will be applied. - class LLaMA: generation - model utils: RMSNorm, Attention, FeedForward, TransformerBlock, Transformer</p> <p>LLaMA makes 3 main improvements to the Transformer architecture: RMSNorm, RoPE, and SwiGLU.</p>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#rmsnorm","title":"RMSNorm","text":"<p>Root mean square layer norm, proposed in 2019. Its capability in handling re-centering (removing mean) and re-scaling (maintaining square) of both inputs and weight matrix can stabilize training and boost model convergence. The RMSNorm only focuses on re-scaling invariance and regularizes the summed inputs according to the root mean square statistics. $$ \\bar{a_i} = \\frac{a_i}{RMS(a)}g_i, \\space where \\space RMS(a) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{a^2_i}} $$</p> <pre><code>class RMSNorm(torch.nn.Module):\n    def __init__(self, dim: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(dim))\n\n    def _norm(self, x):\n        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n\n    def forward(self, x):\n        output = self._norm(x.float()).type_as(x)\n        return output * self.weight\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#attention","title":"Attention","text":"<pre><code>def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n    ndim = x.ndim\n    assert 0 &lt;= 1 &lt; ndim\n    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n    return freqs_cis.view(*shape)\n\n</code></pre> <pre><code>def apply_rotary_emb(\n    xq: torch.Tensor,\n    xk: torch.Tensor,\n    freqs_cis: torch.Tensor,\n        ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n\n    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n    return xq_out.type_as(xq), xk_out.type_as(xk)\n\n</code></pre> <pre><code>def repeat_kv(x: torch.Tensor, n_rep: int) -&gt; torch.Tensor:\n    \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\"\n    bs, slen, n_kv_heads, head_dim = x.shape\n    if n_rep == 1:\n        return x\n    return (\n        x[:, :, :, None, :]\n        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n    )\n</code></pre> <pre><code>class Attention(nn.Module):\n    def __init__(self, args: ModelArgs):\n        super().__init__()\n        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n        model_parallel_size = fs_init.get_model_parallel_world_size()\n        self.n_local_heads = args.n_heads // model_parallel_size\n        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size\n        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n        self.head_dim = args.dim // args.n_heads\n\n        self.wq = ColumnParallelLinear(\n            args.dim,\n            args.n_heads * self.head_dim,\n            bias=False,\n            gather_output=False,\n            init_method=lambda x: x,\n        )\n        self.wk = ColumnParallelLinear(\n            args.dim,\n            self.n_kv_heads * self.head_dim,\n            bias=False,\n            gather_output=False,\n            init_method=lambda x: x,\n        )\n        self.wv = ColumnParallelLinear(\n            args.dim,\n            self.n_kv_heads * self.head_dim,\n            bias=False,\n            gather_output=False,\n            init_method=lambda x: x,\n        )\n        self.wo = RowParallelLinear(\n            args.n_heads * self.head_dim,\n            args.dim,\n            bias=False,\n            input_is_parallel=True,\n            init_method=lambda x: x,\n        )\n\n        self.cache_k = torch.zeros(\n            (\n                args.max_batch_size,\n                args.max_seq_len,\n                self.n_local_kv_heads,\n                self.head_dim,\n            )\n        ).cuda()\n        self.cache_v = torch.zeros(\n            (\n                args.max_batch_size,\n                args.max_seq_len,\n                self.n_local_kv_heads,\n                self.head_dim,\n            )\n        ).cuda()\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        start_pos: int,\n        freqs_cis: torch.Tensor,\n        mask: Optional[torch.Tensor],\n    ):\n        bsz, seqlen, _ = x.shape\n        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n\n        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n\n        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n\n        self.cache_k = self.cache_k.to(xq)\n        self.cache_v = self.cache_v.to(xq)\n\n        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n\n        keys = self.cache_k[:bsz, : start_pos + seqlen]\n        values = self.cache_v[:bsz, : start_pos + seqlen]\n\n        # repeat k/v heads if n_kv_heads &lt; n_heads\n        keys = repeat_kv(keys, self.n_rep)  # (bs, seqlen, n_local_heads, head_dim)\n        values = repeat_kv(values, self.n_rep)  # (bs, seqlen, n_local_heads, head_dim)\n\n        xq = xq.transpose(1, 2)  # (bs, n_local_heads, seqlen, head_dim)\n        keys = keys.transpose(1, 2)\n        values = values.transpose(1, 2)\n        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n        if mask is not None:\n            scores = scores + mask  # (bs, n_local_heads, seqlen, cache_len + seqlen)\n        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n        output = torch.matmul(scores, values)  # (bs, n_local_heads, seqlen, head_dim)\n        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n        return self.wo(output)\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#feedforward","title":"FeedForward","text":"<pre><code>class FeedForward(nn.Module):\n    def __init__(\n        self,\n        dim: int,\n        hidden_dim: int,\n        multiple_of: int,\n        ffn_dim_multiplier: Optional[float],\n    ):\n        super().__init__()\n        hidden_dim = int(2 * hidden_dim / 3)\n        # custom dim factor multiplier\n        if ffn_dim_multiplier is not None:\n            hidden_dim = int(ffn_dim_multiplier * hidden_dim)\n        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n\n        self.w1 = ColumnParallelLinear(\n            dim, hidden_dim, bias=False, gather_output=False, init_method=lambda x: x\n        )\n        self.w2 = RowParallelLinear(\n            hidden_dim, dim, bias=False, input_is_parallel=True, init_method=lambda x: x\n        )\n        self.w3 = ColumnParallelLinear(\n            dim, hidden_dim, bias=False, gather_output=False, init_method=lambda x: x\n        )\n\n    def forward(self, x):\n        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#transformerblock","title":"TransformerBlock","text":"<pre><code>class TransformerBlock(nn.Module):\n    def __init__(self, layer_id: int, args: ModelArgs):\n        super().__init__()\n        self.n_heads = args.n_heads\n        self.dim = args.dim\n        self.head_dim = args.dim // args.n_heads\n        self.attention = Attention(args)\n        self.feed_forward = FeedForward(\n            dim=args.dim,\n            hidden_dim=4 * args.dim,\n            multiple_of=args.multiple_of,\n            ffn_dim_multiplier=args.ffn_dim_multiplier,\n        )\n        self.layer_id = layer_id\n        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        start_pos: int,\n        freqs_cis: torch.Tensor,\n        mask: Optional[torch.Tensor],\n    ):\n        # Add &amp; Norm. add an highway to the attention block.\n        h = x + self.attention.forward(\n            self.attention_norm(x), start_pos, freqs_cis, mask\n        )\n        # feedforward and addition\n        out = h + self.feed_forward.forward(self.ffn_norm(h))\n        return out\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#transformer","title":"Transformer","text":"<p>We implement several utility functions before implementing the transformer model.</p> <pre><code>def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n    t = torch.arange(end, device=freqs.device)  # type: ignore\n    freqs = torch.outer(t, freqs).float()  # type: ignore\n    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n    return freqs_cis\n</code></pre> <pre><code>class Transformer(nn.Module):\n    def __init__(self, params: ModelArgs):\n        super().__init__()\n        self.params = params\n        self.vocab_size = params.vocab_size\n        self.n_layers = params.n_layers\n\n        self.tok_embeddings = ParallelEmbedding(\n            params.vocab_size, params.dim, init_method=lambda x: x\n        )\n\n        self.layers = torch.nn.ModuleList()\n        for layer_id in range(params.n_layers):\n            self.layers.append(TransformerBlock(layer_id, params))\n\n        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n        self.output = ColumnParallelLinear(\n            params.dim, params.vocab_size, bias=False, init_method=lambda x: x\n        )\n\n        self.freqs_cis = precompute_freqs_cis(\n            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n        )\n\n\n    @torch.inference_mode()\n    def forward(self, tokens: torch.Tensor, start_pos: int):\n        _bsz, seqlen = tokens.shape\n        h = self.tok_embeddings(tokens)\n        self.freqs_cis = self.freqs_cis.to(h.device)\n        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n\n        mask = None\n        if seqlen &gt; 1:\n            mask = torch.full(\n                (1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device\n            )\n            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n\n        for layer in self.layers:\n            h = layer(h, start_pos, freqs_cis, mask)\n\n        h = self.norm(h)\n        output = self.output(h).float()\n        return output\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#llama","title":"LLaMa","text":"<p>Let's finally see the default model args. </p> <pre><code>@dataclass\nclass ModelArgs:\n    dim: int = 4096\n    n_layers: int = 32\n    n_heads: int = 32\n    n_kv_heads: Optional[int] = None\n    vocab_size: int = -1  # defined later by tokenizer\n    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n    ffn_dim_multiplier: Optional[float] = None\n    norm_eps: float = 1e-5\n\n    max_batch_size: int = 32\n    max_seq_len: int = 2048\n</code></pre> <pre><code>class Llama:\n    @staticmethod\n    def build(\n        ckpt_dir: str,\n        tokenizer_path: str,\n        max_seq_len: int,\n        max_batch_size: int,\n        model_parallel_size: Optional[int] = None,\n    ) -&gt; \"Llama\":\n        if not torch.distributed.is_initialized():\n            torch.distributed.init_process_group(\"nccl\")\n        if not model_parallel_is_initialized():\n            if model_parallel_size is None:\n                model_parallel_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n            initialize_model_parallel(model_parallel_size)\n\n        local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n        torch.cuda.set_device(local_rank)\n\n        # seed must be the same in all processes\n        torch.manual_seed(1)\n\n        if local_rank &gt; 0:\n            sys.stdout = open(os.devnull, \"w\")\n\n        start_time = time.time()\n        checkpoints = sorted(Path(ckpt_dir).glob(\"*.pth\"))\n        assert len(checkpoints) &gt; 0, f\"no checkpoint files found in {ckpt_dir}\"\n        assert model_parallel_size == len(\n            checkpoints\n        ), f\"Loading a checkpoint for MP={len(checkpoints)} but world size is {model_parallel_size}\"\n        ckpt_path = checkpoints[get_model_parallel_rank()]\n        checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n        with open(Path(ckpt_dir) / \"params.json\", \"r\") as f:\n            params = json.loads(f.read())\n\n        model_args: ModelArgs = ModelArgs(\n            max_seq_len=max_seq_len,\n            max_batch_size=max_batch_size,\n            **params,\n        )\n        tokenizer = Tokenizer(model_path=tokenizer_path)\n        model_args.vocab_size = tokenizer.n_words\n        torch.set_default_tensor_type(torch.cuda.HalfTensor)\n        model = Transformer(model_args)\n        model.load_state_dict(checkpoint, strict=False)\n        print(f\"Loaded in {time.time() - start_time:.2f} seconds\")\n\n        return Llama(model, tokenizer)\n\n    def __init__(self, model: Transformer, tokenizer: Tokenizer):\n        self.model = model\n        self.tokenizer = tokenizer\n\n    @torch.inference_mode()\n    def generate(\n        self,\n        prompt_tokens: List[List[int]],\n        max_gen_len: int,\n        temperature: float = 0.6,\n        top_p: float = 0.9,\n        logprobs: bool = False,\n        echo: bool = False,\n    ) -&gt; Tuple[List[List[int]], Optional[List[List[float]]]]:\n        params = self.model.params\n        bsz = len(prompt_tokens)\n        assert bsz &lt;= params.max_batch_size, (bsz, params.max_batch_size)\n\n        min_prompt_len = min(len(t) for t in prompt_tokens)\n        max_prompt_len = max(len(t) for t in prompt_tokens)\n        assert max_prompt_len &lt;= params.max_seq_len\n        total_len = min(params.max_seq_len, max_gen_len + max_prompt_len)\n\n        pad_id = self.tokenizer.pad_id\n        tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=\"cuda\")\n        for k, t in enumerate(prompt_tokens):\n            tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device=\"cuda\")\n        if logprobs:\n            token_logprobs = torch.zeros_like(tokens, dtype=torch.float)\n\n        prev_pos = 0\n        eos_reached = torch.tensor([False] * bsz, device=\"cuda\")\n        input_text_mask = tokens != pad_id\n        for cur_pos in range(min_prompt_len, total_len):\n            logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)\n            if logprobs:\n                token_logprobs[:, prev_pos + 1 : cur_pos + 1] = -F.cross_entropy(\n                    input=logits.transpose(1, 2),\n                    target=tokens[:, prev_pos + 1 : cur_pos + 1],\n                    reduction=\"none\",\n                    ignore_index=pad_id,\n                )\n            if temperature &gt; 0:\n                probs = torch.softmax(logits[:, -1] / temperature, dim=-1)\n                next_token = sample_top_p(probs, top_p)\n            else:\n                next_token = torch.argmax(logits[:, -1], dim=-1)\n\n            next_token = next_token.reshape(-1)\n            # only replace token if prompt has already been generated\n            next_token = torch.where(\n                input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token\n            )\n            tokens[:, cur_pos] = next_token\n            eos_reached |= (~input_text_mask[:, cur_pos]) &amp; (\n                next_token == self.tokenizer.eos_id\n            )\n            prev_pos = cur_pos\n            if all(eos_reached):\n                break\n\n        if logprobs:\n            token_logprobs = token_logprobs.tolist()\n        out_tokens, out_logprobs = [], []\n        for i, toks in enumerate(tokens.tolist()):\n            # cut to max gen len\n            start = 0 if echo else len(prompt_tokens[i])\n            toks = toks[start : len(prompt_tokens[i]) + max_gen_len]\n            probs = None\n            if logprobs:\n                probs = token_logprobs[i][start : len(prompt_tokens[i]) + max_gen_len]\n            # cut to eos tok if any\n            if self.tokenizer.eos_id in toks:\n                eos_idx = toks.index(self.tokenizer.eos_id)\n                toks = toks[:eos_idx]\n                probs = probs[:eos_idx] if logprobs else None\n            out_tokens.append(toks)\n            out_logprobs.append(probs)\n        return (out_tokens, out_logprobs if logprobs else None)\n\n    def text_completion(\n        self,\n        prompts: List[str],\n        temperature: float = 0.6,\n        top_p: float = 0.9,\n        max_gen_len: Optional[int] = None,\n        logprobs: bool = False,\n        echo: bool = False,\n    ) -&gt; List[CompletionPrediction]:\n        if max_gen_len is None:\n            max_gen_len = self.model.params.max_seq_len - 1\n        prompt_tokens = [self.tokenizer.encode(x, bos=True, eos=False) for x in prompts]\n        generation_tokens, generation_logprobs = self.generate(\n            prompt_tokens=prompt_tokens,\n            max_gen_len=max_gen_len,\n            temperature=temperature,\n            top_p=top_p,\n            logprobs=logprobs,\n            echo=echo,\n        )\n        if logprobs:\n            return [\n                {\n                    \"generation\": self.tokenizer.decode(t),\n                    \"tokens\": [self.tokenizer.decode(x) for x in t],\n                    \"logprobs\": logprobs_i,\n                }\n                for t, logprobs_i in zip(generation_tokens, generation_logprobs)\n            ]\n        return [{\"generation\": self.tokenizer.decode(t)} for t in generation_tokens]\n\n    def chat_completion(\n        self,\n        dialogs: List[Dialog],\n        temperature: float = 0.6,\n        top_p: float = 0.9,\n        max_gen_len: Optional[int] = None,\n        logprobs: bool = False,\n    ) -&gt; List[ChatPrediction]:\n        if max_gen_len is None:\n            max_gen_len = self.model.params.max_seq_len - 1\n        prompt_tokens = []\n        unsafe_requests = []\n        for dialog in dialogs:\n            unsafe_requests.append(\n                any([tag in msg[\"content\"] for tag in SPECIAL_TAGS for msg in dialog])\n            )\n            if dialog[0][\"role\"] == \"system\":\n                dialog = [\n                    {\n                        \"role\": dialog[1][\"role\"],\n                        \"content\": B_SYS\n                        + dialog[0][\"content\"]\n                        + E_SYS\n                        + dialog[1][\"content\"],\n                    }\n                ] + dialog[2:]\n            assert all([msg[\"role\"] == \"user\" for msg in dialog[::2]]) and all(\n                [msg[\"role\"] == \"assistant\" for msg in dialog[1::2]]\n            ), (\n                \"model only supports 'system', 'user' and 'assistant' roles, \"\n                \"starting with 'system', then 'user' and alternating (u/a/u/a/u...)\"\n            )\n            dialog_tokens: List[int] = sum(\n                [\n                    self.tokenizer.encode(\n                        f\"{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()} \",\n                        bos=True,\n                        eos=True,\n                    )\n                    for prompt, answer in zip(\n                        dialog[::2],\n                        dialog[1::2],\n                    )\n                ],\n                [],\n            )\n            assert (\n                dialog[-1][\"role\"] == \"user\"\n            ), f\"Last message must be from user, got {dialog[-1]['role']}\"\n            dialog_tokens += self.tokenizer.encode(\n                f\"{B_INST} {(dialog[-1]['content']).strip()} {E_INST}\",\n                bos=True,\n                eos=False,\n            )\n            prompt_tokens.append(dialog_tokens)\n\n        generation_tokens, generation_logprobs = self.generate(\n            prompt_tokens=prompt_tokens,\n            max_gen_len=max_gen_len,\n            temperature=temperature,\n            top_p=top_p,\n            logprobs=logprobs,\n        )\n        if logprobs:\n            return [\n                {\n                    \"generation\": {\n                        \"role\": \"assistant\",\n                        \"content\": self.tokenizer.decode(t)\n                        if not unsafe\n                        else UNSAFE_ERROR,\n                    },\n                    \"tokens\": [self.tokenizer.decode(x) for x in t],\n                    \"logprobs\": logprobs_i,\n                }\n                for t, logprobs_i, unsafe in zip(\n                    generation_tokens, generation_logprobs, unsafe_requests\n                )\n            ]\n        return [\n            {\n                \"generation\": {\n                    \"role\": \"assistant\",\n                    \"content\": self.tokenizer.decode(t) if not unsafe else UNSAFE_ERROR,\n                }\n            }\n            for t, unsafe in zip(generation_tokens, unsafe_requests)\n        ]\n\n\ndef sample_top_p(probs, p):\n    probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n    probs_sum = torch.cumsum(probs_sort, dim=-1)\n    mask = probs_sum - probs_sort &gt; p\n    probs_sort[mask] = 0.0\n    probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n    next_token = torch.multinomial(probs_sort, num_samples=1)\n    next_token = torch.gather(probs_idx, -1, next_token)\n    return next_token\n\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E3%80%90TODO%E3%80%91Note%20on%20LLaMA%20Code/#references","title":"References","text":"<p>facebookresearch/llama: Inference code for LLaMA models (github.com)</p>"},{"location":"DL_Notes/NLP_Tech/%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/","title":"\u89c4\u5219\u63d0\u53d6\u6587\u672c\u683c\u5f0f\u7ecf\u9a8c\u603b\u7ed3","text":""},{"location":"DL_Notes/NLP_Tech/%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/#1","title":"\u4efb\u52a11","text":"<p>\u9700\u8981\u5728\u56db\u672c\u683c\u5f0f\u4e0d\u4e00\u6837\u7684\u8bcd\u5178\u4e2d\u63d0\u53d6\u51fa\u76f8\u540c\u683c\u5f0f\u7684\u8bcd\u6e90\u4fe1\u606f\uff0c\u8bcd\u6e90\u4e00\u5171\u67099\u5927\u7c7b+\u4e00\u79cd\"Other\"\uff0c\u6587\u672c\u4e2d\u6709\u6570\u4e2a\u8bcd\u6e90\u4fe1\u606f\uff0c\u9700\u8981\u627e\u5230\u6700\u521d\u7684\u90a3\u4e2a\u8bcd\u6e90\u4fe1\u606f\uff0c\u5f52\u52309\u5927\u7c7b\u4e2d\u5e76\u8bb0\u5f55\u4e0b\u6765\u5177\u4f53\u662f\u54ea\u4e00\u7c7b\u3002 \u9700\u8981\u7684\u683c\u5f0f</p> <pre><code>[{\n    \"word\": \"\",\n    \"etymology\": [\n        {\n            \"origin\": \"\",\n            \"source\": \"\",\n            \"excerpt\": \"\"\n        },\n        {\n            \"origin\": \"\",\n            \"source\": \"\",\n            \"excerpt\": \"\"\n        }\n    ]\n}]\n</code></pre>"},{"location":"DL_Notes/NLP_Tech/%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/#_1","title":"\u65b9\u6cd5","text":"<ol> <li>\u7eaf\u89c4\u5219     \u662f\u6307\u4eba\u5de5\u770b\u51fa\u8bcd\u6e90\u7684\u5206\u7c7b\u89c4\u5219\uff0c\u9700\u8981\u627e\u5230\u6570\u636e\u96c6\u91cc\u90fd\u6709\u54ea\u4e9b\u683c\u5f0f\uff0c\u5199\u4e2a\u8ddf\u81ea\u5df1\u7ec4\u522b\u7684\u683c\u5f0f\u5bf9\u5e94</li> <li>\u7528ChatGPT     \u5199prompt\uff0c\u8ba9ChatGPT\u8fd4\u56de\u5206\u7c7b     \u6211\u7684prompt\u5199\u6cd5 \u4ecb\u7ecd+\u7c7b\u522b+\u793a\u8303     <code>Plain     \"An ultimate origin of a word is the language where a word comes from at the very beginning, or the language where it appears at the earliest time. For the given word %s, please find its ultimate origin of this word from the following passage: %s. You should only answer one word from Anglo, Arabic, Asian, Celtic, English, French, Germanic, Greek, Latin, Spanish, or Other, without outputing anything else. If the origin not provided, just output Other. Origin: %s\" % (\"a\", \"prefix meaning \\\"not,\\\" from Latin. a-, short for ab \\\"away from\\\" (cf. avert), or its cognate, Greek. a-, short for apo \\\"away from, from,\\\" both cognate with Skt. apa \\\"away from,\\\" Goth. af, Old.English. of. \", \"Latin\")</code>     \u8fd9\u91cc\u53ef\u4ee5\u770b\u5230\uff0c\u4e3a\u4e86\u9632\u6b62ChatGPT\u5c06English\u7406\u89e3\u6210Other\u800c\u975eAnglo\uff0c\u7279\u610f\u5c06English\u6dfb\u52a0\u5728\u4e86\u5907\u9009\u9879\u4e2d\uff0c\u4e4b\u540e\u518d\u5bf9\u8fd4\u56de\u7684English\u7c7b\u522b\u505a\u4e00\u4e2a\u89c4\u5219\u5904\u7406\u3002</li> <li>\u7528\u9605\u8bfb\u7406\u89e3\u6a21\u578b     \u56e0\u4e3aChatGPT\u6bd4\u8f83\u8d35\uff0c\u5c1d\u8bd5\u7528\u4e00\u4e9b\u9884\u8bad\u7ec3\u7684\u9605\u8bfb\u7406\u89e3\u6a21\u578b\u6765\u505a\u3002     \u4e00\u5f00\u59cb\u627e\u5230\u7684\u662fRoBERTa\uff0c\u5177\u4f53\u662fhuggingface\u4e0a\u7684RoBERTa-based-QA\uff0c\u4f46\u662f\u53d1\u73b0\u8be5\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u4eba\u7c7b\u6307\u4ee4\u7684\u652f\u6301\u5f88\u4e0d\u597d\uff0c\u6bd4\u5982prompt\u4e2d\u5199\u660e\u4e86\u201d\u5982\u679c\u63d0\u4f9b\u7684\u4fe1\u606f\u4e2d\u4e0d\u542b\u4efb\u4f55\u8bcd\u6e90\uff0c\u8bf7\u8fd4\u56deOther\u201c\uff0c\u4f46\u662f\u6a21\u578b\u4ecd\u7136\u4e0d\u4f1a\u6309\u683c\u5f0f\u8fd4\u56de\uff0c\u800c\u662f\u4f1a\u8f93\u51fa\u4e00\u5927\u6bb5\u6587\u5b57\u4ee5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u63d0\u4f9b\u7684\u4fe1\u606f\u4e2d\u7684\u8bcd\u6e90\u4e0d\u5c5e\u4e8e\u4efb\u4f55\u4e00\u7c7b\u3002\u8bf4\u660e\u8fd9\u4e9b\u6a21\u578bfew-shot\u80fd\u529b\u8fd8\u662f\u5e76\u4e0d\u597d\uff0c\u4e5f\u6ca1\u6709\u6839\u636e\u4eba\u7c7b\u6307\u4ee4\u5fae\u8c03\u8fc7\u3002</li> </ol>"},{"location":"DL_Notes/NLP_Tech/%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/#2","title":"\u4efb\u52a12","text":"<p>\u9700\u8981\u5c06\u4e00\u4e2a\u6587\u672c\u5e93\u4e2d\u7684\u6587\u672c\u5206\u8bcd\u540e\u8bcd\u5f62\u8fd8\u539f 1. nltk     \u4f18\u70b9\uff1a\u8c03\u7528\u7b80\u5355\uff0c\u5feb     \u7f3a\u70b9\uff1a\u9884\u8bad\u7ec3\u6a21\u578b\u4e0b\u8f7d\u4e0d\u7a33\u5b9a\uff0c\u5f80\u5f80\u9700\u8981\u624b\u52a8\u4e0b\u8f7d\u540e\u653e\u5728\u672c\u5730\u7684nltk\u6587\u4ef6\u5939\u4e2d\uff0c\u51c6\u786e\u7387\u4f4e\u4e00\u4e9b 2. spaCy     \u4f18\u70b9\uff1a\u51c6\u786e\u7387\u66f4\u9ad8     \u7f3a\u70b9\uff1a\u8c03\u7528\u6162\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4e0b\u8f7d\u4e0d\u7a33\u5b9a 3. stanza     \u4f18\u70b9\uff1a\u51c6\u786e\u7387\u66f4\u9ad8     \u7f3a\u70b9\uff1a\u9884\u8bad\u7ec3\u6a21\u578b\u4e0b\u8f7d\u4e0d\u7a33\u5b9a</p> <p>\u4e09\u4e2a\u5305\u7684\u63a8\u8350\u7a0b\u5ea6\u6392\u5e8f stanza = spaCy &gt; nltk</p>"},{"location":"DL_Notes/NLP_Theory/","title":"Index","text":""},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/","title":"\u4efb\u52a1\u76ee\u6807","text":"<p>\u672c\u5b9e\u9a8c\u65e8\u5728\u6d4b\u8bc4ChatGPT\u5728\u9605\u8bfb\u7406\u89e3\u4efb\u52a1\uff08Multiple-choice Comprehension, MRC\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u65b9\u6cd5\u6316\u6398\u63d0\u793a\u8bcd\uff0c\u901a\u8fc7\u4e0d\u6539\u53d8\u6570\u636e\u96c6\u548c\u6a21\u578b\u53ea\u6539\u53d8\u63d0\u793a\u8bcd\u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u5927\u6a21\u578b\u5728MRC\u4e0a\u7684\u8868\u73b0\u3002</p>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#_2","title":"\u5b9e\u9a8c\u8bbe\u8ba1","text":"<p>\u4e3a\u8282\u7ea6\u65f6\u95f4\u548c\u91d1\u94b1\u6210\u672c\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u5b9e\u9a8c\uff0c\u6211\u4eec\u4ec5\u6d4b\u8bd520\u4e2a\u95ee\u9898</p>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#_3","title":"\u6570\u636e\u96c6","text":"<p>AQuA\u6570\u636e\u96c6\u9898\u63d0\u4f9b\u4e86100,000\u9053\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u6570\u5b66\u9898\u3002 https://github.com/deepmind/AQuA</p>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#benchmark-zero-shot-prompting","title":"Benchmark: Zero-shot Prompting","text":"<p>\u6700\u7b80\u5355\u7684MRC\u95ee\u9898\uff0c\u53ea\u8f93\u5165question\u548coptions The dataset consists of about 100,000 algebraic word problems with natural language rationales. Each problem is a json object consisting of four parts:</p> <ul> <li><code>question</code>\u00a0- A natural language definition of the problem to solve</li> <li><code>options</code>\u00a0- 5 possible options (A, B, C, D and E), among which one is correct</li> <li><code>rationale</code>\u00a0- A natural language description of the solution to the problem</li> <li><code>correct</code>\u00a0- The correct option</li> </ul> <pre><code>{\n\"question\": \"A grocery sells a bag of ice for $1.25, and makes 20% profit. If it sells 500 bags of ice, how much total profit does it make?\",\n\"options\": [\"A)125\", \"B)150\", \"C)225\", \"D)250\", \"E)275\"],\n\"rationale\": \"Profit per bag = 1.25 * 0.20 = 0.25\\nTotal profit = 500 * 0.25 = 125\\nAnswer is A.\",\n\"correct\": \"A\"\n}\n</code></pre>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#self-consistency","title":"Self-Consistency","text":"<pre><code># \u5c06\u95ee\u9898\u6309\u53e5\u5b50\u5206\u5f00\uff0c\u5e76\u968f\u673a\u6253\u4e71\u53e5\u5b50\nquestion_sentences = question.split('. ')\nquestion = '. '.join(shuffled(question_sentences))\n# \u5206\u522b\u5c06\u95ee\u9898\u8f93\u5165\u7ed9\u591a\u4e2aChatGPT\nfor i in range(GPT_number):\n    answers.append(query(ChatGPT_i, question))\n# \u5c06\u56de\u7b54\u66f4\u591a\u7684\u7b54\u6848vote\u4e3a\u6b63\u786e\u7b54\u6848\nfinal_answer = top_one(answers)\n</code></pre> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5148\u5c06question\u968f\u673a\u6253\u4e71\uff0c\u7136\u540e\u8f93\u5165\u7ed9\u4e09\u4e2agpt\uff08\u4e0d\u76f8\u90bb\u7684\u4e09\u8f6e\uff09\uff0c\u8ba9\u5b83\u4eecvote</p>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#multi-step-verifier","title":"multi-step verifier","text":"<p>\u8fd9\u4e2a\u8981\u63a5\u4e00\u4e2averifier model</p> <pre><code># \u5206\u522b\u5c06\u95ee\u9898\u8f93\u5165\u7ed9\u591a\u4e2aChatGPT\uff0c\u63a2\u7d22\u5c3d\u53ef\u80fd\u591a\u7684\u63a8\u7406\u8def\u5f84\nfor i in range(GPT_number):\n    answers.append(query(ChatGPT_i, question))\n\n# \u4f7f\u7528\u4e00\u4e2afine-tuned\u7684Verifier\uff0c\u6839\u636e\u6570\u636e\u96c6\u6807\u7b7e\u4e3aanswer\u7684\u6bcf\u4e00\u6b65\u6253\u5206\nscores = []\nfor answer in answers:\n    score = 0\n    for step in answer:\n        score += Verifier(step, gold_label)\n    scores.append(score)\n\n# \u5c06score\u66f4\u9ad8\u7684\u7b54\u6848vote\u4e3a\u6b63\u786e\u7b54\u6848\nfinal_answer = top_one(scores-&gt;answer)\n</code></pre> <p>\u8fd9\u7bc7\u7684\u6570\u636e\u96c6HotpotQA\uff0c\u8be5\u6570\u636e\u96c6\u5185\u90e8\u63d0\u4f9b\u95ee\u9898\u3001\u56de\u7b54\uff0c\u548c\u76f8\u5e94\u7684\u6587\u7ae0context\u3002</p>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#chain-of-thought-prompting-elicits-reasoning-in-large-language-models","title":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","text":"<p>\u6dfb\u52a0lets think step by step + \u5e26cot\u76841-shot</p> <pre><code>prompt = [I, t, q] -&gt; y\nI: instruction\nt: example\nq: question\ny: answer\n</code></pre> <p>example:</p> <pre><code>There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n</code></pre> <p>applicable to</p> <ul> <li>math word problems (free response)</li> <li>math word problems (multiple choice)</li> <li>CSQA (commonsense)</li> <li>strategyQA</li> <li>date understanding</li> <li>sports understanding</li> <li>SayCan (instructing a robot)</li> <li>Last Letter Concatenation</li> <li>coin flip (state tracking)</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#the-cot-collection-improving-zero-shot-and-few-shot-learning-of-language-models-via-chain-of-thought-fine-tuning","title":"The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning","text":""},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#abstract","title":"Abstract","text":"<ul> <li>introduce CoT collection: a new instruction-tuning dataset that augments 1.88 million CoT rationales across 1060 tasks</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#the-cot-collection","title":"The CoT Collection","text":"<ul> <li>CoT Collection is an instruction-tuning dataset including 1.88 million CoT rationales</li> <li>distribution of data:   </li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#self-consistency-improves-chain-of-thought-reasoning-in-language-models","title":"SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS","text":""},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#introduction","title":"Introduction","text":"<ul> <li>introduce a novel decoding strategy called self-consistency to replace the greedy decoding strategy used in cot prompting</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#method","title":"method","text":"<ul> <li>prompt a language model using chain-of-thought prompting</li> <li>replace \u201cgreedy decode\u201d in CoT prompting by sampling from the language model\u2019s decoder to generate a diverse set of reasoning paths</li> <li>marginalize out the reasoning paths and aggregate by choosing the most consistent answer in the final answer set</li> </ul> <p>two assumptions</p> <ul> <li>we hypothesize that correct reasoning processes, even if they are diverse, tend to have greater agreement in their final answer than incorrect processes.</li> <li>by normalizing the answers. the normalization closer \u2192 generations are \u201csimilarly alike\u201d   </li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#advancement","title":"Advancement","text":"<ul> <li>far simpler than prior approaches (train an additional verifier) or train a re-ranker given additional human annotations to improve generation quality</li> <li>unsupervised</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#interleaving-retrieval-with-cot-reasoning-for-knowledge-intensive-multi-step-questions","title":"Interleaving retrieval with cot reasoning for knowledge-intensive multi-step questions","text":""},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#abstract_1","title":"Abstract","text":"<ul> <li>when necessary knowledge is not available or up-to-date within a model\u2019s parameters</li> <li>multi-step QA: what to retrieve depends on what has already been derived</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#method_1","title":"Method","text":"<p>IRCoT mian components</p> <ul> <li>a base retriever that can take a query and return a given number of paragraphs from a corpus or knowledge source</li> <li>a language model with zero/few-show CoT generation capabilities</li> <li>a small number of annotated questions with reasoning steps explaining how to retrieve at the answer in natural language (CoT) and a set of paragraphs from the knowledge source K that collectively support the reasoning chain and answer.</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#making-large-language-models-better-reasoners-with-step-aware-verifier","title":"Making Large Language Models Better Reasoners with Step-Aware Verifier","text":""},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#abstract_2","title":"Abstract","text":"<p>main components</p> <ul> <li>it generates diverse prompts to explore different reasoning paths for the same question</li> <li>it uses a verifier to filter out incorrect answers based on a weighted voting scheme</li> <li>it verifies each reasoning step individually instead of the whole chain</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#pot-program-of-thought","title":"PoT (Program of Thought)","text":"<p>template original paragraph (incorrect)</p> <pre><code>The first number is 0, the second number is 1, therefore, the third number is 0+1=1.\nThe fourth number is 1+1=2. The fifth number is 1+2=3. The sixth number is 2+3=5.\n(skip..)\nThe 50th number is 32,432,268,459\n</code></pre> <p>PoT (correct)</p> <pre><code>length_of_fibonacci_sequence = 50\nfibonacci_sequence = np.zeros(length_of_)\nfibonacci_sequence[0] = 0\nfibonacci_sequence[1] = 1\nfor i in range(3, length_of_fibonacci_sequence):\n    fibonacci_sequnce[i] = fibonacci_sequence[i-1] +\n    fibonacci_sequence[i-2]\nans = fibonacci_sequence[-1]\n</code></pre>"},{"location":"DL_Notes/NLP_Theory/Chain-of-Thought/#cos-chain-of-symbol-prompting","title":"CoS (Chain of Symbol Prompting)","text":"<p>template shared model input</p> <pre><code>There are a set of bricks. \nThe yellow brick C is on top of the brick E . \nThe yellow brick D is on top of the brick A . \nThe yellow brick E is on top of the brick D . \nThe white brick A is on top of the brick B . \nFor the brick B, the color is white. \nNow we have to get a specific brick. \nThe bricks must now be grabbed from top to bottom, and if the lower brick is to be grabbed, the upper brick must be removed first. \nHow to get brick D?\n</code></pre> <p>cot prompting (wrong)</p> <pre><code>The bricks from bottom to top is B, A, D, E, C \n1. Remove brick A from the top of brick B. \n2. Remove brick E from the top of brick D. \n3. Now brick D is the topmost yellow brick and can be grabbed.\n</code></pre> <p>cos prompting (correct)</p> <pre><code>B/A/D/E/C \nC/E \nE/D \nD\n</code></pre>"},{"location":"DL_Notes/NLP_Theory/Contrastive%20Learning%20and%20Interpretability/","title":"Contrastive Learning and Interpretability","text":"<p>This note is an collection of the paper reading notes of the contrastive learning and readability papers for math problem solving.</p>"},{"location":"DL_Notes/NLP_Theory/Contrastive%20Learning%20and%20Interpretability/#climbing-towards-nlu-on-meaning-form-and-understanding-in-the-age-of-data-2020","title":"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data (2020)","text":"<p>This paper argues that the modern NLP models trained on form has no abilities in understanding natural languages based on both the science and philosophy theories. It is structured as follows. In section Large LMs: Hype and analysis, this paper samples example pieces from news and academic literature that exaggerate the understanding abilities in using words including \"understand\"\"comprehension\"\"recall factual knowledge\", and argues that the current LMs have the ability no other than learning the surface linguistic forms of language rather than understanding them. In section What is meaning?, this paper clarifies the meaning of language as the communicative intent that a parole intends to express, and distinguishes the concept \"meaning\" and \"truth\" as the truth is the meaning that is \"grounded\" to the real world. In section The octopus test, this paper detailedly tells a thought experiment of a super intelligent octopus who can mimic the human response by never receiving the knowledge of the grounded real world of the language meaning, by which this paper argues that it might be that how the language receiver decodes the communicative intends affects the conventional meaning of language. In section More constrained thought experiments, two more thought experiments are provided, training the JAVA and training the English LMs without providing the executing methods the communicative intends, and the paper argues that such tasks are impossible. In section Human language acquisition, this paper supports its idea by providing the example of human children's acquiring knowledge is not only grounded on the world image, but also in the interaction with other people. In section Distributional semantics, this paper argues that in NLP, two methods based on the instincts above are training distributional models on corpora augmented with perceptual data, and looking to interaction data (according to Wittgenstein's \"meaning in use\"). </p>"},{"location":"DL_Notes/NLP_Theory/Contrastive%20Learning%20and%20Interpretability/#information-theory-based-compositional-distributional-semantics-2021","title":"Information Theory-based Compositional Distributional Semantics (2021)","text":"<p>According to the abstract, the contribution of this paper can be concluded as proposing the notion of Information Theory-based Compositional Distributional Semantics (ICDS): (i) We first establish formal properties for embedding, composition, and similarity functions based on Shannon\u2019s Information Theory; (ii) we analyze the existing approaches under this prism, checking whether or not they comply with the established desirable properties; (iii) we propose two parameterizable composition and similarity functions that generalize traditional approaches while fulfilling the formal properties; and finally (iv) we perform an empirical study on several textual similarity datasets that include sentences with a high and low lexical overlap, and on the similarity between words and their description. In section Introduction, the author introduces Frege's concepts of compositionality and contextuality, which respectively refers to that \"the meaning of the whole is a function of the meaning of its parts and the syntactic way in which they are combined\", and that \"the meaning of words and utterances is determined by their context\". This section also introduces the main concern of lacking systematicity by the linguists to the NLP, where systematicity is defined as \"A system is said to exhibit systematicity if, whenever it can process a sentence, it can process systematic variants, where systematic variation is understood in terms of permuting constituents or (more strongly) substituting constituents of the same grammatical category.\" Thus, this section introduces that this paper aims to propose a novel system called Information Theory-based Compositional Distributional Semantics (ICDS). In section Related Work, the author introduces a set of properties in selective proper text representation paradigms which includes \"systematicity\", \"usage context\", \"continuity\", and \"information measurbility\", and introduces a series of previous work under this standard. In section Theoretical Framework, this paper first establishes a geometric interpretation of ICDS, that \"The direction of an embedding represents the pragmatic meaning, and the vector norm of embedding represents how much information the literal utterance provides about its meaning in the pragmatic context\", and then proposes the concept of ICDS as \"there are minimal linguistic units whose semantics are determined by their use and whose amount of information is determined by their specificity. On the other hand, the systematicity of language can be captured by compositional mechanisms while preserving the amount of information of the composite utterance\". Section Formal Definition and Properties formally defines the concepts involved in ICDS, where ($\\pi$,$\\delta$, $\\bigodot$) stand for \"embedding\", \"semantic similarity\", and \"composition function\" respectively. This section points out the embedding function properties (information measurability and angular isometry), composition function properties (composition neutral element, composition norm monotonicity, and sensitivity to stricture), and similarity function properties (angular distance simialrity monotonicity, orthogonal embedding similarity monotonicity, and equidistant embedding simialrity monotonicity). In section Function Analysis and Generalization, this research evaluates several current embedding vector with the proposed framework, while in section Experiment, the semantic representation abilities of several prevailing LLMs including BERT and GPT are evaluated. </p>"},{"location":"DL_Notes/NLP_Theory/Contrastive%20Learning%20and%20Interpretability/#contrastive-explanations-for-model-interpretability-2021","title":"Contrastive Explanations for Model Interpretability (2021)","text":"<p>This paper proposes a data augmentation method to generate counterexample on the bases of NLI datasets, and proves that by training on patterns \"why A rather than B\" with contrastive learning methods, the model performs better than the previous NLI baselines.</p>"},{"location":"DL_Notes/NLP_Theory/Contrastive%20Learning%20and%20Interpretability/#using-counterfactual-contrast-to-improve-compositional-generalization-for-multi-step-quantitative-reasoning-2023","title":"Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning (2023)","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/","title":"Embodied AI","text":"<p>WooooDyy/LLM-Agent-Paper-List: The paper list of the 86-page paper \"The Rise and Potential of Large Language Model Based Agents: A Survey\" by Zhiheng Xi et al. (github.com)</p>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#1-the-birth-of-an-agent-construction-of-llm-based-agents","title":"1. The Birth of An Agent: Construction of LLM-based Agents","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#11-brain-primarily-composed-of-an-llm","title":"1.1 Brain: Primarily Composed of An LLM","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#111-natural-language-interaction","title":"1.1.1 Natural Language Interaction","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#high-quality-generation","title":"High-quality generation","text":"<ul> <li>[2023/08]\u00a0A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity. Yejin Bang et al. arXiv.\u00a0[paper]</li> <li>[2023/06]\u00a0LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models. Yen-Ting Lin et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0Is ChatGPT a Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation. Tao Fang et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#deep-understanding","title":"Deep understanding","text":"<ul> <li>[2023/06]\u00a0Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models. Natalie Shapira et al. arXiv.\u00a0[paper]</li> <li>[2022/08]\u00a0Inferring Rewards from Language in Context. Jessy Lin et al. ACL.\u00a0[paper]</li> <li>[2021/10]\u00a0Theory of Mind Based Assistive Communication in Complex Human Robot Cooperation. Moritz C. Buehler et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#112-knowledge","title":"1.1.2 Knowledge","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#pretrain-model","title":"Pretrain model","text":"<ul> <li>[2023/04]\u00a0Learning Distributed Representations of Sentences from Unlabelled Data. Felix Hill(University of Cambridge) et al. arXiv.\u00a0[paper]</li> <li>[2020/02]\u00a0How Much Knowledge Can You Pack Into the Parameters of a Language Model? Adam Roberts(Google) et al. arXiv.\u00a0[paper]</li> <li>[2020/01]\u00a0Scaling Laws for Neural Language Models. Jared Kaplan(Johns Hopkins University) et al. arXiv.\u00a0[paper]</li> <li>[2017/12]\u00a0Commonsense Knowledge in Machine Intelligence. Niket Tandon(Allen Institute for Artificial Intelligence) et al. SIGMOD.\u00a0[paper]</li> <li>[2011/03]\u00a0Natural Language Processing (almost) from Scratch. Ronan Collobert(Princeton) et al. arXiv.\u00a0[paper]]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#linguistic-knowledge","title":"Linguistic knowledge","text":"<ul> <li>[2023/02]\u00a0A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity. Yejin Bang et al. arXiv.\u00a0[paper]</li> <li>[2021/06]\u00a0Probing Pre-trained Language Models for Semantic Attributes and their Values. Meriem Beloucif et al. EMNLP.\u00a0[paper]</li> <li>[2020/10]\u00a0Probing Pretrained Language Models for Lexical Semantics. Ivan Vuli\u0107 et al. arXiv.\u00a0[paper]</li> <li>[2019/04]\u00a0A Structural Probe for Finding Syntax in Word Representations. John Hewitt et al. ACL.\u00a0[paper]</li> <li>[2016/04]\u00a0Improved Automatic Keyword Extraction Given More Semantic Knowledge. H Leung. Systems for Advanced Applications.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#commonsense-knowledge","title":"Commonsense knowledge","text":"<ul> <li>[2022/10]\u00a0Language Models of Code are Few-Shot Commonsense Learners. Aman Madaan et al.arXiv.\u00a0[paper]</li> <li>[2021/04]\u00a0Relational World Knowledge Representation in Contextual Language Models: A Review. Tara Safavi et al. arXiv.\u00a0[paper]</li> <li>[2019/11]\u00a0How Can We Know What Language Models Know? Zhengbao Jiang et al.arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#actionable-knowledge","title":"Actionable knowledge","text":"<ul> <li>[2023/07]\u00a0Large language models in medicine. Arun James Thirunavukarasu et al. nature.\u00a0[paper]</li> <li>[2023/06]\u00a0DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation. Yuhang Lai et al. ICML.\u00a0[paper]</li> <li>[2022/10]\u00a0Language Models of Code are Few-Shot Commonsense Learners. Aman Madaan et al. arXiv.\u00a0[paper]</li> <li>[2022/02]\u00a0A Systematic Evaluation of Large Language Models of Code. Frank F. Xu et al.arXiv.\u00a0[paper]</li> <li>[2021/10]\u00a0Training Verifiers to Solve Math Word Problems. Karl Cobbe et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#potential-issues-of-knowledge","title":"Potential issues of knowledge","text":"<ul> <li>[2023/05]\u00a0Editing Large Language Models: Problems, Methods, and Opportunities. Yunzhi Yao et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models. Miaoran Li et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. Zhibin Gou et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0Tool Learning with Foundation Models. Yujia Qin et al. arXiv.\u00a0[paper]</li> <li>[2023/03]\u00a0SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models. Potsawee Manakul et al. arXiv.\u00a0[paper]</li> <li>[2022/06]\u00a0Memory-Based Model Editing at Scale. Eric Mitchell et al. arXiv.\u00a0[paper]</li> <li>[2022/04]\u00a0A Review on Language Models as Knowledge Bases. Badr AlKhamissi et al.arXiv.\u00a0[paper]</li> <li>[2021/04]\u00a0Editing Factual Knowledge in Language Models. Nicola De Cao et al.arXiv.\u00a0[paper]</li> <li>[2017/08]\u00a0Measuring Catastrophic Forgetting in Neural Networks. Ronald Kemker et al.arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#113-memory","title":"1.1.3 Memory","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#memory-capability","title":"Memory capability","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#raising-the-length-limit-of-transformers","title":"Raising the length limit of Transformers","text":"<ul> <li>[2023/05]\u00a0Randomized Positional Encodings Boost Length Generalization of Transformers. Anian Ruoss (DeepMind) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023-03]\u00a0CoLT5: Faster Long-Range Transformers with Conditional Computation. Joshua Ainslie (Google Research) et al. arXiv.\u00a0[paper]</li> <li>[2022/03]\u00a0Efficient Classification of Long Documents Using Transformers. Hyunji Hayley Park (Illinois University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2021/12]\u00a0LongT5: Efficient Text-To-Text Transformer for Long Sequences. Mandy Guo (Google Research) et al. arXiv.\u00a0[paper] [code]</li> <li>[2019/10]\u00a0BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. Michael Lewis(Facebook AI) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#summarizing-memory","title":"Summarizing memory","text":"<ul> <li>[2023/08]\u00a0ExpeL: LLM Agents Are Experiential Learners. Andrew Zhao (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/08]\u00a0ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate. Chi-Min Chan (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0MemoryBank: Enhancing Large Language Models with Long-Term Memory. Wanjun Zhong (Harbin Institute of Technology) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0Generative Agents: Interactive Simulacra of Human Behavior. Joon Sung Park (Stanford University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System. Xinnian Liang(Beihang University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0Reflexion: Language Agents with Verbal Reinforcement Learning. Noah Shinn (Northeastern University) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#compressing-memories-with-vectors-or-data-structures","title":"Compressing memories with vectors or data structures","text":"<ul> <li>[2023/07]\u00a0Communicative Agents for Software Development. Chen Qian (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/06]\u00a0ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory. Chenxu Hu(Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory. Xizhou Zhu (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0RET-LLM: Towards a General Read-Write Memory for Large Language Models. Ali Modarressi (LMU Munich) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#memory-retrieval","title":"Memory retrieval","text":"<ul> <li>[2023/08]\u00a0Memory Sandbox: Transparent and Interactive Memory Management for Conversational Agents. Ziheng Huang(University of California\u2014San Diego) et al. arXiv.\u00a0[paper]</li> <li>[2023/08]\u00a0AgentSims: An Open-Source Sandbox for Large Language Model Evaluation. Jiaju Lin (PTA Studio) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/06]\u00a0ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory. Chenxu Hu(Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0MemoryBank: Enhancing Large Language Models with Long-Term Memory. Wanjun Zhong (Harbin Institute of Technology) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0Generative Agents: Interactive Simulacra of Human Behavior. Joon Sung Park (Stanford) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#114-reasoning-planning","title":"1.1.4 Reasoning &amp; Planning","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#reasoning","title":"Reasoning","text":"<ul> <li> <p>[2023/05]\u00a0Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement. Zhiheng Xi (Fudan University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2023-03]\u00a0Large Language Models are Zero-Shot Reasoners. Takeshi Kojima (The University of Tokyo) et al. arXiv.\u00a0[paper][code]</p> </li> <li> <p>[2023/03]\u00a0Self-Refine: Iterative Refinement with Self-Feedback. Aman Madaan (Carnegie Mellon University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2022/05]\u00a0Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning. Antonia Creswell (DeepMind) et al. arXiv.\u00a0[paper]</p> </li> <li> <p>[2022/03]\u00a0Self-Consistency Improves Chain of Thought Reasoning in Language Models. Xuezhi Wang(Google Research) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2022/01]\u00a0Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. Jason Wei (Google Research,) et al. arXiv.\u00a0[paper]</p> </li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#planning","title":"Planning","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#plan-formulation","title":"Plan formulation","text":"<ul> <li>[2023/05]\u00a0Tree of Thoughts: Deliberate Problem Solving with Large Language Models. Shunyu Yao (Princeton University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. Yue Wu(Carnegie Mellon University) et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Reasoning with Language Model is Planning with World Model. Shibo Hao (UC San Diego) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks. Bill Yuchen Lin (Allen Institute for Artificial Intelligence) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0LLM+P: Empowering Large Language Models with Optimal Planning Proficiency. Bo Liu (University of Texas at Austin) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. Yongliang Shen (Microsoft Research Asia) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/02]\u00a0Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. ZiHao Wang (Peking University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/05]\u00a0Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. Denny Zhou (Google Research) et al. arXiv.\u00a0[paper]</li> <li>[2022/05]\u00a0MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. Ehud Karpas (AI21 Labs) et al. arXiv.\u00a0[paper]</li> <li>[2022/04]\u00a0Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. Michael Ahn (Robotics at Google) et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#plan-reflection","title":"Plan reflection","text":"<ul> <li>[2023/08]\u00a0SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. Ning Miao (University of Oxford) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models. Zhipeng Chen (Renmin University of China) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Voyager: An Open-Ended Embodied Agent with Large Language Models. Guanzhi Wang (NVIDA) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0Chat with the Environment: Interactive Multimodal Perception Using Large Language Models. Xufeng Zhao (University Hamburg) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/12]\u00a0LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. Chan Hee Song (The Ohio State University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/10]\u00a0ReAct: Synergizing Reasoning and Acting in Language Models. Shunyu Yao ( Princeton University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/07]\u00a0Inner Monologue: Embodied Reasoning through Planning with Language Models. Wenlong Huang (Robotics at Google) et al. arXiv.\u00a0[paper] [code]</li> <li>[2021/10]\u00a0AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts. Tongshuang Wu (University of Washington) et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#115-transferability-and-generalization","title":"1.1.5 Transferability and Generalization","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#unseen-task-generalization","title":"Unseen task generalization","text":"<ul> <li>[2023/05]\u00a0Training language models to follow instructions with human feedback. Long Ouyang et al. NeurIPS.\u00a0[paper]</li> <li>[2023/01]\u00a0Multitask Prompted Training Enables Zero-Shot Task Generalization. Victor Sanh et al. ICLR.\u00a0[paper]</li> <li>[2022/10]\u00a0Scaling Instruction-Finetuned Language Models. Hyung Won Chung et al. arXiv.\u00a0[paper]</li> <li>[2022/08]\u00a0Finetuned Language Models are Zero-Shot Learners. Jason Wei et al. ICLR.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#in-context-learning","title":"In-context learning","text":"<ul> <li>[2023/08]\u00a0Images Speak in Images: A Generalist Painter for In-Context Visual Learning. Xinlong Wang et al. IEEE.\u00a0[paper]</li> <li>[2023/08]\u00a0Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers. Chengyi Wang et al. arXiv.\u00a0[paper]</li> <li>[2023/07]\u00a0A Survey for In-context Learning. Qingxiu Dong et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Language Models are Few-Shot Learners. Tom B. Brown (OpenAI) et al. NeurIPS.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#continual-learning","title":"Continual learning","text":"<ul> <li>[2023/07]\u00a0Progressive Prompts: Continual Learning for Language Models. Razdaibiedina et al. arXiv.\u00a0[paper]</li> <li>[2023/07]\u00a0Voyager: An Open-Ended Embodied Agent with Large Language Models. Guanzhi Wang et al. arXiv.\u00a0[paper]</li> <li>[2023/01]\u00a0A Comprehensive Survey of Continual Learning: Theory, Method and Application. Liyuan Wang et al. arXiv.\u00a0[paper]</li> <li>[2022/11]\u00a0Continual Learning of Natural Language Processing Tasks: A Survey. Zixuan Ke et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#12-perception-multimodal-inputs-for-llm-based-agents","title":"1.2 Perception: Multimodal Inputs for LLM-based Agents","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#121-visual","title":"1.2.1 Visual","text":"<ul> <li>[2023/05]\u00a0Language Is Not All You Need: Aligning Perception with Language Models. Shaohan Huang et al. arXiv.\u00a0[paper]]</li> <li>[2023/05]\u00a0InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning. Wenliang Dai et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0MultiModal-GPT: A Vision and Language Model for Dialogue with Humans. Tao Gong et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0PandaGPT: One Model To Instruction-Follow Them All. Yixuan Su et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0Visual Instruction Tuning. Haotian Liu et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models. Deyao Zhu. arXiv.\u00a0[paper]</li> <li>[2023/01]\u00a0BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. Junnan Li et al. arXiv.\u00a0[paper]</li> <li>[2022/04]\u00a0Flamingo: a Visual Language Model for Few-Shot Learning. Jean-Baptiste Alayrac et al. arXiv.\u00a0[paper]</li> <li>[2021/10]\u00a0MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer. Sachin Mehta et al.arXiv.\u00a0[paper]</li> <li>[2021/05]\u00a0MLP-Mixer: An all-MLP Architecture for Vision. Ilya Tolstikhin et al.arXiv.\u00a0[paper]</li> <li>[2020/10]\u00a0An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Alexey Dosovitskiy et al. arXiv.\u00a0[paper]</li> <li>[2017/11]\u00a0Neural Discrete Representation Learning. Aaron van den Oord et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#122-audio","title":"1.2.2 Audio","text":"<ul> <li>[2023/06]\u00a0Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding. Hang Zhang et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. Feilong Chen et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language. Zhaoyang Liu et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head. Rongjie Huang et al. arXiv.\u00a0[paper]</li> <li>[2023/03]\u00a0HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. Yongliang Shen et al. arXiv.\u00a0[paper]</li> <li>[2021/06]\u00a0HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units. Wei-Ning Hsu et al. arXiv.\u00a0[paper]</li> <li>[2021/04]\u00a0AST: Audio Spectrogram Transformer. Yuan Gong et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#13-action-expand-action-space-of-llm-based-agents","title":"1.3 Action: Expand Action Space of LLM-based Agents","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#131-tool-using","title":"1.3.1 Tool Using","text":"<ul> <li>[2023/07]\u00a0ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. Yujia Qin et al. arXiv.\u00a0[paper] [code] [dataset]</li> <li>[2023/05]\u00a0Large Language Models as Tool Makers. Tianle Cai et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0CREATOR: Disentangling Abstract and Concrete Reasonings of Large Language Models through Tool Creation. Cheng Qian et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0Tool Learning with Foundation Models. Yujia Qin et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0ChemCrow: Augmenting large-language models with chemistry tools. Andres M Bran (Laboratory of Artificial Chemical Intelligence, ISIC, EPFL) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information. Qiao Jin, Yifan Yang, Qingyu Chen, Zhiyong Lu. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0OpenAGI: When LLM Meets Domain Experts. Yingqiang Ge et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. Yongliang Shen et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models. Chenfei Wu et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/02]\u00a0Augmented Language Models: a Survey. Gr\u00e9goire Mialon et al. arXiv.\u00a0[paper]</li> <li>[2023/02]\u00a0Toolformer: Language Models Can Teach Themselves to Use Tools. Timo Schick et al. arXiv.\u00a0[paper]</li> <li>[2022/05]\u00a0TALM: Tool Augmented Language Models. Aaron Parisi et al. arXiv.\u00a0[paper]</li> <li>[2022/05]\u00a0MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. Ehud Karpas et al. arXiv.\u00a0[paper]</li> <li>[2022/04]\u00a0Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. Michael Ahn et al. arXiv.\u00a0[paper]</li> <li>[2021/12]\u00a0WebGPT: Browser-assisted question-answering with human feedback. Reiichiro Nakano et al. arXiv.\u00a0[paper]</li> <li>[2021/07]\u00a0Evaluating Large Language Models Trained on Code. Mark Chen et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#132-embodied-action","title":"1.3.2 Embodied Action","text":"<ul> <li>[2023/07]\u00a0Interactive language: Talking to robots in real time. Corey Lynch et al. IEEE(RAL)\u00a0[paper]</li> <li>[2023/05]\u00a0Voyager: An open-ended embodied agent with large language models. Guanzhi Wang et al. Arxiv.\u00a0[paper]</li> <li>[2023/05]\u00a0AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments. Sudipta Paul et al. NeurIPS.\u00a0[paper]</li> <li>[2023/05]\u00a0EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought. Yao Mu et al. Arxiv\u00a0[paper] [code]</li> <li>[2023/05]\u00a0NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. Gengze Zhou et al. Arxiv\u00a0[paper]</li> <li>[2023/05]\u00a0AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation. Chuhao Jin et al. Arxiv\u00a0[paper]</li> <li>[2023/03]\u00a0PaLM-E: An Embodied Multimodal Language Model. Danny Driess et al. Arxiv.\u00a0[paper]</li> <li>[2023/03]\u00a0Reflexion: Language Agents with Verbal Reinforcement Learning. Noah Shinn et al. Arxiv\u00a0[paper] [code]</li> <li>[2023/02]\u00a0Collaborating with language models for embodied reasoning. Ishita Dasgupta et al. Arxiv.\u00a0[paper]</li> <li>[2023/02]\u00a0Code as Policies: Language Model Programs for Embodied Control. Jacky Liang et al. IEEE(ICRA).\u00a0[paper]</li> <li>[2022/10]\u00a0ReAct: Synergizing Reasoning and Acting in Language Models. Shunyu Yao et al. Arxiv\u00a0[paper] [code]</li> <li>[2022/10]\u00a0Instruction-Following Agents with Multimodal Transformer. Hao Liu et al. CVPR\u00a0[paper] [code]</li> <li>[2022/07]\u00a0Inner Monologue: Embodied Reasoning through Planning with Language Models. Wenlong Huang et al. Arxiv.\u00a0[paper]</li> <li>[2022/07]\u00a0LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action. Dhruv Shahet al. CoRL\u00a0[paper] [code]</li> <li>[2022/04]\u00a0Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. Michael Ahn et al. Arxiv.\u00a0[paper]</li> <li>[2022/01]\u00a0A Survey of Embodied AI: From Simulators to Research Tasks. Jiafei Duan et al. IEEE(TETCI).\u00a0[paper]</li> <li>[2022/01]\u00a0Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents. Wenlong Huang et al. Arxiv.\u00a0[paper] [code]</li> <li>[2020/04]\u00a0Experience Grounds Language. Yonatan Bisk et al. EMNLP\u00a0[paper]</li> <li>[2019/03]\u00a0Review of Deep Reinforcement Learning for Robot Manipulation. Hai Nguyen et al. IEEE(IRC).\u00a0[paper]</li> <li>[2005/01]\u00a0The Development of Embodied Cognition: Six Lessons from Babies. Linda Smith et al. Artificial Life.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#2-agents-in-practice-applications-of-llm-based-agents","title":"2. Agents in Practice: Applications of LLM-based Agents","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#21-general-ability-of-single-agent","title":"2.1 General Ability of Single Agent","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#211-task-orietned-deployment","title":"2.1.1 Task-orietned Deployment","text":"<p>In web scenarios</p> <ul> <li>[2023/07]\u00a0WebArena: A Realistic Web Environment for Building Autonomous Agents. Shuyan Zhou (CMU) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/07]\u00a0A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis. Izzeddin Gur (DeepMind) et al. arXiv.\u00a0[paper]</li> <li>[2023/06]\u00a0SYNAPSE: Leveraging Few-Shot Exemplars for Human-Level Computer Control. Longtao Zheng (Nanyang Technological University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/06]\u00a0Mind2Web: Towards a Generalist Agent for the Web. Xiang Deng (The Ohio State University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Multimodal Web Navigation with Instruction-Finetuned Foundation Models. Hiroki Furuta (The University of Tokyo) et al. arXiv.\u00a0[paper]</li> <li>[2023/03]\u00a0Language Models can Solve Computer Tasks. Geunwoo Kim (University of California) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/07]\u00a0WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents. Shunyu Yao (Princeton University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2021/12]\u00a0WebGPT: Browser-assisted question-answering with human feedback. Reiichiro Nakano (OpenAI) et al. arXiv.\u00a0[paper]</li> </ul> <p>In life scenarios</p> <ul> <li>[2023/08]\u00a0InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent. Po-Lin Chen et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. Yue Wu (CMU) et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Augmenting Autotelic Agents with Large Language Models. C\u00e9dric Colas (MIT) et al. arXiv.\u00a0[paper]</li> <li>[2023/03]\u00a0Planning with Large Language Models via Corrective Re-prompting. Shreyas Sundara Raman (Brown University) et al. arXiv.\u00a0[paper]</li> <li>[2022/10]\u00a0Generating Executable Action Plans with Environmentally-Aware Language Models. Maitrey Gramopadhye (University of North Carolina at Chapel Hill) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/01]\u00a0Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents. Wenlong Huang (UC Berkeley) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#212-innovation-oriented-deployment","title":"2.1.2 Innovation-oriented Deployment","text":"<ul> <li>[2023/08]\u00a0The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models. Haonan Li (UC Riverside) et al. arXiv.\u00a0[paper]</li> <li>[2023/08]\u00a0ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks. Yeonghun Kang (Korea Advanced Institute of Science and Technology) et al. arXiv.\u00a0[paper]</li> <li>[2023/07]\u00a0Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics. Melanie Swan (University College London) et al. arXiv.\u00a0[paper]</li> <li>[2023/06]\u00a0Towards Autonomous Testing Agents via Conversational Large Language Models. Robert Feldt (Chalmers University of Technology) et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0Emergent autonomous scientific research capabilities of large language models. Daniil A. Boiko (CMU) et al. arXiv.\u00a0[paper]</li> <li>[2023/04]\u00a0ChemCrow: Augmenting large-language models with chemistry tools. Andres M Bran (Laboratory of Artificial Chemical Intelligence, ISIC, EPFL) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/03]\u00a0ScienceWorld: Is your Agent Smarter than a 5th Grader? Ruoyao Wang (University of Arizona) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#213-lifecycle-oriented-deployment","title":"2.1.3 Lifecycle-oriented Deployment","text":"<ul> <li>[2023/05]\u00a0Voyager: An Open-Ended Embodied Agent with Large Language Models. Guanzhi Wang (NVIDA) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory. Xizhou Zhu (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks. Haoqi Yuan (PKU) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/02]\u00a0Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. Zihao Wang (PKU) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/01]\u00a0Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling. Kolby Nottingham (University of California Irvine, Irvine) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#22-coordinating-potential-of-multiple-agents","title":"2.2 Coordinating Potential of Multiple Agents","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#221-cooperative-interaction-for-complementarity","title":"2.2.1 Cooperative Interaction for Complementarity","text":"<p>Disordered cooperation</p> <ul> <li>[2023/07]\u00a0Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. Zhenhailong Wang (University of Illinois Urbana-Champaign) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/07]\u00a0RoCo: Dialectic Multi-Robot Collaboration with Large Language Models. Zhao Mandi, Shreeya Jain, Shuran Song (Columbia University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0ChatLLM Network: More brains, More intelligence. Rui Hao (Beijing University of Posts and Telecommunications) et al. arXiv.\u00a0[paper]</li> <li>[2023/01]\u00a0Blind Judgement: Agent-Based Supreme Court Modelling With GPT. Sil Hamilton (McGill University). arXiv.\u00a0[paper]</li> </ul> <p>Ordered cooperation</p> <ul> <li>[2023/08]\u00a0CGMI: Configurable General Multi-Agent Interaction Framework. Shi Jinxin (East China Normal University) et al. arXiv.\u00a0[paper]</li> <li>[2023/08]\u00a0ProAgent: Building Proactive Cooperative AI with Large Language Models. Ceyao Zhang (The Chinese University of Hong Kong, Shenzhen) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/08]\u00a0AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents. Weize Chen (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/08]\u00a0AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework. Qingyun Wu (Pennsylvania State University ) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/08]\u00a0MetaGPT: Meta Programming for Multi-Agent Collaborative Framework. Sirui Hong (DeepWisdom) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/07]\u00a0Communicative Agents for Software Development. Chen Qian (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/06]\u00a0Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents. Yashar Talebira (University of Alberta) et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Training Socially Aligned Language Models in Simulated Human Society. Ruibo Liu (Dartmouth College) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks. Bill Yuchen Lin (Allen Institute for Artificial Intelligence) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0ChatGPT as your Personal Data Scientist. Md Mahadi Hassan (Auburn University) et al. arXiv.\u00a0[paper]</li> <li>[2023/03]\u00a0CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society. Guohao Li (King Abdullah University of Science and Technology) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents. Varun Nair (Curai Health) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#222-adversarial-interaction-for-advancement","title":"2.2.2 Adversarial Interaction for Advancement","text":"<ul> <li>[2023/08]\u00a0ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate. Chi-Min Chan (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Improving Factuality and Reasoning in Language Models through Multiagent Debate. Yilun Du (MIT CSAIL) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback. Yao Fu (University of Edinburgh) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Examining the Inter-Consistency of Large Language Models: An In-depth Analysis via Debate. Kai Xiong (Harbin Institute of Technology) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate. Tian Liang (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#23-interactive-engagement-between-human-and-agent","title":"2.3 Interactive Engagement between Human and Agent","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#231-instructor-executor-paradigm","title":"2.3.1 Instructor-Executor Paradigm","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#education","title":"Education","text":"<ul> <li>[2023/07]\u00a0Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics. Melanie Swan (UCL) et al. arXiv.\u00a0[paper]<ul> <li>Communicate with humans to help them understand and use mathematics.</li> </ul> </li> <li>[2023/03]\u00a0Hey Dona! Can you help me with student course registration? Vishesh Kalvakurthi (MSU) et al. arXiv.\u00a0[paper]<ul> <li>This is a developed application called Dona that offers virtual voice assistance in student course registration, where humans provide instructions.</li> </ul> </li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#health","title":"Health","text":"<ul> <li>[2023/08]\u00a0Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue. Songhua Yang (ZZU) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0HuatuoGPT, towards Taming Language Model to Be a Doctor. Hongbo Zhang (CUHK-SZ) et al. arXiv.\u00a0[paper] [code] [demo]</li> <li>[2023/05]\u00a0Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback. Shang-Ling Hsu (Gatech) et al. arXiv.\u00a0[paper]</li> <li>[2020/10]\u00a0A Virtual Conversational Agent for Teens with Autism Spectrum Disorder: Experimental Results and Design Lessons. Mohammad Rafayet Ali (U of R) et al. IVA '20.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#other-application","title":"Other Application","text":"<ul> <li>[2023/08]\u00a0RecMind: Large Language Model Powered Agent For Recommendation. Yancheng Wang (ASU, Amazon) et al. arXiv.\u00a0[paper]</li> <li>[2023/08]\u00a0Multi-Turn Dialogue Agent as Sales' Assistant in Telemarketing. Wanting Gao (JNU) et al. IEEE.\u00a0[paper]</li> <li>[2023/07]\u00a0PEER: A Collaborative Language Model. Timo Schick (Meta AI) et al. arXiv.\u00a0[paper]</li> <li>[2023/07]\u00a0DIALGEN: Collaborative Human-LM Generated Dialogues for Improved Understanding of Human-Human Conversations. Bo-Ru Lu (UW) et al. arXiv.\u00a0[paper]</li> <li>[2023/06]\u00a0AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn. Difei Gao (NUS) et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#232-equal-partnership-paradigm","title":"2.3.2 Equal Partnership Paradigm","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#empathetic-communicator","title":"Empathetic Communicator","text":"<ul> <li>[2023/08]\u00a0SAPIEN: Affective Virtual Agents Powered by Large Language Models. Masum Hasan et al. arXiv.\u00a0[paper] [code] [project page] [dataset]</li> <li>[2023/05]\u00a0Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback. Shang-Ling Hsu (Gatech) et al. arXiv.\u00a0[paper]</li> <li>[2022/07]\u00a0Artificial empathy in marketing interactions: Bridging the human-AI gap in affective and social customer experience. Yuping Liu\u2011Thompkins et al.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#human-level-participant","title":"Human-Level Participant","text":"<ul> <li>[2023/08]\u00a0Quantifying the Impact of Large Language Models on Collective Opinion Dynamics. Chao Li et al. CoRR.\u00a0[paper]</li> <li>[2023/06]\u00a0Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning. Anton Bakhtin et al. ICLR.\u00a0[paper]</li> <li>[2023/06]\u00a0Decision-Oriented Dialogue for Human-AI Collaboration. Jessy Lin et al. CoRR.\u00a0[paper]</li> <li>[2022/11]\u00a0Human-level play in the game of Diplomacy by combining language models with strategic reasoning. FAIR et al. Science.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#3-agent-society-from-individuality-to-sociality","title":"3. Agent Society: From Individuality to Sociality","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#31-behavior-and-personality-of-llm-based-agents","title":"3.1 Behavior and Personality of LLM-based Agents","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#311-social-behavior","title":"3.1.1 Social Behavior","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#individual-behaviors","title":"Individual behaviors","text":"<ul> <li>[2023/05]\u00a0Voyager: An Open-Ended Embodied Agent with Large Language Models. Guanzhi Wang (NVIDA) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0LLM+P: Empowering Large Language Models with Optimal Planning Proficiency. Bo Liu (University of Texas) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0Reflexion: Language Agents with Verbal Reinforcement Learning. Noah Shinn (Northeastern University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0PaLM-E: An Embodied Multimodal Language Model. Danny Driess (Google) et al. ICML.\u00a0[paper] [project page]</li> <li>[2023/03]\u00a0ReAct: Synergizing Reasoning and Acting in Language Models. Shunyu Yao (Princeton University) et al. ICLR.\u00a0[paper] [project page]</li> <li>[2022/01]\u00a0Chain-of-thought prompting elicits reasoning in large language models. Jason Wei (Google) et al. NeurIPS.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#group-behaviors","title":"Group behaviors","text":"<ul> <li> <p>[2023/09]\u00a0Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf. Yuzhuang Xu (Tsinghua University) et al. arXiv.\u00a0[paper]</p> </li> <li> <p>[2023/08]\u00a0AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents. Weize Chen (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2023/08]\u00a0AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework. Qingyun Wu (Pennsylvania State University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2023/08]\u00a0ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate. Chi-Min Chan (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2023/07]\u00a0Communicative Agents for Software Development. Chen Qian (Tsinghua University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2023/07]\u00a0RoCo: Dialectic Multi-Robot Collaboration with Large Language Models. Zhao Mandi, Shreeya Jain, Shuran Song (Columbia University) et al. arXiv.\u00a0[paper] [code]</p> </li> <li> <p>[2023/08]\u00a0ProAgent: Building Proactive Cooperative AI with Large Language Models. Ceyao Zhang (The Chinese University of Hong Kong, Shenzhen) et al. arXiv.\u00a0[paper] [code]</p> </li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#312-personality","title":"3.1.2 Personality","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#cognition","title":"Cognition","text":"<ul> <li>[2023/03]\u00a0Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. Thilo Hagendorff (University of Stuttgart) et al. arXiv.\u00a0[paper]</li> <li>[2023/03]\u00a0Mind meets machine: Unravelling GPT-4's cognitive psychology. Sifatkaur Dhingra (Nowrosjee Wadia College) et al. arXiv.\u00a0[paper]</li> <li>[2022/07]\u00a0Language models show human-like content effects on reasoning. Ishita Dasgupta (DeepMind) et al. arXiv.\u00a0[paper]</li> <li>[2022/06]\u00a0Using cognitive psychology to understand GPT-3. Marcel Binz et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#emotion","title":"Emotion","text":"<ul> <li>[2023/07]\u00a0Emotional Intelligence of Large Language Models. Xuena Wang (Tsinghua University) et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0ChatGPT outperforms humans in emotional awareness evaluations. Zohar Elyoseph et al. Frontiers in Psychology.\u00a0[paper]</li> <li>[2023/02]\u00a0Empathetic AI for Empowering Resilience in Games. Reza Habibi (University of California) et al. arXiv.\u00a0[paper]</li> <li>[2022/12]\u00a0Computer says \u201cNo\u201d: The Case Against Empathetic Conversational AI. Alba Curry (University of Leeds) et al. ACL.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#character","title":"Character","text":"<ul> <li>[2023/07]\u00a0Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models. Keyu Pan (ByteDance) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/07]\u00a0Personality Traits in Large Language Models. Mustafa Safdari (DeepMind) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/12]\u00a0Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. Xingxuan Li (Alibaba) et al. arXiv.\u00a0[paper]</li> <li>[2022/12]\u00a0Identifying and Manipulating the Personality Traits of Language Models. Graham Caron et al. arXiv.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#32-environment-for-agent-society","title":"3.2 Environment for Agent Society","text":""},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#321-text-based-environment","title":"3.2.1 Text-based Environment","text":"<ul> <li>[2023/08]\u00a0Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. Aidan O\u2019Gara (University of Southern California) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society. Guohao Li (King Abdullah University of Science and Technology) et al. arXiv.\u00a0[paper] [code]</li> <li>[2020/12]\u00a0Playing Text-Based Games with Common Sense. Sahith Dambekodi (Georgia Institute of Technology) et al. arXiv.\u00a0[paper]</li> <li>[2019/09]\u00a0Interactive Fiction Games: A Colossal Adventure. Matthew Hausknecht (Microsoft Research) et al. AAAI.\u00a0[paper] [code]</li> <li>[2019/03]\u00a0Learning to Speak and Act in a Fantasy Text Adventure Game. Jack Urbanek (Facebook) et al. ACL.\u00a0[paper] [code]</li> <li>[2018/06]\u00a0TextWorld: A Learning Environment for Text-based Games. Marc-Alexandre C\u00f4t\u00e9 (Microsoft Research) et al. IJCAI.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#322-virtual-sandbox-environment","title":"3.2.2 Virtual Sandbox Environment","text":"<ul> <li>[2023/08]\u00a0AgentSims: An Open-Source Sandbox for Large Language Model Evaluation. Jiaju Lin (PTA Studio) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Training Socially Aligned Language Models in Simulated Human Society. Ruibo Liu (Dartmouth College) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/05]\u00a0Voyager: An Open-Ended Embodied Agent with Large Language Models. Guanzhi Wang (NVIDA) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0Generative Agents: Interactive Simulacra of Human Behavior. Joon Sung Park (Stanford University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/03]\u00a0Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks. Haoqi Yuan (PKU) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/06]\u00a0MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge. Linxi Fan (NVIDIA) et al. NeurIPS.\u00a0[paper] [project page]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#323-physical-environment","title":"3.2.3 Physical Environment","text":"<ul> <li>[2023/09]\u00a0RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking. Homanga Bharadhwaj (Carnegie Mellon University) et al. arXiv.\u00a0[paper] [project page]</li> <li>[2023/05]\u00a0AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments. Sudipta Paul et al. NeurIPS.\u00a0[paper]</li> <li>[2023/03]\u00a0PaLM-E: An Embodied Multimodal Language Model. Danny Driess (Google) et al. ICML.\u00a0[paper] [project page]</li> <li>[2022/10]\u00a0Interactive Language: Talking to Robots in Real Time. Corey Lynch (Google) et al. arXiv.\u00a0[paper] [code]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Embodied%20AI/#33-society-simulation-with-llm-based-agents","title":"3.3 Society Simulation with LLM-based Agents","text":"<ul> <li>[2023/08]\u00a0AgentSims: An Open-Source Sandbox for Large Language Model Evaluation. Jiaju Lin (PTA Studio) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/07]\u00a0S$^3$ : Social-network Simulation System with Large Language Model-Empowered Agents. Chen Gao (Tsinghua University) et al. arXiv.\u00a0[paper]</li> <li>[2023/07]\u00a0Epidemic Modeling with Generative Agents. Ross Williams (Virginia Tech) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/06]\u00a0RecAgent: A Novel Simulation Paradigm for Recommender Systems. Lei Wang (Renmin University of China) et al. arXiv.\u00a0[paper]</li> <li>[2023/05]\u00a0Training Socially Aligned Language Models in Simulated Human Society. Ruibo Liu (Dartmouth College) et al. arXiv.\u00a0[paper] [code]</li> <li>[2023/04]\u00a0Generative Agents: Interactive Simulacra of Human Behavior. Joon Sung Park (Stanford University) et al. arXiv.\u00a0[paper] [code]</li> <li>[2022/08]\u00a0Social Simulacra: Creating Populated Prototypes for Social Computing Systems. Joon Sung Park (Stanford University) et al. UIST.\u00a0[paper]</li> </ul>"},{"location":"DL_Notes/NLP_Theory/Explainable%20NLP/","title":"Explainable NLP","text":""},{"location":"DL_Notes/NLP_Theory/Explainable%20NLP/#survey","title":"Survey","text":""},{"location":"DL_Notes/NLP_Theory/Explainable%20NLP/#a-survey-of-the-state-of-explainable-ai-for-natural-language-processing","title":"A Survey of the State  of Explainable AI for Natural Language Processing","text":"<p>This survey thoroughly explains the state of explainable NLP. The Introduction discusses two distinguishing criteria for explanability models (1) whether the explanation is for each prediction individually or the model\u2019s prediction process as a whole, and (2) determining whether generating the explanation requires post-processing or not. In Categorization of Explanations, this paper categorizes the explanation models into local (provides information or justification for the model's prediction on a specific input) vs. global (provides similar justification by revealing how the model's predictive process works, independently of any particular input), and self-explaining (also directly interpretable, generates the explanation at the same time as the prediction, e.g. decision trees, rule-based models, and feature saliency models like attention models) vs. post-hoc (an additional operation is performed after the predictions are made). This section also states that the different categories of models can overlap. In section Aspects of Explanations, this paper introduces three types of explanation techniques: (1) explainability techniques (feature importance, surrogate model, example-driven, provenance-based, declarative induction), (2) operations to enable explainability (first-derivation saliency, layer-wise relevance propagation, and input perturbations, attention, LSTM gating signals, explainability-aware architecture design) and (3) visualization techniques (saliency, raw declarative representations, natural language explanation). The section Evaluation introduces several evaluating metrices. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/","title":"Math Word Problem Solving Read Paper","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#an-introduction-to-math-word-problems","title":"An Introduction to Math Word Problems","text":"<p>The math word problem (MWP) aims to solve simple primary school math problems (in plain-text format) with deep learning methods. The problems usually consists of numbers no larger than 100 and only 5 operators (+, -, *, / and =). This blog is structured as follows. The Dataset part will introduce two main types, one indicating the locations of variables, and the other simply embedding the math formula within the natural language texts. The Methods parts will introduce several prevailing methods in solving this task, including both the models and workflows that improves the accuracy of models.</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#surveys","title":"Surveys","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#the-gap-of-semantic-parsing-a-survey-on-automatic-math-word-problem-solvers-2019","title":"The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem Solvers (2019)","text":"<p>This survey provides a comprehensive introduction to the MWP datasets and methods prior to 2019. This survey defines three stages of MWP solving, the Rule-based matching stage (1960-2010), Semantic parsing, feature engineering and statistical learning stage (2011-2017), and Deep learning and reinforcement learning stage (2017-2019).</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#towards-tractable-mathematical-reasoning-challenges-strategies-and-opportunities-for-solving-math-word-problems-2021","title":"Towards Tractable Mathematical Reasoning: Challenges, Strategies, and Opportunities for Solving Math Word Problems (2021)","text":"<p>This survey introduces the contemporary MWP datasets til 2021, and methods including rule-based, and neural network encoder-decoder structures. Specifically, this paper concludes three strategies for math word solving, (i) direct answer generation, (ii) expression tree generation for inferring answers, and (iii) template retrieval for answer computation. Considering the type of problem solving method, this paper concludes two classes. The first class is non-neural approaches (rule-base or pattern matching approaches, semantic parsing, and statistical machine learning approaches), within which a particular strategy of applying domain knowledge in classifying the problems (e.g. into change, part-whole and compare classes). The second class is neural approaches, including intuitions of (i) predicting the answer directly (ii) generating a set of equations or mathematical expressions and inferring answers from the by executing them (iii) retrieving the templates from a pool of templates derived from training data and augmenting numerical quantities to compute the answer. These neural approaches generally follow encoder-decoder architectures, which fall in four types (i) seq-to-seq (ii) Transformer-to-tree (iii) seq-to-tree (iv) graph-to-tree.   Among the four methods, the tree-structured decoder attend both parents and siblings to generate the next token, while the bottom-up representation of sub-tree of a sibling could further help to derive better outcomes. The graph-based encoder aims to learn different types of relationships among the constituents of MWPs. This section also mentions that \"Data augmentation is a popular preprocessing technique to increase the size of training data\" (reverse operation-based augmentation techniques, different traversal orders of expression trees, and weak supervision).  In section Math Reasoning in Neural Approaches, this paper mentions several further topics under math reasoning, interpretability and explainability, infusing explicit and definitive knowledge, and reinforcement learning. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#datasets","title":"Datasets","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#mawps-a-math-word-problem-repository-2016","title":"MAWPS: A Math Word Problem Repository (2016)","text":"<p>sroy9/mawps: Code for MAWPS: A Math Word Problem Repository (github.com) The data format is as follows.</p> <pre><code>[\n  {\n    \"iIndex\": 1,\n    \"sQuestion\": \"Joan found 70.0 seashells on the beach. She gave Sam some of her seashells . She has 27.0 seashells . How many seashells did she give to Sam ?\",\n    \"lEquations\": [\"X=(70.0-27.0)\"],\n    \"lSolutions\": [43.0]\n  },\n]\n</code></pre>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#math23k-deep-neural-solver-for-math-word-problems-2017","title":"Math23k: Deep Neural Solver for Math Word Problems (2017)","text":"<p>Deep Neural Solver for Math Word Problems (aclanthology.org) This dataset is in Chinese.</p> <pre><code>Problem: Dan have 2 pens, Jessica have 4 pens. How many pens do they have in total ? \nEquation: x = 4+2 \nSolution: 6\n</code></pre>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#mathqa-2019","title":"MathQA (2019)","text":"<p>MathQA-Dataset (math-qa.github.io) This paper proposes a math dataset which enhances the AQuA dataset by providing fully-specified operational programs. This dataset has a diverse range of operators. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#math-2021","title":"MATH (2021)","text":"<p>arxiv.org/pdf/2103.03874.pdf MATH is a LaTeX format dataset, with its answer highlighted in a square block. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#svmap","title":"SVMAP","text":"<p>arkilpatel/SVAMP: NAACL 2021: Are NLP Models really able to Solve Simple Math Word Problems? (github.com) This dataset does not distinguish the data with the texts. An example data is as follows. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#gsm8k-grade-school-math-2021","title":"GSM8k: grade school math (2021)","text":"<p>Collected by OpenAI, this dataset consists of math problems in natural language descriptions, with the math formulas highlighted with special notes.The numbers are not explicitly highlighted with special symbols. Several examples of the data format are as follows. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#draw","title":"DRAW","text":"<p>Providing 1000 grounded word problems.</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#algebra","title":"Algebra","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#asdiv","title":"AsDiv","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#multiarith","title":"MultiArith","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#singleeq","title":"SingleEq","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#methods","title":"Methods","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#models","title":"Models","text":"<p>Prior to 2017, the models for solving MWP are mainly concerning with neural networks. After Transformer has been released in 2017, attention-based models have been thriving. The novel models based on Transformer are mainly modifying the encoder and decoder structures, among which there are graph-encoder and tree-decoders.</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#graph-to-tree-learning-for-solving-math-word-problems-2020","title":"Graph-to-Tree Learning for Solving Math Word Problems (2020)","text":"<p>This paper proposes a attention-based model Graph2Tree, consisting of graph-based encoder and a tree-based decoder. The math word problems are constructed into Quantity Comparison Graph.  </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#math-word-problem-solving-with-explicit-numerical-values-2021","title":"Math Word Problem Solving with Explicit Numerical Values (2021)","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#math23k","title":"Math23K","text":"<p>A novel approach called NumS2T is proposed to solve MWP. NumS2T is constructed with (a) an attention-based seq2seq model to generate its math expressions, (b) a numerical value encoder to obtain the number-aware problem state which are then concatenated with the problem hidden state in (a) to obtain number-aware problem representation, and (c) a numerical properties prediction mechanism for comparing the paired numerical values, determining the category of each numeral and measuring whether they should appear in the target expression.! </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#learning-to-reason-deductively-math-word-problem-solving-as-complex-relation-extraction-2022","title":"Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction (2022)","text":"<p>This paper proposes a novel approach</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#workflows","title":"Workflows","text":"<p>Most of the recent works follow the method of knowledge distilling, which means to generate high quality data with LLMs and then train a small model with the generated (and sometimes then augmented) data. The workflow of such tasks mainly assembles that of the following paper.</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#large-language-models-are-reasoning-teachers","title":"Large Language Models Are Reasoning Teachers","text":"<p>This paper proposes a knowledge distilling method in solving math reasoning problems. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#solving-math-word-problems-via-cooperative-reasoning-induced-language-models-acl-2023","title":"Solving Math Word Problems via Cooperative Reasoning induced Language Models (ACL 2023)","text":"<p>This paper develops a cooperative reasoning-induced PLM for solving MWPs called Cooperative Reasoning (CoRe), with a generator to generate reasoning paths and a verifier to supervise the evaluation. </p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#scaling-relationship-on-learning-mathematical-reasoning-with-large-language-models-2023","title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models (2023)","text":""},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#gsm8k","title":"GSM8k","text":"<p>This paper mainly focus on the following two questions: (i) Which is a better performance indicator of LLMs? (pre-training loss amount/model size) (ii) How to improve small model's performance by data augmentation? To answer the second question, this paper proposes a novel methods in data augmentation in the LLM data generation step which is called Rejection Finetuning (RFT). The algorithm of sampling data in RFT mainly adopts the thought of rejection sampling, which is expressed in the following pseudo-code. This paper assumes such an algorithm will yield as many as possible diverse reasoning paths.  The workflow of the RFT method is illustrated as follows, where the SFT stands for supervised finetuning.  With the novel method RFT, small models such as Llama-7b yields an accuracy of at most 49.7% on GSM8k, 14% higher than the previous SOTA method SFT.</p>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#pal","title":"PAL","text":"<p>This work is a prompt engineering work.</p> <pre><code>Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? \nA: Roger started with 5 tennis balls. tennis_balls = 5 2 cans of 3 tennis balls each is bought_balls = 2 * 3 tennis balls. The answer is answer = tennis_balls + bought_balls \nQ: The bakers at the Beverly Hills Bakery baked 200 loaves of bread on Monday morning. They sold 93 loaves in the morning and 39 loaves in the afternoon. A grocery store returned 6 unsold loaves. How many loaves of bread did they have left?\n</code></pre> <pre><code>A: The bakers started with 200 loaves loaves_baked = 200 They sold 93 in the morning and 39 in the afternoon loaves_sold_morning = 93 loaves_sold_afternoon = 39 The grocery store returned 6 loaves. loaves_returned = 6 The answer is answer = loaves_baked - loaves_sold_morning - loaves_sold_afternoon + loaves_returned\n</code></pre>"},{"location":"DL_Notes/NLP_Theory/Math%20Word%20Problem%20Solving%20Read%20Paper/#preview","title":"Preview","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Autoregressive%20Decoder/","title":"\u3010TODO\u3011Autoregressive Decoder","text":"<p>This note collects papers that demonstrates the shortcomings of autoregressive decoders. Two main common concerns about the autoregressive decoders are that they are lacking the generalizability and the efficiency with respect to the amount of training data, due to the limitation of its structure.</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Autoregressive%20Decoder/#limitation-in-generalizability","title":"Limitation in generalizability","text":"<p>Information theory based: compositionality climbing towards NLU: only learning the surface structure of language</p> <p>In this paper, we </p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Autoregressive%20Decoder/#towards-revealing-the-mystery-behind-chain-of-thought-a-theoretical-perspective-2023","title":"Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective (2023)","text":"<p>This paper points out the reason why the CoT success in prompting LLMs.  \u589e\u52a0\u6a21\u578b\u7684\u6709\u6548\u6df1\u5ea6</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Autoregressive%20Decoder/#deep-encoder-shallow-decoder-reevaluating-the-speed-quality-tradeoff-in-machine-translation","title":"Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation","text":"<p>In section Deep Encoder, Shallow Decoder, this paper discusses the </p> <p>(Edunov et al., 2018; Pinnis et al., 2018; Ng et al., 2019).</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Autoregressive%20Decoder/#limitation-in-error-accumulation","title":"Limitation in error accumulation","text":"<p>GSM8k uses a verifier to correct the mistakes in reasoning paths, which is a worthy attempt. However, more efficient verification and correction in the early reasoning stage should also be explored. GSM8k and scaling relationship also indicates the log linear-hood has not been reached by the autoregressive decoders.</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/","title":"\u786e\u5b9a\u5199\u4e0d\u51fa\u6765\u5148\u653e\u5f03\u5427","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#task-description","title":"Task Description","text":"<p>Natural Language Inference (NLI) problem concerns the logic reasoning relationship of sentences or facts in natural language texts. </p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#relevant-survey","title":"Relevant Survey","text":"<p>There are several relevant surveys on the NLI tasks.</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#a-survey-of-paraphrasing-and-textual-entailment-method-2017","title":"A survey of paraphrasing and textual entailment method (2017)","text":"<p>https://www.jair.org/index.php/jair/article/view/10651</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#an-overview-of-natural-language-inference-data-collection-the-way-forward-2017","title":"An overview of Natural Language Inference Data Collection: The way forward? (2017)","text":"<p>https://aclanthology.org/W17-7203.pdf</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#logical-formalizations-of-commonsense-reasoning-a-survey-2017","title":"Logical formalizations of commonsense reasoning: a survey (2017)","text":"<p>https://www.jair.org/index.php/jair/article/view/11076/26258</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#recent-advances-in-natural-language-inference-a-survey-of-benchmarks-resources-and-approaches-2019","title":"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches (2019)","text":"<p>https://arxiv.org/abs/1904.01172</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#a-survey-on-recognizing-textual-entailment-as-an-nlp-evaluation-2020","title":"A Survey on Recognizing Textual Entailment as an NLP Evaluation (2020)","text":"<p>https://aclanthology.org/2020.eval4nlp-1.10.pdf</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#symbolic-and-neural-approaches-to-natural-language-inference-2021","title":"SYMBOLIC AND NEURAL APPROACHES TO NATURAL LANGUAGE INFERENCE (2021)","text":"<p>https://scholarworks.iu.edu/dspace/bitstream/handle/2022/26642/dissertation_final_hai_hu.pdf?sequence=1&amp;isAllowed=y</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#natural-language-inference-a-dissertation-bill-maccartney","title":"Natural Language Inference a dissertation (BIll MacCartney)","text":"<p>https://www-nlp.stanford.edu/~wcmac/papers/nli-diss.pdf</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#toward-reasoning-in-large-language-models-a-survey","title":"Toward reasoning in large language models: A survey","text":"<p>https://arxiv.org/abs/2212.10403 The structure of this paper is as follows.   This paper first provides differentiations among deductive reasoning, inductive reasoning and abductive reasoning, and among formal reasoning and informal reasoning. At the end, this paper states that it focuses explicitly in informal deductive reasoning in large language models. Deductive reasoning</p> <pre><code>Premise: All mammals have kidneys. \nPremise: All whales are mammals. \nConclusion: All whales have kidneys.\n</code></pre> <p>Inductive reasoning</p> <pre><code>Observation: Every time we see a creature with wings, it is a bird. \nObservation: We see a creature with wings. \nConclusion: The creature is likely to be a bird.\n</code></pre> <p>Abductive reasoning</p> <pre><code>Observation: The car cannot start and there is a puddle of liquid under the engine. \nConclusion: The most likely explanation is that the car has a leak in the radiator.\n</code></pre> <p>In the Towards Reasoning in Large Language Models section, this survey discusses three main methods in solving math reasoning problems. For fully supervised fine-tuning method, it is suggested that the two main limitations are the lack of the datasets containing explicit reasoning, and the lack of the generializability of models. For CoT methods, this paper introduces CoT as a trigger of LLMs reasoning ability, and introduces several variant of CoT including zero-shot CoT, and three methods towards Rationale engineering, Rational refinement (complexity-based prompting, algorithmic prompting, and Auto-CoT), Rationale exploration (self-consistency probing), and Rationale verification. The Hybrid Method section introduces the Reasoning-Enhanced Training and Prompting and the Bootstrapping &amp; Self-Improving methods. In section Measuring Reasoning in Large Language Models, this paper introduces several task variants to the reasoning task, including Arithmetic Reasoning, Commonsense Reasoning and Symbolic Reasoning. Four findings are proposed in this survey, which are that \"Reasoning seems an emergent ability of LLMs\", \"CoT elicits reasoning of LLMs\", \"LLMs show human-like content effect on reasoning\", and \"LLMs are still unskilled at complex reasoning\". This paper also points out concerns on whether LLMs are reasoning or simply \"generating reasoning-like responses\".</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#dataset","title":"Dataset","text":"<p>The natural language reasoning datasets usually follows the multiple choice structure -- given  a premise consisting of a series of sentences and a hypothesis of usually one-sentence length, the label indicates the relationship between them, which are \"entailment\", \"neutral\" or \"contradiction\". According to the length of the premises, the NLI datasets can be classified as sentence-level, paragraph-level and document-level.</p>"},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#sentence-level","title":"Sentence-level","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#paragraph-level","title":"Paragraph-level","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#document-level","title":"Document-level","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#method","title":"Method","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#sentence-level_1","title":"Sentence-level","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#paragraph-level_1","title":"Paragraph-level","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#document-level_1","title":"Document-level","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Natural%20Language%20Inference%20%28NLI%29%20Task/#preview","title":"Preview","text":""},{"location":"DL_Notes/NLP_Theory/%E3%80%90TODO%E3%80%91Neural%20Symbolic%20AI/","title":"\u3010TODO\u3011Neural Symbolic AI","text":"<p>Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning This paper provides an introduction to neural symbolic computing, indicating that the neural symbolic AI aim at integrating as learning from the environment and the ability to reason from what has been learned.</p>"},{"location":"DL_Notes/Python_Usage/Broadcastable%20Vector/","title":"Broadcastable Vector","text":"<p>Broadcasting is a mechanism which allows tensors with different numbers of dimensions to be added or multiplied together by (virtually) replicating the smaller tensor along the dimensions that it is lacking. </p> <p>One tensor is broadcastable to another if the following rules hold. - Each tensor has at least one dimension. - When iterating over the dimension size, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.</p> <p>Examples Same shapes are always broadcastable.</p> <pre><code>x = torch.empty(5,7,3)\ny = torch.empty(5,7,3)\n</code></pre> <p>If one of the vectors does not have at least one dimension, they are not broadcastable.</p> <pre><code>x = torch.empty((0,))\ny = torch.empty(2,2)\n</code></pre> <p>Lining up is from right to left. x and y can line up trailing dimensions</p> <pre><code>x = torch.empty(5, 3, 4, 1)\ny = torch.empty(   3, 1, 1)\n</code></pre> <p>1st trailing dimension: x and y both have dim 1 2nd trailing dimension: y has 1 3rd trailing dimension: x = y 4th trailing dimension: y's dimension does not exist</p>"},{"location":"DL_Notes/Python_Usage/IPDB/","title":"IPDB","text":"<p>Python\u8c03\u8bd5\u5de5\u5177 \u5b89\u88c5</p> <pre><code>pip install ipdb\n</code></pre> <p>\u4f7f\u7528</p> <pre><code>import ipdb\n# some code\nx = 10\nipdb.set_trace()\ny = 20\n# other code\n</code></pre> <p>\u6216\u8005\u4f7f\u7528\u547d\u4ee4\u884c</p> <pre><code>python -m ipdb your_code.py\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/","title":"Pandas DF\u901f\u67e5","text":"<p>\u63d0\u793a\uff1a\u4f46\u662f\u6211\u7684\u5efa\u8bae\u662f\u4e0d\u8981\u7528pandas\uff0c\u91cc\u9762\u5b9e\u73b0\u633a\u4e71\u7684\uff0c\u7ecf\u5e38\u51fa\u73b0\u672a\u77e5\u7684\u526f\u4f5c\u7528\uff0c\u53ef\u4ee5\u76f4\u63a5\u7528csv\u5305</p>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#_1","title":"\u589e","text":"<p>\u6309\u5217\u589e\u52a0</p> <pre><code>citys = ['ny','zz','xy']\ndf.insert(0,'city',citys) #\u5728\u7b2c0\u5217\uff0c\u52a0\u4e0acolumn\u540d\u79f0\u4e3acity\uff0c\u503c\u4e3acitys\u7684\u6570\u503c\u3002\njobs = ['student','AI','teacher']\ndf['job'] = jobs #\u9ed8\u8ba4\u5728df\u6700\u540e\u4e00\u5217\u52a0\u4e0acolumn\u540d\u79f0\u4e3ajob\uff0c\u503c\u4e3ajobs\u7684\u6570\u636e\u3002\ndf.loc[:,'salary'] = ['1k','2k','2k','2k','3k'] #\u5728df\u6700\u540e\u4e00\u5217\u52a0\u4e0acolumn\u540d\u79f0\u4e3asalary\uff0c\u503c\u4e3a\u7b49\u53f7\u53f3\u8fb9\u6570\u636e\u3002\n</code></pre> <p>\u6309\u884c\u589e\u52a0</p> <pre><code>df.loc[4] = ['zz','mason','m',24,'engineer\u2019]#\u82e5df\u4e2d\u6ca1\u6709index\u4e3a\u201c4\u201d\u7684\u8fd9\u4e00\u884c\u7684\u8bdd\uff0c\u8be5\u884c\u4ee3\u7801\u4f5c\u7528\u662f\u5f80df\u4e2d\u52a0\u4e00\u884cindex\u4e3a\u201c4\u201d\uff0c\u503c\u4e3a\u7b49\u53f7\u53f3\u8fb9\u503c\u7684\u6570\u636e\u3002\u82e5df\u4e2d\u5df2\u7ecf\u6709index\u4e3a\u201c4\u201d\u7684\u8fd9\u4e00\u884c\uff0c\u5219\u8be5\u884c\u4ee3\u7801\u4f5c\u7528\u662f\u628adf\u4e2dindex\u4e3a\u201c4\u201d\u7684\u8fd9\u4e00\u884c\u4fee\u6539\u4e3a\u7b49\u53f7\u53f3\u8fb9\u6570\u636e\u3002\ndf_insert = pd.DataFrame({'name':['mason','mario'],'sex':['m','f'],'age':[21,22]},index = [4,5])\nndf = df.append(df_insert,ignore_index = True) #\u8fd4\u56de\u6dfb\u52a0\u540e\u7684\u503c\uff0c\u5e76\u4e0d\u4f1a\u4fee\u6539df\u7684\u503c\u3002ignore_index\u9ed8\u8ba4\u4e3aFalse\uff0c\u610f\u601d\u662f\u4e0d\u5ffd\u7565index\u503c\uff0c\u5373\u751f\u6210\u7684\u65b0\u7684ndf\u7684index\u91c7\u7528df_insert\u4e2d\u7684index\u503c\u3002\u82e5\u4e3aTrue\uff0c\u5219\u65b0\u7684ndf\u7684index\u503c\u4e0d\u4f7f\u7528df_insert\u4e2d\u7684index\u503c\uff0c\u800c\u662f\u81ea\u5df1\u9ed8\u8ba4\u751f\u6210\u3002\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#_2","title":"\u5220","text":"<p>\u5220\u9664\u884c</p> <pre><code>df.drop([1,3],axis = 0,inplace = False)#\u5220\u9664index\u503c\u4e3a1\u548c3\u7684\u4e24\u884c\uff0c\n</code></pre> <p>\u5220\u9664\u5217</p> <pre><code>df.drop(['name'],axis = 1,inplace = False) #\u5220\u9664name\u5217\u3002\ndel df['name'] #\u5220\u9664name\u5217\u3002\nndf = df.pop('age\u2019)#\u5220\u9664age\u5217\uff0c\u64cd\u4f5c\u540e\uff0cdf\u90fd\u4e22\u6389\u4e86age\u5217,age\u5217\u8fd4\u56de\u7ed9\u4e86ndf\u3002\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#_3","title":"\u6539","text":"<p>\u6539\u884c\u5217\u6807\u9898</p> <pre><code>df.columns = ['name','gender','age'] #\u5c3d\u7ba1\u6211\u4eec\u53ea\u60f3\u628a\u2019sex\u2019\u6539\u4e3a\u2019gender\u2019\uff0c\u4f46\u662f\u4ecd\u7136\u8981\u628a\u6240\u6709\u7684\u5217\u5168\u5199\u4e0a\uff0c\u5426\u5219\u62a5\u9519\u3002\ndf.rename(columns = {'name':'Name','age':'Age'},inplace = True) #\u53ea\u4fee\u6539name\u548cage\u3002inplace\u82e5\u4e3aTrue\uff0c\u76f4\u63a5\u4fee\u6539df\uff0c\u5426\u5219\uff0c\u4e0d\u4fee\u6539df\uff0c\u53ea\u662f\u8fd4\u56de\u4e00\u4e2a\u4fee\u6539\u540e\u7684\u6570\u636e\u3002\ndf.index = list('abc')#\u628aindex\u6539\u4e3aa,b,c.\u76f4\u63a5\u4fee\u6539\u4e86df\u3002\ndf.rename({1:'a',2:'b',3:'c'},axis = 0,inplace = True)#\u65e0\u8fd4\u56de\u503c\uff0c\u76f4\u63a5\u4fee\u6539df\u7684index\u3002\n</code></pre> <p>\u6539\u6570\u503c</p> <pre><code>df.loc[1,'name'] = 'aa' #\u4fee\u6539index\u4e3a\u20181\u2019\uff0ccolumn\u4e3a\u2018name\u2019\u7684\u90a3\u4e00\u4e2a\u503c\u4e3aaa\u3002\ndf.loc[1] = ['bb','ff',11] #\u4fee\u6539index\u4e3a\u20181\u2019\u7684\u90a3\u4e00\u884c\u7684\u6240\u6709\u503c\u3002\ndf.loc[1,['name','age']] = ['bb',11]    #\u4fee\u6539index\u4e3a\u20181\u2019\uff0ccolumn\u4e3a\u2018name\u2019\u7684\u90a3\u4e00\u4e2a\u503c\u4e3abb\uff0cage\u5217\u7684\u503c\u4e3a11\u3002\n</code></pre> <p>\u4f7f\u7528iloc[row_index, column_index]</p> <pre><code>df.iloc[1,2] = 19#\u4fee\u6539\u67d0\u4e00\u65e0\u7d20\ndf.iloc[:,2] = [11,22,33] #\u4fee\u6539\u4e00\u6574\u5217\ndf.iloc[0,:] = ['lily','F',15] #\u4fee\u6539\u4e00\u6574\u884c\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#lociloc","title":"\u7b5b\u9009\u6570\u636e\u65b9\u6cd5loc\u3001iloc","text":"<pre><code>import pandas as pd\nimport numpy as np\n\ndates = pd.date_range('20200315', periods = 5)\ndf = pd.DataFrame(np.arange(20).reshape(5,4), index = dates, columns = ['A', 'B','C','D'])\nprint(df)\n</code></pre> <pre><code>#\u8f93\u51fa\nA   B   C   D\n2020-03-15   0   1   2   3\n2020-03-16   4   5   6   7\n2020-03-17   8   9  10  11\n2020-03-18  12  13  14  15\n2020-03-19  16  17  18  19\n</code></pre> <pre><code>print(df['A'])\n</code></pre> <pre><code>#\u8f93\u51fa\n2020-03-15     0\n2020-03-16     4\n2020-03-17     8\n2020-03-18    12\n2020-03-19    16\nFreq: D, Name: A, dtype: int64\n</code></pre> <pre><code>print(df.A)\n</code></pre> <pre><code>#\u8f93\u51fa\n2020-03-15     0\n2020-03-16     4\n2020-03-17     8\n2020-03-18    12\n2020-03-19    16\nFreq: D, Name: A, dtype: int64\n</code></pre> <p>\u8de8\u8d8a\u591a\u884c\u6216\u8005\u591a\u5217</p> <pre><code>print(df[0:3])\n</code></pre> <pre><code>#\u8f93\u51fa\nA  B   C   D\n2020-03-15  0  1   2   3\n2020-03-16  4  5   6   7\n2020-03-17  8  9  10  11\n\n</code></pre> <pre><code>print(df['20200315' : '20200317'])\n</code></pre> <pre><code>#\u8f93\u51fa\nA  B   C   D\n2020-03-15  0  1   2   3\n2020-03-16  4  5   6   7\n2020-03-17  8  9  10  11\n\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#loc","title":"loc\u7eaf\u6807\u7b7e\u7b5b\u9009","text":"<pre><code>import pandas as pd\nimport numpy as np\n\ndates = pd.date_range('20200315', periods = 5)\ndf = pd.DataFrame(np.arange(20).reshape(5,4), index = dates, columns = ['A', 'B','C','D'])\nprint(df)\nprint('\\n')\nprint(df.loc['20200315'])    #\u6253\u5370\u67d0\u4e00\u884c\u7684\u6807\u7b7e\nprint('\\n')\nprint(df.loc[:,['A', 'B']])   #\u6253\u5370A\u3001B\u5c5e\u6027\u7684\u6240\u6709\u884c\nprint('\\n')\nprint(df.loc['20200315', ['A', 'B','C']])\n</code></pre> <pre><code>#\u8f93\u51fa\n             A   B   C   D\n2020-03-15   0   1   2   3\n2020-03-16   4   5   6   7\n2020-03-17   8   9  10  11\n2020-03-18  12  13  14  15\n2020-03-19  16  17  18  19\n\nA    0\nB    1\nC    2\nD    3\nName: 2020-03-15 00:00:00, dtype: int64\n\n             A   B\n2020-03-15   0   1\n2020-03-16   4   5\n2020-03-17   8   9\n2020-03-18  12  13\n2020-03-19  16  17\n\nA    0\nB    1\nC    2\nName: 2020-03-15 00:00:00, dtype: int64\n\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#_4","title":"\u67e5","text":""},{"location":"DL_Notes/Python_Usage/Pandas%20Dataframe%E5%B8%B8%E7%94%A8/#_5","title":"\u904d\u5386","text":"<p>iterrows(): \u6309\u884c\u904d\u5386\uff0c\u5c06DataFrame\u7684\u6bcf\u4e00\u884c\u8fed\u4ee3\u4e3a(index, Series)\u5bf9\uff0c\u53ef\u4ee5\u901a\u8fc7row[name]\u5bf9\u5143\u7d20\u8fdb\u884c\u8bbf\u95ee\u3002 itertuples(): \u6309\u884c\u904d\u5386\uff0c\u5c06DataFrame\u7684\u6bcf\u4e00\u884c\u8fed\u4ee3\u4e3a\u5143\u7956\uff0c\u53ef\u4ee5\u901a\u8fc7row[name]\u5bf9\u5143\u7d20\u8fdb\u884c\u8bbf\u95ee\uff0c\u6bd4iterrows()\u6548\u7387\u9ad8\u3002 iteritems():\u6309\u5217\u904d\u5386\uff0c\u5c06DataFrame\u7684\u6bcf\u4e00\u5217\u8fed\u4ee3\u4e3a(\u5217\u540d, Series)\u5bf9\uff0c\u53ef\u4ee5\u901a\u8fc7row[index]\u5bf9\u5143\u7d20\u8fdb\u884c\u8bbf\u95ee\u3002</p>"},{"location":"DL_Notes/Python_Usage/Python%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"Python\u7c7b\u901f\u67e5","text":""},{"location":"DL_Notes/Python_Usage/Python%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/#class","title":"Class","text":"<p>\u5e38\u89c1\u8fd0\u7b97\u7b26\u91cd\u8f7d\u65b9\u6cd5 </p>"},{"location":"DL_Notes/Python_Usage/Python%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/#operator-at","title":"operator at(@)","text":"<p>An <code>@</code> at the beginning of a line is used for a class and function decorator. Example:</p> <pre><code>class Pizza(object):\n    def __init__(self):\n        self.toppings = []\n\n    def __call__(self, topping):\n        # When using '@instance_of_pizza' before a function definition\n        # the function gets passed onto 'topping'.\n        self.toppings.append(topping())\n\n    def __repr__(self):\n        return str(self.toppings)\n\npizza = Pizza()\n\n@pizza\ndef cheese():        # this function passes to topping()\n    return 'cheese'\n@pizza\ndef sauce():\n    return 'sauce'\n\nprint pizza\n# ['cheese', 'sauce']\n</code></pre> <pre><code>def decorator(func):\n   return func\n\n@decorator\ndef some_func():\n    pass\n</code></pre> <p>is equivalent to this code</p> <pre><code>def decorator(func):\n    return func\n\ndef some_func():\n    pass\n\nsome_func = decorator(some_func)\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Python%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/#kwargs","title":"**kwargs","text":"<p>kwargs is a parameter in Python's functions, which takes an arbitrary numbers of parameters.  Usage:</p> <pre><code>def\u00a0print_keyword_args(**kwargs):\n    # kwargs is a dict of the keyword args passed to the function\n    for\u00a0key, value\u00a0in\u00a0kwargs.iteritems():\n        print\u00a0\"%s = %s\"\u00a0% (key, value)\nprint_keyword_args(first_name=\"John\", last_name=\"Doe\")\n</code></pre> <p>Output: first_name = John last_name = Doe</p>"},{"location":"DL_Notes/Python_Usage/Python%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/#_1","title":"\u6570\u7ec4\u62f7\u8d1d","text":"<pre><code>s1 = [[]] * 3 ## \u662f\u6d45\u62f7\u8d1d\ns1[1].append('xyx')    ## [['xyx'], ['xyx'], ['xyx']]\n\ns2 = [[] for _ in 3]   ## \u662f\u6df1\u62f7\u8d1d\ns2[1].append('xyx')    ## [[], ['xyx'], []]\n\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pytorch/","title":"Pytorch","text":""},{"location":"DL_Notes/Python_Usage/Pytorch/#nnmodulelist-and-nnsequential","title":"nn.ModuleList and nn.Sequential","text":"<p>TLDR: <code>nn.ModuleList</code> is a list which is indexable and without extra functions, while <code>nn.Sequential</code> is a workflow with order and ability to call the forward functions automatically.</p> <p>Please refer to more details from PyTorch \u4e2d\u7684 ModuleList \u548c Sequential: \u533a\u522b\u548c\u4f7f\u7528\u573a\u666f - \u77e5\u4e4e (zhihu.com). </p>"},{"location":"DL_Notes/Python_Usage/Pytorch/#forward-function-in-pytorch","title":"Forward function in Pytorch","text":"<p>In training models with Pytorch, there is no need to explicitly call the forward function. The way to call the forward function is as follows.</p> <pre><code> class Module(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # ...\n    def forward(self, x):\n        # ...\n        return x\ndata = data\nmodel = Module()\nmodel(data)\n</code></pre> <p>instead of <code>model.forward(data)</code>. This is because <code>model(data)</code> equals <code>mode.forward(data)</code> itself. In class <code>nn.Module</code>, the function <code>__call__</code> has been overloaded as</p> <pre><code>def __call__(self, data):\n    return self.forward(data)\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pytorch/#element-wise-matmul-dot","title":"*\u662felement wise @\u548cmatmul\u662f\u77e9\u9635\u76f8\u4e58 dot\u662f\u70b9\u4e58","text":"<pre><code>import torch\n\ntensor1 = torch.tensor([1, 2, 3])\ntensor2 = torch.tensor([4, 5, 6])\n\nresult = tensor1 * tensor2\n\nprint(result)  # Output: tensor([4, 10, 18])\n</code></pre> <pre><code>import torch\n\ntensor1 = torch.tensor([[1, 2], [3, 4]])\ntensor2 = torch.tensor([[5, 6], [7, 8]])\n\nresult = tensor1 @ tensor2\n\nprint(result)  # Output: tensor([[19, 22], [43, 50]])\n</code></pre> <pre><code>import torch\n\ntensor1 = torch.tensor([1, 2, 3])\ntensor2 = torch.tensor([4, 5, 6])\n\nresult = torch.dot(tensor1, tensor2)\n\nprint(result)  # Output: tensor(32)\n</code></pre> <pre><code>import torch\n\ntensor1 = torch.tensor([1, 2, 3])\ntensor2 = torch.tensor([4, 5, 6])\n\nresult = torch.dot(tensor1, tensor2)\n\nprint(result)  # Output: tensor(32)\n</code></pre>"},{"location":"DL_Notes/Python_Usage/Pytorch/#to-train-the-model-with-gpu","title":"To train the model with GPU","text":"<pre><code>import torch\n\n# Step 1: Check for GPU availability\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\n# Step 2: Move the model and data to the GPU\nmodel = YourModel().to(device)\ndata = YourData().to(device)\n\n# Step 3: Update the computation on the GPU\nmodel.to(device)\ndata = data.to(device)\n\n# Step 4: Perform training and inference\nfor epoch in range(num_epochs):\n    # Training loop\n    for batch in data_loader:\n        inputs, labels = batch\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # Perform forward and backward pass, update model parameters\n\n    # Inference\n    with torch.no_grad():\n        for batch in validation_data_loader:\n            inputs, labels = batch\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Perform forward pass for evaluation\n</code></pre>"},{"location":"DL_Notes/Python_Usage/setup%20packages/","title":"Setup packages","text":"<p>\u7f16\u5199setup.py\u6587\u4ef6\u662f\u4e3a\u4e86\u4f7f\u7528Python\u7684setuptools\u6784\u5efa\u5b89\u88c5\u81ea\u5df1\u7684Python\u5305\u3002 \u4e00\u4e2asetup.py\u6587\u4ef6\u5e94\u5f53\u653e\u5728\u5305\u4ee3\u7801\u76ee\u5f55\u4e0b\u3002\u4f8b\u5982\u5305\u4ee3\u7801\u76ee\u5f55\u4e3a</p> <pre><code>your_package_name/\n    __init__.py\n    module1.py\n    module2.py\n    setup.py\n</code></pre> <p>\u5176\u4e2dsetup.py\u7684\u5199\u6cd5\u662f</p> <pre><code>from setuptools import setup\nsetup(\n    name='YourPackageName',\n    version='1.0',\n    author='Your Name',\n    author_email='your@email.com',\n    description='Description of your package',\n    packages=['your_package_name'],   # \u5305\u7684\u76ee\u5f55\u5217\u8868\u3002\u5982\u679c\u6709\u591a\u4e2a\u5305\uff0c\u53ef\u4ee5\u4f7f\u7528find_packages()\u67e5\u627e\n    install_requires=[                # \u8fd9\u4e9b\u4f9d\u8d56\u5c06\u81ea\u52a8\u5b89\u88c5 \n        'dependency1',\n        'dependency2',\n    ],\n)\n</code></pre> <p>\u8bbe\u7f6e\u5b8c\u6210\u540e\uff0c\u5e94\u5f53\u5728\u547d\u4ee4\u884c\u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\u8fd0\u884c\u6253\u5305</p> <pre><code>python setup.py sdist bdist_wheel\n</code></pre> <p>\u7528\u5982\u4e0b\u65b9\u5f0f\u5b89\u88c5</p> <pre><code>pip install dist/YourPackageName-1.0.tar.gz\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Anaconda\u901f\u67e5","text":""},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_1","title":"\u521b\u5efa\u73af\u5883","text":"<pre><code>conda create --name [ENV_NAME] python==3.9\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_2","title":"\u5220\u9664\u73af\u5883","text":"<pre><code> conda remove -n [ENV_NAME] --all\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_3","title":"\u67e5\u770b\u73b0\u5b58\u865a\u62df\u73af\u5883","text":"<pre><code>conda env list\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_4","title":"\u67e5\u770b\u76ee\u524d\u73af\u5883\u5df2\u5b89\u88c5\u5305","text":"<pre><code>conda list\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_5","title":"\u6253\u5f00\u73af\u5883","text":"<pre><code> conda activate [ENV_NAME]\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_6","title":"\u5173\u95ed\u73af\u5883","text":"<pre><code>conda deactivate\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Anaconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#_7","title":"\u5220\u9664\u73af\u5883\u4e2d\u7684\u67d0\u4e2a\u5305","text":"<pre><code>conda remove --name [ENV_NAME] [PACK_NAME]\n</code></pre> <ol> <li>Update specific package:</li> </ol> <pre><code>conda update [PACK_NAME]\n</code></pre> <ol> <li>Update all packages in the current environment:</li> </ol> <pre><code>conda update --all\n</code></pre> <ol> <li>Update all packages in the current environment:</li> </ol> <pre><code>conda update -n myenv --all\n</code></pre> <ol> <li>Update Python:</li> </ol> <pre><code>conda update python\n</code></pre> <ol> <li>Update conda itself:</li> </ol> <pre><code>conda update conda\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Linux/","title":"Linux\u547d\u4ee4\u884c\u901f\u67e5","text":"<p>\u5220\u9664\u6587\u4ef6</p> <pre><code>rm [FILENAME]\n</code></pre> <p>\u5220\u9664\u76ee\u5f55</p> <pre><code>rm -rf [PATH]\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Pytorch%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Pytorch \u5e38\u7528\u547d\u4ee4","text":""},{"location":"DL_Notes/Terminal_Usage/Pytorch%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#install","title":"install","text":"<p>(MacOS, conda, no GPU or CUDA)</p> <pre><code>conda install pytorch torchvision torchaudio -c pytorch\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/Pytorch%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#20220112-cannot-import-name-field-from-torchtext","title":"2022/01/12 cannot import name \u2018Field\u2019 from \u2018torchtext\u2019","text":"<p>\u65b0\u7248torchtext\u628afield\u7c7b\u5220\u4e86\uff0c\u2019.legacy\u2019\u4e5f\u68c0\u6d4b\u4e0d\u5230\uff0c\u7528\u7248\u672c\u56de\u9000</p> <pre><code>pip --default-timeout=100 install torchtext==0.10.0\n</code></pre>"},{"location":"DL_Notes/Terminal_Usage/tmux/","title":"Tmux","text":"<p>install</p> <pre><code>git clone https://github.com/tmux/tmux.git\ncd tmux\nsh autogen.sh\n./configure &amp;&amp; make\n</code></pre> <pre><code># Ubuntu \u6216 Debian\n$ sudo apt-get install tmux\n\n# CentOS \u6216 Fedora\n$ sudo yum install tmux\n\n# Mac\n$ brew install tmux\n</code></pre> <p>\u5f00\u542f\u65b0\u8fdb\u7a0b\u7684\u901a\u7528\u547d\u4ee4</p> <pre><code>tmux new-session -d -s my_session \\; send-keys \"&lt;command&gt;\" Enter\n</code></pre> <p>\u4e0a\u4f20\u6587\u4ef6\u7528ssh\u5230\u670d\u52a1\u5668</p> <pre><code>tmux new-session -d -s my_session \\; send-keys \"rsync filename username@ip_address:/home/username\" Enter\n</code></pre> <p>\u8fd0\u884cpython\u811a\u672c</p> <pre><code>tmux new-session -d -s &lt;session name&gt; \\; send-keys \"python3 &lt;program name&gt;.py\" Enter\n</code></pre> <p>\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u8fdb\u7a0b</p> <pre><code>tmux ls\n</code></pre> <p>\u6740\u6b7b\u8fdb\u7a0b</p> <pre><code>tmux kill-session -t &lt;session name&gt;\n</code></pre> <p>\u901a\u8fc7\u91cd\u5b9a\u5411\u8f93\u51fa\u5b9e\u73b0tmux\u4f1a\u8bdd\u4e2d\u4e0e\u6b63\u5728\u8fd0\u884c\u7684\u7a0b\u5e8f\u901a\u4fe1\u3002</p> <pre><code>tmux new-session -d -s &lt;session name&gt; \\; send-keys \"python3 &lt;program name&gt;.py &gt; output.txt\" Enter\n</code></pre> <p>\u67e5\u770boutput.txt\u7684\u5185\u5bb9</p> <pre><code>cat output.txt\n</code></pre> <p>\u5b9e\u65f6\u76d1\u6d4b\u6587\u4ef6\u7684\u53d8\u5316 \u53ef\u4ee5\u5728\u7ec8\u7aef\u4e2d\u968f\u65f6\u663e\u793aoutput.txt\u7684\u5185\u5bb9</p> <pre><code>tail -f output.txt\n</code></pre> <pre><code>ssh username@server_address tmux ls\n</code></pre> <pre><code>ssh username@server_address tmux ls -t &lt;session_name&gt;\n</code></pre>"},{"location":"Linguistics_Notes/","title":"Index","text":"<p>\u672c\u4e13\u680f\u5305\u542b\u8bed\u8a00\u5b66\u7b14\u8bb0\uff0c\u76ee\u524d\u5df2\u5b8c\u6210\u4ee5\u4e0b\u5185\u5bb9 - \u8bed\u97f3\u5b66 Phonetics - \u8bed\u4e49\u5b66 Semantics - \u53e5\u6cd5\u5b66 Syntax - \u8bed\u8a00\u54f2\u5b66</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/","title":"History of Philosophy of Language","text":"<p>Nov. 9th. 2022</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#talk","title":"\u8fd9\u6b21talk\u4f1a\u8bb2\u4ec0\u4e48","text":"<p>\u2705\u00a0\u4ecb\u7ecd\u8bed\u8a00\u54f2\u5b66\u7684\u601d\u6f6e\u6d41\u53d8\u5386\u7a0b\uff0c\u4ecb\u7ecd\u8bed\u8a00\u4e0a\u7684\u5b9e\u9a8c\u601d\u60f3\u5b9e\u9a8c\uff0c\u8ba8\u8bba\u4e00\u4e9b\u8bed\u8a00\u5b66\u3001\u8ba4\u77e5\u3001\u903b\u8f91\u548c\u54f2\u5b66\u7684\u5173\u8054</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#pol","title":"PoL","text":"<p>\u8bed\u8a00\u54f2\u5b66\u7684\u57fa\u672c\u95ee\u9898\uff1a 1. \u8bed\u8a00\u548c\u4e16\u754c\u7684\u5173\u7cfb 2. \u8bed\u8a00\u6216\u8bed\u8bcd\u7684\u610f\u4e49\u95ee\u9898</p> <p>\u8bed\u8a00\u54f2\u5b66\u548c\u8bed\u8a00\u5b66 \u8bed\u8a00\u5b66\u548c\u8bed\u8a00\u54f2\u5b66\u7684\u8054\u7cfb\u7d27\u5bc6\uff0c\u4f46\u662f\u662f\u4e24\u95e8\u5b66\u79d1\u3002 20\u4e16\u7eaa\u54f2\u5b66\u4e0a\u53d1\u751f\u4e86\u8bed\u8a00\u8f6c\u5411\uff0c\u8fd9\u4e5f\u662f\u73b0\u4ee3\u8bed\u8a00\u5b66\u5f62\u6210\u7684\u65f6\u5019\u3002 \u8bed\u8a00\u5b66\u662f\u5bf9\u8bed\u8a00\u89c4\u5f8b\u548c\u8fd9\u4e9b\u89c4\u5f8b\u7684\u5e94\u7528\u7684\u7814\u7a76\uff0c\u8bed\u8a00\u54f2\u5b66\u66f4\u5173\u5fc3\u8bed\u8a00\u66f4\u672c\u8d28\u66f4\u62bd\u8c61\u7684\u610f\u4e49\u3002</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#history-of-pol","title":"History of PoL","text":"<p>\u83b1\u5e03\u5c3c\u8328\uff1a\u63d0\u51fa\u903b\u8f91\u8bed\u8a00\uff0c\u7b80\u5386\u4eba\u5de5\u8bed\u8a00\u7684\u52aa\u529b \u5f3a\u8c03\u81ea\u7136\u8bed\u8a00\u4f9d\u8d56\u4e8e\u77e5\u8bc6\uff0c\u56e0\u6b64\u5206\u6709\u77e5\u89c9\u7684\u6a21\u7cca\u3001\u6b67\u4e49\u7b49\u79cd\u79cd\u7f3a\u9677\u3002\u81ea\u7136\u8bed\u8a00\u4e0d\u662f\u63cf\u8ff0\u5ba2\u89c2\u4e8b\u7269\u7684\u6700\u4f73\u5de5\u5177\uff0c\u4e3a\u4e86\u63a2\u7a76\u771f\u7406\uff0c\u5fc5\u987b\u5efa\u7acb\u4e00\u4e2a\u7531\u666e\u904d\u7b26\u53f7\u7ec4\u6210\u7684\u66f4\u4e3a\u6e05\u695a\u7684\u7b26\u53f7\u4f53\u7cfb\u3002\u8fd9\u79cd\u52aa\u529b\u5728\u6570\u5b66\u65b9\u9762\u662f\u5353\u6709\u6210\u6548\u7684\uff0c\u6bd4\u5982\u5fae\u79ef\u5206\u7b26\u53f7\u3002</p> <p>\u7d22\u7eea\u5c14\uff1a \u7d22\u7eea\u5c14\u6700\u5927\u7684\u5f71\u54cd\u662f\u300a\u666e\u901a\u8bed\u8a00\u5b66\u300b\u3002\u6211\u4eec\u4e00\u822c\u8ba4\u4e3a\u7d22\u7eea\u5c14\u662f\u4e00\u4f4d\u8bed\u8a00\u5b66\u5bb6\uff0c\u4f46\u662f\u4ed6\u5728\u8fd9\u672c\u4e66\u4e2d\u63d0\u51fa\u7684\u201c\u80fd\u6307\u201d\u4e0e\u201c\u6240\u6307\u201d\u7406\u8bba\uff0c\u662f\u54f2\u5b66\u91cc\u7684\u7b26\u53f7\u5b66\u7684\u5f00\u7aef\u3002 \u8bed\u8a00\u662f\u7528\u58f0\u97f3\u8868\u8fbe\u601d\u60f3\u7684\u7b26\u53f7\u7cfb\u7edf\uff0c\u7b26\u53f7\u662f\u7528\u4ee5\u8868\u793a\u8005\u548c\u88ab\u8868\u793a\u8005\u7684\u7ed3\u5408\u3002 \u6211\u4eec\u4f1a\u8bf4\uff0c\u58f0\u97f3\u672c\u8eab\u4e0d\u80fd\u65bd\u6307\uff0c\u53ea\u6709\u5904\u5728\u67d0\u79cd\u7279\u5b9a\u5173\u7cfb\u4e2d\uff08\u8bed\u8a00\u5b9a\u4e49\u4e86\u58f0\u97f3\u548c\u5b9e\u4f53\u4e4b\u95f4\u7684\u5173\u7cfb\uff09\uff0c\u58f0\u97f3\u624d\u6709\u4e86\u610f\u4e49\u3002 \u4efb\u610f\u6027\u539f\u5219\u662f\uff0c\u5982\u6b64\u8fd9\u822c\u7684\u65bd\u6307\u548c\u5982\u6b64\u8fd9\u822c\u7684\u6240\u6307\u7ed3\u5408\u800c\u6210\u7684\u4e00\u4e2a\u7b26\u53f7\uff0c\u662f\u4efb\u610f\u7684\u3002eg. \u989c\u8272\u4e0e\u989c\u8272\u8bcd\u7684\u8054\u7ed3\u662f\u4efb\u610f\u7684\uff0c\u989c\u8272\u7684\u754c\u9650\u4e0e\u989c\u8272\u8bcd\u7684\u8054\u7ed3\u4e5f\u662f\u4efb\u610f\u7684\u3002</p> <pre><code>\n\"\u7eff\"\u4e0d\u4ec5\u548c\u7eff\u989c\u8272\u76f8\u8fde\uff0c\u800c\u4e14\u548c\u201c\u84dd\u201d\u201c\u9752\u201d\u7b49\u8bed\u8bcd\u76f8\u8fde\u3002\n\u5982\u679c\u6ca1\u6709\u201c\u84dd\u201d\u201c\u9752\u201d\uff0c\u6211\u4eec\u5c31\u4e0d\u80fd\u77e5\u9053\u201c\u7eff\u201d\u6240\u754c\u5b9a\u7684\u989c\u8272\u8303\u56f4\u3002\n\n\u201c\u4e03\u8272\u5f69\u8679\u201d\n\u65e5\u8bed\u4e0d\u533a\u5206\u201c\u84dd\u201d\u548c\u201c\u7eff\u201d\uff0c\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u201c\u9752\u201d\uff08aoi\uff09\uff0c\u65e5\u8bed\u6bcd\u8bed\u8005\u5728\u9274\u522b\u84dd\u8272\u548c\u7eff\u8272\u65f6\u53cd\u5e94\u65f6\u9ad8\u4e8e\u82f1\u8bed\u6bcd\u8bed\u8005\u3002\n\u4e00\u79cd\u5317\u6b27\u8bed\u8a00\u6709\u4e03\u79cd\u84dd\u8272\u7684\u540d\u79f0\u3002\n</code></pre> <p>\u6211\u4eec\u4e60\u60ef\u628a\u8bed\u8bcd\u548c\u60c5\u5883\u7684\u8054\u7cfb\u79f0\u4f5c\u7eb5\u5750\u6807\u6216\u8bed\u5883\u5750\u6807\uff0c\u628a\u8bed\u8bcd\u4e4b\u95f4\u7684\u8054\u7cfb\u79f0\u4f5c\u6a2a\u5750\u6807\u548c\u903b\u8f91\u5750\u6807\u3002 eg. \u5b8c\u5f62\u586b\u7a7a\u9898 </p> <p>eg. \u6570\u636e\u5e93\u5173\u7cfb\u6a21\u578b\u7684\u5c5e\u6027\u3001\u5143\u7ec4 </p> <p>\u975e\u5e38\u6709\u8da3\uff0c\u7d22\u7eea\u5c14\u5199\u8fd9\u672c\u8bed\u8a00\u5b66\u6559\u6750\u65f6\uff0c\u4e16\u754c\u4e0a\u5e76\u6ca1\u6709\u7b26\u53f7\u5b66\u8fd9\u4e2a\u5b66\u79d1\u3002\u5728\u4ed6\u63d0\u51fa\u201c\u80fd\u6307\u201d\u201d\u6240\u6307\u201c\u8fd9\u4e2a\u6982\u5ff5\u540e\uff0c\u7b26\u53f7\u5b66\u5728\u4ed6\u201d\u80fd\u6307\u201c\u5728\u201d\u6240\u6307\u201c\u7684\u94fe\u6761\u4e0a\u6ed1\u52a8\u8fd9\u4e00\u8bba\u65ad\u7684\u57fa\u7840\u4e0a\u8bde\u751f\uff0c\u5e76\u81f3\u4eca\u6210\u4e3a\u6cd5\u56fd\u54f2\u5b66\u7684\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002</p> <p>\u5f17\u96f7\u683c\uff1a \u5f17\u96f7\u683c\u662f\u516c\u8ba4\u7684\u5206\u6790\u54f2\u5b66\u3001\u8bed\u8a00\u54f2\u5b66\u548c\u73b0\u4ee3\u6570\u7406\u903b\u8f91\u7684\u5f00\u521b\u8005\u3002</p> <p>\u300a\u6982\u5ff5\u6587\u5b57\uff1a\u4e00\u79cd\u6a21\u4eff\u7b97\u672f\u8bed\u8a00\u6784\u9020\u7684\u7eaf\u601d\u7ef4\u7684\u5f62\u5f0f\u8bed\u8a00\u300b\u4e3b\u8981\u5de5\u4f5c\u662f\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957\u4eba\u5de5\u7b26\u53f7\u7cfb\u7edf\uff0c\u6392\u9664\u4e86\u81ea\u7136\u8bed\u8a00\u4e2d\u4fee\u8f9e\u4e4b\u7c7b\u7684\u4e1c\u897f\uff0c\u4e13\u6ce8\u4e8e\u6982\u5ff5\u672c\u8eab\u548c\u6982\u5ff5\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u56e0\u6b64\uff0c\u5b83\u5c06\u6392\u9664\u81ea\u7136\u8bed\u8a00\u7684\u6a21\u7cca\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002\u7528\u8fd9\u5957\u7b26\u53f7\u7cfb\u7edf\u6765\u91cd\u65b0\u8868\u8ff0\u7b97\u672f\u7684\u57fa\u672c\u6982\u5ff5\u548c\u63a8\u7406\u89c4\u5219\uff0c\u660e\u786e\u6240\u6709\u63a8\u7406\u7684\u524d\u63d0\uff0c\u4fdd\u8bc1\u4e00\u4e2a\u8bc1\u660e\u4e2d\u5404\u4e2a\u547d\u9898\u95f4\u7684\u6240\u6709\u63a8\u7406\u89c4\u5219\uff0c\u4f7f\u63a8\u7406\u4e0d\u518d\u57fa\u4e8e\u76f4\u89c9\uff0c\u4e5f\u6ca1\u6709\u8df3\u8dc3\u548c\u8131\u8282\u3002</p> <p>\u5bf9\u8bed\u8a00\u54f2\u5b66\u5f71\u54cd\u6700\u6df1\u7684\u662f\u4ed6\u5728\u300a\u7b97\u672f\u57fa\u7840\u300b\u4e2d\u63d0\u51fa\u7684\u4e09\u6761\u8457\u540d\u539f\u5219\uff1a</p> <ol> <li>\u59cb\u7ec8\u628a\u5fc3\u7406\u7684\u4e1c\u897f\u548c\u903b\u8f91\u7684\u4e1c\u897f\u3001\u4e3b\u89c2\u7684\u4e1c\u897f\u548c\u5ba2\u89c2\u7684\u4e1c\u897f\u4e25\u683c\u533a\u5206\u5f00\u3002\u8fd9\u4e00\u6761\u53cd\u5bf9\u5f53\u65f6\u751a\u4e3a\u6d41\u884c\u7684\u5fc3\u7406\u4e3b\u4e49\u3002\u5f17\u96f7\u683c\u4e3b\u5f20\u903b\u8f91\u5b66\u5bb6\u7814\u7a76\u7684\u662f\u8bed\u8a00\u8868\u8fbe\u5f0f\u3002\u8bed\u8a00\u8868\u8fbe\u5f0f\u662f\u53ef\u4ee5\u516c\u5f00\u8003\u5bdf\u7684\uff0c\u610f\u4e49\u7814\u7a76\u5e94\u5f53\u57fa\u4e8e\u8fd9\u4e9b\u8868\u8fbe\u5f0f\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u5bf9\u5fc3\u7406\u8fc7\u7a0b\u7684\u81c6\u6d4b\u3002</li> <li>\u7edd\u4e0d\u5b64\u7acb\u5730\u5bfb\u95ee\u4e00\u4e2a\u8bcd\u7684\u610f\u4e49\uff0c\u800c\u53ea\u5728\u4e00\u4e2a\u547d\u9898\u7684\u4e0a\u4e0b\u6587\u4e2d\u5bfb\u95ee\u8bcd\u7684\u610f\u601d\u3002\u88ab\u79f0\u4e3a\u8bed\u5883\u539f\u5219\u548c\u4e0a\u4e0b\u6587\u539f\u5219\uff0c\u6307\u51fa\u8bed\u4e49\u7814\u7a76\u7684\u6700\u5c0f\u5355\u4f4d\u8d77\u7801\u662f\u53e5\u5b50\uff0c\u4e0d\u662f\u8bcd\uff0c\u4e0d\u662f\u8868\u5c42\u8bed\u6cd5\u3002\u6211\u4eec\u6ce8\u610f\u5230\u8fd9\u4e00\u6761\u4e0e\u7b2c\u4e00\u6761\u76f8\u5173\uff0c\u56e0\u4e3a\u5982\u679c\u7814\u7a76\u8bcd\uff0c\u8bcd\u4f9d\u8d56\u7684\u5fc5\u7136\u662f\u610f\u4e49\u5728\u5fc3\u7406\u8fc7\u7a0b\u4e2d\u7684\u6620\u5c04\uff0c\u800c\u7814\u7a76\u53e5\u5b50\uff0c\u6211\u4eec\u4f1a\u628a\u8bed\u8bcd\u5728\u53e5\u5b50\u4e2d\u7684\u8054\u7cfb\u5f53\u4f5c\u610f\u4e49\u3002</li> <li>\u7edd\u4e0d\u5fd8\u8bb0\u6982\u5ff5\u548c\u5bf9\u8c61\u7684\u533a\u522b\u3002</li> </ol> <p>\u4e24\u4e2a\u601d\u7ef4\u5b9e\u9a8c\uff1a</p> <ol> <li> <p>\u6307\u79f0\u76f8\u540c\u800c\u610f\u4e49\u4e0d\u540c\u7684\u8bcd     <code>\u201c\u542f\u660e\u661f\u201d\u548c\u201c\u957f\u5e9a\u661f\u201d\u662f\u540c\u4e00\u9897\u884c\u661f\u2014\u2014\u2014\u2014\u91d1\u661f\u3002     \u4f46\u662f\u4e24\u4e2a\u540d\u8bcd\u7684\u610f\u4e49\u4e0d\u540c\uff0c\u5927\u591a\u6570\u65f6\u5019\u4e0d\u80fd\u66ff\u6362\u3002     \u201c\u4ed6\u5929\u8fd8\u6ca1\u4eae\u5c31\u8d77\u8eab\uff0c\u8fce\u7740\u542f\u660e\u661f\u5411\u4e1c\u8d70\u53bb\u3002\u201d</code></p> </li> <li> <p>\u51fd\u5f0f\u7406\u8bba     <code>\uff08 \uff09\u662f\u4e2d\u56fd\u7684\u9996\u90fd     \uff08 \uff09= \"\u4f26\u6566\"\u3001\"\u5317\u4eac\"     \u53ea\u6709\u586b\u5165\u5317\u4eac\u7684\u65f6\u5019\u624d\u662f\u771f\u547d\u9898</code></p> </li> </ol> <p>\u7f57\u7d20\uff1a\u903b\u8f91 \u6df1\u5165\u4e13\u540d\u548c\u901a\u540d\u3001\u6096\u8bba\u3001\u6392\u4e2d\u5f8b\u3002</p> <p>\u7ef4\u7279\u6839\u65af\u5766\uff1a \u524d\u671f\u601d\u60f3\u300a\u903b\u8f91\u54f2\u5b66\u8bba\u300b </p> <p>\u201c\u4e16\u754c\u662f\u4e8b\u5b9e\u7684\u7efc\u5408\u201d\uff1a\u201c\u53f8\u9a6c\u5149\u662f\u5510\u671d\u4eba\u201d\u7b26\u5408\u903b\u8f91\uff0c\u4f46\u4e0d\u7b26\u5408\u4e8b\u5b9e\u3002</p> <p>\u56fe\u50cf\u8bba \u8bed\u8a00\u662f\u547d\u9898\u7684\u603b\u548c\u800c\u4e0d\u662f\u540d\u79f0\u7684\u603b\u548c\u3002 \u4eba\u5728\u4ea4\u6d41\u601d\u60f3/\u547d\u9898\u65f6\uff0c\u4ea4\u6d41\u7684\u662f\u8111\u4e2d\u7684\u56fe\u50cf\u3002 \u4ed6\u7684\u524d\u671f\u601d\u60f3\u542f\u53d1\u4e86\u7ef4\u4e5f\u7eb3\u5b66\u6d3e\uff1a\u4eba\u5de5\u8bed\u8a00\uff0c\u903b\u8f91\u8bed\u8a00 \u5341\u4e5d\u4e16\u7eaa\u672b\u4ee5\u6765\u4eba\u5de5\u8bed\u8a00\u7684\u5c1d\u8bd5\uff1a\u201c\u4e16\u754c\u8bed\uff08Esperanto\uff09\u201d\uff0c\u4e18\u5409\u5c14\u63a8\u5d07\u7684\u57fa\u672c\u82f1\u8bed\uff0c\u81ea\u7136\u8bed\u8a00\u4e2d\u5bf9\u201c\u5973\u4eba\u201d\u201c\u5973\u6027\u201d\u201c\u5973\u58eb\u201d\u201c\u5987\u5973\u201d\u8fd9\u6837\u7684\u6307\u79f0\u7684\u89c4\u8303\u5c1d\u8bd5\u3002 \u540e\u671f\u601d\u60f3\u300a\u54f2\u5b66\u7814\u7a76\u300b \u8bed\u8a00\u6e38\u620f\uff08Sprachspiel\uff09 \u8bed\u8a00\u7684\u529f\u80fd\u7684\u672c\u8d28\uff1a\u4e00\u65b9\u558a\u51fa\u8bed\u8bcd\uff0c\u53e6\u4e00\u65b9\u4f9d\u7167\u8fd9\u4e9b\u8bed\u8bcd\u6765\u884c\u52a8\u3002</p> <pre><code>\u8001\u5e08\u6307\u7740\u77f3\u5934\u8bf4\u201c\u77f3\u5934\u201d\uff0c\u5b66\u751f\u8ddf\u7740\u8bf4\u201c\u77f3\u5934\u201d\u3002\n</code></pre> <pre><code>\u4e22\u624b\u7ee2\u65f6\u5531\u7740\u201c\u8f7b\u8f7b\u5730\u653e\u5728\u5c0f\u670b\u53cb\u7684\u8eab\u540e\u201d\uff0c\u628a\u624b\u7ee2\u653e\u5728\u5c0f\u670b\u53cb\u7684\u8eab\u540e\n</code></pre> <p>\u4e0e\u524d\u671f\u56fe\u50cf\u7406\u8bba\u7684\u5bf9\u6bd4\uff1a\u5728\u56fe\u50cf\u7406\u8bba\u4e2d\uff0c\u8bed\u8a00\u4ece\u6839\u672c\u4e0a\u662f\u4e00\u79cd\u53cd\u6620\uff1b\u5728\u8bed\u8a00\u6e38\u620f\u8bf4\u4e2d\uff0c\u8bed\u8a00\u9996\u5148\u662f\u4e00\u79cd\u6d3b\u52a8\u3002 \u610f\u4e49\u6765\u6e90\u4e8e\u4f7f\u7528\u3002</p> <pre><code>\u6211\u4eec\u5173\u5fc3\u201c\u9524\u5b50\u201d\u662f\u4ec0\u4e48\u65f6\uff0c\n\u5173\u5fc3\u7684\u662f\u201c\u4f7f\u7528\u4e00\u628a\u9524\u5b50\u201d\uff0c\n\u800c\u4e0d\u662f\u201c\u9524\u5b50\u610f\u5473\u7740\u2026\u2026\u201d\n\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u4e5f\u6b63\u662f\u4ece\u201c\u4f7f\u7528\u4e00\u628a\u9524\u5b50\u201d\u6765\u5b9a\u4e49\u9524\u5b50\n</code></pre> <pre><code>\u5982\u4f55\u533a\u5206\u201c\u4f7f\u7528\u201d\u201c\u6709\u7528\u201d\u201c\u5229\u7528\u201d\uff1f\n\u5728\u4e00\u4e9b\u60c5\u5883\u4e2d\u80fd\u7528\uff0c\u5728\u4e00\u4e9b\u60c5\u5883\u4e2d\u4e0d\u80fd\u7528\u3002\n</code></pre> <p>\u8bed\u8a00\u6e38\u620f\u7684\u7c7b\u522b   \u5bb6\u65cf\u76f8\u4f3c\u7406\u8bba\uff08Familien\u00e4hnlichkeiten\uff09</p> <p>\u201c\u4e00\u4e2a\u5bb6\u65cf\u7684\u6709\u4e9b\u6210\u5458\u6709\u4e00\u6837\u7684\u9f3b\u5b50\uff0c\u53e6\u4e00\u4e9b\u6709\u4e00\u6837\u7684\u7709\u6bdb\uff0c\u8fd8\u6709\u4e00\u4e9b\u6709\u4e00\u6837\u7684\u6b65\u6001\uff1b\u8fd9\u4e9b\u76f8\u4f3c\u4e4b\u5904\u4ea4\u53c9\u91cd\u53e0\u3002\u201c </p> <p>\u5185\u6db5\uff1a\u4e00\u4e2a\u6982\u5ff5\u7684\u5b9a\u4e49 \u5916\u5ef6\uff1a\u4e00\u4e2a\u6982\u5ff5\u5305\u542b\u7684\u4e0b\u5c5e\u6982\u5ff5\u7684\u8303\u56f4 \u901a\u540d\u7684\u4e0b\u5c5e\u8bcd\uff0c\u5404\u79cd\u4e13\u540d\u4e4b\u95f4\u5e76\u6ca1\u6709\u4e25\u683c\u7684\u754c\u9650\uff0c\u4e00\u4e2a\u76f8\u4f3c\u53e6\u4e00\u4e2a\uff0c\u5206\u4eab\u4e0d\u540c\u7684\u5171\u540c\u7279\u5f81\u3002 </p> <p>\u751f\u6d3b\u5f62\u5f0f\uff08Lebens Form\uff09\uff1a\u5e38\u8bc6\u7684\u91cd\u8981\u6027  </p> <pre><code>\u201c\u626b\u5e1a\u5728\u90a3\u91cc\u201d\u5df2\u7ecf\u8db3\u591f\u6e05\u6670\u3002\n\u201c\u626b\u5e1a\u628a\u548c\u626b\u5e1a\u5934\u5728\u90a3\u91cc\u201d\uff0c\u867d\u7136\u5206\u6790\u5f97\u66f4\u6e05\u695a\uff0c\u4f46\u5728\u4ea4\u9645\u4e2d\u8ba9\u4eba\u8d39\u89e3\u3002\n</code></pre> <p>\u4eff\u4f5b\u6211\u4eec\u53ea\u8981\u66f4\u591a\u8bf4\u4e00\u70b9\uff0c\u591a\u5206\u6790\u4e00\u70b9\uff0c\u4e8b\u60c5\u5c31\u4f1a\u66f4\u6e05\u695a\uff0c\u4eff\u4f5b\u6ca1\u6709\u4e00\u53e5\u8bdd\u672c\u8eab\u5c31\u662f\u8db3\u591f\u6e05\u695a\u7684\u3002</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#conclusion-of-agreements","title":"Conclusion of Agreements","text":"<ol> <li>\u8bed\u8a00\u7684\u610f\u4e49\u4f9d\u8d56\u4e8e\u7b26\u53f7\u4e0e\u7b26\u53f7\u4e4b\u95f4\u76f8\u4e92\u5b9a\u4e49\uff0c\u4e0e\u771f\u5b9e\u4e16\u754c\u7684\u5bf9\u8c61\u6ca1\u6709\u7edd\u5bf9\u7684\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\u3002</li> <li>\u8bed\u8a00\u7684\u529f\u80fd\u5728\u4e8e\u53d1\u51fa\u548c\u5b8c\u6210\u547d\u4ee4\u3002</li> <li>\u81ea\u7136\u8bed\u8a00\u771f\u5b9e\u73b0\u8c61\u6bd4\u4eba\u9020\u8bed\u8a00\u89c4\u5219/\u903b\u8f91\u8868\u8fbe\u5f0f\u66f4\u80fd\u53cd\u5e94\u4eba\u8111\u7684\u8ba4\u77e5\u3001\u66f4\u503c\u5f97\u7814\u7a76\u3002</li> </ol>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#history-of-nlp","title":"History of NLP","text":"<ol> <li>\u57fa\u4e8e\u89c4\u5219\u7684 \u2192 \u7ef4\u7279\u6839\u65af\u5766\u524d\u671f\u53ca\u4ee5\u524d\u7684\u7eaf\u903b\u8f91\u8bed\u8a00\uff0c\u4eba\u9020\u8bed\u8a00\u3002</li> <li>\u57fa\u4e8e\u7edf\u8ba1\u7684\u548c\u6df1\u5ea6\u5b66\u4e60 \u2192 \u7ef4\u7279\u6839\u65af\u5766\u540e\u671f\u7684\u8bed\u8a00\u610f\u4e49\u5728\u4f7f\u7528\u4e2d\u3002</li> <li>\u548c\u7ed3\u5408\u8bed\u8a00\u5b66\u3001\u8ba4\u77e5\u77e5\u8bc6 \u2192 \u4e54\u59c6\u65af\u57fa\u7684\u8bed\u8a00\u7684\u610f\u4e49\u5728\u521b\u9020\u4e2d\u3002</li> </ol>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#pol_1","title":"PoL\u7684\u5176\u5b83\u95ee\u9898","text":"<p>\u963f\u4f69\u5c14\u603b\u7ed3\u897f\u65b9\u54f2\u5b66\u7684\u53d1\u5c55\uff1a \u53e4\u4ee3\u54f2\u5b66\u6ce8\u91cd\u7684\u662f\u672c\u4f53\u8bba\uff0c\u4ece\u8fd1\u4ee3\u5f00\u59cb\uff0c\u54f2\u5b66\u6ce8\u91cd\u7684\u662f\u8ba4\u8bc6\u8bba\uff0c\u523020\u4e16\u7eaa\uff0c\u54f2\u5b66\u6ce8\u91cd\u7684\u662f\u8bed\u8a00\u3002 \u672c\u4f53\u8bba\u7684\u95ee\u9898\uff1a\u4ec0\u4e48\u4e1c\u897f\u5b58\u5728\uff0c\u4ec0\u4e48\u662f\u5b9e\u5728\u7684\u57fa\u672c\u5b58\u5728\u5f62\u5f0f\u3002 \u8ba4\u8bc6\u8bba\u7684\u95ee\u9898\uff1a\u54ea\u4e9b\u4e1c\u897f\u662f\u6211\u4eec\u80fd\u8ba4\u8bc6\u7684\uff0c\u6211\u4eec\u662f\u600e\u6837\u8ba4\u8bc6\u8fd9\u4e9b\u4e1c\u897f\u7684\u3002 \u8bed\u8a00\u7684\u95ee\u9898\uff1a\u6211\u4eec\u5728\u4f55\u79cd\u610f\u4e49\u4e0a\u80fd\u591f\u8ba4\u8bc6\u5b58\u5728\u2014\u2014\u800c\u610f\u4e49\u7684\u9996\u8981\u8f7d\u4f53\u662f\u8bed\u8a00\u3002\u2192 Linguistic Turn</p> <p>PoL\u7684\u5176\u5b83topic\uff1a 1. \u6307\u79f0\u4e0e\u5b9e\u4f53\uff0c\u8bed\u8a00\u4e0e\u610f\u4e49\u7684\u5173\u7cfb 2. \u901a\u540d\u4e0e\u4e13\u540d\uff0c\u8bcd\u4e49\u7684\u8303\u56f4 3. \u771f\u7406\u7406\u8bba 4. \u300a\u6211\u4eec\u8d56\u4ee5\u751f\u5b58\u7684\u9690\u55bb\u300b\uff1a\u9690\u55bb\u65e0\u5904\u4e0d\u5728\uff0c\u4e0d\u4ec5\u5b9a\u4e49\u4e2d\u7684\u201cxx\u662fxx\u201d\u662f\u9690\u55bb\uff0c\u6709\u65f6\u5355\u4e2a\u8bcd\u5c31\u662f\u4e00\u4e2a\u9690\u55bb\u3002</p> <p>\u52a8\u8bcd\u662f\u9690\u55bb</p> <pre><code>\u65f6\u95f4\u5728\u6d41\u901d\u3002\n</code></pre> <p>\u4ecb\u8bcd\u662f\u9690\u55bb</p> <pre><code>I\u2019m feeling up today.\nHe is down.\n\u9ad8\u5174\u4e3a\u4e0a\uff0c\u60b2\u4f24\u4e3a\u4e0b\u3002\nWake up.\nHe fell asleep.\n\u6709\u610f\u8bc6\u4e3a\u4e0a\uff0c\u65e0\u610f\u8bc6\u4e3a\u4e0b\u3002\nHe fell ill.\nShe dropped dead.\n\u5065\u5eb7\u548c\u751f\u547d\u4e3a\u4e0a\uff0c\u75be\u75c5\u548c\u6b7b\u4ea1\u4e3a\u4e0b\u3002\nI have controlled over her.\nHe fell from power.\n\u63a7\u5236\u6216\u5f3a\u8feb\u4e3a\u4e0a\uff0c\u88ab\u63a7\u5236\u6216\u88ab\u5f3a\u8feb\u4e3a\u4e0b\u3002\nMy income rose last year.\nThe number of errors is low.\n\u66f4\u591a\u4e3a\u4e0a\uff0c\u66f4\u5c11\u4e3a\u4e0b\u3002\n</code></pre> <p>\u4e54\u59c6\u65af\u57fa\uff1a \u7ed3\u6784\u4e3b\u4e49\u8bed\u8a00\u5b66\u5230\u8f6c\u6362\u751f\u6210\u8bed\u6cd5\u3002 </p> <ol> <li>\u8bed\u8a00\u80fd\u529b/\u8bed\u8a00\u8868\u73b0\uff1a\u8bed\u8a00\u80fd\u529b\u662f\u4eba\u5148\u5929\u5177\u6709\u7684\u72ec\u7acb\u80fd\u529b\uff0c\u5b83\u901a\u8fc7\u5b66\u4e60\u67d0\u79cd\u6216\u67d0\u4e9b\u7279\u5b9a\u8bed\u8a00\u5c55\u73b0\u51fa\u6765\u3002</li> <li>\u6df1\u5c42\u7ed3\u6784/\u8868\u5c42\u7ed3\u6784\uff1a\u6df1\u5c42\u7ed3\u6784\u901a\u8fc7\u8f6c\u6362\u89c4\u5219\u751f\u6210\u8868\u5c42\u7ed3\u6784\u3002</li> </ol> <p>\u8bed\u8a00\u5b66\u7684\u5de5\u4f5c\u4e0d\u5e94\u5f53\u662f\u641c\u96c6\u8bed\u8a00\u7d20\u6750\u52a0\u4ee5\u5f52\u7eb3\uff0c\u800c\u662f\u8981\u89e3\u91ca\u8bed\u8a00\u7684\u521b\u9020\u6027\u3002</p> <p>CNF</p> <pre><code>S -&gt; AB\nA -&gt; AA | a\nB -&gt; b | e\n</code></pre> <p>\u8f6c\u6362\u751f\u6210\u8bed\u6cd5\u89c4\u5219 $\\Sigma = {NP, Vp, T, N, Npsing, NPpl, Aux, V, C, M, En, S, Past, Af}$</p> <pre><code>S -&gt; NP + VP\nVP -&gt; Verb + NP\nNP -&gt; Det + N\nVerb -&gt; Aux + V\nDet -&gt; the, a...\nN -&gt; man, ball...\nAux -&gt; will, can...\nV -&gt; hit, see...\n</code></pre> <p>\u4f20\u7edf\uff08\u6210\u5206\uff09\u8bed\u6cd5\u89c4\u5219</p> <pre><code>1. \u4e3b + \u8c13\n2. \u4e3b + \u8c13 + \u5bbe\n3. \u4e3b + \u7cfb + \u8868\n4. \u4e3b + \u8c13 + \u5bbe + \u53cc\u5bbe\n5. \u4e3b + \u8c13 + \u5bbe + \u5bbe\u8865\n6. \u4e3b + \u8c13 + \u5e76\u5217\u5bbe\n\n...\n</code></pre> <p>\u300a\u53e5\u6cd5\u7ed3\u6784\u300b\uff081957\uff09\u6838\u5fc3\u53e5\u548c\u8f6c\u6362\u6982\u5ff5\u3002 </p> <p>\u751f\u6210\u6b65\u9aa4 1. \u751f\u6210\u6838\u5fc3\u53e5\u3002     <code>S -&gt; X1 | X2 | ... Xn</code></p> <ol> <li> <p>\u8f6c\u6362\u7ed3\u6784\uff08\u66ff\u6362\u3001\u7701\u7565\u3001\u6dfb\u52a0\u3001\u6362\u4f4d\uff09\u3002     <code>X1 -&gt; Y1Z1 | ...     ...</code></p> </li> <li> <p>\u6dfb\u52a0\u5f62\u6001\u97f3\u4f4d\u89c4\u5219\u3002     <code>Z1 -&gt; W1     ...     Zn -&gt; Wn</code></p> </li> </ol> <p>\u8f6c\u6362\uff1a\u6574\u4e2a\u8f6c\u6362\u751f\u6210\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u4e09\u4e2a\u6b65\u9aa4</p> <ol> <li>\u901a\u8fc7\u77ed\u8bed\u7ed3\u6784\u6539\u5199\u89c4\u5219\uff0c\u5f97\u5230\u8868\u8fbe\u5f0f$R_c$\uff0c$R_c$\u7531\u975e\u7ec8\u7aef\u8bed\u7c7b\u7b26\u53f7\u7ec4\u6210\uff0c\u662f\u6df1\u5c42\u7ed3\u6784\u3002</li> <li>\u901a\u8fc7\u8bcd\u6c47\u63d2\u5165\u89c4\u5219\u5f97\u5230\u8868\u8fbe\u5f0f$R_1$\uff0c$R_1$\u7531\u7ec8\u7aef\u8bed\u7c7b\u7b26\u53f7\u7ec4\u6210\uff0c\u4f46\u4ecd\u662f\u6df1\u5c42\u7ed3\u6784\u3002</li> <li>\u901a\u8fc7\u8f6c\u6362\u89c4\u5219\u5f97\u5230\u8868\u8fbe\u5f0f$R_1$\uff0c$R_1$\u5f53\u7136\u8fd8\u662f\u7531\u975e\u7ec8\u7aef\u8bed\u7c7b\u7b26\u53f7\u7ec4\u6210\uff0c\u4f46\u5b83\u662f\u8868\u5c42\u7ed3\u6784\u3002 </li> </ol> <p>\u6df1\u5c42\u7ed3\u6784\u548c\u8868\u5c42\u7ed3\u6784 \u4e54\u59c6\u65af\u57fa\u8bed\u6cd5\u4f53\u7cfb\u4e2d\uff0c\u6307\u53e5\u5b50\u751f\u6210\u8fc7\u7a0b\u4e2d\u7279\u5b9a\u9636\u6bb5\u6240\u91c7\u7528\u7684\u4e00\u79cd\u7279\u6b8a\u64cd\u4f5c\u624b\u6bb5\u6216\u89c4\u5219\u3002\u6df1\u5c42\u7ed3\u6784\u662f\u5b83\u7684\u8f93\u5165\uff0c\u8868\u5c42\u7ed3\u6784\u662f\u5b83\u7684\u8f93\u51fa\u3002 \u6709\u7684\u53e5\u5b50\u8868\u5c42\u7ed3\u6784\u4e0d\u540c\uff0c\u6df1\u5c42\u7ed3\u6784\u76f8\u4f3c\u3002\u901a\u8fc7\u8f6c\u6362\u64cd\u4f5c\u53ef\u4ee5\u76f8\u4e92\u8f6c\u5316\u3002 </p> <p>\u6709\u7684\u53e5\u5b50\u6df1\u5c42\u7ed3\u6784\u4e0d\u540c\uff0c\u8868\u5c42\u7ed3\u6784\u76f8\u4f3c\u3002\u901a\u8fc7\u8f6c\u6362\u64cd\u4f5c\u4e0d\u80fd\u76f8\u4e92\u8f6c\u5316\u3002 </p> <p>\u4e3a\u4ec0\u4e48\u4eca\u5929\u6211\u4eec\u8981\u8c08\u8bed\u8a00\u54f2\u5b66\uff1f \u9648\u5609\u6620\u8001\u5e08\uff1a\u79d1\u5b66\u662f\u4e00\u4e2a\u4e25\u5bc6\u7684\u6574\u6d01\u7684\u4f53\u7cfb\uff0c\u539f\u56e0\u662f\u5b83\u628a\u6240\u6709\u6df7\u6c8c\u7684\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\u629b\u5728\u4e86\u8fd9\u4e2a\u4f53\u7cfb\u4e4b\u5916\u3002[\u300a\u8d70\u51fa\u552f\u4e00\u771f\u7406\u89c2\u300b\uff0c2020] \u6240\u4ee5\u54f2\u5b66\u7684\u95ee\u9898\u662f\u7814\u7a76\u88ab\u79d1\u5b66\u6254\u51fa\u53bb\u7684\u6df7\u6c8c\u3002 \u8bed\u8a00\u54f2\u5b66\u5c31\u50cf\u201c\u5165\u4fb5\u7684\u5b9e\u5728\u754c\u201d\uff0c\u201c\u8fb9\u754c\u7684\u6d4b\u8bd5\u70b9\u201d\u3002</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#recommended-reading","title":"Recommended Reading","text":"<p>\u300a\u8bed\u8a00\u54f2\u5b66\u300b\u9648\u5609\u6620 \u300a\u666e\u901a\u8bed\u8a00\u5b66\u300b\u7d22\u7eea\u5c14 \u300a\u903b\u8f91\u54f2\u5b66\u8bba\u300b\u7ef4\u7279\u6839\u65af\u5766 \u300a\u54f2\u5b66\u7814\u7a76\u300b\u7ef4\u7279\u6839\u65af\u5766 \u300a\u6211\u4eec\u8d56\u4ee5\u751f\u5b58\u7684\u9690\u55bb\u300b\u4e54\u6cbb\u00b7\u83b1\u8003\u592b \u300a\u5fc3\u667a\u3001\u8bed\u8a00\u548c\u673a\u5668\u300b\u5f90\u82f1\u747e</p>"},{"location":"Linguistics_Notes/History%20of%20Philosophy%20of%20Language/#_1","title":"\u8ba8\u8bba","text":"<p>\u662f\u5426\u6240\u6709\u6ca1\u6709\u7528\u8bed\u8a00\u8868\u8fbe\u7684\u77e5\u8bc6\uff0c\u90fd\u53ef\u4ee5\u88ab\u7528\u8bed\u8a00\u8868\u8fbe\uff1f\uff08not NP or NP-hard\uff09 \u53ea\u5b66\u4e60\u8bed\u8a00\u662f\u5426\u80fd\u6a21\u62df\u4eba\u7684\u667a\u80fd\u6c34\u5e73\uff1f \u6a21\u578b\u662f\u5426\u9700\u8981\u5e94\u5bf9\u6240\u6709\u7684\u5f02\u5e38\u60c5\u51b5/\u673a\u5668\u8bed\u8a00\u7684\u76ee\u6807\u672c\u8eab\u8981\u4e0e\u4eba\u7c7b\u8bed\u8a00\u6709\u6240\u533a\u522b</p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/","title":"Philosophy of Language and NLP","text":"<p>Aug. 25th. 2023</p> <p>This talk aims both to provide an introduction to the subject Philosophy of Language (a similar subject with semantics and pragmatics, according to its definition; PoL hereafter), and give a summary on the recent ongoing discussion on the linguistics concepts in NLP (e.g. \"meaning\", \"understanding\", \"reasoning\", \"grounding\").</p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#a-preview-of-this-talk","title":"A Preview of This Talk","text":"<p>1st 40min: History of philosophy of language 2nd 40min: Recent papers and discussions on PoL topics in NLP 3rd 10min: Discussion on take-away</p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#the-location-of-pol-on-the-academic-coordinate","title":"The Location of PoL on the Academic Coordinate","text":"<p>Before we start this talk, we will first provide a brief definition of the term Philosophy of Language in our talk here. The PoL concerns mainly the two following questions, (i) The relationship between the natural language and the world, (ii) The relationship between the human languages and their meaning. Chen (2003) believes that the PoL and the linguistics are two different subjects. He suggests that the linguistics is the study of language rules and patterns and the application of them, while the PoL pays more attention on the more abstract and essential features of the human language (e.g. its relation to the cognition). The author of this talk believes, according to the definition of PoL, it is a subject that closely involves the semantics and pragmatics branches in linguistics. However the PoL and linguistics overlap or not, it is commonly believed that the subject PoL was born in the 1920s, when the linguistic turn was put on stage in the European philosophy. </p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#history-of-pol","title":"History of PoL","text":"<p>Now we will dive into the history of PoL. This section is parted \"person by person\". It is noticed that \"person-by-person\" is a common structure of most of the philosophy history, as most of the philosophy progresses are propelled by giants instead of the common people.</p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#gottfried-wilhelm-leibniz","title":"Gottfried Wilhelm Leibniz","text":"<p>The main contribution of Leibniz is </p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#ferdinand-de-saussure","title":"Ferdinand de Saussure","text":""},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#friedrich-ludwig-gottlob-frege","title":"Friedrich Ludwig Gottlob Frege","text":""},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#bertrand-russell","title":"Bertrand Russell","text":"<p>Bertrand Russell is a pure logician. </p>"},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#ludwig-wittgenstein","title":"Ludwig Wittgenstein","text":""},{"location":"Linguistics_Notes/Philosophy%20of%20Language%20and%20NLP/#noam-chomsky","title":"Noam Chomsky","text":""},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/","title":"Introduction","text":"<p>We will introduce the reductions of \u201cwanna\u201d, \u201cgonna\u201d, \u201cgotta\u201d, explain their reasons and provide a  in several AmE dialects. Our inspiration for choosing this topic is from our watching television programs. Thus we will first show several pieces of video clips to get you familiar about our topic.</p> <p>An interesting fact of this phenomenon: It is focused in bias analysis in hate speech detection task. A reduced form is 20%~30% more likely to be classified as hate speech as it is considered more related to African American English. [9]</p>"},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#video-clip-examples","title":"Video Clip Examples\u2b50","text":""},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#theory","title":"Theory","text":"<p>In the following section, we will give a theoretical analysis of the phenomenon we found.</p>"},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#relevant-studies","title":"Relevant Studies","text":"<p>[1]Patterns of Function Words Reduction</p> <ul> <li>The reduction of function words is showed as following changes:<ul> <li>Vowel quality</li> <li>Coda consonant deletion</li> <li>Word speech rate</li> </ul> </li> <li>In the context of a higher rate of speech, the function word is significantly more likely to reduce.</li> <li>Significantly less reduction is found when the following word begins with a vowel than when it begins with a consonant.</li> <li>High-frequency words are likely to have weakened pronunciation.</li> <li>Collocational effects also contribute to the distribution of function word reduction.</li> </ul> <p>[2]Wanna Contraction and prosodic boundary\u2b50</p> <ul> <li>Abstract<ul> <li>Wanna-contraction is a phonological process that involves the shortening or weakening of the words \"want to\" to \"wanna\", \"going to\" to \"gonna\".</li> <li>by nature: phonological weakening or shortening of the function word \u201cto\u201d</li> <li>sensitive to: lengthening of the syllables at the prosodic boundary</li> <li>no more reducing arises when the function word is stressed or lengthened. Lengthening blocks the contraction</li> </ul> </li> <li> <p>Method: Case study</p> <ul> <li> <p>sentense-final postion: strong form.</p> <p><code>a. I want to (wanna) dance//with somebody.5  b. I don\u2018t want to (*wanna)//.</code></p> </li> <li> <p>\u201cwanna\u201d contraction to be one way of disambiguating the sentence</p> </li> <li>no \u201cwanna\u201d contraction takes place with the lengthening of the final word</li> <li>\u8fd9\u7bc7\u91cc\u4e0b\u9762\u7684\u7ed3\u8bba\u5927\u81f4\u8bb2\u7684\u662f\u5728wanna/gonna/gotta+verb\u505a\u8c13\u8bed\u7684\u60c5\u51b5\u4e0b\u4f1areduction\uff0c\u52a0\u540d\u8bcd\u6216\u4f5c\u4e3a\u5176\u5b83\u53e5\u5b50\u6210\u5206\u7684\u65f6\u5019\u4e0d\u4f1a\u3002\u6211\u9700\u8981\u518d\u53bb\u7ec6\u5206\u4e00\u4e0b</li> </ul> </li> </ul> <p>[3]Multiple Spell-Out and Contraction at the Syntax-Phonology Interface</p> <ul> <li>Abstract<ul> <li>\u201cwanna\u201d contraction is possible in the subject-control case (Who do you wanna marry?) but blocked in the DP+infinitival case (Who do you wanna marry you?)</li> </ul> </li> </ul> <p>[4]Frequency and Category Factors in the Reduction and Assimilation of Function Words: EPG and Acoustic Measures</p> <ul> <li>Abstract<ul> <li>to confirm whether syntactically defined function words are indeed phonologically and phonetically reduced or assimilated.</li> </ul> </li> </ul> <p>[5]Reduction of English Function Words in Switchboard</p> <ul> <li>Abstract<ul> <li>Corpus analysis: 10 frequent English function words, 8458 occurrence, 4-hour example from Switchboard corpus</li> <li>Method: linear and logistic regression models</li> <li>Features: word length, form of vowel (basic, full, reduced), final obstruent deletion.</li> <li>Effect factors: speaking rate, predictability, the form of the following word, planning problem disfluencies</li> </ul> </li> <li>Rate of speech<ul> <li>affects all measures of reduction</li> <li>compare: fast rate of 7.5 syllables/sec and slow rate of 2.5 syllables/sec, the estimated increase in the odds(=#full/#reduced, \u4e00\u4e2a\u6587\u672c\u91cc\u81ea\u5df1\u5b9a\u4e49\u7684\u516c\u5f0f) of full vowel is 2.2 times</li> <li>Most strongly affected words: a, the, to, and, I.</li> </ul> </li> <li>Planning problems, disfluency<ul> <li>\u8fd9\u6bb5\u7684\u610f\u601d\u5e94\u8be5\u662f\u8bf4\u8bdd\u4eba\u60f3\u4e0d\u8d77\u6765\u4e86\u505c\u987f\u7684\u65f6\u5019\uff08\u4f8b\u5982\u8bf4the that\uff09\uff0c\u505c\u987f\u4e4b\u524d\u7684\u8bf4\u7684\u90a3\u4e2a\u8bcd\u4e0d\u4f1areduce</li> <li>\u201cFox Tree and Clark suggested that such planning problems are likely to cause words in immediately preceding speech to have less reduced pronunciations.\u201d</li> </ul> </li> <li>Following consonant/vowel<ul> <li>more reduced forms before a consonant than before a vowel.</li> <li>\u201cto\u201d is greatly affected</li> </ul> </li> <li>Predictability and frequency<ul> <li>higher-frequency words are more likely to have weakened pronunciations in the previous several words.</li> <li>Jespersen: might be misleading</li> </ul> </li> <li>Collocations</li> </ul> <p>[6]From Reduction to Emancipation: Is \u201cgonna\u201d A Word?\u2b50</p> <p>P.133</p> <p>Corpus Perspectives on Patterns of Lexis</p> <p>[7]Communicative efficiency and the Principle of No Synonymy: predictability effects and the variation of want to and wanna</p> <p>Variables:</p> <ul> <li>structural variables: expression, infinitive, neg_part, question, subject</li> <li>socialinguistic variables: speaker, sex, ageGroup</li> <li>variables related to style, register, text type: textType, settingID, speechRate, formal-informal, informative-aesthetic</li> <li>predictability: (=[5]\u91cc\u7684planning problem)</li> </ul> <p>[8]Some Informal Contractions in American English</p> <p>\u5199\u5f97\u4e0d\u662f\u5f88\u597d</p> <p>[9]Exploring the Role of Grammar and Word Choice in Bias Toward African American English (AAE) in Hate Speech Classification, Diyi Yang</p> <ul> <li>Abstract<ul> <li>AAE is more likely to be misclassified as hate speech.</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#our-conclusion","title":"Our Conclusion\u2b50","text":""},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#-involves-syntax-phonology-interface","title":"- involves syntax-phonology interface","text":""},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#corpus-analysis","title":"Corpus Analysis","text":"<p>In this section, a corpus analysis is carried out to confirm the theories in the literature.</p> <p>\u600e\u4e48\u542c\uff1a\u7528\u7b2c\u4e09\u4e2ainternational dialect\u8fd9\u4e2a\u5e93\u3002\u91cc\u9762\u53ef\u4ee5\u9009\u62e9African, North American, South American\uff0c\u5176\u4e2d\u6bcf\u4e00\u4e2a\u53c8\u6709\u5730\u57df\u4e4b\u5206\u3002\u91cc\u9762\u90fd\u6709transcription\uff0c\u76f4\u63a5\u641c\u7d22\u6709\u6ca1\u6709\u8fd9\u4e09\u4e2a\u8bcd\u7ec4\uff0c\u6709\u5c31\u5b9a\u4f4d\u542c\u4e00\u4e0b\u3002</p> <p>\u53ef\u80fd\u4e0d\u80fd\u627e\u9f50\u6240\u6709\u53d8\u91cf\uff0c\u6211\u81ea\u5df1\u542c\u7684\u65f6\u5019\u89c9\u5f97\u662f\u5f88\u5c11\u7684\uff0c\u80fd\u627e\u5230\u591a\u5c11\u7b97\u591a\u5c11\u597d\u4e86\u3002</p>"},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#relevant-corpus-resources","title":"Relevant Corpus Resources","text":"<ul> <li> <p>Common Voice</p> <p>Iterating Dataset Access on Common Voice</p> </li> <li> <p>People\u2019s Speech\u2b50</p> <p>MLCommons/peoples_speech \u00b7 Datasets at Hugging Face</p> </li> <li> <p>International Dialects\u2b50</p> <p>Accents and Dialects of England | IDEA: International Dialects of English Archive</p> </li> <li> <p>(a dataset in Kaggle)</p> </li> <li> <p>openSLR</p> <p>openslr.org</p> </li> <li> <p>Stanford CS22S</p> <p>CS224S: Spoken Language Processing</p> </li> </ul>"},{"location":"Linguistics_Notes/Phonetics/Reduction%20of%20Intentional%20verb%2Bprep/#corpus-analysis_1","title":"Corpus Analysis","text":"<p>\u6bcf\u4e2a\u8bb0\u5f55\u4e00\u4e2a\u6bd4\u503c\uff1a#reduction/#\u542c\u4e86\u7684\u53e5\u5b50\u3002\u6bcf\u4e2a\u53d8\u91cf10\uff5e15\u6761\u5373\u53ef\uff0c\u8fd93\u4e2a\u77ed\u8bed\u51fa\u73b0\u4e00\u6b21\u7b97\u4e00\u6761\uff0c\u4e0d\u662f\u4e00\u4eba\u7b97\u4e00\u6761</p> <ul> <li> <p>General Pattern\u2b50</p> <p>\u53bb\u542c\u4e94\u79cd\u60c5\u51b5</p> <ul> <li>\u5728verb\u524d\uff0c\u4e00\u8d77\u505a\u8c13\u8bed\uff08\u671f\u671breduction\u591a\uff09</li> <li>\u5728noun\u524d\uff08\u671f\u671bfully pronounced\u591a\uff09</li> <li>\u5728\u53e5\u5c3e\uff08\u671f\u671bfully pronounced\u591a\uff09</li> <li>\u53e5\u5b50\u91cc\u6709\u4e24\u4e2awanna/gonna+verb\uff0c\u5176\u4e2d\u4e00\u4e2a\u7684verb\u4e3a\u907f\u514d\u91cd\u590d\u88ab\u7701\u7565\u4e86\uff08\u671f\u671bfully pronounced\u591a\uff09</li> <li>want/got/go\u56e0\u4e3a\u8bed\u4e49\uff0c\u88ab\u5f3a\u8c03\u4e86\uff08\u671f\u671bfully pronounced\u591a\uff09</li> <li>Dialect\u2b50</li> <li>\u5206\u6210\u7f8e\u56fd\u897f\u3001\u5357\u3001\u4e2d\u3001\u5317\u53bb\u542c\uff0c\u671f\u671b#reduction in \u897f\u3001\u5317&gt;\u4e2d\u3001\u5357</li> <li>\u91cd\u70b9\u542c\uff1a\u4ee5\u52a0\u5dde\u4e3a\u4f8b\u7684\u3001\u4ee5\u6ce2\u58eb\u987f\u4e3a\u4f8b\u7684\u3001\u4ee5\u5fb7\u5dde\u4e3a\u4f8b\u7684</li> <li>Race\u2b50</li> </ul> <p>African\u7684\u5728\u5e93\u91cc\u6bd4\u8f83\u5c11</p> <ul> <li>African American English</li> <li>Whiter</li> <li>Gender</li> </ul> <p>\u5206\u6210\u7537\u5973\u53bb\u542c\uff0c\u671f\u671b#reduction in \u7537&gt;\u5973</p> </li> </ul>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/","title":"Signal Basics","text":""},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#_1","title":"\u6d4a\u97f3\u4e0e\u6e05\u97f3","text":"<p>\u5f53\u58f0\u5e26\u5904\u4e8e\u6536\u7d27\u72b6\u6001\uff0c\u6d41\u7ecf\u7684\u6c14\u6d41\u4f7f\u58f0\u5e26\u632f\u52a8\uff0c\u8fd9\u65f6\u4ea7\u751f\u7684\u97f3\u662f\u6d4a\u97f3\uff08voiced sound\uff09\uff1b\u5f53\u58f0\u5e26\u5904\u4e8e\u653e\u677e\u72b6\u6001\uff0c\u4e0d\u4f34\u6709\u58f0\u5e26\u632f\u52a8\u7684\u97f3\uff0c\u79f0\u4e3a\u6e05\u97f3\uff08unvoiced sound\uff09\u3002</p>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#_2","title":"\u6fc0\u52b1\u6e90\u4e0e\u6ee4\u6ce2\u5668","text":"<p>\u6c14\u6d41\u4e0e\u58f0\u95e8\u662f\u6fc0\u52b1\u6e90\uff0c\u58f0\u9053\u662f\u6ee4\u6ce2\u5668\u3002</p>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#_3","title":"\u5171\u632f\u5cf0","text":"<p>\u58f0\u95e8\u7684\u8d28\u91cf\u51b3\u5b9a\u57fa\u97f3\u9891\u7387\uff0c\u57fa\u9891\u7684\u9ad8\u4f4e\u4e5f\u4e0e\u6027\u522b\u548c\u5e74\u9f84\u76f8\u5173\u3002\u7537\u6027\u5927\u7ea6\u572860\uff5e200hz\u3002\u5973\u6027\u548c\u513f\u7ae5\u5927\u7ea6\u5728200\uff5e450hz\u3002</p> <p>\u4eba\u7684\u53d1\u58f0\u5668\u5b98\uff08\u58f0\u9053\u548c\u53e3\u8154\uff09\u808c\u8089\u8f83\u8f6f\uff0c\u963b\u5c3c\u8f83\u5927\uff0c\u4f1a\u5bf9\u8f83\u591a\u7684\u9891\u7387\u4ea7\u751f\u5171\u9e23\u3002\u628a\u58f0\u9053\u5f53\u4f5c\u4e00\u4e2a\u53d1\u97f3\u7684\u8c10\u632f\u8154\u4f53\u6765\u770b\uff0c\u5f53\u53d1\u97f3\u7684\u6fc0\u52b1\u9891\u7387\u7b49\u4e8e\u58f0\u9053\u7684\u8c10\u632f\u9891\u7387\u65f6\uff0c\u5373\u4e24\u4e2a\u9891\u7387\u76f8\u7b49\uff0c\u58f0\u9053\u5c31\u4f1a\u4ee5\u6700\u5927\u7684\u632f\u5e45\u6765\u56de\u9707\u8361\uff0c\u4e5f\u5c31\u662f\u5171\u9e23\u3002\u5171\u9e23\u5f15\u8d77\u4e86\u8c10\u632f\u8154\u632f\u52a8\uff0c\u63a5\u7740\u58f0\u9053\u5c31\u653e\u5927\u4e86\u67d0\u4e9b\u9891\u7387\u6210\u5206\uff0c\u5e76\u8870\u51cf\u5176\u5b83\u9891\u7387\u6210\u5206\uff0c\u4ece\u800c\u4ea7\u751f\u67d0\u4e9b\u8c10\u632f\u9891\u7387\uff0c\u5728\u9891\u7387\u7279\u6027\u4e0a\u88ab\u653e\u5927\u7684\u8c10\u632f\u9891\u7387\u5c31\u4f1a\u9646\u7eed\u5cf0\u8d77\uff0c\u4e00\u822c\u628a\u8fd9\u4e9b\u5171\u632f\u9891\u7387\u79f0\u4e3a\u5171\u632f\u9891\u7387\uff0c\u5cf0\u79f0\u4e3aformant\u3002</p> <p>\u5173\u4e8e\u5171\u632f\u9891\u7387\u7684\u5927\u5c0f\uff0c\u56e0\u4e3a\u53e3\u8154\u548c\u58f0\u9053\u53ef\u4ee5\u7ec4\u5408\u6210\u5404\u79cd\u5f62\u72b6\u548c\u5c3a\u5bf8\uff0c\u6240\u4ee5\u58f0\u9053\u6709\u4e0d\u540c\u7684\u5171\u632f\u9891\u7387\u3002</p> <p>\u5173\u4e8e\u5171\u632f\u9891\u7387\u7684\u8bed\u4e49\uff0c\u7531\u4e8e\u6d4a\u97f3\u548c\u5143\u97f3\u662f\u58f0\u5e26\u632f\u52a8\u4ea7\u751f\u7684\uff0c\u6240\u4ee5\u4e00\u822c\u8ba4\u4e3a\u5171\u632f\u5cf0\u4e0e\u6d4a\u97f3\u548c\u5143\u97f3\u5bc6\u5207\u76f8\u5173\u3002 </p> <p>\u7406\u60f3\u58f0\u9053\u6a21\u578b </p> <p>\u4e0b\u9762\u56fe\u662f\u4e3b\u8981\u5143\u97f3\u548c\u7b2c\u4e00\u4e8c\u5171\u632f\u5cf0\u7684\u9891\u7387\u5bf9\u5e94\u56fe\u3002</p> <p></p> <p>\u4e09\u4e2a\u5143\u97f3\u548c\u5171\u632f\u5cf0\u7684\u5bf9\u5e94\u5173\u7cfb\u5982\u4e0b\u3002\u4e00\u4e2a\u97f3\u7d20\u53ef\u4ee5\u7528\u4e09\u4e2a\u5171\u632f\u5cf0\u8868\u793a\uff0c\u6bcf\u4e2a\u5171\u632f\u5cf0\u7684\u9891\u8c31\u7279\u6027\u90fd\u53ef\u4ee5\u7528\u4e00\u4e2aGMM\u6765\u5efa\u6a21\u62df\u5408\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e09\u4e2aGMM\u53ef\u4ee5\u5efa\u6a21\u62df\u5408\u4e00\u4e2a\u97f3\u7d20\uff0c\u8fd9\u4e5f\u5c31\u662f\u4e3a\u4ec0\u4e48HMM\u9700\u8981\u4e09\u4e2a\u72b6\u6001\u3002\u800c\u4e00\u822c\u5b9e\u9645\u4e2d\u6211\u4eec\u7528\u4e94\u4e2aHMM\u72b6\u6001\uff0c\u56e0\u4e3a\u6e05\u97f3\uff08\u975e\u6587\u672c\u56e0\u7d20\uff09\u6bd4\u8f83\u590d\u6742\uff0c\u9700\u8981\u4e94\u4e2a\u5171\u632f\u5cf0\u624d\u80fd\u8f83\u597d\u8868\u793a\u3002</p> <p>\u4e8b\u5b9e\u4e2d\u7684\u95ee\u9898\u6ca1\u6709\u8fd9\u4e48\u7b80\u5355\uff0c\u5982\u679c\u8003\u8651\u53d8\u65f6\uff0c\u5f53\u5f62\u6210\u4e00\u4e2a\u8bcd\u8bed\u65f6\uff0c\u6bcf\u4e2a\u97f3\u7d20\u603b\u4f1a\u4e0e\u524d\u540e\u7684\u97f3\u7d20\u5173\u8054\uff0c\u79f0\u4e3a\u534f\u540c\u53d1\u97f3\u3002\u7531\u4e8e\u534f\u540c\u53d1\u97f3\u7684\u4f5c\u7528\uff0c\u524d\u540e\u4e24\u4e2a\u5171\u632f\u5cf0\u53ef\u80fd\u4f1a\u91cd\u53e0\u6216\u8005\u9760\u8fd1\uff0c\u6216\u8005\u76f8\u4e92\u4f5c\u7528\uff0c\u6b64\u65f6\u5f88\u96be\u8bf4\u4e09\u4e2a\u5171\u632f\u5cf0\u8868\u793a\u4e00\u4e2a\u72ec\u7acb\u7684\u5143\u97f3\uff0c\u8fd9\u4e09\u4e2a\u5171\u632f\u5cf0\u53ef\u80fd\u4f1a\u5e26\u6709\u522b\u7684\u524d\u540e\u97f3\u7d20\u9891\u8c31\u7279\u6027\u5728\u5176\u4e2d\u3002</p> <p></p>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#spectrogram-spectral-waterfall-voice-print","title":"\u8bed\u8c31\u56fe(spectrogram, spectral waterfall, voice-print)","text":"<p>\u8bed\u8c31\u56fe\u6709\u4e09\u4e2a\u7ef4\u5ea6\uff1ax\u8f74\u65f6\u95f4\uff0cy\u8f74\u9891\u7387\uff0cz\u8f74\u8f90\u503c\u3002 </p> <p></p>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#_4","title":"\u5143\u97f3\u548c\u8f85\u97f3\u7684\u8bed/\u9891\u8c31\u56fe\u7279\u5f81","text":"<p>\u5143\u97f3\u7684\u8bed\u8c31\u56fe\u5dee\u5f02</p> <ul> <li>\u5f00\u53e3\u5ea6\u8d8a\u5927\uff0cf1\u8d8a\u9ad8</li> <li>\u820c\u4f4d\u8d8a\u9760\u524d\uff0cf2\u8d8a\u9ad8</li> <li>\u4e0d\u5706\u5507\u5143\u97f3\u7684f3\u6bd4\u5706\u5507\u5143\u97f3\u9ad8</li> </ul> <p></p> <p>f3\u6700\u660e\u663e\u7684\u4f53\u73b0\u662f\u5728\u8f85\u97f3/r/\u4e2d\uff0cf3\u660e\u663e\u4f4e</p> <p>\u8f85\u97f3\u7684\u8bed\u8c31\u56fe\u5dee\u5f02  \u533a\u5206voiced\u548cvoiceless</p> <ul> <li>voice\u5468\u671f\u6ce2\uff0cvoiceless\u975e\u5468\u671f\u6ce2</li> <li>voice\u4e8c\u7ef4\u9891\u8c31\u56fe\u4e0a\u6709\u57fa\u9891\u548c\u8c10\u6ce2\u7ed3\u6784\uff0cvoiceless\u4e8c\u7ef4\u9891\u8c31\u4e0a\u6742\u4e71\u65e0\u7ae0</li> <li>voice\u8bed\u8c31\u56fe\u4e0a\u9762\u6709\u4ee3\u8868\u58f0\u5e26\u632f\u52a8\u7684\u6d4a\u97f3\u6760\uff0cvoiceless\u65e0\u6d4a\u97f3\u6760\uff0c\u6709\u51b2\u76f4\u6761\u6216\u4e71\u7eb9</li> </ul>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#acoustic-aspects-of-consonants","title":"Acoustic Aspects of Consonants","text":""},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#english-plosives-p-b-t-d-k-g","title":"English plosives: /p/ /b/ /t/ /d/ /k/ /g/","text":"<ul> <li>/p//b/ are produced with the constriction at the lips</li> <li>/t//d/ are produced with the constriction of the blade of tongue</li> <li>/k//g/ are produced with the constriction of the back of the tongue</li> </ul> <p>four acoustic properties of plosives</p> <ul> <li>duration of stop gap: silent period in the closure phase</li> <li>voicing bar: a dark bar that is shown at the low frequencies and its usually below 200Hz</li> <li>release burst: a strong vertical spike</li> <li>aspiration: a short frication noise before vowel formants begin and it is usually in 30ms  </li> </ul> <p>\u7b2c\u56db\u7ae0\u5143\u8f85\u97f3\u7684\u58f0\u5b66\u77e5\u8bc6\u8fa8\u6790.ppt</p> <p>Music lab https://esp.mit.edu/download/a29f71f1fddf4f6470eb50726aa98de4/L7357_Phonetics_2hrs_Splash2013.pdf</p> <p>https://www.mq.edu.au/__data/assets/pdf_file/0009/911646/vowels.pdf</p> <p>Acoustic structure of consonants</p> <p>Human Voices and the Wah Pedal</p> <p>3.2. Acoustic Aspects of Consonants</p>"},{"location":"Linguistics_Notes/Phonetics/Signal%20Basics/#_5","title":"\u5e38\u7528\u97f3\u9891\u7279\u5f81","text":"<p>\u97f3\u9891\u7279\u5f81\u63d0\u53d6\u2014\u2014\u5e38\u7528\u97f3\u9891\u7279\u5f81 - LeeLIn\u3002 - \u535a\u5ba2\u56ed</p> <p>\u5f00\u6e90\u9879\u76eeaudioFlux: \u9488\u5bf9\u97f3\u9891\u9886\u57df\u7684\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\u5e93 - audioFluxLab - \u535a\u5ba2\u56ed</p>"},{"location":"Linguistics_Notes/Semantics/","title":"Grading","text":"<p>mid-term: 35% final: 50% participation: 15%</p>"},{"location":"Linguistics_Notes/Semantics/#two-tests","title":"Two tests","text":"<p>Two  tests  will   be  given   during  the  term,  one  in  the  middle  and  one  at  the  end of  the term, covering all the material covered up to that point in the course. The tests will be a combination of various types of questions, including true/false and short essay. </p>"},{"location":"Linguistics_Notes/Semantics/#final-review-for-fun","title":"Final Review &amp; For Fun","text":"<p>The following parts are written in preparation for the final review but I upload it as well for you to read for fun.</p>"},{"location":"Linguistics_Notes/Semantics/#noble-semanticians","title":"Noble Semanticians","text":"Name Field Contribution Live Nation Institution Fun facts Noam Chomsky mainly in syntax generative grammar, transformational grammar, government and binding theory, minimalist program, productivity of language, recursivity of language 1928- USA MIT Most prominent linguist alive Ferdinand de Saussure linguist and semiotician founder of semiotics. concepts: sign, signifier vs. signified, diachronic vs. synchronic, language vs. parole, paradigmatic vs. syntagmatic 1857-1913 Switzerland University of Geneva, Switzerland Charles Sanders Peirce philosopher, mathematician, logician founder of semiotics. concepts: index, icon, symbol. 1839-1914 Milford Pennsylvania JHU Michel Br\u00e9al comparative grammar coined the term \u201csemantics\u201d, diachronic focus 1832-1915 born in Rheinlan (Germany), studied in Paris and Berlin in Paris Leonard Bloomfield structural linguistics structural linguistics, language as a self-regulating system, behaviorism(stimulus-response testing) 1887-1949 Yale University reject introspection Aristotle polymath term logic, initiator of western scientific tradition 384-322 BC Stagira, Greece tutor of Alexander the Great Gottlob Freg philosopher, logician, mathematician predicate logic, sense(sentence\u2019s proposition) vs. reference (its truth value) 1848-1925 German University of Jena extreme right-wing views Peter Geach philosopher, professor of logic donkey sentence (1962) 1916-2013 England Oxford Richard Montegue semanticist Montegue grammar: syntax and semantics go together 1930-1971 student of Alfred Tarski, gay man, killed in his apartment, four influential papers Gareth Evans philosopher philosophy of mind, work on reference, e-type anaphora 1946-1980 England Oxford Irene Heim semanticist definite and indefinite pronouns 1954- German, Munich MIT, phd 1982 advisor: Barbara Partee Hans Kamp philosopher and linguist discourse representation theory (DRT) 1954- Dutch Bertrand Russell philosopher, logician logic, philosophy of mathematician 1872-1970 Wales, Britain Cambridge Henri\u00ebtte de Swart linguist tense and aspect, negation, bare nominals and indefinite noun phrases. She has also investigated the role of semantics in language evolution, and was involved in the development of bidirectional optimality theory. 1961- Dutch director of Netherlands Graduate School of Linguistics and Utrecht Institute of Linguistics"},{"location":"Linguistics_Notes/Semantics/#example-questions","title":"Example questions","text":"<p>What is a donkey pronoun?</p> <pre><code>A donkey sentence is such that an expected existential is interpreted as universal taking wide scope.\n</code></pre> <p>What is a discourse pronoun: </p> <pre><code>outside the scope of existing quantifier\ne.g. No student studies semantics. He is outside.\n</code></pre> <p>The scope of a quantifier is always bound in the clause it appears.</p> <pre><code> True\n</code></pre> <p>What is quantifier raising?</p> <pre><code>Chmosky and May.\nLF, \n</code></pre> <p>What are De Morgan\u2019s laws?</p> <pre><code>~(p or q) &lt;=&gt; (~p) and (~q)\n~(p and q) &lt;=&gt; (~p) or (~q)\n</code></pre> <p>What are conditional laws</p> <pre><code>p -&gt; q &lt;=&gt; ~p or q\n</code></pre> <p>When is the indefinite \u201ca\u201d not an existential quantifier?</p> <pre><code>1. donkey sentence\n2. generic noun phrase. A woman is difficult to please. \\forall x(Wx -&gt; Dx)\n3. John is a plumber.pj\n</code></pre> <p>2 readings: Some boy smiled at Jane and some boy kissed Molly.</p> <pre><code>\\exist x(Bx and Sx,j and Kx,m)\n\\exist x(Bx and Sx,j) and \\forall y(By and Ky,m)\n</code></pre> <p>2 Types of Recursion</p> <pre><code>embedding and coordination\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/","title":"Definition Clearification","text":""},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#what-is-semantics","title":"What is semantics?","text":"<ul> <li>Study of meaning with regard to natural language.</li> <li>mean = signify, import, denote, represent</li> <li>meaning = sense, significance, signification, acceptance, import</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#the-topics-involving","title":"The topics involving:","text":"<ul> <li>Semantics vs. semiotics<ul> <li>semiotics is the use signs to convey meaning</li> <li>Ferdinand de Saussure: signifier (phonic and orthographic form that evokes an idea (the signified)) vs. signified (idea in our mind that the signifier evokes). The referent is the actual object in the world that the signified points to.</li> <li>Charles Sanders Peirce: icon (mimic of reality), index (real indicator of the presence of some real event), symbol (arbitrarily evokes or represents something in the world)</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#meaning-capturing-metalanguage-tools","title":"Meaning capturing: metalanguage tools","text":"<ul> <li> <p>parenthesis     ```     small dogs and cats: </p> <ul> <li>small (dogs and cats)</li> <li>(small dogs) and cats</li> </ul> <p>// example of scope of quantifier ```</p> </li> <li> <p>logical quantifier     ```     every body did not cry:</p> <ul> <li>every not (boy did cry) 'no boy did cry'</li> <li>not every (boy did cry) 'at least one boy did cry' ```</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#ways-to-capture-meaning-henriette-de-swart","title":"Ways to capture meaning: (Henri\u00ebtte de Swart)","text":"<ul> <li>mentalistic approach: words itself stands for meaning.<ul> <li>prototype: a central or typical member of a category.</li> <li>difficulty: cannot describe functional words: only, of, just</li> <li>by psycho semanticians</li> </ul> </li> <li>referential approach: words refer to things to entities.<ul> <li>intensionality: world-creating predicates</li> <li>difficulty: things do not exists</li> <li>by formal semanticians</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#predicatepredicate-calculusfirst-order-predicate-logic","title":"Predicate/Predicate Calculus/First-order Predicate Logic","text":"<ul> <li> <p>everything but the subject     e.g. John likes grammar.</p> </li> <li> <p>content verb or adjective taking arguments     e.g. like (John, grammar).</p> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#map-of-linguistics-theory","title":"Map of Linguistics Theory","text":"<pre><code>graph TD\n  Language_Ability --&gt; Competence\n  Language_Ability --&gt; Performance\n  Competence --&gt; Grammar\n  Competence --&gt; Lexicon\n  Grammar --&gt; Semantics\n  Grammar --&gt; Phonology\n  Grammar --&gt; Syntax\n  Grammar --&gt; Pragmantics\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#semantics-syntax","title":"Semantics &amp; Syntax","text":""},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#syntax-needs-semantics","title":"Syntax needs semantics","text":"<ul> <li> <p>We can/cannot study syntax without semantics.</p> <p><code>Colorless green ideas sleep furiously.</code></p> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#semantics-needs-syntax","title":"Semantics needs Syntax","text":"<ul> <li>Semantics needs syntax: Semantics is how meaning is assigned to linguistic expressions.     SOV and SVO.</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#semantics-pragmatics","title":"Semantics &amp; Pragmatics","text":"<ul> <li>irony and metaphor</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#context-and-deixis","title":"Context and Deixis","text":""},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#deixis-needs-context","title":"Deixis needs context","text":"<p>Deixis is how objects, events and situations relate to the here and now of the speakers. It shows that utterance meaning cannot be fully determined by sentence meaning.</p> <ul> <li>tense (present and past)</li> <li>demonstratives (this, that)</li> <li>pronouns (I, you, etc.)</li> <li>adverbials (here, there, etc.)</li> </ul> <pre><code>(Last week) (I) play(ed) tennis with Chris.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#deictic-vs-anaphoric-use-of-pronouns","title":"Deictic  vs. Anaphoric use of pronouns","text":"<p>Deictic: pointing context Anaphoric: linguistic expression context. pronoun resolution: antecedent - pronoun</p>  \ud83d\udcad index - indices (higher register) / indexes    \ud83d\udcad Desiderata (high-register way to say Goal, desideratum. sl.)"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#map-of-semantics-taxomony","title":"Map of Semantics / Taxomony","text":"<p>Semantics - lexical semantics     - meaning of lexical items     - smaller unites     - mainly words     - morphemes - compositional semantics     - meaning of larger units     - phrases and sentences     - word combination</p>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#utterance-sentence-proposition","title":"Utterance / Sentence / Proposition","text":"<ul> <li>utterance: the concrete result of a distinct act of speaking by an actual speaker</li> <li>sentence: abstract results of one one more act of sentence/writing</li> <li>proposition: the meaning of sentence independent of speaker context</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#lexical-semantics","title":"lexical semantics","text":"<ul> <li>meanings of lexical items</li> <li>smaller units</li> </ul> <pre><code>abiguity: bank, punch, pitcher\nsynonymy: beautiful-lovely, \nantonymy: male-female\nhyponymy: set -&gt; superset\ntaxonomy: set -&gt; subset\nsymmetric relation: marry. mutually entail each other\nconverse relation: send, sell\nmeronomy: \n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#1-homonymy","title":"1) homonymy","text":"<ul> <li>homographs: written the same. lab, match, stroke</li> <li>homophones: same pronunciation, distinct orthography. ring vs. wring, phase vs. faze, sent vs. cent</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#2-polysemy","title":"2) polysemy","text":"<ul> <li>related meaning for the same words.</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#3-synonymy","title":"3) synonymy","text":"<ul> <li>neutral - derogatory</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#4-antonymy","title":"4) antonymy","text":"<ul> <li>simple opposite, black and white: dead - alive, pass - fail, hit - miss, present - absent</li> <li>gradable: cold - cool - tepid - warm - hot, silent - audible - soft - loud</li> <li>reverse: same perspective, distinct directions, often movements involved, pull - push, come - go, lift - push down, leave - return</li> <li>converse: same relationship, distinct perspective, above - below, own - belong to, employer - employee. the subject and objects of a predicate.</li> <li>taxonomic sisters<ul> <li>equal part of a whole</li> <li>color of spectrum: blue, green, red, yellow, purple</li> <li>days of the week: Monday, Tuesday</li> <li>fingers of the hand: thumb, index finger, ring finger, middle finger</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#5-hyponymy","title":"5) hyponymy","text":"<ul> <li>sets: subsets and supersets</li> <li>hyponym of  = type of</li> <li>hypernym of  = subsumes</li> <li>car - vehicles, bottles - container.</li> <li>transitive relationships</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#6-meronymy","title":"6) meronymy","text":"<p>part-whole relationship</p> <p>subtypes of meronymy</p> <ul> <li>from part to whole: is part of</li> <li>from whole to part: has / have<ul> <li>steering wheel - car, roof - house, trunk - tree, keyboard - lap</li> </ul> </li> <li>from member to collection, from collection to member</li> <li>from portions to mass (is a portion of), from mass to portion ()can be separated into).<ul> <li>mass noun: liquid, salt, paper, homework, love</li> <li>count noun: laptop, tree, car</li> <li>drop of liquid - liquid, grain of salt - salt, sheet of paper - paper, bottle of beer - beer</li> </ul> </li> </ul> <pre><code>pistachio - almond taxonymy\nlaugh - cry \nmove in - move out\ncry - weep\nRMB - monetary unit\ngrilfriend - wife\nsit - stand\njump - hop\ngood - bad\nbeat - beet\nrise - fall reverse\ncigarette - cigar taxonymy\nkid - goat \ndragon - monster\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#compositional-semantics","title":"Compositional semantics","text":"<ul> <li>causation feature: kill - cause to cease to be alive, open - cause to be open,</li> <li>problem: too many features need, residual meaning</li> <li>semantics need syntax: a. Jim hit Sally b. Sally hit Jim.</li> <li>thematic roles: agent - patient - recipient - beneficiary - goal - theme - experiencer - instrument - source - percept (Frank saw the bottle)</li> <li>hit (agent, patient)</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#inventory-of-components","title":"Inventory of components","text":"<ul> <li>actor or agent</li> <li>patient</li> <li>theme</li> <li>experiencer</li> <li>beneficiary</li> <li>instrument</li> <li>goal</li> <li>source</li> <li>recipient</li> <li>percept: being perceived</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#important-linguistics","title":"Important linguistics","text":"<p>Michel Br\u00e9al: coined semantics</p> <p>Ferdinand de Saussure: semiotician, diachronic vs. synchronic. </p> <p>Leonard Bloomfield: structural linguistics, Language, behaviorism(stimulus-response testing). reject introspection(theorize about language learning by thinking about on ones own experience)</p>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#diachronic-synchronic","title":"Diachronic &amp; Synchronic","text":"<ul> <li>course in general linguistics (1916)</li> <li>across time | with time</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#signifier-signified-referent","title":"Signifier &amp; Signified &amp; Referent","text":"<ul> <li>signified: ideas in mind</li> <li>referent: real objects</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#langue-parole","title":"Langue &amp; Parole","text":"<ul> <li>competence &amp; performance</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#paradigmatic-syntagmatic","title":"Paradigmatic &amp; Syntagmatic","text":"<ul> <li>paradigmatic relation: a relation \u201cbetween an individual unit and others that can replace it in a given sequence\u201d.</li> <li>syntagmatic relation: a relation \u201cbetween elements that form parts of some form, sequence, construction\u201d.</li> </ul> <p>Noam Chomsky Syntax</p>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#generative-grammar","title":"Generative Grammar","text":"<ul> <li>transformational grammar, deep structure, Standard Theory</li> <li>semantic precedes syntax</li> <li>transformations manipulate semantic structures</li> <li>lexical items inserted at surface syntax</li> <li>reliance on semantic features</li> <li>reliance on lexical decomposition</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#ambiguity","title":"Ambiguity","text":"<ul> <li>lexical ambiguity</li> <li>scope (quantifiers)</li> <li>syntactic ambiguity</li> <li>pronoun resolution</li> </ul> <p>e.g. Flying planes can be dangerous.</p> <pre><code>graph TD\n  are --&gt; planes\n    planes --&gt; flying\n    are --&gt; dangerous\n</code></pre> <pre><code>graph TD\n    is --&gt; flying\n    flying --&gt; planes\n    is --&gt; dangerous\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#pronoun-resolution","title":"pronoun resolution","text":"<ul> <li> <p>anaphora</p> <ul> <li>anaphor(pronoun takes antecendent)</li> <li>cataphor(pronoun takes posteedent)</li> </ul> <p><code>c John said he would helps. No boy said he would help. no boy: all the boy not, not exist a boy</code></p> </li> <li> <p>coreference(coreferential): refer to same person</p> </li> <li>quantification<ul> <li>covariance: the relation between \u201che\u201d and every/all, \u201che\u201d refers to all single one</li> <li>binding: \u201che\u201d binds \u201cevery\u201d/\u201dall\u201d</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#inference","title":"Inference","text":"<p>notes: cf. compare, e.g. for example</p> <pre><code>graph TD\n  Inference --&gt; Entailment\n  Inference --&gt; Presuppositions\n  Inference --&gt; Implicature\n</code></pre> <p>any conclusion drawn from a set of propositions, from something someone has said and so on.</p>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#entailment","title":"Entailment","text":"<ul> <li>If A is true, then B is true.</li> </ul> <pre><code>Three girls were present. -&gt; More than two girls were present.\nThree girls were not present. kills More than two girls were present.\n</code></pre> <p>Cannot be cancelled</p> <pre><code># Three girls were present, but actually two girls come.\n#: semantically wrong\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#presupposition","title":"Presupposition","text":"<ul> <li>If A is uttered then B is taken for granted.</li> <li>survives negation</li> </ul> <pre><code>Jim regrets ignoring the first problem. -&gt; Jim has the first problem.\nJim does not regret ignoring the first problem. -&gt; Jim has the first problem.\n</code></pre> <p>cannot be cancelled</p> <pre><code># Jim regrets ignoring the first problem, but he does not have the first problem.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#implicature","title":"Implicature","text":"<ul> <li>If A is uttered, then B is assumed to be true.</li> <li>kills negation</li> <li>can be cancelled</li> </ul> <pre><code>Susan blushes when Jim looks at her, but she does not have a crush on him.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#compositionality","title":"Compositionality","text":"<p>Proposed by Noam Chomsky, the term compositionality entails three dimension. </p> <ul> <li>productivity<ul> <li>Key idea behind generative grammar. A relatively small number of combinatory rules may allow speakers to use a finite set of words to create a very large number of sentence.</li> </ul> </li> <li>generativity</li> <li>recursivity<ul> <li>coordination: I like puppies and ice cream and clear skies and good wine and\u2026</li> <li>embedding: Frank thinks Sam said you deny Sue is cute\u2026</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Definition%20Clearification/#principle-of-compositionally-of-meaning","title":"Principle of compositionally of meaning","text":"<p>The meaning of the whole is a function of the meaning of its parts and the way they are put together.: \u2026 is determined by\u2026</p>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/","title":"Logics & Formal Semantics","text":""},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#metalanguage","title":"Metalanguage","text":"<ul> <li>object language: the language we talk about</li> <li>metalanguage: the language that we use to talk about the object language</li> </ul> <pre><code>a. January has 31 days.\nb. *******January******* has 7 letters.\nb*. 'January' has 7 letters.\n</code></pre> <p>Liar sentence</p> <pre><code>(31) Sentence (31) is false.\n</code></pre> <p>solutions: (\u4e0d\u8003)</p> <ul> <li> <p>fuzzy logic      <code>x = NOT(x)     x = 1 - x     x = 0.5</code></p> </li> <li> <p>Alfred Tarski     paradox arises only in languages that are \u201csemantically closed\u201d.</p> </li> <li> <p>Arthur Prior     equivalent     <code>This statement is false.     This statement is true and this statement is false.</code></p> </li> <li> <p>Saul Kripke     Whether a sentence is paradoxical or not can be depend upon contingent facts.     <code>A majority of what Jones says about me is false.</code></p> <p><code>Smith is a big spender. Smith is soft on crime. Everything Smith says about me is true.</code></p> <p>If a statement's truth value is ultimately tied up in some evaluable fact about the world, that statement is \"grounded\". If not, that statement is \"ungrounded\". Ungrounded statements do not have a truth value. Liar statements and liar-like statements are ungrounded, and therefore have no truth value.</p> </li> <li> <p>Jon Barwise and John Etchemendy     \u201cdenial\u201d or \u201cnegation\u201d</p> </li> <li> <p>Dialetheism</p> <p>Dialetheism is the view that there are true contradictions. Dialetheism raises its own problems. Chief among these is that since dialetheism recognizes the liar paradox, an intrinsic contradiction, as being true, it must discard the long-recognized\u00a0principle of explosion, which asserts that any proposition can be deduced from a contradiction, unless the dialetheist is willing to accept trivialism \u2013 the view that\u00a0all propositions are true. Since trivialism is an intuitively false view, dialetheists nearly always reject the explosion principle. Logics that reject it are called\u00a0paraconsistent.</p> </li> <li> <p>Non-cognitivism</p> </li> <li>Bhartrhari\u2019s perspectivism</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#connectives-truth-and-truth-conditions","title":"Connectives, truth, and truth conditions","text":"<p>logic overview</p> <pre><code>graph TD\n  Logic --&gt; Logic_from_antiquity\n    Logic --&gt; Predicate_Logic\n    Logic_from_antiquity --&gt; Term_Logic\n    Logic_from_antiquity --&gt; Propositional_Logic\n</code></pre> <p>logic from antiquity: older</p> <p>predicate logic: newer</p> <p>Aristotle: term logic</p> <p>Gottlob Frege: predicate logic</p>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#history-of-logics","title":"History of Logics","text":"<ul> <li>term logic (syllogism logic)<ul> <li>Aristotle</li> <li>syllogism</li> </ul> </li> <li>propositional logic (predicate calculus, semantic, sentence, symbolic logic)<ul> <li>antiquity</li> <li>proposition: true and false</li> <li>logical words</li> </ul> </li> <li>predicate logic<ul> <li>gottlob frege</li> <li>meaning</li> <li>quantifier</li> </ul> </li> </ul> <p>Not applied for - question (?) - exclamation - modal: modal logic</p>  \ud83d\udcad ergo: therefore"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#term-logic","title":"Term logic","text":""},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#modus-ponens","title":"Modus Ponens","text":"<p>Means of putting, MP syllogism, affirming the antecedent</p> <pre><code>P(conditional statement): If it rain, I do not go to school.\nH: It rains.\nC: I do not go to class.\n</code></pre> <p>Formal fallacy: affirming the consequent. Abductive reasoning.</p> <pre><code>P: If it rains, I will not go to class.\nH: I do not go to class.\nC: * It rains.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#modus-tollens","title":"Modus Tollens","text":"<p>Means of carrying, MT syllogism, denying the consequent. </p> <pre><code>P: If it has not been cloudy, it does not rain.\nH: It rains.\nC: It has been cloudy.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#hypothetical-syllogism","title":"Hypothetical syllogism","text":"<p>principle of transitivity</p> <pre><code>P: If it rains, the soils goes wet. If the soil goes wet, the plants grow.\nH: It rains.\nC: The plants grow.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#disjunctive-syllogism","title":"Disjunctive syllogism","text":"<p>two premises and a conclusion</p> <pre><code>P: It either rains or its sunny.\nH: It rains.\nC: It is not sunny.\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#three-types-of-reasoning","title":"Three types of reasoning","text":"<ul> <li> <p>Deductive reasoning</p> <p>general to the particular. based on entailment</p> </li> <li> <p>Inductive reasoning</p> <p>particular to the general. empiricism</p> </li> <li> <p>Abductive reasoning</p> <p>formal fallacy. All dogs bark, Fido barks, Fido is a dog.</p> <p>Abductive reasoning allows inferring a as an explanation of b. As a result of this inference, abduction allows the precondition a to be abducted from the consequence b.</p> <p>Properly used, abductive reasoning can be a useful source of\u00a0priors in\u00a0Bayesian statistics.</p> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#propositional-logic","title":"Propositional logic","text":"<ul> <li>propositional 1: p</li> <li>propositional 2: q</li> <li>propositional 3: r</li> <li>negation: $\\neg$</li> <li>conjunction:</li> <li>disjunction:</li> <li>inclusive disjunction</li> <li>exclusive disjunction</li> <li>conditional:</li> <li>biconditional:</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#conditional-material-implication","title":"conditional, material implication","text":"<ul> <li>antecedent</li> <li>consequent</li> <li>\u2192, arrow.</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#biconditional","title":"biconditional","text":"<ul> <li>\u2194</li> <li>if and only if</li> <li>logical equivalence</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#de-swarts-formalizations","title":"De Swarts formalizations","text":"<ul> <li>$\\phi$ phi, any proposition</li> <li>$\\psi$ psi, any other proposition</li> <li>wff, well-formed formula</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#well-formed-formula","title":"Well-formed formula","text":"<ul> <li>Any atomic proposition is itself a wff.</li> <li>If $\\phi$ is wff, then $\\neg\\phi$ is wff.</li> <li>Two wff\u2019s conbinations under logical operators are a wff.</li> <li>No other are wff.</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#propositional-practice","title":"Propositional practice","text":"John is happy. p John is not happy. ~p John is happy or sad. p or q exlusive John is happy, not sad. p and ~q If John has eaten, John is happy. p -&gt; q If John has not eaten, John is not happy. ~p -&gt; ~q John is hungry or thirsty. p or q inclusive. John left before you did. p John is not hungry or thirsty. ~(p or q inclusive) &lt;-&gt; ~p and ~q John is not hungry and thirsty. ~(p and q) &lt;-&gt; ~p or ~q inclusive If John did not laugh, then John cried. ~p \u2192 q \u2194 p or q If John laughed, then John also cried. p \u2192 q \u2194 ~p or q inclusive John did not laugh, or John cried. ~p or q \u2194 p \u2192 q John laughed, or John cried and beat on the table. p and (q or r) \u2194 (p and q) or  (p and r) John is not happy, but rather sad. (scope of \u201cnot\u201d) ~p and q. * ~(p and q) John is not happy, or sad. ~(p and q) John is not happy, or John is sad. ~p or q John did not help us or hinder us. ~(p or q) \u2194 ~p and ~q John did not help us or John hinders us. ~p or q <ul> <li>Tautology: necessarily true</li> <li>Contradiction: necessarily false</li> <li>Contingent: possible</li> </ul> <pre><code>John is friendly or John is not friendly.\n</code></pre> p V_e ~p T T F F T T <pre><code>John is friendly and John is not friendly.\n</code></pre> p and ~p T F F F F T <pre><code>It is not the case that John is not friendly.\n</code></pre> ~ ~ p T F T F T F <p>contingent.</p> <pre><code>It is not the case that John is hungry or John is not grumpy.\n</code></pre> ~( p or ~q F T T T F T T F F F T T T F F F"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#material-implication","title":"Material implication \u2192","text":"<p>converse: q\u2192p. affirming the consequent</p> <p>inverse: ~p\u2192~q. denying the antecedent</p> <p>contrapositive: ~q\u2192~p. modus tollens</p> <p>given p\u2192q.</p> <ul> <li>Sufficient condition: if p is True, p is the necessary condition for q so q must be True.</li> <li>Necessary condition: if q is True, q is not a necessary condition for p so p may or may not be True.</li> </ul> <p>Although it was extremely cold, Sally did not stay indoors.</p> <pre><code>~q-&gt;p\np and ~q\n</code></pre> <p>We get a holiday, or we protest.</p> <pre><code>~p-&gt;q\np or q\n</code></pre> <p>Jone said that Jane helped him.</p> <pre><code>p\np and q\n</code></pre> <p>John\u2019s sister burped</p> <pre><code>p: John has a sister. presupposition, assume it true\nq: This sister burped.\np\np and q\n</code></pre> <p>John arrives before Jane left</p> <pre><code>p before q\n</code></pre> <p>John did not arrive before Jane left.</p> <pre><code>~p before q\np ~before q\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#predication-and-quantification","title":"Predication and Quantification","text":"<p>universal quantifier: every, each, all, any, only</p> <p>existential quantifier: a, some, there is $\\exist$, for all $\\forall$</p> <p>predicate, argument</p> <p>John may like Sally.</p> <pre><code>predicate: may like\n</code></pre> <p>John has a crush on Sally.</p> <pre><code>predicate: has a crush on\n</code></pre> <p>Frank is the father of Susan.</p> <pre><code>predicate: is the father of\n</code></pre> <p>Frank is Susan\u2019s father.</p> <pre><code>predicate: is...'s father\n</code></pre> <p>Adjunct: if, probably, means, of course, early</p> <p>Valent, empty place holder: formal subject</p>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#collective-and-distributive-readings","title":"Collective and distributive readings","text":"<pre><code>Jogn and Molly ate a pizza.\np: one pizza, ate one together.   distributive\np and q: two pizzas, each ate a pizza.  collective\n</code></pre> <pre><code>Cinthia and Sam have saved 100 dollars.\np: together 100 dollars\np and q: 200 dollars\n</code></pre> <p>Content verb is a predicate, but functional verbs are not</p> <p>John obviously spoke with Jane because he had to.</p> <pre><code>predicate: spoke with\nargument: John, Jane\nadjuncts: obviously, because he had to.\n</code></pre> <p>If I get a chance, I will probably try to avoid the mistake.</p> <pre><code>predicate: will try to \nargument: I, avoid the mistake\nadjuncts: If I get a chance, probably\n</code></pre> <p>John performed Jill\u2019s operation first.</p> <pre><code>\n</code></pre> <p>The person who talk loudly is Jim\u2019s father.</p> <pre><code>predicate: is someone's father\nargument: the person who talk loudly, Jim\nadjunct: \n</code></pre> <p>the talking loudly person</p> <pre><code>predicate: talking\nargument: person\nadjunct: loudly\n</code></pre> <p>predicate: the nodes that are connected in SUD parsing tree</p> <p>universal dependency (UD)</p> <p>syntactic-universal dependency (SUD)</p> <pre><code>graph TD\n  Primitive_units_within_propositions --&gt; Predicates\n  Primitive_units_within_propositions --&gt; Arguments\n    Arguments --&gt; individuals_Terms\n    individuals_Terms --&gt; constants\n    individuals_Terms --&gt; variables\n</code></pre> <p>lexical  predicates vs. syntactic predicates</p> <ul> <li>lexical: content verbs, adjectives, common nouns, some prepositions</li> <li>syntactic: content verbs plus functional elements, adjective plus functional elements, predicate expressions (nouns, prepositions, subordinators, plus functional elements)</li> </ul> <p>individual constants vs. individual variables</p> <ul> <li>names and definite descriptions: John, the first one, the idea</li> <li>quantified phrases: every man, some idea, no paper</li> </ul> <p>e.g. We think John likes Susan.</p> <pre><code>T(w, Lj,s)\n</code></pre> <p>Types of predicates:</p> <ul> <li>converse: husband-wife, above-below, precede-follow</li> <li>symmetric: be the roommate of, be married to, be related to</li> <li>reflexive: see oneself, praise oneself</li> <li>transitive: older than, be north of, be a sibling of</li> </ul> <p>e.g. Monica hid her bicycle.</p> <pre><code>x hide y: Hx,y\nMonica: m\nher bicycle: b\nHm,b\n</code></pre> <p>e.g. Monica did not hide her bicycle.</p> <pre><code>x hide y: Hx,y\nMonica: m\nher bicycle: b\n~Hm,b\n</code></pre> <p>e.g. Monica laughed and cried.</p> <pre><code>Monica: m\nlaugh: L()\ncry: C()\nLm and Cm\n</code></pre> <p>e.g. Jim sent Monica his dog.</p> <pre><code>Sj,m,d\n</code></pre> <p>e.g. William did not help or hinder Mike.</p> <pre><code>~ (H1w,m or H2w,m) \n</code></pre> <p>e.g. Jennifer promise to help.</p> <pre><code>P(j, Hj)\n</code></pre> <p>e.g. Jennifer did not promise to help.</p> <pre><code>~P(j,Hj)\n</code></pre> <p>e.g. Jennifer promise to not laugh.</p> <pre><code>P(j,~Lj)\n</code></pre> <p>e.g. Mike claimed he wanted to help.</p> <pre><code>C(m, W(m/x, Hm/x))\n\nm: Mike\nx: maybe some other\n</code></pre> <p>e.g. John asked Mandy to stop laughing.</p> <pre><code>A(j, m, S(m, Lm))\n</code></pre> <p>e.g. John and Larry called Molly.</p> <pre><code>Cj,m and Cl,m\nC(j and l, m)\n</code></pre> <p>e.g. Molly did not call John and Larry.</p> <pre><code>~C(m, j) and ~C(m, l)\n~C(m, j and l)\n~C(m, j) or ~C(m, l)\n</code></pre> <p>entailment: (universal instantiation) </p> <p>every dog barks \u2192 if something is a dog, then it is a dog.</p> <p>Universal quantification</p> <p>$\\forall$x (Dx \u2192 Bx)</p> <p>D = (d1, d2, d3,\u2026)</p> <p>$\\forall$x (Dx \u2192 Bx)= (Bd1 and Bd2 and Bd3, \u2026.)</p> <p>Existential quantification</p> <p>$\\exist$x (Dx and Bx)</p> <p>D = (d1, d2, d3,\u2026)</p> <p>$\\exist$x (Dx and Bx) = (Bd1 or Bd2 or Bd3, \u2026.)</p> <p>e.g. Every cat barfed.</p> <pre><code>\\forall x (Cx -&gt; Bx)\n</code></pre> <p>e.g. The cat barfed.</p> <pre><code>Bc\n</code></pre> <p>e.g. Bill fed cat.</p> <pre><code>\\forall x (Cx -&gt; Fb,x)\n</code></pre> <p>e.g. Some dog barked at Fred.</p> <pre><code>\\exist x (Dx and Bx,f)\n</code></pre> <p>e.g. Fred scolded some dog.</p> <pre><code>\\exist x (Dx and Sf,x)\n</code></pre> <p>e.g. Fred and Susan avoid some dog.</p> <pre><code>\\exist x (Dx and Af,x and As,x)\n\\exits x (Dx and Af,x) and \\exist y (Dy and Af,s)\n</code></pre> <p>e.g. No dog barks.</p> <pre><code>\\forall x (Dx -&gt; ~Bx)\n~\\exist x (Dx and Bx)\n</code></pre> <p>e.g. Bill fed no dog.</p> <pre><code>~\\exist x (Dx and Fb,x)\n\\forall x (Dx -&gt; ~Fb,x)\n</code></pre> <p>e.g. No dog barked at Susan or chased Fred.</p> <pre><code>~\\exist x ((Dx and (Bx,s or Cx,f))\n\\forall x ((Dx -&gt; (~Bx,s and ~Cx,f))\n\\forall x ((Dx -&gt; ~(Bx,s or Cx,f))\n</code></pre> <p>Scope ambiguity</p> <p>e.g. Some boy kissed every girl.</p> <pre><code>\\exist x \\forall y (Bx and (Gy -&gt; Kx,y)) = \\exist x(Bx and \\forall y (Gy -&gt; Kx,y))\n\\forall y \\exist x (Gy -&gt; (Bx and Kx,y)) = \\forall y (Gy -&gt; \\exist x (Bx and Kx,y))\n</code></pre> <p>Every boy kissed some girl.</p> <pre><code>\\forall x (Bx -&gt; \\exist (Gy and Kxy)) &lt;=&gt; \\forall x \\exist y (Gy and Kxy)\n</code></pre> <p>Every students did not laugh.</p> <pre><code>\\forall x (Sx -&gt; ~Lx) &lt;=&gt; ! \\exist x (Sx and Lx)\n~\\forall x (Sx -&gt; Lx) &lt;=&gt; \\exist (Sx and ~Lx)\n</code></pre> <p>Not every student laughs.</p> <pre><code>~\\forall x (Sx -&gt; Lx) &lt;=&gt; \\exist (Sx and ~Lx)\n\n</code></pre> <pre><code>graph TD\n  laughed --&gt; student\n    student --&gt; /every\n    /every --&gt; not\n</code></pre> <p>each studnet did not laugh.</p> <pre><code>\\forall x (Sx -&gt; ~Lx) \n~\\forall x (Sx -&gt; Lx)\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#polarity-item","title":"Polarity item","text":"<p>any: negative polarity item</p> <p>John did not pass every exam.</p> <pre><code>~\\forall x (Ex -&gt; Pj,x) &lt;=&gt; \\exist x (Ex and Pj,x)\n\\forall x (Ex -&gt; ~Pj,x)\n</code></pre> <p>John did not pass any exam.</p> <pre><code>\\forall x (Ex -&gt; ~Pj,x)\n</code></pre> <ul> <li>universal quantifier: all, every, each, any</li> <li>existential: some, a/an, one, there is</li> </ul> <p>e.g. </p> <p>Jack saw a rat.</p> <pre><code>\\exist x (Rx and Sj,x) \n</code></pre> <p>Jack is a rat.</p> <p>the quantifier is in the predicate but not the argument. here rat is a constant.</p> <pre><code>Rj\n</code></pre> <p>Jack knows no genius.</p> <p>use not exist to render \u201cno\u201d</p> <pre><code>~\\exist x (Gx and Kj,x)  &lt;=&gt; \\forall x (Gx -&gt; ~Kj,x)\n</code></pre> <p>Jack is no genius. &lt;=&gt; Jack is not a genius.</p> <pre><code>~Gj\n</code></pre> <p>These problems are difficult.</p> <pre><code>Dp\n</code></pre> <p>These problems are difficult ones.</p> <pre><code>Dp\n</code></pre> <p>All the problems are difficult.</p> <pre><code>\\forall x (Px -&gt; Dx)\n</code></pre> <p>These problems are all the problems.</p> <pre><code>Ap\n</code></pre> <p>These problems are not all the problems.</p> <pre><code>~Ap\n</code></pre> <p>Jack is our plumber.</p> <pre><code>Pj\n</code></pre> <p>Our plumer is Jack. (has presupposition)</p> <pre><code>Pj\n</code></pre> <p>Everything counts.</p> <p>whether thing includes animate and inanimate.</p> <pre><code>\\forall x (Cx)\n\\forall x (Tx -&gt; Cx)\n</code></pre> <p>Everybody counts.</p> <pre><code>*\\forall x (Cx)\n\\forall x (Px -&gt; Cx)\n</code></pre> <p>predicates</p> <ul> <li>content words</li> <li>adjectives</li> <li>predicative expressions (common nouns, adjectives, preposition, subordinators)</li> <li> <p>some prepositions.</p> <p>The present under the tree is big. (prepositions that gives location)</p> </li> <li> <p>argument nouns.</p> </li> </ul> <p>common nouns</p> <ul> <li>John is a teacher. Tj</li> <li>Every teacher was present. \\forall x (Tx \u2192 Px)</li> <li>The teacher was present. Pt</li> </ul> <p>content verbs are the core of syntactic predicates</p> <p>adjectives are most always the core of syntactic predicates.</p> <p>e.g. Mike\u2019s wife thinks Mikes if lazy.</p> <ul> <li>thinks (Mike\u2019s wife, Mike is Lazy) - propositional</li> <li>\u2018s (Mike, wife) \u2018Mike has a wife\u2019 - presuppositional: does not affect the truth value</li> <li>is lazy (Mike) - intensional: does not affect the truth value</li> </ul> <p>predicates inside individual constants are presuppositional</p> <p>A thin man was present.</p> <ul> <li>was present (a thin man)</li> <li>thin (a man)</li> <li>\\exist x (Mx and Tx and Px)</li> </ul> <p>predicates inside \u2026 .are propositional</p> <p>e.g. Every barking is harmless</p> <p>has true or false impact on the truth</p> <pre><code>\\forall x ((Dx and Bx) -&gt; Hx)\n</code></pre> <p>this proposition has to show up in the predicate</p> <p>The barking dog is harmless.</p> <pre><code>Hd\n</code></pre> <p>the presupposition does not show in the predicate</p> <p>John avoids every dog he sees.</p> <pre><code>\\forall x ((Dx and Sj,x) -&gt; Aj,x)\n</code></pre> <p>John said every dog barks.</p> <p>intensional</p> <pre><code>Sj\nS(j,\\forall x (Dx -&gt; Bx)) \nSj,I  ; I for intensional argument predicate\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#adjunct-predicates","title":"Adjunct predicates","text":"<p>Jane probably teased Sam last night</p> <ul> <li>teased (Jane, Sam)</li> <li>probably (Jane, teased Sam last night) - model adverbs</li> <li>last night (Jane teased Sam) - temporal adjuncts</li> </ul> <p>John arrived drunk.</p> <ul> <li>arrived (John)</li> <li>drunk (John)</li> </ul> <p>Jim burped twice.</p> <p>twice: propositional or presuppositional</p> <p>Susan did not cheat yesterday.</p> <p>Mary stayed because John stayed.</p> <ul> <li>stayed (Mary)</li> <li>stayed (John)</li> <li>because (Mary stayed, John stayed)</li> </ul> <p>Mary did not stay because John stayed</p> <ul> <li>~stay (Mary)</li> <li>~because ()</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#restricted-quantification","title":"restricted quantification","text":"<p>Every boy was hungry</p> <pre><code>\\forall x: Bx(Hx)\n</code></pre> <p>Some boy was hungry.</p> <pre><code>\\exist x: Bx(Hx)\n</code></pre> <p>Every cat barfed.</p> <pre><code>\\forall x: Cx(Bx)\n</code></pre> <p>Bill fed every cat.</p> <pre><code>\\forall x (Cx, Fb,x)\n\\forall x: Cx(Fb,x)\n</code></pre> <p>Some dog barked at Fred.</p> <pre><code>\\exist x (Dx, Bx,f)\n\\exist x: Dx(Bx,f)\n</code></pre> <p>Fred and Susan avoid some dog.</p> <pre><code>\\exist x(Dx and (Af,x and As,x))\n\\exist x: Dx (Af,x and Af,x)\n</code></pre> <p>No dog barks.</p> <pre><code>~\\exist x (Dx and Bx) &lt;=&gt; ~\\exist x: Dx (Bx)\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#formal-predicate-semantics","title":"Formal Predicate Semantics","text":"<pre><code>graph TD\n  Semantic_Rules --&gt; Model\n  Semantic_Rules --&gt; Valuation_Function\n    Model --&gt; Universe_of_Discourse\n    Model --&gt; Interpretation_Function\n    Universe_of_Discourse --&gt; entities\n</code></pre> <ul> <li>model M:<ul> <li>Universe of discourse in which all constants have clearly assigned values</li> <li>A limited part of a world (real or imagined), a discourse context</li> <li>Clearly defined</li> <li>Values of linguistics expressions known</li> </ul> </li> <li>universe/domain of discourse U/D<ul> <li>Constants all the constants in M (set members)</li> </ul> </li> <li> <p>interpretation function I</p> <ul> <li>Assign a value to an individual constant</li> </ul> <p><code>I(name) \u2192 meaning</code></p> </li> <li> <p>assignment function g[x/e]</p> <ul> <li>Assign a value to an individual variable</li> <li>g iterates all the variables and assigns the value</li> <li>g() := for x in domain of e</li> </ul> <p><code>g(type of object) -&gt; meaning</code></p> </li> <li> <p>valuation function V</p> <ul> <li>Assigns a value 1 or 0 to a wffs. (propositions)</li> </ul> <p><code>V(p) = 1/0 V(Bs) = 1/0</code></p> </li> <li> <p>[[\\alpha]]^M the denotation of \\alpha wrt M (same as interpretation function I)</p> <p><code>[[name]]^M -&gt; meaning</code></p> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Logics%20%26%20Formal%20Semantics/#relation","title":"Relation","text":"<ul> <li>if t is a constant, [[]]^{M,g} = I(t)</li> <li>if t is a variable, [[]]^{M,g} = g(t)</li> </ul>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/","title":"Scope Ambiguity","text":""},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#scope-ambiguity","title":"Scope Ambiguity","text":""},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#scope-and-anaphora","title":"Scope and Anaphora","text":"<p>antecedent vs. postcedent</p> <p>anaphor vs. cataphor</p> <p>Predicate logic is suited to capture natural language meaning</p> <p>allow recursion = recursivity</p> <p>two sources of recursion</p> <ul> <li>coordination: john likes cats, dogs, beer</li> <li>embedding: John said that Mary knws that Bill thinks that Jane claims that</li> </ul> <pre><code>some boy kissed every girl.\n\nEvery girl was kissed by some boy.\n</code></pre> <pre><code>Someone mentioned tehy called everyone.\n\n\\forall x: Px\\forall y(M(x, Cxy))\n\n</code></pre> <p>linear order: negative polarity item</p> <pre><code>graph TD\n  DS -.Transformation.-&gt; SS\n    SS -.send off.-&gt; PF\n    SS -.send off.-&gt; LF\n    PF -.acoustic representation.-&gt; SS\n    LF -.semantic interpretation.-&gt; SS\n</code></pre> <p>Transformation: </p> <ul> <li>Jane laughed at Bill</li> <li>Bill was laughed at by Jane</li> </ul> <p>CALLOUT: annotation, connotation and denotation</p> <ul> <li> <p>annotation</p> <ul> <li>a critical or explanatory commentary or analysis</li> <li>a comment added to a text</li> <li>the process of writing such comment or commentary</li> <li>(computing) metadata added to a document or program</li> <li>(genetics) information relating to the genetic structure of sequences of bases</li> </ul> </li> <li> <p>connotation: intension.</p> <ul> <li> <p>A meaning of a word or phrase that is suggested or implied, as opposed to a denotation, or literal meaning. A characteristic of words or phrases, or of the contexts that words and phrases are used in.</p> <p>The\u00a0connotations\u00a0of the phrase \"you are a dog\" are that you are physically unattractive or morally reprehensible, not that you are a canine.</p> </li> <li> <p>A technical term in logic used by J. S. Mill and later logicians to refer to the attribute or aggregate of attributes connoted by a term, and contrasted with\u00a0denotation\u00a0.</p> <p>The two expressions \"the morning star\" and \"the evening star\" have different\u00a0connotations\u00a0but the same denotation (i.e. the planet Venus).</p> </li> </ul> </li> <li> <p>denotation</p> <ul> <li>its explicit or direct meaning, as distinguished from the ideas or meanings associated with it or suggested by it. Simply put, a word\u2019s\u00a0denotation\u00a0is what that word\u00a0means\u00a0or directly represents.</li> </ul> </li> </ul>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#solution-for-scope-ambiguity","title":"Solution for scope ambiguity","text":"<p>Quantifier-raising  - NC RM - syntactic structure comes before the semantic structure - The movement we make in SS to remove ambiguity in DS is called quantifier-raising. - take the quantifier to the higher position to show the scope</p> <p>Quantifier-in - Montague grammar - The derivational illustration is called quantifier-in. - each predicate take an argument once a time</p> <p>Quantifier storage - Cooper storage - semantic ambiguity not represented in syntactic structure - semantic representation in which scope ambiguities are obtained without special syntactic rules</p>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#quantifier-in","title":"Quantifier-in","text":"<p>interrogative: asking a question</p> <pre><code>which woman does every man love?\n</code></pre> <p>which scopes over every.</p>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#scope-ambiguity_1","title":"Scope ambiguity","text":"<p>e.g.  some boy did not laugh.</p> <pre><code>\\exist x (Boy(x) and ~Laugh(x))\n~\\exist x (Boy(x) and Laugh(x))\n</code></pre> <p>some boy kissed no girl.</p> <pre><code>\\exist x (Boy(x) and ~\\exist y (Girl(y) and Kiss(x, y)))\n~\\exist y (Girl(y) and \\exist x (Boy(x) and Kiss(x, y))): there was no girl kissed by a boy\n</code></pre> <p>every boy kissed no girl.</p> <pre><code>\\forall x (Boy(x) and ~\\forall y(Girl(y) and Kiss(x, y)))\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#deictic","title":"Deictic","text":"<p>No boy said he was hungry.</p> <p>No boy was present. He was outside instead.: \u201che\u201d is trying to refer to \u201dno boy\u201d but outside the scope.</p> <p>pronoun $\\sub$ anaphora</p>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#discourse-anaphora","title":"Discourse Anaphora","text":"<p>e.g. </p> <pre><code>Every student was present and she was interested.\n</code></pre> <p>every: scopes over \u201cEvery student was present\u201d</p> <p>every: an indefinite quantifier. \u201cshe\u201d\u2019s antecedent is not clear</p> <p>\u201cshe\u201d is hardly bound by the antecedent. \u201cshe\u201d is free * ungrammatical: \u4e0d\u5408\u8bed\u6cd5\u7684, syntactic</p>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#infelicitous-semantic-fit-the-context","title":"infelicitous: \u4e0d\u5408\u9002\u7684, semantic, fit the context","text":"<ul> <li>sentence pronoun: within the same clause</li> <li> <p>discourse pronoun: in separate clauses</p> </li> <li> <p>sentence quantifier:     <code>Some boy said he was hungry.     No boy said he was hungry.</code></p> </li> <li> <p>discourse quantifier:     <code>Some boy was present; he was hungry.     #No boy was present; he was hungry.   // he is free</code></p> </li> <li> <p>coreference     individual constants     <code>Fred thought he was the the best</code></p> </li> <li> <p>binding     individual variables     <code>Every student thinks he/she is the best</code></p> </li> </ul> <p>So we may conclude the following rules for e-type anaphora. BUT this part has NOT been verified with any authority. Do NOT take them as given truths during exams.</p> <ul> <li>F: universal quantifier + singular pronoun</li> <li>T: universal quantifier + plural pronoun</li> <li>F: negated quantifier + singular pronoun</li> <li>T: negated quantifier + plural pronoun, semantically plural but grammatically singular</li> <li>T: existential quantifier + singular pronoun</li> </ul> <p>e.g. No boy thinks that he has a chance.</p> <pre><code>~\\exist x(Boy(x) and Think(x, Has-a-chance(x)))\n</code></pre> <p>A particular boy said he wanted to kiss every girl. He then did it.</p> <pre><code>\\exist !x(Bx and  W(x, K(x, \\forall y(Gy -&gt; K(x, y))))) and K(x, y)\n</code></pre>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#donkey-anaphora","title":"Donkey anaphora","text":"<p>if a farmer owns a donkey, he beats it.</p> <pre><code>* \\exist x (Fx and \\exist y (Dy and O(x, y))) -&gt; B(x, y)\n\\forall x \\forall y (Fx and Dy and O(x, y) -&gt; B(x, y))\n</code></pre> <p>= every farmer who owns a donkey beats it.</p> <pre><code>\\exist x(Fx and \\exist y (Dy and O(x, y)) -&gt; B(x, y))  // y is free\n</code></pre> <p>\u2757\u2757\u2757</p> <p>A donkey sentence is such that an expected existential is interpreted as universal taking wide scope.</p> <p>donkey pronoun can be: it, him, they (can also be plural forms) </p> <p>\u201ca\u201d: generic indefinite</p> <pre><code>A woman is a difficult thing to please.\n</code></pre> <p>[Every farmer [who owns a donkey] beats it.]</p> <p>universal wide scope: it scopes more over the relative clause</p> <p>The problem - Existential with narrow scope - interpreted as universal with wide scope - in conditional clauses - in restriction of every</p> <p>Conclusion - the machinery of predicate logic is broken - cannot capture meaning of natural language</p> <p>If a student tries, she passes the exam.</p> <pre><code>(\\exist x(Sx and Tx)) -&gt; Py   ; y is free\n\\exist x((Sx and Tx)) -&gt; Py)\n</code></pre> <p>interpretation</p> <pre><code>\\forall x((Sx and Tx) -&gt; px)\n</code></pre> <p>Solutions for donkey anaphora:</p> <ul> <li> <p>E-type anaphora</p> <ul> <li>Gareth Evans, 1970s, philosopher, university of Oxford, logic, philosophy of mind</li> <li>pronoun outside the scope of their binder</li> <li> <p>initial examples     ```     A student came in. She had a question about the exam.     she = the student came in</p> <p>Bill owns some sheep and Max vaccinates them. them = the sheep Bill owns. E-type pronoun, some sheep scopes over the first half ```</p> </li> <li> <p>If a student likes Copenhagen, she is happy.     <code>she = for every case we examine, the student is</code></p> </li> <li> <p>every student who reads a semantic paper likes it.     <code>Bill owns a cat. Max takes care of it.     Bill is a cat-owner. #Max takes care of it.</code></p> </li> </ul> </li> <li> <p>DRT (Dynamic binding theory)</p> <ul> <li>discourse anaphora and donkey pronouns</li> <li>intermediate level</li> <li>Irene Heim (1982) and Hans Kamp (1981)</li> <li>Discourse Representation Theory (DRT)<ul> <li>embedding conditions</li> <li>language of boxes</li> <li>boxes constantly updated</li> <li>embedded boxes in accessible</li> </ul> </li> </ul> </li> <li> <p>Unselective binding     example of the subject is \u2018unselectively bound\u2019 by a special \u2018generic operator.     <code>Dogs bark.     A dog barks.</code></p> </li> </ul> <p>Reference: Unselective Binding</p>"},{"location":"Linguistics_Notes/Semantics/Scope%20Ambiguity/#chapter-6-in-short-discoursedonkey-anaphora","title":"Chapter 6 in short: Discourse/Donkey Anaphora","text":"<p>(\u52a0\u7c97\u7684\u662fDonkey anaphora\u548cE-type anaphora\u7684\u533a\u522b)</p> <p>Discourse: basic unit of interpretation</p> <ul> <li>Dynamic theory of meaning: look beyond the meaning of individual sentences and determine the way they are pieced together to make discourse</li> <li>discourse anaphora: anaphora in sequence of sentences (instead of single sentence)</li> <li> <p>Donkey sentence: is such that an expected existential is interpreted as universal taking wide scope. / sentences that contain a pronoun with clear meaning but whose syntactical role in the sentence poses challenges to grammarians (wikipedia)</p> <ul> <li>universal: each, every, all, not all, not every</li> <li>existential: a, one, some, no</li> <li> <p>e.g.     <code>every farmer who owns a donkey beats *it*.     it: (corresponding to the) existential (\"a\") but interpreted as universal</code></p> <p><code>every police officer who arrested a murder insulted *him*. him</code></p> <p><code>every farmer who owns some sheep cleans *them*. them</code></p> </li> </ul> </li> <li> <p>donkey anaphora = donkey pronoun: it, him, they (can also be plural forms)</p> </li> <li> <p>Analysis of donkey anaphora: Montague grammar</p> <p>e.g. </p> <p><code>\\forall x(Farmer(x) and \\exist y (Donkey(y) and Owns(x,y)) -&gt; Beat(x,y))</code></p> </li> </ul> <p>Anaphoric relations in sentence and discourse - E-type anaphora: pronoun outside the scope of binder, not bound, content of pronoun reconstructed, reconstruction based on context     - in separate sentences</p> <pre><code>    ```\n    A student came in. *She*(the student came in) had a question about the exam.\n    ```\n\n- in the same sentence but outside the scope\n    ```\n    If a student likes Copenhagen, *she*(for every case we examine, the student in question who likes Copenhagen) is happy.\n    ```\n\n- problem of compound: antecedent must appear as a noun?\n    ```\n    Bill owns a cat. Max takes care of it.\n    Bill is a cat-owner. # Max takes care of it.\n    ```\n</code></pre> <ul> <li>unselective binding + Discourse Representation Theory (DRT)<ul> <li>embedded conditions</li> <li>language of boxes, boxes constantly updated</li> <li>Accessibility: the antecedent to be in a box \u2018as high as\u2019(same box or left box) or \u2018higher than\u2019 the discourse referent for the pronoun</li> <li>\u21d2 binds all left variables. unselective quantification over all the variables. unselective binding</li> </ul> </li> <li>dynamic binding<ul> <li>TODO</li> </ul> </li> </ul> <p>Anaphora resolution - TODO</p>"},{"location":"Linguistics_Notes/Syntax/Chomsky%E2%80%99s%20Universal%20Grammar/","title":"Introduction","text":"<p>Syntax\u7684\u610f\u4e49\u5728\u4e8e\u627e\u5230\u4e00\u79cdgrammar\uff0c\u80fd\u591f\u751f\u6210\u67d0\u79cd\u8bed\u8a00\u4e2d\u7684\u6240\u6709\u53e5\u5b50\u3002</p> <p>Grammar\u662f\u57fa\u4e8e\u89c4\u5219\u7684\uff0c\u4e0d\u80fd\u7528high order of statistical approximation to English\u6765\u66ff\u4ee3\u3002</p>"},{"location":"Linguistics_Notes/Syntax/Chomsky%E2%80%99s%20Universal%20Grammar/#basic-linguistics","title":"Basic Linguistics","text":"<p>DFA &amp; Regular language</p> <p>\u8c13\u8bcd\u903b\u8f91\u3002\u4f46\u6211\u4eec\u4e0d\u5173\u5fc3\u5176\u4e2d\u7684\u8bed\u4e49\uff0c\u53ea\u9700\u5173\u5fc3CFG\u7684\u5f62\u5f0f\u3002</p>"},{"location":"Linguistics_Notes/Syntax/Chomsky%E2%80%99s%20Universal%20Grammar/#phrase-structure-limitation","title":"Phrase Structure &amp; Limitation","text":"<p>\u81ea\u7136\u8bed\u8a00\u7684CFG\uff08\u4ee5\u82f1\u8bed\u4e3a\u4f8b\uff09\u6784\u6210\u8bed\u6cd5\u7684\u57fa\u7840\u90e8\u5206\u3002</p> <p>\u4f46\u8fd9\u6837\u63cf\u8ff0\u81ea\u7136\u8bed\u8a00\u7684\u5de5\u5177\u8fd8\u662f\u4e0d\u80fd\u751f\u6210\u6240\u6709\u5408\u7406\u7684\u53e5\u5b50\uff0c\u6545\u5f15\u5165a more powerful model combining phrase structure and grammatical transformation\uff0c\u5f97\u5230\u8f6c\u6362-\u751f\u6210\u6587\u6cd5\u3002</p>"},{"location":"Linguistics_Notes/Syntax/Chomsky%E2%80%99s%20Universal%20Grammar/#on-the-goals-of-linguistic-theory","title":"On the Goals of Linguistic Theory","text":"<p>\u4ece\u4e00\u822c\u8bed\u6cd5\u4e2d\u5f52\u7eb3\u51faUG\u7406\u8bba\uff0c\u5bf9UG\u7684\u671f\u671b\u7531\u5f3a\u81f3\u5f31\u4e3a\uff1a</p> <ul> <li>\u80fd\u901a\u8fc7UG\u81ea\u52a8\u5316\u5730\u4ece\u8bed\u6599\u5e93\u4e2d\u5f52\u7eb3\u8bed\u6cd5</li> <li>\u80fd\u7528UG\u81ea\u52a8\u5316\u5224\u5b9a\u4e00\u4e2a\u8bed\u6cd5\u662f\u5426\u6700\u4f18\u5730\u603b\u7ed3\u4e86\u8bed\u6599\u5e93\u4e2d\u7684\u53e5\u5b50</li> <li>\u80fd\u7528UG\u81ea\u52a8\u5316\u5224\u5b9a\u4e24\u4e2a\u8bed\u6cd5\u4e2d\u54ea\u4e2a\u66f4\u7b26\u5408\u8bed\u6599\u5e93\u4e2d\u7684\u53e5\u5b50</li> </ul>"},{"location":"Linguistics_Notes/Syntax/Chomsky%E2%80%99s%20Universal%20Grammar/#the-explanatory-power-of-linguistic-theory","title":"The Explanatory Power of Linguistic Theory","text":"<p>\u5e94\u8be5\u7814\u7a76competence\uff0c\u800c\u975eperformance</p>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/","title":"UD and SUD","text":"<p>In full spelling, Universal Dependency gammar and Surface Syntax Universal Dependency grammar.</p>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/#tools","title":"Tools","text":"<p>AllenNLP Demo CoreNLP Tool</p>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/#concepts","title":"Concepts","text":"<ul> <li>UD: universal dependency</li> <li>SUD: (surface) syntactic universal dependency</li> </ul>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/#ud","title":"UD","text":"<p>Dependency grammar\u00a0(DG) is an approach to the study of the syntax and grammar of natural languages that is quite distinct from\u00a0phrase structure grammar\u00a0(PSG), which is also known as\u00a0constituency grammar. The modern history of DG begins with\u00a0Lucien Tesni\u00e8re's major oeuvre (1959), whereas the modern history of PSG begins arguably with\u00a0Noam Chomsky's first prominent work (1957).</p> <p>DG views linguistic structures in terms of a\u00a0one-to-one mapping\u00a0of atomic linguistic units to the nodes in structure, whereas PSG assumes a\u00a0one-to-one-or-more mapping. The distinction is clearly visible when one compares the tree structures. The next trees are taken from the\u00a0Wikipedia article on DG:</p> <p></p>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/#sud","title":"SUD","text":"<p>[Surface Syntactic Universal Dependencies (SUD) | SUD](https://surfacesyntacticud.github.io/ SUD is an annotation scheme for syntactic dependency treebanks, and has a nearly perfect degree of two-way convertibility with the Universal Dependencies scheme (UD). Contrary to UD, it is based on syntactic criteria (favoring functional heads) and the relations are defined on distributional and functional bases.</p> <p></p>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/#general-principles-of-sud","title":"General principles of SUD","text":"<ul> <li>The definition of relations is based on syntactic positions rather than semantic positions.</li> <li>Functional heads (instead of lexical heads): The head of a unit is the distributional head, that is, the element that control the distribution of the unit.</li> <li>SUD relations are organized in taxonomic hierarchy: A relation that is the daughter of another one inherits its syntactic properties with the addition of specific properties. Indeed, sometimes, we cannot take into account all possible distinctions, either because of the conversion from different treebanks not containing enough information, or because a sentence does not allow to make a clear decision.</li> <li>It is possible to distinguish between\u00a0arguments\u00a0and\u00a0modifiers: Although this distinction involves semantic criteria (an argument of a lexical unit L is an obligatory participant in the semantic description of L), we consider that it is hard to avoid, because especially for verb dependents, most language have special functions.</li> <li>A\u00a0multiple coordination, such as\u00a0John, Mary and Peter, is analyzed as a chain instead of a bouquet: One of the main argument for the chain-analysis is that it reduces the dependency length.</li> </ul>"},{"location":"Linguistics_Notes/Syntax/UD%20and%20SUD/#specific-sud-relations","title":"Specific SUD relations","text":"<p>SUD has 4 specific syntactic relations and a few extended relations: - subj - udep - comp     - comp:aux     - comp:cleft     - comp:obj     - comp:obl     - comp:pred - mod</p>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/","title":"X-bar theory","text":"<p>\u751f\u6210\u53e5\u6cd5\u548c\u6210\u5206\u53e5\u6cd5\u4e4b\u95f4\u7684\u533a\u522b</p> <pre><code>[The big book of poems with the blue cover] is on the table.\n</code></pre> <p>\u6210\u5206\u53e5\u6cd5\u505a\u51fa\u6765\uff0csubject\u662f\u4e00\u4e2a\u9ad8\u5ea6\u4e3a1\u7684\u6811</p> <p>\u53e5\u5b50\u4e4b\u95f4\u7684\u6210\u5206\u901a\u8fc7\u4e24\u4e24\u7ec4\u5408\u8fd8\u80fd\u505a\u51fa\u65b0\u7684\u9ad8\u5ea6</p> <p>one-replacement</p> <ul> <li>The big one with the blue cover is on the table</li> <li>The big one of poems with the blue cover is on the table</li> <li>The big book of poems with the blue one is on the table</li> <li>I bought the big book of poems with the blue cover but not that one</li> <li>I bought the book of poems with the blue cover but not that one with the red cover</li> </ul> <p>\u7528one-replacement\u63a2\u6d4b\u9650\u5b9a\u8bcd\u4e4b\u95f4\u7684\u8ddd\u79bb\u5173\u7cfb\uff08\u52a8\u8bcd\u7528did so/did too\uff09</p> <ul> <li>\u5982\u679c\u4e24\u4e2a\u6210\u5206\u4e4b\u95f4\u4e0d\u80fd\u63d2\u5165one\u8bf4\u660e\u5173\u7cfb\u66f4\u8fd1</li> <li>\u5982\u679c\u4e24\u4e2a\u6210\u5206\u53ef\u4ee5\u88ab\u4e00\u4e2aone\u66ff\u4ee3\u8bf4\u660e\u5173\u7cfb\u66f4\u8fd1</li> </ul> <pre><code>Mika loved the policeman intensively.\nSusan did so half-heartedly.\n*Susan did so the baker.\n</code></pre> <pre><code>graph TD\n  NP --&gt; D\n    D --&gt; the\n    NP --&gt; N1\n    N1 --&gt; AdjP\n    AdjP --&gt; big\n    N1 --&gt; N2\n    N2 --&gt; N3\n    N2 --&gt; PP1\n    N3 --&gt; N\n    N --&gt; book\n    N3 --&gt; PP2\n    PP2 --&gt; of_poems\n    PP1 --&gt; with_the_blue_cover\n</code></pre> <p>\u52a0\u5165\u4e86bar level\uff0cbook\u4e0eof poems\u6784\u6210\u4e00\u4e2a\u4e2d\u95f4\u6295\u5c04X-bar\uff0c\u6784\u6210\u4e00\u4e2aconstituent\u3002\u4f7f\u5f97\u6bcf\u4e2a\u53e5\u5b50\u90fd\u80fd\u88ab\u753b\u6210\u4e00\u4e2a\u4e8c\u53c9\u6811\u5f62\u5f0f</p> <p>\u751f\u6210\u53e5\u6cd5\u5b66\u6d3e\uff1a\u4e0a\u4e16\u7eaa\u4e94\u5341\u5e74\u4ee3\u3002classical theory and standard theory\u30021988\u5e74\u63d0\u51fa\u4e86government and binding theory\u3002lexicon, D-S, S-S, PF, LF</p>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#n-bar","title":"N-bar","text":"<p>\u539f\u672cNP\u6839\u636e\u4e00\u7cfb\u5217\u89c4\u5219\u4e0d\u662f\u4e8c\u53c9\u6811\uff0c\u6bd4\u5982N\u2192</p> <p>N-bar theory\u8ba4\u4e3a\u53ef\u4ee5\u90fd\u53d8\u6210\u4e8c\u53c9\u6811</p> <p>\u89c4\u5219\u6bd4\u5982</p> <pre><code>NP -&gt; Det N'\nN' -&gt; AP N'\nN' -&gt; N PP\n</code></pre> <p>\u7b2c\u4e00\u6761\u79f0\u4e3a\u4e00\u4e2a\u6700\u5927\u6295\u5c04</p>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#v-bar","title":"V-bar","text":"<pre><code>VP -&gt; V'   // \u9884\u7559\u4e00\u4e2a\u4f4d\u7f6e\u7ed9\u6f5c\u5728\u7684specifier\uff0c\u5373\u4f7f\u6ca1\u6709\nV' -&gt; AdvP V' | V' PP | V' AdvP\nV' -&gt; V(NP)\n</code></pre>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#abj-bar","title":"Abj-bar","text":"<pre><code>AdjP -&gt; Adj'\nAdj' -&gt; (AdvP) Adj' | Adj' (AdvP)\nAdj' -&gt; Adj(PP)\n</code></pre>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#p-bar","title":"P-bar","text":"<pre><code>PP -&gt; P'\nP' -&gt; P'(PP) | (AdvP)P'\nP' -&gt; P(NP)\n</code></pre> <p>\u4e2d\u5fc3\u8bcdX \u2192 \u4e2d\u95f4\u6295\u5c04X\u2019 \u2192 \u6700\u5927\u6295\u5c04XP\u3002\u4e0d\u80fd\u76f4\u63a5\u5230XP\uff0c\u4e00\u5b9a\u8981\u6709\u4e2d\u95f4\u6295\u5c04</p>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#parameter-of-word-orders","title":"Parameter of Word Orders \u7ba1\u7ea6\u8bba\uff0c \u539f\u5219\u4e0e\u53c2\u6570\u7406\u8bba","text":"<p>\u6839\u636eX-bar\u7406\u8bba\uff0c\u53ef\u4ee5\u5bf9\u4e00\u4e9b\u8bed\u8a00\u7684\u4e0d\u540c\u8bed\u5e8f\uff08\u5982SVO\uff0cSOV\u7b49\uff09\u7ed9\u51fa\u8bed\u6cd5\u53c2\u6570\u5316\u89e3\u91ca</p> <p>specifier\u548ccomplement\u53ef\u4ee5\u51fa\u73b0\u5728\u5176sister\u7684\u4e24\u4fa7\uff0c\u8fd9\u79cd\u6295\u5c04\u7684\u5de6\u53f3\u533a\u522b\u88ab\u79f0\u4e3aparameter setting</p>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#_1","title":"\u753b\u6811\u7684","text":"<ul> <li>\u9996\u5148\u754c\u5b9a\u6210\u5206\u5728X-bar\u6846\u67b6\u4e2d\u7684\u53e5\u6cd5\u4f4d\u7f6e\uff0c\u5373complement &amp; adjunct &amp; specifier &amp; head</li> <li>\u5148\u627e\u5230head\uff08\u4ee5\u53ca\u5176sister complement\u6210\u5206\uff09\uff0c\u6ce8\u610fcomplement &amp; adjunct\uff08&amp; specifier\uff09\u5fc5\u987b\u4e5f\u8981\u662f\u72ec\u7acb\u7684XP\u6210\u5206\uff0c\u4e0d\u80fd\u662f\u4e00\u4e2a\u5355\u72ec\u7684X</li> <li>\u6309\u7167head \u2192 complement \u2192 adjunct \u2192 specifier \u7684\u987a\u5e8f\u753b\u6811</li> <li>Even if there is no specifier, put an XP on top of the projection. This indicates that there are no more modifiers of the head X.</li> <li>Keep in mind that none of the X-bar rules are optional. This indicates that there are no more modifiers of the head X.</li> </ul>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#head-movement","title":"Head Movement \u4e2d\u5fc3\u8bed\u79fb\u4f4d","text":"<p>head movement: movement from a head to another head position</p> <p>\u53e5\u5b50\u53ef\u4ee5\u53d1\u751fmovement\u7684\u6807\u5fd7</p>"},{"location":"Linguistics_Notes/Syntax/%E8%BD%AC%E6%8D%A2%E7%94%9F%E6%88%90%E5%8F%A5%E6%B3%95/#-reading","title":"- \u4e00\u4e2a\u53e5\u6cd5\u7ed3\u6784\u5177\u6709\u4e24\u79cdreading","text":"<p>shortest movement</p> <p>shortest: let the path of a movement be the set of nodes that dominate the original position of the moved item, and do not dominate the leading site.</p>"},{"location":"Math_Notes/","title":"\u7d22\u5f15","text":"<p>\u672c\u4e13\u680f\u5185\u5bb9\u4e3a\u6570\u5b66\u7b14\u8bb0\uff0c\u5305\u62ec\u4ee5\u4e0b\u5206\u652f\uff1a - \u56fe\u8bba - \u79bb\u6563\u6570\u5b66</p>"},{"location":"Math_Notes/Normal%20Forms/","title":"Normal Forms","text":""},{"location":"Math_Notes/Normal%20Forms/#conjunctive-normal-form-cnf","title":"Conjunctive Normal Form (CNF)","text":"<p>conjunction of one or more clauses</p> <pre><code>(A or ~B or ~C) and (~D or E or F)\n</code></pre>"},{"location":"Math_Notes/Normal%20Forms/#disjunctive-normal-form","title":"Disjunctive Normal Form","text":"<pre><code>\uff08A and ~B and ~C\uff09or (~D and E and F)\n</code></pre>"},{"location":"Math_Notes/Normal%20Forms/#algebraic-normal-form","title":"Algebraic Normal Form","text":"<p>one more terms are combined into terms by AND, and one more terms are combined by XOR</p> <pre><code>a XOR b XOR (a AND b) XOR (a AND b AND c)\n</code></pre>"},{"location":"Math_Notes/Normal%20Forms/#negation-normal-form-nnf","title":"Negation Normal Form (NNF)","text":"<p>if the negation operator is only applied to variables and the only other allowed Boolean operators are conjunctions and disjunctions</p> <pre><code>~A and B\n</code></pre>"},{"location":"Math_Notes/Normal%20Forms/#chomsky-normal-form","title":"Chomsky Normal Form","text":"<p>formal language theory \u5047\u7684</p> <pre><code>A \u2192 BC\nA \u2192 a\nS \u2192 \u03b5\n</code></pre> <p>Category:Normal forms (logic)</p>"},{"location":"Math_Notes/%E9%9B%B6%E6%95%A3%E7%9A%84%E9%A2%98/","title":"\u96f6\u6563\u7684\u9898","text":"<ol> <li> LHS\u6210\u7acb\u7684\u6761\u4ef6\u662f \u5982\u679c\u5b58\u5728\u4e00\u4e2ax\u4f7fP(x)\u4e0d\u6210\u7acb\uff0c\u5c31\u4e0d\u7528\u7ba1Q(y)\u662f\u5426\u6210\u7acb \u6216\u6240\u6709P(x)\u90fd\u6210\u7acb\uff0c\u4e14Q(y)\u6210\u7acb</li> </ol> <p>RHS\u6210\u7acb\u7684\u6761\u4ef6\u662f \u5fc5\u987b\u6240\u6709x\u90fd\u4f7fP(x)\u4e0d\u6210\u7acb\uff0c\u624d\u80fd\u4e0d\u7ba1Q(y)\u662f\u5426\u6210\u7acb \u6216\u6240\u6709P(x)\u90fd\u6210\u7acb\uff0c\u4e14Q(y)\u6210\u7acb</p> <p>\u6240\u4ee5\u5f53$\\exists x$\u4f7fP(x)\u4e3a\u5047\uff0c\u4f46\u662f\u5176\u5b83x\u4f7fp(x)\u4e3a\u771f\uff0c\u4e14$\\forall y$\u4f7fQ(y)\u4e3a\u5047\u65f6\uff0cLHS\u662f\u771f\u7684\uff0c\u4f46\u662fRHS\u662f\u5047\u7684\uff0c\u6240\u4ee5LHS$\\neq$RHS. </p> <p>\u6309\u7167\u8fd9\u4e2a\u53ef\u4ee5\u4e3e\u4e00\u4e2a\u4f8b\u5b50 U = \u81ea\u7136\u6570 P(x) = x \u662f\u5947\u6570 Q(y) = y \u662f\u8d1f\u6570</p>"},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/","title":"\u56fe\u8bba","text":""},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/#basic-properties","title":"Basic Properties","text":"<ul> <li>can be used to calculate the spanning trees of give graphs</li> <li>spectral decomposition allows constructing low dimensional embeddings that appear in many machine learning applications</li> <li>easy to define in simple graph</li> <li>for undirected graphs, both the adjacency matrix and the Laplacian matrix are symmetric, and col-sum are 0</li> <li>\u662f\u534a\u6b63\u5b9a\u77e9\u9635</li> <li>\u7279\u5f81\u503c\u4e2d0\u7684\u4e2a\u6570\uff0c\u662f\u8fde\u901a\u5b50\u56fe\u7684\u4e2a\u6570</li> <li>\u6700\u5c0f\u7279\u5f81\u503c\u662f0\uff0c\u56e0\u4e3a\u62c9\u666e\u62c9\u65af\u77e9\u9635\u6bcf\u4e00\u884c\u7684\u548c\u4e3a0</li> <li>\u6700\u5c0f\u975e0\u7279\u5f81\u503c\u662f\u56fe\u7684\u4ee3\u6570\u8fde\u901a\u5ea6</li> </ul>"},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/#definition","title":"Definition","text":"<p>or L = D(degree matrix) - A(adjacency matrix)</p>"},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/#normalization","title":"Normalization","text":""},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/#eigendecomposition","title":"Eigendecomposition","text":""},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/#gcnlaplace","title":"\u4e3a\u4ec0\u4e48GCN\u8981\u7528\u5230laplace\u77e9\u9635","text":"<ul> <li>\u62c9\u666e\u62c9\u65af\u77e9\u9635\u53ef\u4ee5\u8c31\u5206\u89e3\uff08\u7279\u5f81\u5206\u89e3\uff09GCN\u662f\u4ece\u8c31\u57df\u7684\u89d2\u5ea6\u63d0\u53d6\u62d3\u6251\u56fe\u7684\u7a7a\u95f4\u7279\u5f81\u7684\u3002</li> <li>\u62c9\u666e\u62c9\u65af\u77e9\u9635\u53ea\u5728\u4e2d\u5fc3\u5143\u7d20\u548c\u4e00\u9636\u76f8\u90bb\u5143\u7d20\u5904\u6709\u975e\u96f6\u5143\u7d20\uff0c\u5176\u4ed6\u4f4d\u7f6e\u7686\u4e3a0.</li> <li>\u4f20\u7edf\u5085\u91cc\u53f6\u53d8\u6362\u516c\u5f0f\u4e2d\u7684\u57fa\u51fd\u6570\u662f\u62c9\u666e\u62c9\u65af\u7b97\u5b50\uff0c\u501f\u52a9\u62c9\u666e\u62c9\u65af\u77e9\u9635\uff0c\u901a\u8fc7\u7c7b\u6bd4\u53ef\u4ee5\u63a8\u5bfc\u51faGraph\u4e0a\u7684\u5085\u91cc\u53f6\u53d8\u6362\u516c\u5f0f\u3002</li> </ul>"},{"location":"Math_Notes/Graph%20Theory/Laplacian%20Matrix/#reference","title":"Reference","text":"<p>Laplacian matrix</p>"},{"location":"Other_Courses/","title":"\u7d22\u5f15","text":"<p>\u672c\u4e13\u680f\u5305\u62ec\uff1a - \u5728ZJU\u4e0a\u8fc7\u7684\u5176\u5b83\u8bfe\u7a0b\u7b14\u8bb0 - \u975e\u4e0a\u8ff0\u4e13\u680f\u7c7b\u522b\u7684\u5176\u5b83\u7f51\u8bfe\u7b14\u8bb0</p> <p>\u5df2\u7ecf\u6574\u7406\u8bfe\u7a0b - \u6253\u5f00\u827a\u672f\u4e4b\u95e8-\u94a2\u7434 \u671f\u672b\u770b\u8c31\u8bc6\u66f2\u590d\u4e60\u8bb2\u4e49</p>"},{"location":"Other_Courses/%E6%89%93%E5%BC%80%E8%89%BA%E6%9C%AF%E4%B9%8B%E9%97%A8-%E9%92%A2%E7%90%B4%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/","title":"\u94a2\u7434\u671f\u672b\u590d\u4e60","text":"<p>\u53ef\u7528\u4e8e\u590d\u4e60\u671f\u672b\u8003\u8bd5\u770b\u8c31\u8bc6\u66f2\u9898\u3002</p>"},{"location":"Other_Courses/%E6%89%93%E5%BC%80%E8%89%BA%E6%9C%AF%E4%B9%8B%E9%97%A8-%E9%92%A2%E7%90%B4%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_1","title":"\u4e0a\u8bfe\u8bb2\u7684","text":"<p>\u65af\u5361\u62c9\u8482   \u65af\u79d1\u91cc\u4e9a\u5bbe  \u666e\u7f57\u79d1\u83f2\u8036\u592b  </p>"},{"location":"Other_Courses/%E6%89%93%E5%BC%80%E8%89%BA%E6%9C%AF%E4%B9%8B%E9%97%A8-%E9%92%A2%E7%90%B4%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/#_2","title":"\u770b\u8c31\u8bc6\u66f2","text":"<p>\u4e50\u8c31\u521d\u59cb\u6807\u8bb0\uff1a - \u901f\u5ea6\u6807\u8bb0 - \u62cd\u53f7 - \u8c03\u53f7 - \u4e34\u65f6\u53d8\u97f3\u8bb0\u53f7 - \u8fd0\u97f3\u6cd5\u8bb0\u53f7 - \u88c5\u9970\u97f3\u8bb0\u53f7 - \u8e0f\u677f\u6807\u8bb0 - \u7ec7\u4f53\u2014\u2014\u4f34\u594f\u4e0e\u65cb\u5f8b\u7684\u5173\u7cfb</p> <p>(\u7b2c\u4e00\u884c\u601d\u6377\u7684\uff0c\u7b2c\u4e8c\u884c\u6211\u7684)</p> <ol> <li> <p>\u5df4\u8d6bC\u5927\u8c03\u524d\u594f\u66f2\uff0c\u5e73\u5747\u5f8b\u4f5c\u54c1\u7b2c\u4e8c\u8282</p> <p>C\u5927\u8c03\u594f\u9e23\u66f2\u30104/4\u62cd\u3011\u5206\u58f0\u90e8 \u590d\u8c03\u97f3\u4e50 \u6ca1\u6709\u8df3\u97f3 \u4e00\u822c\u90fd\u6ca1\u6709\u8fde\u97f3\u7ebf \u6709\u8de8\u8fc7\u62cd\u5b50/\u5c0f\u7ed3\u7684\u5ef6\u97f3\u7ebf pedal tone \u7ba1\u98ce\u7434 \u8282\u594f\u578b\u7684\u6a21\u4eff \u6ca1\u6709\u8e0f\u677f\u6807\u8bb0</p> <p>C\uff0844\u62cd\uff09\uff0cC\u5927\u8c03\uff0c\u6ca1\u6709\u5565\u88c5\u9970\u97f3\uff0c\u6ca1\u6709\u8e0f\u677f\uff0c\u6ca1\u6709\u5565\u5f3a\u5f31\u8bb0\u53f7\uff0c\u5347\u964d\u8bb0\u53f7\u6bd4\u8f83\u591a\uff08\u56e0\u4e3a\u662fC\u5927\u8c03\uff09\uff0c\u5de6\u53f3\u624b\u611f\u89c9\u662f\u5728\u4ea4\u66ff\u5f39\u97f3\u9636\uff0c\u7ecf\u5e38\u6709\u5de6\u624b\u5f88\u957f\u5f88\u957f\u7684\u4fdd\u6301\u97f3\u7684\u4f34\u594f\u3002</p> </li> <li> <p>\u65af\u5361\u62c9\u8482D\u5927\u8c03\u594f\u9e23\u66f2. K. 119</p> <p>D\u5927\u8c03\u594f\u9e23\u66f2\u30102\u4e2a\u5347\u53f7 3/8\u62cd\u3011\uff1a\u6280\u5de7\u6027 \u8df3\u8dc3 \u6a21\u4eff\u54cd\u677f \u5feb\u901f\u4e0b\u884c\u7684\u97f3\u9636\uff0c\u8fde\u97f3\u7ebf\u8fde\u5230\u8df3\u97f3</p> <p>38\u62cd\uff0cD\u5927\u8c03\uff08\u5347fa do\uff09\uff0c\u6709\u51e0\u5904\u95f4\u65ad\u7684\u5ef6\u97f3\u8e0f\u677f\uff08\u4e0d\u8d85\u8fc71\u5c0f\u8282\uff09\uff0c\u96f6\u661f\u6709p/mf\u8bb0\u53f7\uff0c\u4e2d\u95f4\u6709\u4e00\u5927\u6bb5\u7d27\u6328\u7740\u7684fp\uff08\u5728\u5e72\u561b\uff09\uff0c\u65cb\u5f8b\u901a\u5e38\u6709\u6574\u53e5\u6574\u53e5\u7684\u4e0a\u5347\u548c\u4e0b\u964d\uff0c\u4f34\u594f\u8981\u4e48\u662f\u4e09\u4e2a\u8df3\u97f3\uff0c\u8981\u4e48\u662f\u4e09\u4e2a\u76f8\u540c\u7684\u548c\u5f26</p> </li> <li> <p>\u83ab\u624e\u7279C\u5927\u8c03\u94a2\u7434\u594f\u9e23\u66f2Kv.330</p> <p>C\u5927\u8c03\u594f\u9e23\u66f2\u30102/4\u62cd\u3011 \u77ed\u8df3\u97f3 \u88c5\u9970\u97f3 \u53cc\u97f3\u91cd\u590d \u4e24\u97f3\u8fde\u4e24\u97f3\u8df3 \u5de6\u624b\u6ca1\u6709\u8de8\u8d8a\u5f88\u957f\u7684\u97f3\u7a0b \u67f1\u5f0f\u548c\u5f26\u4f34\u594f\u5c45\u591a \u559c\u6b22\u501a\u97f3 closing\u90e8\u5206\u540c\u6837\u7684\u8282\u594f\u578b</p> <p>24\u62cd\uff0cC\u5927\u8c03\uff0c\u5de6\u624b\u6709\u79fb\u52a8\u5230\u9ad8\u97f3\u8c31\u8868\uff0c\u6709\u96f6\u661f\u7684mf/p\u8bb0\u53f7\uff0c\u6709\u5f88\u591a\u5f88\u591a\u88c5\u9970\u97f3\uff08\u501a\u97f3\uff09\uff0c\u6ca1\u6709\u8e0f\u677f\uff0c\u4e3b\u65cb\u5f8b\u7684\u4f34\u594f\u662f\u4e00\u4e2a\u4e0a\u4e0b\u98a0\u5012\u7684\u963f\u8d1d\u5c14\u8482\u4f4e\u97f3\uff0c\u53f3\u624b\u97f3\u7b26\u7684\u65f6\u503c\u90fd\u5f88\u77ed</p> </li> <li> <p>\u8d1d\u591a\u82ac\u6708\u5149\u594f\u9e23\u66f2\u7b2c\u4e09\u4e50\u7ae0</p> <p>\u6708\u5149\u594f\u9e23\u66f2\u3010\u5347C\u5c0f\u8c03 8\u5206\u97f3\u7b26\uff0c2\u62cd\u3011\uff0c\u7b2c\u4e09\u4e50\u7ae0\u3010\u56db\u4e2a\u5347\u53f7\u3011 sf\u4e2d\u97f3\u5feb\u901f\u8df3\u97f3 \u7436\u97f3</p> <p>C\uff0844\u62cd\uff09\uff0c\uff08\u5347fa do so re\uff09\uff0c\u6709\u5c11\u91cf\u77ed\u6682\u7684\u5ef6\u97f3\u8e0f\u677f\uff0c\u6709\u5c11\u91cf\u4e24\u4e09\u4e2a\u4e00\u7ec4\u7684\u501a\u97f3\uff0c\u6709\u5f88\u591asf\uff0cff\u8bb0\u53f7\uff0c\u8bed\u53e5\u5168\u90fd\u662f\u4e0a\u5347\u7684\uff0c\u6216\u8fde\u7eed\u7684\u91cd\u97f3\uff0c\u540e\u9762\u4f34\u594f\u4e5f\u6709\u4e00\u6bb5\u963f\u8d1d\u5c14\u8482\u4f4e\u97f3\uff0c\u6700\u540e\u6709\u4e00\u6bb5\u5de8\u5927\u7684\u4e0a\u5347\u4e0b\u964d</p> </li> <li> <p>\u8212\u4f2f\u7279\u5373\u5174\u66f2op90, no3</p> <p>\u5373\u5174\u66f2\u30106\u4e2a\u964d\u53f78\u62cd\u3011\uff1a\u53d1\u5c55\u9010\u6b65 \u548c\u58f0\u5f20\u529b\u63a8\u8fdb 4\u4e2a\u4e8c\u5206\u65f6\u503c</p> <p>88\u62cd\uff0c\u964d6\u4e2a\uff0c\u53f3\u624b\u65cb\u5f8b\u5206\u9ad8\u4e2d\uff0c\u9ad8\u97f3\u662f\u4fdd\u6301\u97f3\uff0c\u4e2d\u97f3\u662f\u62c6\u5206\u548c\u5f26\uff0c\u4f4e\u97f3\u4e5f\u662f\u4fdd\u6301\u97f3\uff0c\u6ca1\u6709\u592a\u5927\u7684\u8d77\u4f0f\u53d8\u5316\uff0c\u6ca1\u6709\u8e0f\u677f\uff0c\u6ca1\u6709\u592a\u591a\u5f3a\u5f31\u6807\u8bb0</p> </li> <li> <p>\u8096\u90a6\u5347C\u5c0f\u8c03\u5706\u821e\u66f2\uff0cop64\uff0cno2</p> <p>\u5706\u821e\u66f2\u4f34\u594f\u5f62  \u30103/4\u62cd 4\u5347\u53f7\u53d85\u964d\u53f7\u3011</p> <p>34\u62cd\uff0c\u67094\u4e2a\u5347\u53f7(E)\uff0c\u4e3b\u8981\u52a8\u673a\u662f\u90a3\u4e2asol-la-sol-re, sol-la-sol-do\u7ec4\u5408\uff0c\u540e\u9762\u6709\u4e00\u6b21\u53d8\u8c03\uff0c5\u4e2a\u964d\u53f7\uff08\u5347C\uff09\uff0c\u6709\u5f88\u591a\u8e0f\u677f\uff0c\u8bb0\u53f7\u5927\u591a\u6570\u662fpp\u7b49\u5f31\u97f3\u8bb0\u53f7\uff0c\u6709\u5c11\u91cf\u88c5\u9970\u97f3\uff08\u8fd9\u4e2a\u53eb\u4f34\u97f3\u8fd8\u662f\u501a\u97f3\uff1f\u4e0e\u524d\u9762\u4e0d\u4e00\u6837\u7684\uff09\uff0c\u56e0\u4e3a\u662f\u5706\u821e\u66f2\uff0c\u5de6\u624b\u4f34\u594f\u4e00\u76f4\u662f\u5178\u578b\u7684\u5706\u821e\u66f2\u4f34\u594f</p> </li> <li> <p>\u8096\u90a6\u5347C\u5c0f\u8c03\u5e7b\u60f3\u5373\u5174\u66f2\uff0cop66</p> <p>\u5347C\u5c0f\u8c03\u5e7b\u60f3\u5373\u5174\u66f2\u30106/8\u62cd\u3011\uff1a \u53f3\u624b\u56db\u4e2a\u97f3\u548c\u5de6\u624b\u4e09\u4e2a\u97f3\u5361\u70b9  \u5f88\u591a\u91cd\u97f3\u8bb0\u53f7  \u7b2c\u4e00\u6b21\u5f3a\u8c03\u4f4e\u58f0 \u7b2c\u4e8c\u6b21\u5f3a\u8c03\u9ad8\u58f0\uff08\u5927\u4e8e\u53f7\uff09 \u5de6\u624b\u8d77\u4f0f\u7684\u4f34\u594f\u5f62 \u53f3\u624b\u5355\u97f3\u65cb\u5f8b \u5185\u58f0\u90e8</p> <p>68\u62cd\uff0c4\u4e2a\u5347\u53f7\uff08E\uff09\uff0c \u4f9d\u7136\u6709\u5f88\u591a\u8e0f\u677f\uff0c \u5de6\u624b\u662f\u62c6\u5206\u7684\u97f3\u5f88\u591a\u7684\u548c\u5f26\uff0c\u53f3\u624b\u5f88\u5feb\uff0c\u5de6\u53f3\u624b\u6839\u672c\u5bf9\u4e0d\u4e0a\u7b11\u6b7b\uff0c\u4f9d\u65e7\u53d8\u8c03\u4e00\u6b21\u52305\u4e2a\u964d\u53f7\uff08\u5347C\uff09\uff0c \u6709\u88c5\u9970\u97f3\uff0c\u6709\u96f6\u661f\u51e0\u4e2asf\u8bb0\u53f7\uff0c</p> </li> <li> <p>\u8096\u90a6\u5347C\u5c0f\u8c03\u591c\u66f2</p> <p>\u5347C\u5c0f\u8c03\u591c\u66f2\u30104/4\u62cd\u3011\uff1a\u8d85\u8fc7\u516b\u5ea6\u7684\u4f34\u594f 4\u97f3\u7ec4 6\u97f3\u7ec4 \u8fde\u7eed\u4e0a\u4e0b\u7684\u97f3\u9636 18\u8fde\u97f3 35\u8fde\u97f3 \u4e32\u97f3</p> <p>E\uff0cC\uff0844\u62cd\uff09\uff0c\u5f88\u591a\u8e0f\u677f\uff0c\u5de6\u624b\u662f\u4f4e-\u4e2d-\u9ad8-\u4e2d\u7684\u62c6\u5206\uff0c\u4e2d\u95f4\u53f3\u624b\u6709\u4e00\u53e5\u5f88\u53d9\u4e8b\u6027\u7684\u53e5\u5b50\uff0c\u6709ppp\u8fd9\u6837\u975e\u5e38\u5f31\u7684\u8bb0\u53f7\uff0c</p> </li> <li> <p>\u8212\u66fc\u51b2\u52a8op12, no2</p> <p>\u51b2\u52a8\u30104\u964d\u53f7\u21925\u964d\u53f7\u21922\u964d\u53f7 6/8\u62cd\u3011\uff1a \u65cb\u5f8b\u5728\u5de6\u624b \u4f1a\u51fa\u73b0sf</p> <p>68\u62cd\uff0c\u964dA\uff08\u56db\u4e2a\u964d\u53f7\uff09\u5230E\u5230\u5347C\u5230\u964dB\uff08\u4e24\u4e2a\u964d\u53f7\uff09\uff0c\u53d8\u8c03\u5f88\u591a\uff0c\u53f3\u624b\u8981\u4e48\u662f\u5f88\u591a\u548c\u5f26\u7684\u4e09\u8fde\u6572\u51fb\uff0c\u8981\u4e48\u5c31\u662f\u91cd\u590d\u7684\u62c6\u5206\u548c\u5f26\uff08\u6bcf\u4e00\u7ec4\u90fd\u6709\u4e00\u4e2a\u4fdd\u6301\u97f3\uff09\uff0c\u964dB\u8c03\u65f6\u4f34\u594f\u975e\u5e38\u4f4e\uff0c \u65e0\u8e0f\u677f</p> </li> <li> <p>\u674e\u65af\u7279\u7231\u4e4b\u68a6</p> <p>\u7231\u4e4b\u68a6\u30104\u964d\u53f7\u21925\u964d\u53f7\u21925\u5347\u53f7 6/4\u62cd\u3011\uff1a\u4f2a\u58f0\u4e50 \u827a\u672f\u6b4c\u66f2 \u5355\u97f3\u65cb\u5f8b \u5728\u4f4e\u97f3\u8c31\u53f7\u9ad8\u97f3\u8c31\u53f7\u95f4\u5de6\u53f3\u624b\u95f4\u8df3\u8dc3  \u674e\u65af\u7279\u7684\u5370\u8c61\u6d3e\u7279\u8272  \u8f6c\u8c03\u540e\u5230\u65cb\u5f8b\u5230\u6700\u9ad8\u97f3 \u89c4\u6574\u7684\u5bf9\u4f4d   \u53cc\u97f3\u65cb\u5f8b    \u5de6\u624b\u9ad8\u97f3\u8c31\u53f7\u4f4e\u97f3\u8c31\u53f7\u53d8\u5316  \u3010\u53cc\u97f3\u65cb\u5f8b\u5728\u9ad8\u58f0\u3011\u4e14\u5f3a\u8c03 appassionato \u8d1d\u591a\u82ac\u548c\u674e\u65af\u7279\u7231\u7528   \u5de6\u624b\u8de8\u8d8a piu smorz</p> <p>64\u62cd\uff0c\u964dA\uff0c\u65cb\u5f8b\u5206\u9ad8\u4e2d\u4f4e\uff0c\u4e2d\u662f\u4fdd\u6301\u97f3\uff0c\u9ad8\u662f\u62c6\u5206\u548c\u5f26\uff0c\u4e2d\u95f4\u6709\u5f88\u674e\u65af\u7279\u7684\u53d8\u6001\u7684\u624b\u6eda\u952e\u76d8\u8bed\u53e5\u548c\u5927\u8de8\u5ea6\u7838\u7434\u8bed\u53e5\uff0c\u540e\u9762\u6709\u4e00\u6bb5\u53d8\u5230\u4e2d\u662f\u62c6\u5206\u548c\u5f26\u9ad8\u662f\u4fdd\u6301\u97f3\uff0c</p> </li> <li> <p>\u674e\u65af\u7279\u949f</p> <p>\u949f\u30105\u5347\u53f7 6/8\u62cd\u3011\uff1a\u5f88\u8fdc\u7684\u8df3\u8dc3\u97f3\u7a0b \u4e0a\u4e0b\u7b26\u5e72 \u9ad8\u97f3\u8df3\u8dc3 \u5feb\u901f\u8dd1\u52a8</p> <p>68\u62cd\uff0cB\uff08\u964dC\uff0c5\u4e2a\u5347\u53f7\uff09\uff0c \u5145\u6ee1\u975e\u5e38\u674e\u65af\u7279\u7684\u5927\u8de8\u5ea6\u7838\u7434\u548c\u624b\u6eda\u952e\u76d8\uff0c</p> </li> <li> <p>\u67f4\u53ef\u592b\u65af\u57fa\u516d\u6708\u8239\u6b4c</p> <p>\u8239\u6b4c\u3010\u603b\u4f53\u4e0a\u4e24\u964d\u53f7 \u4f1a\u51fa\u73b0\u5355\u5347\u53f7 4/4\u62cd\u3011\uff1a\u4e24\u5355\u97f3\u4e00\u548c\u58f0\u4f34\u594f</p> <p>44\u62cd\uff08C\uff09\uff0c\u964dB\uff08\u4e24\u4e2a\u964d\u53f7\uff09\uff0c\u53f3\u624b\u975e\u5e38\u53d9\u4e8b\u6027\uff0c\u6709\u5f88\u591a\u77ed\u6682\u8e0f\u677f\uff0c\u4e3b\u5bfc\u52a8\u673a\u662f\u4e00\u53e5re-mi-fa-sol-si-do-re-sol-fa-sol-re\uff0c\u4e2d\u95f4\u6709\u4e24\u5c0f\u8282\u7684\u548c\u5f26\u5168\u90e8\u7528\u7436\u97f3\u5f39\u51fa</p> </li> <li> <p>\u52c3\u62c9\u59c6\u65af\u95f4\u594f\u66f2</p> <p>\u95f4\u594f\u66f2\u30103\u5347\u53f7 3/4\u62cd\u3011\uff1a\u67f1\u5f0f\u548c\u5f26\u7684\u7ec7\u4f53 \u6bd4\u8f83\u548c\u7f13</p> <p>34\u62cd\uff0cA\u5927\u8c03\uff083\u4e2a\u5347\u53f7\uff09\uff0c\u4e3b\u5bfc\u52a8\u673a\u662fdo-si-re\uff0cdo-si-la\uff08\u4e5f\u6709\u4e00\u4e9b\u4f34\u594f\u662f\u4e0a\u4e0b\u98a0\u5012\u7684\u8fd9\u4e2a\u52a8\u673a\uff09\uff0c\u6ca1\u6709\u8e0f\u677f\uff0c</p> </li> <li> <p>\u5fb7\u5f6a\u897f\u6c34\u4e2d\u5012\u5f71</p> <p>\u6c34\u6c60\u5012\u5f71\u30105\u964d\u53f7\u21920\u964d\u53f7\u21923\u964d\u53f7\u21925\u964d\u53f7 4/8\u62cd\u3011\uff1a\u6cd5\u6587 \u91cd\u590d\u51fa\u73b0pp\u5f31\u97f3 \u52a0\u4e0a\u4fdd\u6301\u97f3\u7684\u65cb\u5f8b\u65cb\u5f8b\u7ebf\u6761 \u6ca1\u5728\u8c31\u5b50\u5199\u8e0f\u677f \u5e73\u884c\u516b\u5ea6\u4e0a\u4e0b\u884c Mesure doux et expression au Mouv \u5feb\u901f\u8f7b\u5de7\u5f31\u8dd1\u52a8</p> <p>48\u62cd\uff0c\u964dD\uff08\u5347C\uff0c\u4e94\u4e2a\u964d\u53f7\uff09\uff0c\u975e\u5e38\u591a\u66f2\u5185\u5347\u964d\u8bb0\u53f7\uff0c\u65e0\u8e0f\u677f\uff0c\u6709\u957f\u53e5\u76847\u5ea6\u97f3\u62c6\u5206\u6eda\u952e\u76d8\uff0c\u540e\u534a\u6bb5\u6709\u8de8\u8d8a\u5de6\u53f3\u624b\u7684\u8bed\u53e5\uff0cff\u548cppp\u4ea4\u66ff\u51fa\u73b0\uff0c\u6709\u53d8\u8c03\uff08\u5230\u964dE\uff0c\u4e09\u4e2a\u964d\u53f7\uff09\uff0c\u5f88\u591a\u6cd5\u8bed\uff08\u554a\u8fd9\u662f\u53ef\u4ee5\u8bf4\u7684\u5417\uff09\uff0c\u7ed3\u5c3e\u5904\u8bb8\u591a\u6781\u9ad8\u4e0e\u6781\u4f4e\u7684\u516b\u5ea6\u4fdd\u6301\u97f3\uff0c\u8bb0\u53f7\u5199\u7740\u6709\u8fbd\u8fdc\u611f</p> </li> <li> <p>\u62c9\u5a01\u5c14\u6c34\u4e4b\u5b09\u620f</p> <p>\u6c34\u7684\u5b09\u620f\u30104\u5347\u53f7 4/4\u62cd \u4e2d\u95f4\u7a7f\u63d2\u4e86 2/4\u62cd\u3011\uff1a\u7b80\u77ed\u91cd\u590d pp \u5c0f\u5355\u5143\u91cd\u590d \u5de6\u624b\u65cb\u5f8b \u4e24\u4e2a\u5c0f\u7ed3\u4ecepp\u2192ff\u2192pp </p> <p>44\u62cd\uff0cE\uff08\u56db\u4e2a\u5347\u53f7\uff09\uff0c\u53f3\u624b\u62c6\u5206\u5f97\u6ca1\u6709\u5fb7\u5f6a\u897f\u5168\uff0c\u662f\u4e94\u5ea6\u97f3\uff08\u4f46\u5176\u5b9e\u6211\u770b\u4e0d\u51fa\u6765\u4f60\u77e5\u9053\u5417\uff09\uff0c\u4ed6\u4e0d\u662f\u5f88\u6709\u8fbd\u8fdc\u611f\uff0c\u91cd\u590d\u7684\u5c0f\u8282\u5f88\u591a\uff0c\u4e3b\u65cb\u5f8b\u5728\u540e\u534a\u6bb5\u6709\u56de\u5f52</p> </li> <li> <p>\u62c9\u8d6b\u9a6c\u5c3c\u8bfa\u592bG\u5c0f\u8c03\u524d\u594f\u66f2op23 no5</p> <p>G\u5c0f\u8c03\u524d\u594f\u66f2\u30102\u964d\u53f7\u3011\uff1a\u8df3\u97f3\u548c\u4fdd\u6301\u97f3\u540c\u65f6\u51fa\u73b0\uff0c \u5de6\u53f3\u540c\u6837\u7684\u65cb\u5f8b \u77ed\u77ed\u957f\u8282\u594f\u578b 4\u4e2a\u97f3\u4e00\u8d77\u7684\u8df3\u97f3 \u80a2\u4f53\u5f88\u6574\u9f50</p> <p>C\uff0844\u62cd\uff09\uff0c\u4e24\u4e2a\u964d\u53f7\uff0c\u5f88\u591a\u548c\u5f26\u7684\u8fde\u7eed\u6572\u51fb\uff0c\u6572\u5b8c\u7f13\u548c\u4e86\u4e00\u9635\uff0c\u5de6\u624b\u662f\u5347\u964d\u5347\u964d\u7684\u97f3\u9636\uff0c\u7136\u540e\u53c8\u5f00\u59cb\u548c\u5f26\u6572\u7434\uff0c\u6ca1\u6709\u8e0f\u677f\uff0c\u548c\u5f26\u4e0a\u6709\u5de8\u591a\u8df3\u97f3\u91cd\u97f3\u7b26\u53f7\uff0c</p> </li> <li> <p>\u65af\u79d1\u91cc\u4e9a\u5bbe\u7ec3\u4e60\u66f2 op8 no12</p> <p>\u7ec3\u4e60\u66f2\u30105\u5347\u53f7\u3011\u516b\u5ea6\u65cb\u5f8b</p> <p>44\u62cd\uff0c\u516d\u4e2a\u5347\u53f7\uff08\u5347F\uff09\uff0c\u4e00\u76f4\u5728\u7528\u516b\u5ea6\u6f14\u594f\u65cb\u5f8b\uff0c\u65e0\u8e0f\u677f\uff0c\u597d\u50cf\u627e\u4e0d\u51fa\u4ec0\u4e48\u522b\u7684\u7279\u70b9\uff0c\u5c31\u5de6\u53f3\u624b\u5168\u662f\u516b\u5ea6\uff0c</p> </li> <li> <p>\u666e\u7f57\u79d1\u83f2\u8036\u592b\u5e74\u8f7b\u7684\u6731\u4e3d\u53f6</p> <p>\u5e74\u8f7b\u7684\u6731\u4e3d\u53f6\u30104/4\u3011vivace\u6d3b\u7248 \u53d8\u5316\u97f3\u5f88\u591a \u77ed\u8df3\u97f3 psubito</p> <p>44\u62cd\uff0cC\u5927\u8c03\uff0c\u65e0\u8e0f\u677f\uff0c\u53f3\u624b\u5f88\u591a\u7c7b\u4f3c\u963f\u8d1d\u5c14\u8482\u548c\u5f26\u4f46\u4e0d\u662f\u7684\u7684\u8df3\u97f3\uff0c\u6216\u5728\u7528\u4e0a\u5347\u7684\u97f3\u9636\uff0c\u8df3\u97f3\u975e\u5e38\u591a\uff0c\u4e2d\u95f4\u53d8\u8c03\u5230A\u5927\u8c03\uff0c\u7565\u5e73\u9759(tranquillo)\uff0c\u540e\u9762\u53d8\u56deC\u5927\u8c03\u548c\u8df3\u97f3\u5f88\u591a\u72b6\u6001\uff0c\u7136\u540e\u5230G\u5927\u8c03\u53c8\u5f00\u59cb\u53d9\u4e8b\uff0c\u53f3\u624b\u662f\u4f34\u594f\u5de6\u624b\u662f\u65cb\u5f8b\u3002\u611f\u89c9\u53d8\u8c03\u548c\u60c5\u611f\u53d8\u5316\u5f88\u591a\u662f\u8fd9\u66f2\u7684\u7279\u70b9\uff0c\u56e0\u4e3a\u662f\u6b4c\u5267</p> </li> <li> <p>\u683c\u4ec0\u6e29\u524d\u594f\u66f2no1</p> <p>\u524d\u594f\u66f2\u3010\u4e24\u964d\u53f7 2/4\u3011\u91cd\u590d \u5207\u5206\uff08\u5927\u4e8e\u53f7\uff09 \u73b0\u4ee3 \u62c9\u7f8e\u98ce</p> <p>24\u62cd\uff0c\u964dB\u5927\u8c03\uff0c\u5f00\u5934\u770b\u5230\u4fdd\u6301\u97f3\u8bb0\u53f7\u548c\u5f3a\u97f3\uff0c\u5de6\u624b\u770b\u8d77\u6765\u662f\u4e0d\u592a\u548c\u8c10\u7684\u6709\u6253\u51fb\u6027\u7684\u4f34\u594f\uff0c\u53f3\u624b\u4e3b\u65cb\u5f8b\u662fdo-re-fa-si-si, do-re-fa-la-la\uff0c\u51fa\u73b0\u4e24\u6b21\uff0c\u5f88\u77ed\u7684\u4e00\u9996\uff08\u8fd9\u4e2a\u80fd\u7b97\u5417\u554a\u554a\u554a\uff09</p> </li> <li> <p>\u5df4\u6258\u514b\u5728\u6237\u5916</p> <p>\u5728\u6237\u5916\u30102/4\u62cd\u3011\u7b2c\u4e00\u6bb5 \u6253\u51fb\u4e50 \u7ecf\u5e38\u6709\u5de6\u53f3\u4ea4\u6362\u7684\u611f\u89c9 \u6b63\u53cd\u62cd\u4e2d\u5370 \u4e24\u4e2a\u4f4e\u97f3\u8c31\u53f7</p> <p>24\u62cd\uff0cC\u5927\u8c03\uff0c\u5de6\u53f3\u624b\u90fd\u5728\u4f4e\u97f3\uff0c\u5230\u5904\u662f\u4e0d\u548c\u8c10\u7684\u6253\u51fb\u4e50\u58f0\uff08\u5927\u90e8\u5206\u6709\u964d\u53f7\u7684\u548c\u5f26\uff0c\u6216\u76f8\u90bb\u97f3\u6324\u5728\u4e00\u8d77\u6784\u6210\u7684\u548c\u5f26\u90fd\u662f\uff09\uff0c\u4e2d\u95f4\u53d8\u5316\u523034\u62cd\uff0c\u4e5f\u5f88\u77ed</p> </li> </ol>"},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/","title":"\u7d22\u5f15","text":"<p>\u672c\u7ae0\u8282\u5305\u542b\u4e00\u4e9b\u6742\u4e03\u6742\u516b\u7684\u4e1c\u897f</p>"},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/APA%20Format/","title":"APA Format","text":"<p>\u6211\u559c\u6b22\u7528\u5f15\u6587\u81ea\u52a8\u751f\u6210\u5668\uff0c\u63a8\u8350\u51e0\u4e2a</p> <ul> <li>\u6700\u597d\u7528\u7684\uff1azotero\u81ea\u52a8\u751f\u6210\u6216Google\u5b66\u672f\u641c\u7d22\u81ea\u52a8\u751f\u6210</li> <li>http://www.citethisforme.com/zh/apa/source-type</li> <li>http://cite.readpaul.com/</li> </ul>"},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/APA%20Format/#apa-style","title":"\u5916\u8bed\u8bba\u6587\u6587\u732e\u5f15\u7528\u683c\u5f0f\u2014\u2014APA Style","text":"<p>APA\u683c\u5f0f\u6307\u7684\u662f\u7f8e\u56fd\u5fc3\u7406\u5b66\u4f1a\uff08American Psychological Association\uff0c\u7b80\u79f0APA\uff09\u51fa\u7248\u7684\u300a\u7f8e\u56fd\u5fc3\u7406\u534f\u4f1a\u51fa\u7248\u624b\u518c\u300b\uff08Publication Manual of the American Psychological Association\uff09\u3002\u5b83\u8d77\u6e90\u4e8e1929\u5e74\uff0c\u5230\u76ee\u524d\u4e3a\u6b62\u5df2\u7ecf\u66f4\u65b0\u81f3\u7b2c\u4e03\u7248\uff0c\u603b\u9875\u6570\u4e5f\u5df2\u7ecf\u8d85\u8fc7400\u9875\uff0c\u91cc\u9762\u8be6\u7ec6\u89c4\u8303\u4e86\u6587\u7ae0\u7684\u9875\u9762\u683c\u5f0f\uff08\u884c\u95f4\u8ddd\u3001\u5b57\u4f53\u3001\u5b57\u53f7\u3001\u9875\u8fb9\u8ddd\u7b49\u7b49\uff09\u3001\u56fe\u8868\u8868\u683c\\\u53c2\u8003\u6587\u732e\u7b49\u7b49\uff0c\u6781\u4e3a\u5168\u9762\u3002APA\u4e3b\u8981\u7528\u4e8e\u5fc3\u7406\u3001\u6559\u80b2\u53ca\u793e\u4f1a\u79d1\u5b66\u7b49\u5b66\u79d1\u3002\u5176\u89c4\u8303\u683c\u5f0f\u4e3b\u8981\u5305\u62ec\u6587\u5185\u6587\u732e\u5f15\u7528\uff08Reference Citations in Text\uff09\u548c\u6587\u672b\u53c2\u8003\u6587\u732e\u5217\u8868\uff08Reference List\uff09\u4e24\u5927\u90e8\u5206\u3002</p> <p>APA\u683c\u5f0f\u5f3a\u8c03\u51fa\u7248\u7269\u7684\u5e74\u4ee3\uff08Time of the Publication Year\uff09\u800c\u4e0d\u5927\u6ce8\u91cd\u539f\u6587\u4f5c\u8005\u7684\u59d3\u540d\u3002\u5f15\u6587\u65f6\u5e38\u5c06\u51fa\u7248\u5e74\u4ee3\u7f6e\u4e8e\u4f5c\u8005\u7f29\u5199\u7684\u540d\uff08the Initial of Author\u2019s First Name\uff09\u4e4b\u524d\u3002</p> <p>\u4e00\u3001\u6587\u5185\u6587\u732e\u5f15\u7528\uff08ReferenceCitations in Text\uff09</p> <p>1.\u5355\u4e00\u4f5c\u8005</p> <p>\u683c\u5f0f\u5e94\u4e3a\u201c\uff08\u4f5c\u8005\u59d3\u6c0f\uff08\u975e\u9996\u5b57\u6bcd\uff09\uff0c\u53d1\u8868\u5e74\u4efd\uff09\u201d\u3002\u82e5\u4f5c\u8005\u59d3\u540d\u5728\u6587\u7ae0\u4e2d\u5df2\u88ab\u63d0\u53ca\uff0c\u53ea\u9700\u6807\u51fa\u5e74\u4efd\u5c31\u597d\uff08\u82e5\u9700\u8981\u53ef\u52a0\u4e0a\u9875\u6570\uff09\uff0c\u4ecd\u9700\u4f7f\u7528\u62ec\u53f7\u3002\u591a\u4f4d\u4f5c\u8005\u4ee5\u4e0a\u540c\u7406\u3002\u4f8b\u5982\uff1a</p> <p>A recent study found a possible genetic cause of alcoholism (Pauling, 2005). Pauling (2005) discovered a possible genetic cause of alcoholism.</p> <p>2.\u4e24\u4f4d\u4f5c\u8005</p> <p>\u4f5c\u8005\u59d3\u6c0f\u5fc5\u987b\u4ee5\u4ed6\u4eec\u7684\u540d\u5b57\u5728\u5176\u53d1\u8868\u6587\u7ae0\u5185\u7684\u987a\u5e8f\u6765\u6392\u5e8f\u3002\u82e5\u4e24\u4e2a\u4f5c\u8005\u90fd\u5728\u62ec\u53f7\u5185\u5f15\u7528\uff0c\u540d\u5b57\u4e2d\u95f4\u9700\u52a0\u4e0a\u201c&amp;\u201d\u7b26\u53f7\uff1b\u82e5\u4e0d\u5728\u62ec\u53f7\u5185\u5219\u4f7f\u7528\u201cand\u201d\u3002\u4f8b\u5982\uff1a</p> <p>A recent study found a possible genetic cause of alcoholism (Pauling &amp; Liu, 2005). Pauling and Liu (2005) discovered a possible genetic cause of alcoholism.</p> <p>3.\u4e09\u81f3\u4e94\u4f4d\u4f5c\u8005</p> <p>\u7b2c\u4e00\u6b21\u5f15\u7528\u65f6\u9700\u5217\u4e3e\u5168\u90e8\u7684\u4f5c\u8005\uff0c\u5f80\u540e\u82e5\u5f15\u7528\u76f8\u540c\u7684\u6587\u732e\uff0c\u53ea\u9700\u4e3e\u51fa\u6700\u4e3b\u8981\u7684\u4f5c\u8005\uff0c\u518d\u52a0\u4e0a\u201cet al.\u201d\u3002\u4f46\u662f\uff0c\u5728\u53c2\u8003\u6587\u732e\u90e8\u5206\uff0c\u5168\u90e8\u4f5c\u8005\u7684\u59d3\u540d\u7686\u987b\u5217\u4e3e\u51fa\u6765\u3002\u4f8b\u5982\uff1a</p> <p>A recent study found a possible genetic cause of alcoholism (Pauling, Liu, &amp; Guo, 2005). Pauling, Liu, and Guo (2005) conducted a study that discovered a possible genetic cause of alcoholism. Pauling et al. (2005) discovered a possible genetic cause of alcoholism. A recent study found a possible genetic cause of alcoholism (Pauling et al., 2005).</p> <p>4.\u516d\u4f4d\u4f5c\u8005\u4ee5\u4e0a</p> <p>\u4e3e\u51fa\u7b2c\u4e00\u4f4d\u4f5c\u8005\u5373\u53ef\uff0c\u683c\u5f0f\u5e94\u4e3a\u201c\uff08\u4f5c\u8005\u00a0et al.\uff0c\u5e74\u4efd\uff09\u201d\u3002\u5728\u53c2\u8003\u6587\u732e\u90e8\u5206\uff0c\u5168\u90e8\u4f5c\u8005\u7684\u59d3\u540d\u7686\u987b\u5217\u4e3e\u51fa\u6765\u3002\u4f8b\u5982\uff1a</p> <p>Pauling et al. (2005) discovered a possible genetic cause of alcoholism.</p> <p>5.\u591a\u7bc7\u6587\u732e\uff0c\u540c\u4e00\u4f5c\u8005</p> <p>\u82e5\u4e00\u4f5c\u8005\u6709\u591a\u7bc7\u4f60\u60f3\u5f15\u7528\u7684\u6587\u732e\uff0c\u53ea\u9700\u7528\u9017\u53f7\u6765\u533a\u9694\u4f5c\u54c1\u7684\u53d1\u8868\u5e74\u4efd\uff08\u6700\u65e9\u5230\u6700\u665a\u4f9d\u5e8f\u6392\u5217\uff09\u3002\u82e5\u591a\u7bc7\u6587\u732e\u5728\u540c\u4e00\u5e74\u5185\u53d1\u8868\uff0c\u8bf7\u5728\u5e74\u4efd\u540e\u9762\u52a0\u4e0aa\u3001b\u3001c\u2026\u2026\u7b49\u6807\u6ce8\u3002\uff08\u6309\uff1aabc\u7684\u4f7f\u7528\u9700\u4e0e\u53c2\u8003\u6587\u732e\u90e8\u5206\u6709\u6240\u5bf9\u5e94\uff0c\u800c\u8fd9\u4e9b\u6587\u732e\u7684\u7f16\u6392\u4ee5\u6807\u9898\u540d\u79f0\u7684\u5b57\u6bcd\u6765\u51b3\u5b9a\u3002\uff09\u4f8b\u5982\uff1a</p> <p>A recent study found a possible genetic cause of alcoholism (Pauling, 2004, 2005a, 2005b). Pauling (2004, 2005a, 2005b) conducted a study that discovered a possible genetic cause of alcoholism</p> <p>6.\u591a\u7bc7\u6587\u732e\uff0c\u591a\u4f4d\u4f5c\u8005</p> <p>\u6839\u636e\u4e0a\u4e00\u4e2a\u7684\u89c4\u5219\uff0c\u5e76\u4e14\u4f7f\u7528\u5206\u53f7\u9694\u5f00\u3002\u6392\u5e8f\u5148\u4f9d\u7167\u4f5c\u8005\u59d3\u6c0f\u7684\u5b57\u6bcd\uff0c\u63a5\u7740\u662f\u53d1\u8868\u5e74\u4efd\u3002\u4f8b\u5982\uff1a</p> <p>A recent study found a possible genetic cause of alcoholism (Alford, 1995; Pauling, 2004, 2005; Sirkis, 2003)</p> <p>7.\u76f4\u63a5\u5f15\u8ff0</p> <p>\u683c\u5f0f\u4e0e\u524d\u8ff0\u65e0\u4e0d\u540c\uff0c\u4e00\u6837\u4e3a\u201c\uff08\u4f5c\u8005\uff0c\u5e74\u4efd\uff0c\u9875\u6570\uff09\u201d\u3002\u4f8b\u5982\uff1a</p> <p>When asked why his behavior had changed so dramatically, Max simply said \u201cI think it\u2019s the reinforcement\u201d (Pauling, 2004, p. 69).</p> <p>\u4e8c\u3001\u6587\u672b\u53c2\u8003\u6587\u732e\u5217\u8868\uff08Reference List\uff09</p> <p>\u5728\u53c2\u8003\u6587\u732e\u90e8\u5206\uff0cAPA\u683c\u5f0f\u89c4\u5b9a\u90e8\u5206\u7684\u4eba\u540d\u5fc5\u987b\u4ee5\u59d3\uff08Family name\uff09\u7684\u5b57\u6bcd\u987a\u5e8f\u6765\u6392\u5217\uff0c\u5305\u62ec\u540d\uff08first name\uff09\u7684\u524d\u7f00\u3002</p> <p>1.\u5355\u4e00\u4f5c\u8005\u8457\u4f5c\u7684\u4e66\u7c4d\u3002\u4f8b\u5982\uff1a</p> <p>Sheril, R. D. (1956).\u00a0The terrifying future: Contemplating color television. San Diego: Halstead.</p> <p>2.\u4e24\u4f4d\u4f5c\u8005\u4ee5\u4e0a\u5408\u8457\u7684\u4e66\u7c4d\u3002\u4f8b\u5982\uff1a</p> <p>Smith, J., &amp; Peter, Q. (1992).\u00a0Hairball: An intensive peek behind the surface of an enigma. Hamilton, ON: McMaster University Press.</p> <p>3.\u6587\u96c6\u4e2d\u7684\u6587\u7ae0\u3002\u4f8b\u5982\uff1a</p> <p>Mcdonalds, A. (1993). Practical methods for the apprehension and sustained containment of supernatural entities. In G. L. Yeager (Ed.),\u00a0Paranormal and occult studies: Case studies in application\u00a0(pp. 42\u201364). London: OtherWorld Books.</p> <p>4.\u671f\u520a\u4e2d\u7684\u6587\u7ae0\u3002\u4f8b\u5982\uff1a</p> <p>Crackton, P. (1987). The Loonie: God\u2019s long-awaited gift to colourful pocket change?\u00a0Canadian Change, 64(7), 34\u201337.</p> <p>5.\u6708\u520a\u6742\u5fd7\u4e2d\u7684\u6587\u7ae0\u3002\u4f8b\u5982\uff1a</p> <p>Henry, W. A., III. (1990, April 9). Making the grade in today\u2019s schools.\u00a0Time, 135, 28-31.</p> <p>6.\u62a5\u7eb8\u4e2d\u7684\u6587\u7ae0\u3002\u4f8b\u5982\uff1a</p> <p>Wrong, M. (2005, August 17). Misquotes are \u201cProblematastic\u201d says Mayor.\u00a0Toronto Sol.,\u00a04.</p> <p>7.\u653f\u5e9c\u5b98\u65b9\u6587\u732e</p> <p>Revenue Canada. (2001).\u00a0Advanced gouging: Manual for employees\u00a0(MP 65\u2013347/1124). Ottawa: Minister of Immigration and Revenue.</p> <p>8.\u9488\u5bf9\u7535\u5b50\u6587\u732e\u3001\u7f51\u7ad9\u548c\u7ebf\u4e0a\u6587\u7ae0\uff0cAPA\u683c\u5f0f\u7684\u7f51\u7ad9\u4e0a\u6709\u8ba2\u5b9a\u4e00\u4e9b\u57fa\u672c\u7684\u89c4\u5219\uff0c\u7b2c\u4e00\u5c31\u662f\u63d0\u4f9b\u8bfb\u8005\u8be6\u7ec6\u7684\u6587\u732e\u5185\u5bb9\u6765\u6e90\uff0c\u7b2c\u4e8c\u4e3a\u63d0\u4f9b\u5176\u6709\u6548\u7684\u53c2\u8003\u6765\u6e90\u3002</p> <p>\u2474\u00a0\u7f51\u7edc\u6587\u7ae0\u7684\u6253\u5370\u7248\u672c</p> <p>Marlowe, P., Spade, S., &amp; Chan, C. (2001). Detective work and the benefits of colour versus black and white [Electronic version].Journal of Pointless Research, 11,123\u2013124.</p> <p>\u2475\u00a0\u7535\u5b50\u671f\u520a\u7684\u6587\u7ae0\uff08\u53ea\u6709\u7f51\u7edc\u7248\u7684\u671f\u520a\uff09</p> <p>Blofeld, E. S. (1994, March 1). Expressing oneself through Persian cats and modern architecture.Felines &amp; Felons, 4,Article 0046g. Retrieved October 3, 1999, from\u00a0\u7f51\u9875\u5730\u5740.</p> <p>\u2476\u00a0\u7535\u5b50\u77ed\u4fe1\uff08newsletter\uff09\u7684\u6587\u7ae0</p> <p>Paradise, S., Moriarty, D., Marx, C., Lee, O. B., Hassel, E., et al. (1957, July). Portrayals of fictional characters in reality-based popular writing: Project update.Off the beaten path, 7(3). Retrieved October 3, 1999, from\u00a0\u7f51\u9875\u5730\u5740.</p> <p>\u2477\u00a0\u5355\u7bc7\u7ebf\u4e0a\u6587\u732e\uff08\u65e0\u4f5c\u8005\u53ca\u8457\u4f5c\u65e5\u671f\uff09</p> <p>What I did today.(n.d.). Retrieved August 21, 2002, from\u00a0\u7f51\u9875\u5730\u5740.</p> <p>\u2478\u00a0\u4ece\u5927\u5b66\u8bfe\u7a0b\u6216\u7cfb\u4e0a\u7f51\u7ad9\u53d6\u5f97\u7684\u6587\u732e</p> <p>Rogers, B. (2078).Faster-than-light travel: What we\u2019ve learned in the first twenty years.Retrieved August 24, 2079, from Mars University, Institute for Martian Studies Web site:\u00a0\u7f51\u9875\u5730\u5740.</p> <p>\u2479\u00a0\u4ece\u6570\u636e\u5e93\u641c\u5bfb\u7684\u671f\u520a\u6587\u7ae0\u7684\u7535\u5b50\u590d\u5236\u7248\u672c\uff083\u81f35\u4f4d\u4f5c\u8005\uff09</p> <p>Costanza, G., Seinfeld, J., Benes, E., Kramer, C., &amp; Peterman, J. (1993).\u00a0Minuti\u00e6 and insignificant observations from the nineteen-nineties.Journal about Nothing, 52,475\u2013649. Retrieved October 31, 1999,\u00a0from NoTHINGJournals database.</p> <p>\u247a\u00a0\u7535\u5b50\u90ae\u4ef6\u6216\u5176\u4ed6\u4e2a\u4eba\u901a\u8baf\uff08\u4e0d\u51fa\u73b0\u5728\u53c2\u8003\u6587\u732e\u5217\u8868\u4e2d\uff0c\u4ec5\u5728\u6587\u4e2d\u6807\u51fa\uff09\u3002\u4f8b\u5982\uff1a</p> <p>(A. Monterey, personal communication, September 28, 2001).</p> <p>9.\u50a8\u5b58\u4e8e\u5149\u789f\u7684\u4e66\u7c4d</p> <p>Nix, G. (2002).\u00a0Lirael, Daughter of the Clayr\u00a0[CD].\u00a0New York: Random House/Listening Library.</p> <p>10.\u50a8\u5b58\u4e8e\u5f55\u97f3\u5e26\u7684\u4e66\u7c4d</p> <p>Nix, G. (2002).\u00a0Lirael, Daughter of the Clayr\u00a0[Cassette Recording No. 1999-1999-1999]\u3002New York: Random House/Listening Library.</p> <p>APA\u683c\u5f0f\u8303\u6587\u53ef\u6d4f\u89c8\u7f51\u9875\uff1a</p> <p>MLA Sample Essay</p> <p>\u5176\u8be6\u7ec6\u7684\u4ecb\u7ecd\u53ef\u53c2\u770b\u7f8e\u56fd\u4f5b\u8499\u7279\u5927\u5b66\u56fe\u4e66\u9986\u5927\u536b\u2022W\u2022\u8c6a\u7eaa\u5ff5\u56fe\u4e66\u9986\uff08David W. Howe Memorial Library of THE UNIVERSITY OF VERMONT Libraries\uff09\u7f51\u7ad9\u4e0a\u7684\u201cAPA (American Psychological Association) Style\u201d\u7f51\u9875\uff08\u7f51\u5740\uff1a</p> <p>APA (American Psychological Association) Style | Howe Library</p>"},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/DL%26NLP%20%E5%85%A5%E9%97%A8%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86/","title":"DL&NLP \u5165\u95e8\u8d44\u6e90\u6574\u7406","text":"<p>Machine Learning Theory Google\u7684\u4e00\u4e2a\u6559\u7a0b\uff0c\u91cc\u9762\u7684playground\u505a\u5f97\u6bd4\u8f83\u76f4\u89c2\uff0c\u65e0\u9700\u4ee3\u7801 Machine Learning \u00a0|\u00a0 Google for Developers</p> <p>Machine Learning Technology</p> <p>Deep Learning Theory</p> <p>Deep Learning Technology Pytorch\u6559\u7a0b\uff0c\u53ef\u4ee5\u770b\u7740\u4ee3\u7801\u624b\u6284\u4e00\u4e0b Welcome to PyTorch Tutorials \u2014 PyTorch Tutorials 2.0.1+cu117 documentation</p> <p>numpy: numpy 100 exercise rougier/numpy-100: 100 numpy exercises (with solutions) (github.com)</p> <p>Pytorch PyTorch\u6df1\u5ea6\u5b66\u4e60\u5feb\u901f\u5165\u95e8\u6559\u7a0b\uff08\u7edd\u5bf9\u901a\u4fd7\u6613\u61c2\uff01\uff09\u3010\u5c0f\u571f\u5806\u3011_\u54d4\u54e9\u54d4\u54e9_bilibili</p> <p>Attention-based Models and Transformer Let's build GPT: from scratch, in code, spelled out. - YouTube</p> <p>Natural Language Processing Theory Stanford CS224N: NLP with Deep Learning | Winter 2021 | Lecture 1 - Intro &amp; Word Vectors - YouTube</p> <p>natural language processing technology Stanford CS 224N | Natural Language Processing with Deep Learning</p> <p>Reinforcement Learning \u8611\u83c7\u4e66EasyRL (datawhalechina.github.io) Codes: boyu-ai/Hands-on-RL: https://hrl.boyuai.com/ (github.com) datawhalechina/easy-rl: \u5f3a\u5316\u5b66\u4e60\u4e2d\u6587\u6559\u7a0b\uff08\u8611\u83c7\u4e66\uff09\uff0c\u5728\u7ebf\u9605\u8bfb\u5730\u5740\uff1ahttps://datawhalechina.github.io/easy-rl/</p> <p>Computer Vision Computer Vision | Universit\u00e4t T\u00fcbingen (uni-tuebingen.de)</p>"},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/Notion%E5%92%8CObsidian%EF%BC%8C%E9%80%89%E5%93%AA%E4%B8%80%E4%B8%AA/","title":"Notion vs. Obsidian","text":"<p>\u5148\u5199\u4e00\u4e2a\u7b80\u5355\u7684\u7ed3\u8bba</p> \u4f18\u70b9/\u5de5\u5177 Notion Obsidian \u8bed\u6cd5 \u81ea\u5df1\u7684\u4e00\u5957\u8bed\u6cd5\uff0c\u90e8\u5206\u662fmarkdown \u7eafmarkdown \u4e66\u5199\u901f\u5ea6 \u6162 \u5feb \u6587\u6863\u6574\u9f50\u7a0b\u5ea6 \u9ad8 \u4f4e \u90e8\u7f72\u5230mkdocs\u96be\u6613 \u6613\uff0c\u53ef\u76f4\u63a5\u7528 \u96be\uff0c\u9700\u8c03\u6574\u5f88\u591a\u683c\u5f0f \u5bfc\u51fa\u4e2d\u6587\u652f\u6301\u7a0b\u5ea6 \u53ea\u6709\u4e09\u79cd\u5b57\u4f53\uff0c\u90e8\u5206\u4e2d\u6587\u7f3a\u5b57 \u5b57\u4f53\u591a\uff0c\u652f\u6301\u6bd4\u8f83\u597d <p>\u76ee\u524d\u6211\u9009\u62e9\u7684workflow</p> <pre><code>graph TD\n    \u542c\u5199 --&gt; Notion \n    Notion -- \u6709\u65f6\u95f4 --&gt; Obsidian\n    \u6709\u65f6\u95f4\u6162\u6162\u5199 --&gt; Obsidian\n    Obsidian -- \u4f7f\u7528\u540c\u4e00\u6587\u4ef6\u5939 --&gt; mkdocs\n\n</code></pre> <p>Obsidian to mkdocs 1. \u56fe\u7247\u8def\u5f84\u95ee\u9898\uff1a     \u9700\u8981\u5728\u8bbe\u7f6e\u4e2d\u5173\u95ed\u4f7f\u7528wiki\u8def\u5f84\uff0c\u4fdd\u8bc1\u6240\u6709\u56fe\u7247\u90fd\u7528md\u8bed\u6cd5<code>![]()</code>     \u4e14\u9700\u8981\u4f7f\u7528\u76f8\u5bf9\u8def\u5f84\uff0c\u5373\u524d\u9762\u52a0<code>./</code>\u7684\u90a3\u79cd</p>"},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/ZOTERO%20%E7%AE%80%E4%BB%8B%E5%8F%8A%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/","title":"ZOTERO\u7b80\u4ecb","text":""},{"location":"%E7%9E%8E%E8%AF%B4%E4%B8%80%E4%BA%9B%E4%B8%9C%E8%A5%BF/%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7/","title":"\u4e8c\u7ef4\u7801\u751f\u6210\u5668","text":"<p>\u751f\u6210\u957f\u5f97\u4e0d\u50cf\u4e8c\u7ef4\u7801\u7684\u4e8c\u7ef4\u7801 \u76f4\u63a5\u626b\u4e0b\u9762\u7684\u4e8c\u7ef4\u7801\u53ef\u4ee5\u8fdb\u5165\u7f51\u7ad9 </p>"}]}